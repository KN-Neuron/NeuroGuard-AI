{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ad524af1318f5c5",
   "metadata": {},
   "source": [
    "# Model training notebook\n",
    "\n",
    "This notebook is made for training the TDNN models from XVector.py module\n",
    "\n",
    "In this notebook we carry out the grid search over the model's hyperparameters defined in grid dictionary and save the results as tensorboard runs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "116f9ce1f591a47f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T19:56:36.888295Z",
     "start_time": "2025-11-12T19:56:36.834581Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T19:56:37.015747Z",
     "start_time": "2025-11-12T19:56:36.961766Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from eeg_lib.utils.helpers import get_device\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Number of GPU: \", torch.cuda.device_count())\n",
    "    print(\"GPU Name: \", torch.cuda.get_device_name())\n",
    "\n",
    "\n",
    "device = get_device()\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22e4f474ae7ddca0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T19:56:37.056989Z",
     "start_time": "2025-11-12T19:56:37.015747Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mne\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "babb7c7beaf4d783",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T19:56:37.096759Z",
     "start_time": "2025-11-12T19:56:37.056989Z"
    }
   },
   "outputs": [],
   "source": [
    "from eeg_lib.commons.constant import DATASETS_FOLDER\n",
    "from eeg_lib.data.data_loader.EEGDataExtractor import EEGDataExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69692076fda27c34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T19:56:37.141792Z",
     "start_time": "2025-11-12T19:56:37.096759Z"
    }
   },
   "outputs": [],
   "source": [
    "from eeg_lib.utils.engine import create_user_profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2534b26b03a8a66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T19:56:37.183918Z",
     "start_time": "2025-11-12T19:56:37.141792Z"
    }
   },
   "outputs": [],
   "source": [
    "from eeg_lib.utils.helpers import compute_genuine_imposter_distances, compute_threshold_metrics, compute_f1_vs_threshold, split_test_data_for_verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34ce0cc0bf21cec9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T19:56:37.225994Z",
     "start_time": "2025-11-12T19:56:37.185846Z"
    }
   },
   "outputs": [],
   "source": [
    "from eeg_lib.utils.visualisations import plot_distance_distribution_on_ax, plot_threshold_metrics, plot_f1_vs_threshold, plot_distance_distribution_return, plot_f1_vs_threshold_return, plot_threshold_metrics_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbde9b5925b39a40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T19:56:42.690735Z",
     "start_time": "2025-11-12T19:56:37.225994Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_DIR = f\"{DATASETS_FOLDER}/Kolory/\"\n",
    "\n",
    "extractor = EEGDataExtractor(data_dir=DATA_DIR, tmax=5.0, lfreq=7.0, tmin=-2.0)\n",
    "eeg_df, participants_info = extractor.extract_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60f917fe666631fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T19:56:42.729588Z",
     "start_time": "2025-11-12T19:56:42.690735Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1eeda5cc203a259c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T19:56:42.768827Z",
     "start_time": "2025-11-12T19:56:42.730594Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid, GroupKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57e978badd2e2c0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T19:56:42.809276Z",
     "start_time": "2025-11-12T19:56:42.768827Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "219b143d814250b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T19:56:42.848524Z",
     "start_time": "2025-11-12T19:56:42.809276Z"
    }
   },
   "outputs": [],
   "source": [
    "from eeg_lib.data.data_loader.TDNNFeatures import extract_features, extract_psd_features\n",
    "from eeg_lib.data.TDNNDataset import TDNNDataset, get_dataset\n",
    "from eeg_lib.models.verification.XVector import XVectorEmbeddingModel\n",
    "from eeg_lib.losses.ProxyNCALoss import ProxyNCALoss\n",
    "from eeg_lib.utils.visualisations import plot_tsne\n",
    "from eeg_lib.utils.visualisations import create_handles\n",
    "from eeg_lib.utils.helpers import split_train_test\n",
    "from eeg_lib.models.similarity.centroids import SimilarityCentroidsVerifier, get_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17fe7ddd55e71204",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T19:56:42.891132Z",
     "start_time": "2025-11-12T19:56:42.849531Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6140e0550eb827",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T19:56:42.929399Z",
     "start_time": "2025-11-12T19:56:42.892138Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR, ExponentialLR, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1498a40906ff79ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T19:56:42.967949Z",
     "start_time": "2025-11-12T19:56:42.930452Z"
    }
   },
   "outputs": [],
   "source": [
    "from eeg_lib.models.verification.XVector import get_ecapa_model, get_standard_model, pretrain, fine_tune, create_embeddings, fine_tune_arcface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820cdf7263adf281",
   "metadata": {},
   "source": [
    "grid with defined available hyperparameters for the TDNN model (ECAPA_TDNNv2 in particular)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d88580b0a1d8925",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T19:56:43.007225Z",
     "start_time": "2025-11-12T19:56:42.967949Z"
    }
   },
   "outputs": [],
   "source": [
    "K = 2\n",
    "RUNS_FOLDER = \"runs_ECAPA\"\n",
    "APPENDIX = \"ECAPAv8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "958c3afa40d4faaf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T19:56:43.047236Z",
     "start_time": "2025-11-12T19:56:43.007225Z"
    }
   },
   "outputs": [],
   "source": [
    "grid = {\n",
    "    \"batch_size\" : [64],\n",
    "    \"softmax_learning_rate\" : [0.001],\n",
    "    \"proxy_learning_rate\" : [0.001],\n",
    "    \"softmax_epochs\" : [20],\n",
    "    \"proxy_epochs\" : [80],\n",
    "    \"softmax_learning_rate_decay\" : [0.95],\n",
    "    \"proxy_learning_rate_decay\" : [0.95],\n",
    "    \"augmentation\" : [True],\n",
    "    \"std\" : [0.02],\n",
    "    \"embedding_dim\" : [256],\n",
    "    \"dropout_rate\" : [0.25],\n",
    "    \"scale\" : [10],\n",
    "    \"margin\" : [0.1],\n",
    "    \"layer1_filters\" : [512],\n",
    "    \"layer2_filters\" : [512],\n",
    "    \"layer3_filters\" : [1024],\n",
    "    \"layer4_filters\" : [1024],\n",
    "    \"layer5_filters\" : [1500],\n",
    "    \"layer_1_dilatation\" : [1],\n",
    "    \"layer_2_dilatation\" : [2],\n",
    "    \"layer_3_dilatation\" : [3],\n",
    "    \"layer_1_stride\" : [1],\n",
    "    \"layer_2_stride\" : [1],\n",
    "    \"layer_3_stride\" : [2],\n",
    "    \"no_norm\" : [True]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b021284f5bf66dc",
   "metadata": {},
   "source": [
    "Data loading and preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "565ebcc4f04a6dba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T19:56:43.127832Z",
     "start_time": "2025-11-12T19:56:43.049242Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set participants: ['022e8467@1910' 'fd8a3308@1135' '39285860@1825' '25d0bdb3@1318'\n",
      " 'd87e1bd3@1806' '54e60118@1339' '548fd734@1628' 'bf2d2193@1638'\n",
      " 'e08138e2@1731' '011595b1@1651' '06f240e9@1215' 'f82b5699@1757'\n",
      " 'e43a9f9f@0941' '8dca0725@1418' '2882ae26@1441' '6e542bc2@0845'\n",
      " 'e283301e@1606' '51ec2c20@0923' '446b3735@1618' '8bd3032e@1746'\n",
      " 'ffae50df@1712' '9e8bae0e@1828' '541c91f2@1456' 'b34b1427@0906'\n",
      " '3033b74a@1626' '90441f44@1643' '6d9a8b86@1613']\n",
      "Test set participants: ['36eea4bb@1519' '46607ce4@1717' '2718372d@1400']\n",
      "Training labels: ['011595b1@1651' '022e8467@1910' '06f240e9@1215' '25d0bdb3@1318'\n",
      " '2882ae26@1441' '3033b74a@1626' '39285860@1825' '446b3735@1618'\n",
      " '51ec2c20@0923' '541c91f2@1456' '548fd734@1628' '54e60118@1339'\n",
      " '6d9a8b86@1613' '6e542bc2@0845' '8bd3032e@1746' '8dca0725@1418'\n",
      " '90441f44@1643' '9e8bae0e@1828' 'b34b1427@0906' 'bf2d2193@1638'\n",
      " 'd87e1bd3@1806' 'e08138e2@1731' 'e283301e@1606' 'e43a9f9f@0941'\n",
      " 'f82b5699@1757' 'fd8a3308@1135' 'ffae50df@1712']\n",
      "Test labels: ['2718372d@1400' '36eea4bb@1519' '46607ce4@1717']\n"
     ]
    }
   ],
   "source": [
    "X_train_tmp, X_test_tmp, y_train_tmp, y_test_tmp = split_train_test(eeg_df=eeg_df,test_size=0.1, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6ab2f2431510fd0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T19:56:43.165525Z",
     "start_time": "2025-11-12T19:56:43.127832Z"
    }
   },
   "outputs": [],
   "source": [
    "epoch_length = X_train_tmp[0].shape[1]\n",
    "div, mod = divmod(epoch_length, 50)\n",
    "truncated_length = div*50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9097a7d358bcb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T19:59:30.260999Z",
     "start_time": "2025-11-12T19:56:43.165525Z"
    }
   },
   "outputs": [],
   "source": [
    "extracted_X_train = []\n",
    "for epoch in X_train_tmp:\n",
    "    extracted_X_train.append(extract_features(epoch, fs=250, trunc=truncated_length).T) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2bcc1469ba530538",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T19:59:55.329992Z",
     "start_time": "2025-11-12T19:59:30.262003Z"
    }
   },
   "outputs": [],
   "source": [
    "extracted_X_test = []\n",
    "for epoch in X_test_tmp:\n",
    "    extracted_X_test.append(extract_features(epoch, fs=250, trunc=truncated_length).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6d471e0212a57528",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T19:59:55.372207Z",
     "start_time": "2025-11-12T19:59:55.329992Z"
    }
   },
   "outputs": [],
   "source": [
    "le_train = LabelEncoder()\n",
    "le_train.fit(y_train_tmp)\n",
    "y_train_encoded = le_train.transform(y_train_tmp)\n",
    "\n",
    "le_test = LabelEncoder()\n",
    "le_test.fit(y_test_tmp)\n",
    "y_test_encoded = le_test.transform(y_test_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c5a9064d27cc60f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T19:59:55.443228Z",
     "start_time": "2025-11-12T19:59:55.372207Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = np.array(extracted_X_train)\n",
    "X_test = np.array(extracted_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3f0aec6c46925d0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T19:59:55.487010Z",
     "start_time": "2025-11-12T19:59:55.443228Z"
    }
   },
   "outputs": [],
   "source": [
    "scalers = {}\n",
    "X_train_norm = np.empty_like(X_train)\n",
    "X_test_norm = np.empty_like(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "29d653fd7246c9b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T19:59:55.699160Z",
     "start_time": "2025-11-12T19:59:55.487010Z"
    }
   },
   "outputs": [],
   "source": [
    "# scaling per feature\n",
    "for f in range(X_train.shape[1]):\n",
    "    scalers[f] = StandardScaler().fit(X_train[:, f, :])\n",
    "    X_train_norm[:, f,:] = scalers[f].transform(X_train[:, f, :])\n",
    "    X_test_norm[:, f, :] = scalers[f].transform(X_test[:, f, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ba1e84dfe851a994",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T19:59:55.782913Z",
     "start_time": "2025-11-12T19:59:55.699160Z"
    }
   },
   "outputs": [],
   "source": [
    "num_train_classes = len(np.unique(y_train_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bf71525aad12a787",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T19:59:55.841761Z",
     "start_time": "2025-11-12T19:59:55.782913Z"
    }
   },
   "outputs": [],
   "source": [
    "groups = np.array(y_train_encoded)\n",
    "X = X_train_norm\n",
    "y = np.array(y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "172874a89e844ed7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T19:59:55.884554Z",
     "start_time": "2025-11-12T19:59:55.842767Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_loader_from_indecies(X_arr,y_arr, indicies, hparams):\n",
    "    X_sub = X_arr[indicies]\n",
    "    y_sub = y_arr[indicies]\n",
    "    loader = get_dataset(hparams, X_sub, y_sub)\n",
    "    return loader, X_sub, y_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f61da3d391c79cf8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T19:59:55.923616Z",
     "start_time": "2025-11-12T19:59:55.884554Z"
    }
   },
   "outputs": [],
   "source": [
    "splitter = GroupKFold(n_splits=K)\n",
    "splits = splitter.split(X,y,groups=groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "53ea73cbb5a0e0fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T19:59:55.964187Z",
     "start_time": "2025-11-12T19:59:55.924628Z"
    }
   },
   "outputs": [],
   "source": [
    "custom_colors = ['#e6194b', '#3cb44b', '#ffe119', '#4363d8', '#f58231', '#911eb4',\n",
    "                 '#46f0f0', '#f032e6', '#bcf60c', '#fabebe', '#008080', '#e6beff',\n",
    "                 '#9a6324', '#fffac8', '#800000', '#aaffc3', '#808000', '#ffd8b1',\n",
    "                 '#000075', '#808080', '#ffffff', '#000000', '#a9a9a9', '#ff69b4',\n",
    "                 '#b0e0e6', '#32cd32', '#ff4500', '#da70d6', '#ff1493', '#7fffd4']\n",
    "cmap = ListedColormap(custom_colors[:30])\n",
    "\n",
    "custom_colors = ['#e6194b',  # Red\n",
    "                 '#3cb44b',  # Green\n",
    "                 '#4363d8',  # Blue\n",
    "                 '#ffe119',  # Yellow\n",
    "                 '#911eb4',  # Purple\n",
    "                 '#f58231']  # Orange\n",
    "\n",
    "cmap2 = ListedColormap(custom_colors[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a45c9f760d0f371",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T19:59:56.009078Z",
     "start_time": "2025-11-12T19:59:55.964187Z"
    }
   },
   "outputs": [],
   "source": [
    "train_handles = create_handles(y_train_tmp, cmap)\n",
    "test_handles = create_handles(y_test_tmp, cmap2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6667079522c94da7",
   "metadata": {},
   "source": [
    "In the tensorboard run we save:\n",
    "\n",
    "- pretaraining loss\n",
    "- pretraining accuracy\n",
    "- finetuning loss\n",
    "- centroid based accuracy metric for train and test data\n",
    "- test and train TSNE figures\n",
    "- genuine vs imposter plots for both cosine and euclidean distances train and test\n",
    "- threshold values, f1 score at threshold, accuracy at threshold, for cosine, euclidean metrics, train and test data\n",
    "- plots for f1 vs threshold\n",
    "- plots for accuracy vs threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b554658bc291752",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T19:59:56.047935Z",
     "start_time": "2025-11-12T19:59:56.010083Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f3dbec981baec6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T20:16:08.038343Z",
     "start_time": "2025-11-12T19:59:56.047935Z"
    }
   },
   "outputs": [],
   "source": [
    "for run_idx, hparams in enumerate(ParameterGrid(grid), start=1):\n",
    "    print(\"RUN NUMBER: {}\".format(run_idx))\n",
    "    run_name = f\"run_{run_idx}\"\n",
    "    writer = SummaryWriter(log_dir=f\"{RUNS_FOLDER}/{run_name}_{APPENDIX}\")\n",
    "    # print(hparams)\n",
    "    writer.add_hparams(hparams, {})\n",
    "    \n",
    "    avg_fold_acc = 0\n",
    "    avg_fold_f1 = 0\n",
    "    fold_idx = 0\n",
    "    for train_idx, val_idx in splits:\n",
    "        fold_idx += 1\n",
    "        print(f\"FOLD: {fold_idx}\")\n",
    "    \n",
    "        _, X_tr_sub, y_tr_sub = make_loader_from_indecies(X, y, train_idx, hparams) \n",
    "        _, X_val_sub, y_val_sub = make_loader_from_indecies(X,y,val_idx,hparams)\n",
    "        \n",
    "        # print(\"unique labels in train:\", np.unique(y_tr_sub)[:10], \"n_unique:\", len(np.unique(y_tr_sub)))\n",
    "        # print(\"label max:\", y_tr_sub.max(), \"expected max:\", len(np.unique(y_tr_sub))-1)\n",
    "        \n",
    "        unique_train = np.unique(y_tr_sub)\n",
    "        train_label_map = {old:new for new, old in enumerate(unique_train)}\n",
    "        y_tr_mapped = np.array([train_label_map[x] for x in y_tr_sub], dtype=int)\n",
    "        num_classes_fold =len(unique_train)\n",
    "        \n",
    "        train_loader = get_dataset(hparams, X_tr_sub, y_tr_mapped)\n",
    "        val_loader = get_dataset(hparams, X_val_sub, y_val_sub)\n",
    "        \n",
    "        # Sanity-check: labels in the train loader must be within [0, num_classes_fold-1]\n",
    "        # for bx, by in train_loader:\n",
    "        #     print(\"train batch labels min,max:\", by.min().item(), by.max().item())\n",
    "        #     assert by.min().item() >= 0 and by.max().item() < num_classes_fold, \"Mapped labels out of range!\"\n",
    "        #     break\n",
    "        \n",
    "        model = pretrain(hparams, device, X_tr_sub.shape[1], len(np.unique(y_tr_sub)), train_loader, writer, \"ECAPA2\", fold_idx).to(device)\n",
    "        model = fine_tune_arcface(model, hparams, device, train_loader, len(np.unique(y_tr_sub)), writer, fold=fold_idx).to(device)\n",
    "    \n",
    "    # checkpoint = {\n",
    "    #     \"model_state_dict\": model.state_dict()\n",
    "    # }\n",
    "    # torch.save(checkpoint, \"saved_models/ECAPA2/init_model_for_featuregrid.pth\")\n",
    "        model.to('cpu')\n",
    "        embd_train, embd_val = create_embeddings(model, X_tr_sub, X_val_sub,hparams)\n",
    "    \n",
    "        centroid_train_acc, centroid_val_acc = get_accuracy(embd_train, embd_val, y_tr_sub, y_val_sub)\n",
    "    \n",
    "        writer.add_scalar(f\"Final_Centroid_Accuracy_fold_{fold_idx}/train\", centroid_train_acc)\n",
    "        writer.add_scalar(f\"Final_Centroid_Accuracy_fold_{fold_idx}/val\", centroid_val_acc)\n",
    "    \n",
    "        tsne_train = TSNE(n_components=2, random_state=42).fit_transform(embd_train)\n",
    "        tsne_val = TSNE(n_components=2, random_state=42).fit_transform(embd_val)\n",
    "    \n",
    "        scaler = MinMaxScaler(feature_range=(0,1))\n",
    "        tsne_train_scaled = scaler.fit_transform(tsne_train)\n",
    "        tsne_val_scaled = scaler.transform(tsne_val)\n",
    "        \n",
    "        uniq_train, inv_train = np.unique(y_tr_sub, return_inverse=True)\n",
    "        uniq_val,   inv_val   = np.unique(y_val_sub, return_inverse=True)\n",
    "        \n",
    "        C_train = len(uniq_train)\n",
    "        C_val   = len(uniq_val)\n",
    "        \n",
    "        cmap_train = cm.get_cmap('tab20', C_train) if C_train <= 20 else cm.get_cmap('hsv', C_train)\n",
    "        cmap_val   = cm.get_cmap('tab20', C_val)   if C_val   <= 20 else cm.get_cmap('hsv', C_val)\n",
    "        \n",
    "        train_patches = [mpatches.Patch(color=cmap_train(i), label=str(uniq_train[i])) for i in range(C_train)]\n",
    "        val_patches   = [mpatches.Patch(color=cmap_val(i),   label=str(uniq_val[i]))   for i in range(C_val)]\n",
    "        \n",
    "    \n",
    "        fig_train = plot_tsne(tsne_train_scaled,\n",
    "              cmap_train,\n",
    "              inv_train,\n",
    "              handles=train_patches,\n",
    "              alpha=0.5,\n",
    "              title=\"TSNE Visualization training data XVector\",\n",
    "              xlabel=\"TSNE embedding dimension 1\",\n",
    "              ylabel=\"TSNE embedding dimension 2\",\n",
    "              centroids=None,\n",
    "              return_fig=True)\n",
    "    # plt.show(fig_train)\n",
    "        writer.add_figure(f\"tsne_train_fold_{fold_idx}\", fig_train)\n",
    "        fig_val = plot_tsne(tsne_val_scaled,\n",
    "              cmap_val,\n",
    "              inv_val,\n",
    "              handles=val_patches,\n",
    "              alpha=0.5,\n",
    "              title=\"TSNE Visualization test data XVector\",\n",
    "              xlabel=\"TSNE embedding dimension 1\",\n",
    "              ylabel=\"TSNE embedding dimension 2\",\n",
    "              centroids=None, return_fig=True )\n",
    "        # plt.show(fig_test)\n",
    "        embd_unit = embd_train / np.linalg.norm(embd_train, axis=1, keepdims=True)\n",
    "        writer.add_figure(f\"tsne_val_fold_{fold_idx}\", fig_val)\n",
    "    \n",
    "        fig = plot_distance_distribution_return(\n",
    "            embeddings=embd_unit,\n",
    "            participant_ids=y_tr_sub,\n",
    "            distance_type=\"euclidean\",\n",
    "            bins=30\n",
    "        )\n",
    "    # plt.show(fig)\n",
    "        writer.add_figure(f\"distance_distribution_euclidean_fold_{fold_idx}\", fig)\n",
    "    \n",
    "        fig = plot_distance_distribution_return(\n",
    "            embeddings=embd_train,\n",
    "            participant_ids=y_tr_sub,\n",
    "            distance_type=\"cosine\",\n",
    "            bins=30\n",
    "        )\n",
    "    # plt.show(fig)\n",
    "        writer.add_figure(\"distance_distribution_cosine\", fig)\n",
    "    \n",
    "        # train\n",
    "        user_profiles = create_user_profiles(embd_train, y_tr_sub)\n",
    "        for metric in (\"euclidean\", \"cosine\"):\n",
    "            genuine_dists, imposter_dists = compute_genuine_imposter_distances(\n",
    "                    embeddings=embd_train ,\n",
    "                    ids=y_tr_sub,\n",
    "                    user_profiles=user_profiles,\n",
    "                    distance_metric=metric\n",
    "                )\n",
    "            \n",
    "            (\n",
    "                thresholds, fnr_list, fpr_list, acc_list,\n",
    "                best_T, best_fnr, best_fpr, best_acc\n",
    "            ) = compute_threshold_metrics(genuine_dists, imposter_dists, num_thresholds=200)\n",
    "            \n",
    "            writer.add_scalar(f\"{metric}_best_threshold_train_fold_{fold_idx}\", best_T)\n",
    "            writer.add_scalar(f\"{metric}_best_acc_train_fold_{fold_idx}\", best_acc)\n",
    "            writer.add_scalar(f\"{metric}_FNR/FPR_threshold_train_fold_{fold_idx}\", best_fnr)\n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "            fig = plot_threshold_metrics_return(\n",
    "                thresholds, fnr_list, fpr_list, acc_list,\n",
    "                best_T, best_fnr, best_fpr, best_acc\n",
    "            )\n",
    "            # plt.show(fig)\n",
    "            writer.add_figure(f\"threshold_metrics_train_{metric}_fold_{fold_idx}\", fig)\n",
    "            \n",
    "            thresholds, f1_list, best_T, best_f1 = compute_f1_vs_threshold(\n",
    "                genuine_dists, imposter_dists, num_thresholds=300\n",
    "            )\n",
    "            writer.add_scalar(f\"{metric}_best_f1_train_fold_{fold_idx}\", best_f1)\n",
    "            \n",
    "\n",
    "            \n",
    "            fig = plot_f1_vs_threshold_return(thresholds, f1_list, best_T, best_f1)\n",
    "            writer.add_figure(f\"f1_vs_threshold_train_{metric}_fold_{fold_idx}\", fig)\n",
    "            # plt.show(fig)\n",
    "    \n",
    "\n",
    "        # vaL\n",
    "        profile_embd, profile_ids, verify_embd, verify_ids = split_test_data_for_verification(\n",
    "            embd_val, y_val_sub, profile_ratio=0.6\n",
    "        )\n",
    "        \n",
    "        val_user_profiles = create_user_profiles(profile_embd, profile_ids)\n",
    "        for metric in (\"euclidean\", \"cosine\"):\n",
    "        \n",
    "            genuine_dists, imposter_dists = compute_genuine_imposter_distances(\n",
    "                embeddings=verify_embd,\n",
    "                ids=verify_ids,\n",
    "                user_profiles=val_user_profiles,\n",
    "                distance_metric=metric\n",
    "            )\n",
    "            \n",
    "            (\n",
    "                test_thresholds, test_fnr_list, test_fpr_list, test_acc_list,\n",
    "                test_best_T, test_best_fnr, test_best_fpr, test_best_acc\n",
    "            ) = compute_threshold_metrics(genuine_dists, imposter_dists, num_thresholds=200)\n",
    "            writer.add_scalar(f\"{metric}_best_threshold_val_fold_{fold_idx}\", test_best_T)\n",
    "            writer.add_scalar(f\"{metric}_best_acc_val_fold_{fold_idx}\", test_best_acc)\n",
    "            writer.add_scalar(f\"{metric}_FNR/FPR_th0reshold_val_fold_{fold_idx}\", test_best_fnr)\n",
    "            \n",
    "            \n",
    "            if metric == \"cosine\":\n",
    "                avg_fold_acc += test_best_acc\n",
    "            \n",
    "            fig = plot_threshold_metrics_return(\n",
    "                test_thresholds, test_fnr_list, test_fpr_list, test_acc_list,\n",
    "                test_best_T, test_best_fnr, test_best_fpr, test_best_acc\n",
    "            )\n",
    "            # plt.show(fig)\n",
    "            writer.add_figure(f\"threshold_metrics_{metric}_val_fold_{fold_idx}\", fig)\n",
    "            \n",
    "            test_thresholds_f1, test_f1_list, test_best_T_f1, test_best_f1 = compute_f1_vs_threshold(\n",
    "                genuine_dists, imposter_dists, num_thresholds=300\n",
    "            )\n",
    "            writer.add_scalar(f\"{metric}_best_f1_val_fold_{fold_idx}\", test_best_f1)\n",
    "            \n",
    "            if metric == \"cosine\":\n",
    "                avg_fold_f1 += test_best_f1\n",
    "            \n",
    "            fig = plot_f1_vs_threshold_return(test_thresholds_f1, test_f1_list, test_best_T_f1, test_best_f1)\n",
    "            # plt.show(fig)\n",
    "            writer.add_figure(f\"f1_vs_threshold_val_{metric}_fold_{fold_idx}\", fig)\n",
    "    avg_fold_acc = avg_fold_acc / fold_idx\n",
    "    avg_fold_f1 = avg_fold_f1 / fold_idx\n",
    "    writer.add_scalar(\"Average Fold Accuracy cosine\", avg_fold_acc)\n",
    "    writer.add_scalar(\"Average Fold F1 cosine\", avg_fold_f1)\n",
    "    writer.close()                                                                                    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
