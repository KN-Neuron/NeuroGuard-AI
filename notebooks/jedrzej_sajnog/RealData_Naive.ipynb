{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Notebook\n",
    "Naive approach to the real data, the exact same as \"Kolory\" dataset just training the model on real data one epoch at a time, no epoch concatenation, no information about event. Just the eeg signal."
   ],
   "id": "ad01599d07f1831b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T07:38:16.141515Z",
     "start_time": "2025-08-26T07:38:16.068501Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "6eac488a334ca1db",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T07:38:19.076810Z",
     "start_time": "2025-08-26T07:38:16.142528Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "print(\"Number of GPU: \", torch.cuda.device_count())\n",
    "print(\"GPU Name: \", torch.cuda.get_device_name())\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ],
   "id": "aabd87ca3398faf3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPU:  1\n",
      "GPU Name:  NVIDIA GeForce RTX 2060\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T07:38:20.261549Z",
     "start_time": "2025-08-26T07:38:19.078323Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mne\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "c1ca1173d373a002",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T07:38:20.296261Z",
     "start_time": "2025-08-26T07:38:20.262600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from eeg_lib.commons.constant import DATASETS_FOLDER\n",
    "from eeg_lib.data.data_loader.EEGDataExtractor import EEGDataExtractor"
   ],
   "id": "e2b9831ed78bb082",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T07:38:21.422732Z",
     "start_time": "2025-08-26T07:38:20.297792Z"
    }
   },
   "cell_type": "code",
   "source": "from eeg_lib.utils.engine import create_user_profiles",
   "id": "9dcec22cb9bdc9ab",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T07:38:21.464098Z",
     "start_time": "2025-08-26T07:38:21.423768Z"
    }
   },
   "cell_type": "code",
   "source": "from eeg_lib.utils.helpers import compute_genuine_imposter_distances, compute_threshold_metrics, compute_f1_vs_threshold, split_test_data_for_verification",
   "id": "bd8712548f604c5b",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T07:38:21.506558Z",
     "start_time": "2025-08-26T07:38:21.465302Z"
    }
   },
   "cell_type": "code",
   "source": "from eeg_lib.utils.visualisations import plot_distance_distribution_on_ax, plot_threshold_metrics, plot_f1_vs_threshold, plot_distance_distribution_return, plot_f1_vs_threshold_return, plot_threshold_metrics_return",
   "id": "af48e9df967cc12f",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "DATA_DIR = f\"{DATASETS_FOLDER}/Real/\"\n",
    "\n",
    "extractor = EEGDataExtractor(data_dir=DATA_DIR, lfreq=7.0)\n",
    "eeg_df, participants_info = extractor.extract_dataframe()"
   ],
   "id": "f5cad960bdc883a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T07:38:22.969972Z",
     "start_time": "2025-08-26T07:38:22.927702Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from matplotlib.colors import ListedColormap"
   ],
   "id": "b8ae5535fa90a95e",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T07:38:23.011604Z",
     "start_time": "2025-08-26T07:38:22.970478Z"
    }
   },
   "cell_type": "code",
   "source": "from sklearn.model_selection import ParameterGrid, GroupKFold",
   "id": "e1fce67b05707a8d",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T07:38:23.052431Z",
     "start_time": "2025-08-26T07:38:23.012611Z"
    }
   },
   "cell_type": "code",
   "source": "import torch.nn as nn",
   "id": "a0bf02fc367f02f4",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T07:38:23.110353Z",
     "start_time": "2025-08-26T07:38:23.053436Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from eeg_lib.data.data_loader.TDNNFeatures import extract_features, extract_psd_features\n",
    "from eeg_lib.data.TDNNDataset import TDNNDataset, get_dataset\n",
    "from eeg_lib.models.verification.XVector import XVectorEmbeddingModel\n",
    "from eeg_lib.losses.ProxyNCALoss import ProxyNCALoss\n",
    "from eeg_lib.utils.visualisations import plot_tsne\n",
    "from eeg_lib.utils.visualisations import create_handles\n",
    "from eeg_lib.utils.helpers import split_train_test\n",
    "from eeg_lib.models.similarity.centroids import SimilarityCentroidsVerifier, get_accuracy"
   ],
   "id": "76d1bba62b1d1763",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T07:38:23.152487Z",
     "start_time": "2025-08-26T07:38:23.111489Z"
    }
   },
   "cell_type": "code",
   "source": "from torch.utils.tensorboard import SummaryWriter",
   "id": "c77dfede8aeb5e94",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T07:38:23.196083Z",
     "start_time": "2025-08-26T07:38:23.154495Z"
    }
   },
   "cell_type": "code",
   "source": "from torch.optim.lr_scheduler import StepLR, ExponentialLR, ReduceLROnPlateau",
   "id": "1cb9a19607a2c77b",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T07:38:23.238026Z",
     "start_time": "2025-08-26T07:38:23.196591Z"
    }
   },
   "cell_type": "code",
   "source": "from eeg_lib.models.verification.XVector import get_ecapa_model, get_standard_model, pretrain, fine_tune, create_embeddings, fine_tune_arcface",
   "id": "7c5be7375e1651cf",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T07:38:23.281084Z",
     "start_time": "2025-08-26T07:38:23.239033Z"
    }
   },
   "cell_type": "code",
   "source": [
    "K = 5\n",
    "RUNS_FOLDER = \"runs_ECAPA_real\"\n",
    "APPENDIX = \"ECAPAv0\"\n",
    "grid = {\n",
    "    \"batch_size\": [64],\n",
    "    \"softmax_learning_rate\": [0.001],\n",
    "    \"proxy_learning_rate\": [0.001],\n",
    "    \"softmax_epochs\": [10],\n",
    "    \"proxy_epochs\": [10],\n",
    "    \"softmax_learning_rate_decay\": [0.95],\n",
    "    \"proxy_learning_rate_decay\": [0.95],\n",
    "    \"augmentation\": [True],\n",
    "    \"std\": [0.02],\n",
    "    \"embedding_dim\": [256],\n",
    "    \"dropout_rate\": [0.25],\n",
    "    \"scale\": [10],\n",
    "    \"margin\": [0.1],\n",
    "    \"layer1_filters\": [512],\n",
    "    \"layer2_filters\": [512],\n",
    "    \"layer3_filters\": [1024],\n",
    "    \"layer4_filters\": [1024],\n",
    "    \"layer5_filters\": [1500],\n",
    "    \"layer_1_dilatation\": [1],\n",
    "    \"layer_2_dilatation\": [2],\n",
    "    \"layer_3_dilatation\": [3],\n",
    "    \"layer_1_stride\": [1],\n",
    "    \"layer_2_stride\": [1],\n",
    "    \"layer_3_stride\": [2],\n",
    "    \"no_norm\": [True]\n",
    "}"
   ],
   "id": "97b4fc3e7efddbaa",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T07:38:23.325108Z",
     "start_time": "2025-08-26T07:38:23.282091Z"
    }
   },
   "cell_type": "code",
   "source": "eeg_df['participant_id'] = eeg_df['participant_id'].replace(\"11_raw\", \"1\").replace('12_raw', '1').replace('21_raw', '2').replace('22_raw', '2')",
   "id": "67f8a8bb9e928559",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T07:38:23.366625Z",
     "start_time": "2025-08-26T07:38:23.326114Z"
    }
   },
   "cell_type": "code",
   "source": "X_train_tmp, X_test_tmp, y_train_tmp, y_test_tmp = split_train_test(eeg_df=eeg_df, test_size=0.33, random_state=42)",
   "id": "b3e84fbfe256a8af",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set participants: ['2' 'AB-2025-07-26_raw']\n",
      "Test set participants: ['1']\n",
      "Training labels: ['2' 'AB-2025-07-26_raw']\n",
      "Test labels: ['1']\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T07:38:23.408683Z",
     "start_time": "2025-08-26T07:38:23.366625Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epoch_length = X_train_tmp[0].shape[1]\n",
    "div, mod = divmod(epoch_length, 50)\n",
    "truncated_length = div*50"
   ],
   "id": "bb62c9b901056d72",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T07:38:50.799091Z",
     "start_time": "2025-08-26T07:38:23.408683Z"
    }
   },
   "cell_type": "code",
   "source": [
    "extracted_X_train = []\n",
    "for epoch in X_train_tmp:\n",
    "    extracted_X_train.append(extract_features(epoch, fs=250, trunc=truncated_length).T) "
   ],
   "id": "9f9d263b13f12200",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T07:39:08.628987Z",
     "start_time": "2025-08-26T07:38:50.799091Z"
    }
   },
   "cell_type": "code",
   "source": [
    "extracted_X_test = []\n",
    "for epoch in X_test_tmp:\n",
    "    extracted_X_test.append(extract_features(epoch, fs=250, trunc=truncated_length).T)"
   ],
   "id": "1b5e4165ece678bf",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T07:39:08.667648Z",
     "start_time": "2025-08-26T07:39:08.629998Z"
    }
   },
   "cell_type": "code",
   "source": [
    "le_train = LabelEncoder()\n",
    "le_train.fit(y_train_tmp)\n",
    "y_train_encoded = le_train.transform(y_train_tmp)\n",
    "\n",
    "le_test = LabelEncoder()\n",
    "le_test.fit(y_test_tmp)\n",
    "y_test_encoded = le_test.transform(y_test_tmp)"
   ],
   "id": "b2d2acf96689153a",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T07:39:08.711474Z",
     "start_time": "2025-08-26T07:39:08.667648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train = np.array(extracted_X_train)\n",
    "X_test = np.array(extracted_X_test)"
   ],
   "id": "9ae6fcac82c412ca",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T07:39:08.751207Z",
     "start_time": "2025-08-26T07:39:08.712502Z"
    }
   },
   "cell_type": "code",
   "source": [
    "scalers = {}\n",
    "X_train_norm = np.empty_like(X_train)\n",
    "X_test_norm = np.empty_like(X_test)"
   ],
   "id": "88beaa0aeeefb423",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T07:39:08.929079Z",
     "start_time": "2025-08-26T07:39:08.751207Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# scaling per feature\n",
    "for f in range(X_train.shape[1]):\n",
    "    scalers[f] = StandardScaler().fit(X_train[:, f, :])\n",
    "    X_train_norm[:, f,:] = scalers[f].transform(X_train[:, f, :])\n",
    "    X_test_norm[:, f, :] = scalers[f].transform(X_test[:, f, :])"
   ],
   "id": "352448532ea497e5",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T07:39:08.968290Z",
     "start_time": "2025-08-26T07:39:08.930150Z"
    }
   },
   "cell_type": "code",
   "source": "num_train_classes = len(np.unique(y_train_encoded))",
   "id": "f5d0273d0c61dd47",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T07:39:09.008634Z",
     "start_time": "2025-08-26T07:39:08.968290Z"
    }
   },
   "cell_type": "code",
   "source": [
    "custom_colors = ['#e6194b', '#3cb44b', '#ffe119', '#4363d8', '#f58231', '#911eb4',\n",
    "                 '#46f0f0', '#f032e6', '#bcf60c', '#fabebe', '#008080', '#e6beff',\n",
    "                 '#9a6324', '#fffac8', '#800000', '#aaffc3', '#808000', '#ffd8b1',\n",
    "                 '#000075', '#808080', '#ffffff', '#000000', '#a9a9a9', '#ff69b4',\n",
    "                 '#b0e0e6', '#32cd32', '#ff4500', '#da70d6', '#ff1493', '#7fffd4']\n",
    "cmap = ListedColormap(custom_colors[:2])\n",
    "\n",
    "custom_colors = ['#e6194b',  # Red\n",
    "                 '#3cb44b',  # Green\n",
    "                 '#4363d8',  # Blue\n",
    "                 '#ffe119',  # Yellow\n",
    "                 '#911eb4',  # Purple\n",
    "                 '#f58231']  # Orange\n",
    "\n",
    "cmap2 = ListedColormap(custom_colors[:2])"
   ],
   "id": "d510a718f5e00502",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T07:39:09.047909Z",
     "start_time": "2025-08-26T07:39:09.008634Z"
    }
   },
   "cell_type": "code",
   "source": "import matplotlib.patches as mpatches\n",
   "id": "c460339de868b921",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T07:39:09.088741Z",
     "start_time": "2025-08-26T07:39:09.047909Z"
    }
   },
   "cell_type": "code",
   "source": [
    "unique_ids = np.unique(y_test_tmp)\n",
    "test_handles = []\n",
    "num_ids = len(unique_ids)\n",
    "for i in range(num_ids):\n",
    "    color = cmap(float(i) / (len(unique_ids)))\n",
    "    patch = mpatches.Patch(color=color, label=str(unique_ids[i]))\n",
    "    test_handles.append(patch)"
   ],
   "id": "40136da2ed55f4e9",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T07:39:09.127958Z",
     "start_time": "2025-08-26T07:39:09.088741Z"
    }
   },
   "cell_type": "code",
   "source": "train_handles = create_handles(y_train_tmp, cmap)",
   "id": "b3e2c08dc62b8631",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T07:39:27.893490Z",
     "start_time": "2025-08-26T07:39:09.127958Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for run_idx, hparams in enumerate(ParameterGrid(grid), start=1):\n",
    "    print(f\"RUN NUMBER: {run_idx}\")\n",
    "    print(\"Parameters: \", hparams)\n",
    "    run_name =f\"run_{run_idx}\"\n",
    "    writer = SummaryWriter(log_dir=f\"{RUNS_FOLDER}/{run_name}_{APPENDIX}\")\n",
    "    writer.add_hparams(hparams,{})\n",
    "    \n",
    "    train_loader = get_dataset(hparams,X_train_norm, y_train_encoded)\n",
    "    model = pretrain(hparams, device, X_train_norm.shape[1], num_train_classes, train_loader, writer, \"ECAPA2\").to(device)\n",
    "    model, final_loss = fine_tune_arcface(model, hparams, device, train_loader, num_train_classes, writer, return_final_loss=True)\n",
    "    model = model.to(\"cpu\")\n",
    "    \n",
    "    embd_train, embd_test = create_embeddings(model, X_train_norm, X_test_norm,hparams)\n",
    "    centroid_train_acc, centroid_test_acc = get_accuracy(embd_train, embd_test, y_train_encoded, y_test_encoded)\n",
    "    \n",
    "    writer.add_scalar(f\"Final_Centroid_Accuracy_/train\", centroid_train_acc)\n",
    "    writer.add_scalar(f\"Final_Centroid_Accuracy_/test\", centroid_test_acc)\n",
    "    \n",
    "    tsne_train = TSNE(n_components=2, random_state=42).fit_transform(embd_train)\n",
    "    tsne_test = TSNE(n_components=2, random_state=42).fit_transform(embd_test)\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    tsne_train_scaled = scaler.fit_transform(tsne_train)\n",
    "    tsne_test_scaled = scaler.transform(tsne_test)\n",
    "    \n",
    "    fig_train = plot_tsne(tsne_train_scaled,\n",
    "      cmap,\n",
    "      y_train_encoded,\n",
    "      handles=train_handles,\n",
    "      alpha=0.5,\n",
    "      title=\"TSNE Visualization training data XVector\",\n",
    "      xlabel=\"TSNE embedding dimension 1\",\n",
    "      ylabel=\"TSNE embedding dimension 2\",\n",
    "      centroids=None,\n",
    "      return_fig=True)\n",
    "    # plt.show(fig_train)\n",
    "    writer.add_figure(f\"tsne_train\", fig_train)\n",
    "    fig_test = plot_tsne(tsne_test_scaled,\n",
    "          cmap2,\n",
    "          y_test_encoded,\n",
    "          handles=test_handles,\n",
    "          alpha=0.5,\n",
    "          title=\"TSNE Visualization test data XVector\",\n",
    "          xlabel=\"TSNE embedding dimension 1\",\n",
    "          ylabel=\"TSNE embedding dimension 2\",\n",
    "          centroids=None, return_fig=True )\n",
    "    embd_unit = embd_train / np.linalg.norm(embd_train, axis=1, keepdims=True)\n",
    "    writer.add_figure(f\"tsne_test\", fig_test)\n",
    "        # train\n",
    "    user_profiles = create_user_profiles(embd_train, y_train_encoded)\n",
    "    for metric in (\"euclidean\", \"cosine\"):\n",
    "        genuine_dists, imposter_dists = compute_genuine_imposter_distances(\n",
    "                embeddings=embd_train ,\n",
    "                ids=y_train_encoded,\n",
    "                user_profiles=user_profiles,\n",
    "                distance_metric=metric\n",
    "            )\n",
    "        \n",
    "        (\n",
    "            thresholds, fnr_list, fpr_list, acc_list,\n",
    "            best_T, best_fnr, best_fpr, best_acc\n",
    "        ) = compute_threshold_metrics(genuine_dists, imposter_dists, num_thresholds=200)\n",
    "        \n",
    "        writer.add_scalar(f\"{metric}_best_threshold_train\", best_T)\n",
    "        writer.add_scalar(f\"{metric}_best_acc_train\", best_acc)\n",
    "        writer.add_scalar(f\"{metric}_FNR/FPR_threshold_train\", best_fnr)\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        fig = plot_threshold_metrics_return(\n",
    "            thresholds, fnr_list, fpr_list, acc_list,\n",
    "            best_T, best_fnr, best_fpr, best_acc\n",
    "        )\n",
    "        # plt.show(fig)\n",
    "        writer.add_figure(f\"threshold_metrics_train_{metric}\", fig)\n",
    "        \n",
    "        thresholds, f1_list, best_T, best_f1 = compute_f1_vs_threshold(\n",
    "            genuine_dists, imposter_dists, num_thresholds=300\n",
    "        )\n",
    "        writer.add_scalar(f\"{metric}_best_f1_train_fold\", best_f1)\n",
    "        \n",
    "\n",
    "        \n",
    "        fig = plot_f1_vs_threshold_return(thresholds, f1_list, best_T, best_f1)\n",
    "        writer.add_figure(f\"f1_vs_threshold_train_{metric}_fold\", fig)\n",
    "        # plt.show(fig)\n",
    "\n",
    "\n",
    "    # vaL\n",
    "    profile_embd, profile_ids, verify_embd, verify_ids = split_test_data_for_verification(\n",
    "        embd_test, y_test_encoded, profile_ratio=0.6\n",
    "    )\n",
    "    \n",
    "    val_user_profiles = create_user_profiles(profile_embd, profile_ids)\n",
    "    for metric in (\"euclidean\", \"cosine\"):\n",
    "    \n",
    "        genuine_dists, imposter_dists = compute_genuine_imposter_distances(\n",
    "            embeddings=verify_embd,\n",
    "            ids=verify_ids,\n",
    "            user_profiles=val_user_profiles,\n",
    "            distance_metric=metric\n",
    "        )\n",
    "        \n",
    "        (\n",
    "            test_thresholds, test_fnr_list, test_fpr_list, test_acc_list,\n",
    "            test_best_T, test_best_fnr, test_best_fpr, test_best_acc\n",
    "        ) = compute_threshold_metrics(genuine_dists, imposter_dists, num_thresholds=200)\n",
    "        writer.add_scalar(f\"{metric}_best_threshold_test\", test_best_T)\n",
    "        writer.add_scalar(f\"{metric}_best_acc_test_fold\", test_best_acc)\n",
    "        writer.add_scalar(f\"{metric}_FNR/FPR_threshold_test\", test_best_fnr)\n",
    "        \n",
    "        \n",
    "        fig = plot_threshold_metrics_return(\n",
    "            test_thresholds, test_fnr_list, test_fpr_list, test_acc_list,\n",
    "            test_best_T, test_best_fnr, test_best_fpr, test_best_acc\n",
    "        )\n",
    "        # plt.show(fig)\n",
    "        writer.add_figure(f\"threshold_metrics_{metric}_test\", fig)\n",
    "        \n",
    "        test_thresholds_f1, test_f1_list, test_best_T_f1, test_best_f1 = compute_f1_vs_threshold(\n",
    "            genuine_dists, imposter_dists, num_thresholds=300\n",
    "        )\n",
    "        writer.add_scalar(f\"{metric}_best_f1_test\", test_best_f1)\n",
    "        \n",
    "        \n",
    "        fig = plot_f1_vs_threshold_return(test_thresholds_f1, test_f1_list, test_best_T_f1, test_best_f1)\n",
    "        # plt.show(fig)\n",
    "        writer.add_figure(f\"f1_vs_threshold_test_{metric}\", fig)\n",
    "    writer.close()"
   ],
   "id": "d6560056a78fec9f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN NUMBER: 1\n",
      "Parameters:  {'augmentation': True, 'batch_size': 64, 'dropout_rate': 0.25, 'embedding_dim': 256, 'layer1_filters': 512, 'layer2_filters': 512, 'layer3_filters': 1024, 'layer4_filters': 1024, 'layer5_filters': 1500, 'layer_1_dilatation': 1, 'layer_1_stride': 1, 'layer_2_dilatation': 2, 'layer_2_stride': 1, 'layer_3_dilatation': 3, 'layer_3_stride': 2, 'margin': 0.1, 'no_norm': True, 'proxy_epochs': 10, 'proxy_learning_rate': 0.001, 'proxy_learning_rate_decay': 0.95, 'scale': 10, 'softmax_epochs': 10, 'softmax_learning_rate': 0.001, 'softmax_learning_rate_decay': 0.95, 'std': 0.02}\n",
      "[Pretrain] Epoch 1/10  Loss=0.6535  Acc=0.6106\n",
      "[Pretrain] Epoch 2/10  Loss=0.5370  Acc=0.7789\n",
      "[Pretrain] Epoch 3/10  Loss=0.3556  Acc=1.0000\n",
      "[Pretrain] Epoch 4/10  Loss=0.3087  Acc=1.0000\n",
      "[Pretrain] Epoch 5/10  Loss=0.2780  Acc=1.0000\n",
      "[Pretrain] Epoch 6/10  Loss=0.2512  Acc=1.0000\n",
      "[Pretrain] Epoch 7/10  Loss=0.2279  Acc=1.0000\n",
      "[Pretrain] Epoch 8/10  Loss=0.2080  Acc=1.0000\n",
      "[Pretrain] Epoch 9/10  Loss=0.1911  Acc=1.0000\n",
      "[Pretrain] Epoch 10/10  Loss=0.1767  Acc=1.0000\n",
      "[ArcFace Fine‑tune] Epoch 1/10  Loss=0.4837\n",
      "[ArcFace Fine‑tune] Epoch 2/10  Loss=0.0329\n",
      "[ArcFace Fine‑tune] Epoch 3/10  Loss=0.0000\n",
      "[ArcFace Fine‑tune] Epoch 4/10  Loss=0.0000\n",
      "[ArcFace Fine‑tune] Epoch 5/10  Loss=0.0000\n",
      "[ArcFace Fine‑tune] Epoch 6/10  Loss=0.0000\n",
      "[ArcFace Fine‑tune] Epoch 7/10  Loss=0.0000\n",
      "[ArcFace Fine‑tune] Epoch 8/10  Loss=0.0000\n",
      "[ArcFace Fine‑tune] Epoch 9/10  Loss=0.0000\n",
      "[ArcFace Fine‑tune] Epoch 10/10  Loss=0.0000\n"
     ]
    }
   ],
   "execution_count": 31
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
