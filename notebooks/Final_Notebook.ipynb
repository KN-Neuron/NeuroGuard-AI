{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-06T07:01:57.300080Z",
     "start_time": "2025-07-06T07:01:57.279366Z"
    }
   },
   "source": [
    "import torch\n",
    "\n",
    "print(\"Number of GPU: \", torch.cuda.device_count())\n",
    "print(\"GPU Name: \", torch.cuda.get_device_name())\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPU:  1\n",
      "GPU Name:  NVIDIA GeForce RTX 2060\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "186a008aca5d4794"
  },
  {
   "cell_type": "code",
   "id": "c512409357f76165",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T07:01:57.455832Z",
     "start_time": "2025-07-06T07:01:57.451779Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mne\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 64
  },
  {
   "cell_type": "code",
   "id": "7ac989d125d61d0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T07:01:57.487012Z",
     "start_time": "2025-07-06T07:01:57.470873Z"
    }
   },
   "source": [
    "from eeg_lib.commons.constant import DATASETS_FOLDER\n",
    "from eeg_lib.data.data_loader.EEGDataExtractor import EEGDataExtractor"
   ],
   "outputs": [],
   "execution_count": 65
  },
  {
   "cell_type": "code",
   "id": "d7ce75d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T07:01:57.535263Z",
     "start_time": "2025-07-06T07:01:57.518209Z"
    }
   },
   "source": [
    "from eeg_lib.utils.engine import create_user_profiles"
   ],
   "outputs": [],
   "execution_count": 66
  },
  {
   "cell_type": "code",
   "id": "13aef380",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T07:01:57.554302Z",
     "start_time": "2025-07-06T07:01:57.549768Z"
    }
   },
   "source": "from eeg_lib.utils.helpers import compute_genuine_imposter_distances, compute_threshold_metrics, compute_f1_vs_threshold, split_test_data_for_verification",
   "outputs": [],
   "execution_count": 67
  },
  {
   "cell_type": "code",
   "id": "2adc19c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T07:01:57.582684Z",
     "start_time": "2025-07-06T07:01:57.577624Z"
    }
   },
   "source": "from eeg_lib.utils.visualisations import plot_distance_distribution_on_ax, plot_threshold_metrics, plot_f1_vs_threshold, plot_distance_distribution_return, plot_f1_vs_threshold_return, plot_threshold_metrics_return",
   "outputs": [],
   "execution_count": 68
  },
  {
   "cell_type": "code",
   "id": "ad0e4d155de5cad3",
   "metadata": {},
   "source": [
    "DATA_DIR = f\"{DATASETS_FOLDER}/Kolory/\"\n",
    "\n",
    "extractor = EEGDataExtractor(data_dir=DATA_DIR)\n",
    "eeg_df, participants_info = extractor.extract_dataframe()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8bc74479e4871767",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T07:02:05.681827Z",
     "start_time": "2025-07-06T07:02:05.677088Z"
    }
   },
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from matplotlib.colors import ListedColormap"
   ],
   "outputs": [],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T07:02:05.685939Z",
     "start_time": "2025-07-06T07:02:05.681827Z"
    }
   },
   "cell_type": "code",
   "source": "from sklearn.model_selection import ParameterGrid",
   "id": "c045b5c1d9aee31c",
   "outputs": [],
   "execution_count": 71
  },
  {
   "cell_type": "code",
   "id": "a29adcc20af40112",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T07:02:05.690210Z",
     "start_time": "2025-07-06T07:02:05.685939Z"
    }
   },
   "source": [
    "import torch.nn as nn"
   ],
   "outputs": [],
   "execution_count": 72
  },
  {
   "cell_type": "code",
   "id": "be90e77744238fce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T07:02:05.694687Z",
     "start_time": "2025-07-06T07:02:05.690210Z"
    }
   },
   "source": [
    "from eeg_lib.data.data_loader.TDNNFeatures import extract_features\n",
    "from eeg_lib.data.TDNNDataset import TDNNDataset\n",
    "from eeg_lib.models.verification.XVector import XVectorEmbeddingModel\n",
    "from eeg_lib.losses.ProxyNCALoss import ProxyNCALoss\n",
    "from eeg_lib.utils.visualisations import plot_tsne\n",
    "from eeg_lib.utils.visualisations import create_handles\n",
    "from eeg_lib.utils.helpers import split_train_test\n",
    "from eeg_lib.models.similarity.centroids import SimilarityCentroidsVerifier"
   ],
   "outputs": [],
   "execution_count": 73
  },
  {
   "cell_type": "code",
   "id": "f033a3e520d41549",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T07:02:05.698388Z",
     "start_time": "2025-07-06T07:02:05.694687Z"
    }
   },
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ],
   "outputs": [],
   "execution_count": 74
  },
  {
   "cell_type": "code",
   "id": "cc48fe852fe4a436",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T07:02:05.701823Z",
     "start_time": "2025-07-06T07:02:05.698388Z"
    }
   },
   "source": [
    "from torch.optim.lr_scheduler import StepLR, ExponentialLR, ReduceLROnPlateau"
   ],
   "outputs": [],
   "execution_count": 75
  },
  {
   "cell_type": "markdown",
   "id": "a29010bf1809f7f2",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T07:02:05.706550Z",
     "start_time": "2025-07-06T07:02:05.701823Z"
    }
   },
   "cell_type": "code",
   "source": [
    "grid = {\n",
    "    \"batch_size\" : [64],\n",
    "    \"softmax_learning_rate\" : [0.001, 0.01],\n",
    "    \"proxy_learning_rate\" : [0.001, 0.05, 0.01],\n",
    "    \"softmax_epochs\" : [50,75,100,150],\n",
    "    \"proxy_epochs\" : [50,75,100,150],\n",
    "    \"softmax_learning_rate_decay\" : [0.95],\n",
    "    \"proxy_learning_rate_decay\" : [0.95],\n",
    "    \"augmentation\" : [True],\n",
    "    \"std\" : [0.02],\n",
    "    \"embedding_dim\" : [32],\n",
    "    \"dropout_rate\" : [0.25],\n",
    "    \"scale\" : [7],\n",
    "    \"layer1_filters\" : [512],\n",
    "    \"layer2_filters\" : [512],\n",
    "    \"layer3_filters\" : [1024],\n",
    "    \"layer4_filters\" : [1024],\n",
    "    \"layer5_filters\" : [1500],\n",
    "    \"layer_1_dilatation\" : [1],\n",
    "    \"layer_2_dilatation\" : [2],\n",
    "    \"layer_3_dilatation\" : [3],\n",
    "    \"layer_1_stride\" : [1],\n",
    "    \"layer_2_stride\" : [1],\n",
    "    \"layer_3_stride\" : [2],\n",
    "}"
   ],
   "id": "e027e3962a53073d",
   "outputs": [],
   "execution_count": 76
  },
  {
   "cell_type": "markdown",
   "id": "fb85123b8e308f07",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "id": "c5a32ffa101a16b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T07:02:05.740315Z",
     "start_time": "2025-07-06T07:02:05.706550Z"
    }
   },
   "source": [
    "X_train_tmp, X_test_tmp, y_train_tmp, y_test_tmp = split_train_test(eeg_df=eeg_df,test_size=0.2, random_state=42)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set participants: ['fd8a3308@1135' 'e08138e2@1731' '541c91f2@1456' '011595b1@1651'\n",
      " '2718372d@1400' '6e542bc2@0845' '2882ae26@1441' '548fd734@1628'\n",
      " '51ec2c20@0923' 'bf2d2193@1638' '022e8467@1910' '06f240e9@1215'\n",
      " 'e283301e@1606' '25d0bdb3@1318' 'b34b1427@0906' 'e43a9f9f@0941'\n",
      " '8dca0725@1418' 'ffae50df@1712' '9e8bae0e@1828' '36eea4bb@1519'\n",
      " '46607ce4@1717' '54e60118@1339' '90441f44@1643' '3033b74a@1626']\n",
      "Test set participants: ['f82b5699@1757' '6d9a8b86@1613' 'd87e1bd3@1806' '8bd3032e@1746'\n",
      " '39285860@1825' '446b3735@1618']\n",
      "Training labels: ['011595b1@1651' '022e8467@1910' '06f240e9@1215' '25d0bdb3@1318'\n",
      " '2718372d@1400' '2882ae26@1441' '3033b74a@1626' '36eea4bb@1519'\n",
      " '46607ce4@1717' '51ec2c20@0923' '541c91f2@1456' '548fd734@1628'\n",
      " '54e60118@1339' '6e542bc2@0845' '8dca0725@1418' '90441f44@1643'\n",
      " '9e8bae0e@1828' 'b34b1427@0906' 'bf2d2193@1638' 'e08138e2@1731'\n",
      " 'e283301e@1606' 'e43a9f9f@0941' 'fd8a3308@1135' 'ffae50df@1712']\n",
      "Test labels: ['39285860@1825' '446b3735@1618' '6d9a8b86@1613' '8bd3032e@1746'\n",
      " 'd87e1bd3@1806' 'f82b5699@1757']\n"
     ]
    }
   ],
   "execution_count": 77
  },
  {
   "cell_type": "markdown",
   "id": "311c0991467c6a8f",
   "metadata": {},
   "source": [
    "feature extraction similar to Mel frequency cepstral coefficients"
   ]
  },
  {
   "cell_type": "code",
   "id": "3c3c5ed359ffe72b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T07:03:04.455300Z",
     "start_time": "2025-07-06T07:02:05.741819Z"
    }
   },
   "source": [
    "extracted_X_train = []\n",
    "for epoch in X_train_tmp:\n",
    "    extracted_X_train.append(extract_features(epoch, frame_length=50).T) "
   ],
   "outputs": [],
   "execution_count": 78
  },
  {
   "cell_type": "code",
   "id": "8378f6897c377587",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T07:03:19.334275Z",
     "start_time": "2025-07-06T07:03:04.455300Z"
    }
   },
   "source": [
    "extracted_X_test = []\n",
    "for epoch in X_test_tmp:\n",
    "    extracted_X_test.append(extract_features(epoch, frame_length=50).T)"
   ],
   "outputs": [],
   "execution_count": 79
  },
  {
   "cell_type": "code",
   "id": "12b79d263bb737f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T07:03:19.339809Z",
     "start_time": "2025-07-06T07:03:19.334275Z"
    }
   },
   "source": [
    "le_train = LabelEncoder()\n",
    "le_train.fit(y_train_tmp)\n",
    "y_train_encoded = le_train.transform(y_train_tmp)\n",
    "\n",
    "le_test = LabelEncoder()\n",
    "le_test.fit(y_test_tmp)\n",
    "y_test_encoded = le_test.transform(y_test_tmp)"
   ],
   "outputs": [],
   "execution_count": 80
  },
  {
   "cell_type": "markdown",
   "id": "71b58d784b500b1f",
   "metadata": {},
   "source": [
    "### Standardization"
   ]
  },
  {
   "cell_type": "code",
   "id": "7cd5efdd405ef85d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T07:03:19.355224Z",
     "start_time": "2025-07-06T07:03:19.339809Z"
    }
   },
   "source": [
    "X_train = np.array(extracted_X_train)\n",
    "X_test = np.array(extracted_X_test)"
   ],
   "outputs": [],
   "execution_count": 81
  },
  {
   "cell_type": "code",
   "id": "185c2381172aa424",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T07:03:19.359273Z",
     "start_time": "2025-07-06T07:03:19.355224Z"
    }
   },
   "source": [
    "scalers = {}\n",
    "X_train_norm = np.empty_like(X_train)\n",
    "X_test_norm = np.empty_like(X_test)"
   ],
   "outputs": [],
   "execution_count": 82
  },
  {
   "cell_type": "code",
   "id": "b6b012ca801af4e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T07:03:19.437106Z",
     "start_time": "2025-07-06T07:03:19.359273Z"
    }
   },
   "source": [
    "# scaling per feature\n",
    "for f in range(X_train.shape[1]):\n",
    "    scalers[f] = StandardScaler().fit(X_train[:, f, :])\n",
    "    X_train_norm[:, f,:] = scalers[f].transform(X_train[:, f, :])\n",
    "    X_test_norm[:, f, :] = scalers[f].transform(X_test[:, f, :])"
   ],
   "outputs": [],
   "execution_count": 83
  },
  {
   "cell_type": "markdown",
   "id": "571a4761cc2ac96b",
   "metadata": {},
   "source": [
    "### Model and dataset creation"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T07:03:19.440955Z",
     "start_time": "2025-07-06T07:03:19.437106Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_dataset(hparams, X_train, y_train):\n",
    "    augmentation = hparams[\"augmentation\"]\n",
    "    batch_size = hparams[\"batch_size\"]\n",
    "    std = hparams[\"std\"]\n",
    "    \n",
    "    dataset = TDNNDataset(X_train, y_train, augmentation=augmentation, std=std)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    return dataloader\n",
    "    "
   ],
   "id": "c24e2ef15c08a262",
   "outputs": [],
   "execution_count": 84
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T07:03:19.446665Z",
     "start_time": "2025-07-06T07:03:19.440955Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_model(hparams, input_features, num_classes):\n",
    "    embedding_dim = hparams[\"embedding_dim\"]\n",
    "    dropout_rate = hparams[\"dropout_rate\"]\n",
    "    \n",
    "    model = XVectorEmbeddingModel(input_features=input_features,\n",
    "                                  num_classes=num_classes,\n",
    "                                  embedding_dim=embedding_dim,\n",
    "                                  dropout1=dropout_rate,\n",
    "                                  dropout2=dropout_rate,\n",
    "                                  dropout3=dropout_rate,\n",
    "                                  dropout4=dropout_rate,\n",
    "                                  layer1_filt=hparams[\"layer1_filters\"],\n",
    "                                  layer2_filt=hparams[\"layer2_filters\"],\n",
    "                                  layer3_filt=hparams[\"layer3_filters\"],\n",
    "                                  layer4_filt=hparams[\"layer4_filters\"],\n",
    "                                  layer5_filt=hparams[\"layer5_filters\"],\n",
    "                                  layer_1_dilatation=hparams[\"layer_1_dilatation\"],\n",
    "                                  layer_2_dilatation=hparams[\"layer_2_dilatation\"],\n",
    "                                  layer_3_dilatation=hparams[\"layer_3_dilatation\"],\n",
    "                                  layer_1_stride=hparams[\"layer_1_stride\"],\n",
    "                                  layer_2_stride=hparams[\"layer_2_stride\"],\n",
    "                                  layer_3_stride=hparams[\"layer_3_stride\"],)\n",
    "    return model"
   ],
   "id": "83e0fc8dedd628a3",
   "outputs": [],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T07:03:19.453723Z",
     "start_time": "2025-07-06T07:03:19.446665Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def pretrain(hparams, device, input_features, num_classes, dataloader, writer=None):\n",
    "    lr = hparams[\"softmax_learning_rate\"]\n",
    "    weight_decay = hparams[\"softmax_learning_rate_decay\"]\n",
    "    epochs = hparams[\"softmax_epochs\"]\n",
    "    \n",
    "    \n",
    "    model = get_model(hparams, input_features, num_classes).to(device)\n",
    "    if writer is not None:\n",
    "        rnd_sample = torch.randn(1, input_features, num_classes).to(device)\n",
    "        writer.add_graph(model, rnd_sample)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = ExponentialLR(optimizer, gamma=weight_decay)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "        total_seen = 0\n",
    "        \n",
    "        for data, labels in dataloader:\n",
    "            data = data.to(device)\n",
    "            labels = labels.to(device).long()\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(data)\n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item() * data.size(0)\n",
    "            pred = logits.argmax(dim=1)\n",
    "            total_correct += (pred == labels).sum().item()\n",
    "            total_seen += data.size(0)\n",
    "            \n",
    "        avg_loss = total_loss / total_seen\n",
    "        acc = total_correct / total_seen\n",
    "        if writer is not None:\n",
    "            writer.add_scalar(\"Pretrain/Loss\", avg_loss, epoch)\n",
    "            writer.add_scalar(\"Pretrain/Accuracy\", acc, epoch)\n",
    "        print(f\"[Pretrain] Epoch {epoch+1}/{epochs}  Loss={avg_loss:.4f}  Acc={acc:.4f}\")\n",
    "        scheduler.step()\n",
    "    return model"
   ],
   "id": "fe3784dd714ec141",
   "outputs": [],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T07:03:19.460138Z",
     "start_time": "2025-07-06T07:03:19.453723Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def fine_tune(model, hparams, device, dataloader, num_classes, writer=None):\n",
    "    lr = hparams[\"proxy_learning_rate\"]\n",
    "    weight_decay = hparams[\"proxy_learning_rate_decay\"]\n",
    "    epochs = hparams[\"proxy_epochs\"]\n",
    "    scale = hparams[\"scale\"]\n",
    "    embedding_dim = hparams[\"embedding_dim\"]\n",
    "    \n",
    "    model.classifier = None\n",
    "    proxy_loss = ProxyNCALoss(num_classes=num_classes,\n",
    "                          embedding_dim=embedding_dim, scale=scale).to(device)\n",
    "    optimizer = optim.Adam(list(model.parameters()) + list(proxy_loss.parameters()), lr=lr)\n",
    "    scheduler = ExponentialLR(optimizer, gamma=weight_decay)\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for data, labels in dataloader:\n",
    "            data, labels = data.to(device), labels.to(device).long()\n",
    "            optimizer.zero_grad()\n",
    "            emb = model(data, return_embedding=True, no_norm=True)\n",
    "            loss = proxy_loss(emb, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item() * data.size(0)\n",
    "        avg_loss = total_loss / len(dataloader.dataset)\n",
    "        if writer is not None:\n",
    "            writer.add_scalar(\"Finetune/Loss\", avg_loss, epoch)\n",
    "        print(f\"[Fine-tune] Epoch {epoch+1}/{epochs}  Loss={avg_loss:.4f}\")\n",
    "        scheduler.step()\n",
    "    return model"
   ],
   "id": "83c3032651c24aa6",
   "outputs": [],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T07:03:19.465577Z",
     "start_time": "2025-07-06T07:03:19.460138Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_embeddings(model, X_train, X_test,hparams):\n",
    "    embeddings = []\n",
    "    test_embeddings = []\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for epoch in X_train:\n",
    "            embeddings.append(model(torch.tensor(epoch, dtype=torch.float, requires_grad=False).unsqueeze(0), return_embedding=True, no_norm=True))\n",
    "        for epoch in X_test:\n",
    "            test_embeddings.append(model(torch.tensor(epoch, dtype=torch.float, requires_grad=False).unsqueeze(0), return_embedding=True, no_norm=True))\n",
    "    embd = torch.stack(embeddings).reshape((X_train.shape[0],hparams[\"embedding_dim\"])).numpy()\n",
    "    test_embd = torch.stack(test_embeddings).reshape((X_test.shape[0],hparams[\"embedding_dim\"])).numpy()\n",
    "    return embd, test_embd"
   ],
   "id": "33c1c4584f1b045c",
   "outputs": [],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T07:03:19.471452Z",
     "start_time": "2025-07-06T07:03:19.465577Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_accuracy(embd, test_embd, y_train_encoded, y_test_encoded):\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    train_normalized = scaler.fit_transform(embd)\n",
    "    test_normalized = scaler.transform(test_embd)\n",
    "    centroid_verifier_actual = SimilarityCentroidsVerifier()\n",
    "    \n",
    "    centroid_verifier_actual.compute_true_centroids(y_train_encoded, train_normalized)\n",
    "    train_acc = 0\n",
    "    for i in range(len(train_normalized)):\n",
    "        true_label = y_train_encoded[i]\n",
    "        predicted_label, _ = centroid_verifier_actual.classify_embedding(train_normalized[i])\n",
    "        if predicted_label == true_label:\n",
    "            train_acc += 1\n",
    "    train_acc = train_acc/len(train_normalized)\n",
    "    \n",
    "    centroid_verifier_actual_test = SimilarityCentroidsVerifier()\n",
    "    centroid_verifier_actual_test.compute_true_centroids(y_test_encoded, test_normalized)\n",
    "    test_acc = 0\n",
    "    for i in range(len(test_normalized)):\n",
    "        true_label = y_test_encoded[i]\n",
    "        predicted_label, _ = centroid_verifier_actual_test.classify_embedding(test_normalized[i])\n",
    "        if predicted_label == true_label:\n",
    "            test_acc += 1\n",
    "    test_acc = test_acc/len(test_normalized)\n",
    "    \n",
    "    return train_acc, test_acc"
   ],
   "id": "396eb9f8ee0b4941",
   "outputs": [],
   "execution_count": 89
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T07:03:19.475964Z",
     "start_time": "2025-07-06T07:03:19.471452Z"
    }
   },
   "cell_type": "code",
   "source": "num_train_classes = len(np.unique(y_train_encoded))",
   "id": "2bf56097c852294b",
   "outputs": [],
   "execution_count": 90
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T07:03:19.480793Z",
     "start_time": "2025-07-06T07:03:19.475964Z"
    }
   },
   "cell_type": "code",
   "source": [
    "custom_colors = ['#e6194b', '#3cb44b', '#ffe119', '#4363d8', '#f58231', '#911eb4',\n",
    "                 '#46f0f0', '#f032e6', '#bcf60c', '#fabebe', '#008080', '#e6beff',\n",
    "                 '#9a6324', '#fffac8', '#800000', '#aaffc3', '#808000', '#ffd8b1',\n",
    "                 '#000075', '#808080', '#ffffff', '#000000', '#a9a9a9', '#ff69b4',\n",
    "                 '#b0e0e6', '#32cd32', '#ff4500', '#da70d6', '#ff1493', '#7fffd4']\n",
    "cmap = ListedColormap(custom_colors[:30])\n",
    "\n",
    "custom_colors = ['#e6194b',  # Red\n",
    "                 '#3cb44b',  # Green\n",
    "                 '#4363d8',  # Blue\n",
    "                 '#ffe119',  # Yellow\n",
    "                 '#911eb4',  # Purple\n",
    "                 '#f58231']  # Orange\n",
    "\n",
    "cmap2 = ListedColormap(custom_colors[:6])"
   ],
   "id": "851a3b19efc28289",
   "outputs": [],
   "execution_count": 91
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T07:03:19.488729Z",
     "start_time": "2025-07-06T07:03:19.480793Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_handles = create_handles(y_train_tmp, cmap)\n",
    "test_handles = create_handles(y_test_tmp, cmap2)"
   ],
   "id": "1815030b5efc6858",
   "outputs": [],
   "execution_count": 92
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T16:56:05.943368Z",
     "start_time": "2025-07-06T07:03:19.488729Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for run_idx, hparams in enumerate(ParameterGrid(grid), start=1):\n",
    "    run_name = f\"run_{run_idx}\"\n",
    "    writer = SummaryWriter(log_dir=f\"runs/{run_name}\")\n",
    "    writer.add_hparams(hparams, {})\n",
    "    \n",
    "    train_loader = get_dataset(hparams,X_train_norm, y_train_encoded)\n",
    "    model = pretrain(hparams, device, X_train_norm.shape[1], num_train_classes, train_loader, writer).to(device)\n",
    "    model = fine_tune(model, hparams, device, train_loader, num_train_classes, writer).to(device)\n",
    "    model.to('cpu')\n",
    "    embd_train, embd_test = create_embeddings(model, X_train_norm, X_test_norm,hparams)\n",
    "    \n",
    "    train_acc, test_acc = get_accuracy(embd_train, embd_test, y_train_encoded, y_test_encoded)\n",
    "    \n",
    "    writer.add_scalar(\"Final_Accuracy/train\", train_acc)\n",
    "    writer.add_scalar(\"Final_Accuracy/test\", test_acc)\n",
    "    \n",
    "    tsne_train = TSNE(n_components=2, random_state=42).fit_transform(embd_train)\n",
    "    tsne_test = TSNE(n_components=2, random_state=42).fit_transform(embd_test)\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    tsne_train_scaled = scaler.fit_transform(tsne_train)\n",
    "    tsne_test_scaled = scaler.transform(tsne_test)\n",
    "    \n",
    "    fig_train = plot_tsne(tsne_train_scaled,\n",
    "          cmap,\n",
    "          y_train_encoded,\n",
    "          handles=train_handles,\n",
    "          alpha=0.5,\n",
    "          title=\"TSNE Visualization training data XVector\",\n",
    "          xlabel=\"TSNE embedding dimension 1\",\n",
    "          ylabel=\"TSNE embedding dimension 2\",\n",
    "          centroids=None,\n",
    "          return_fig=True)\n",
    "    writer.add_figure(\"tsne_train\", fig_train)\n",
    "    fig_test = plot_tsne(tsne_test_scaled,\n",
    "          cmap2,\n",
    "          y_test_encoded,\n",
    "          handles=test_handles,\n",
    "          alpha=0.5,\n",
    "          title=\"TSNE Visualization test data XVector\",\n",
    "          xlabel=\"TSNE embedding dimension 1\",\n",
    "          ylabel=\"TSNE embedding dimension 2\",\n",
    "          centroids=None, return_fig=True )\n",
    "    embd_unit = embd_train / np.linalg.norm(embd_train, axis=1, keepdims=True)\n",
    "    writer.add_figure(\"tsne_test\", fig_test)\n",
    "    \n",
    "    fig = plot_distance_distribution_return(\n",
    "        embeddings=embd_unit,\n",
    "        participant_ids=np.array(y_train_encoded),\n",
    "        distance_type=\"euclidean\",\n",
    "        bins=30\n",
    "    )\n",
    "    writer.add_figure(\"distance_distribution_euclidean\", fig)\n",
    "    \n",
    "    fig = plot_distance_distribution_return(\n",
    "        embeddings=embd_train,\n",
    "        participant_ids=np.array(y_train_encoded),\n",
    "        distance_type=\"cosine\",\n",
    "        bins=30\n",
    "    )\n",
    "    writer.add_figure(\"distance_distribution_cosine\", fig)\n",
    "    \n",
    "    # train\n",
    "    user_profiles = create_user_profiles(embd_train, np.array(y_train_encoded))\n",
    "    for metric in (\"euclidean\", \"cosine\"):\n",
    "        genuine_dists, imposter_dists = compute_genuine_imposter_distances(\n",
    "                embeddings=embd_train ,\n",
    "                ids=np.array(y_train_encoded),\n",
    "                user_profiles=user_profiles,\n",
    "                distance_metric=metric\n",
    "            )\n",
    "        \n",
    "        (\n",
    "            thresholds, fnr_list, fpr_list, acc_list,\n",
    "            best_T, best_fnr, best_fpr, best_acc\n",
    "        ) = compute_threshold_metrics(genuine_dists, imposter_dists, num_thresholds=200)\n",
    "        \n",
    "        fig = plot_threshold_metrics_return(\n",
    "            thresholds, fnr_list, fpr_list, acc_list,\n",
    "            best_T, best_fnr, best_fpr, best_acc\n",
    "        )\n",
    "        writer.add_figure(f\"threshold_metrics_train_{metric}\", fig)\n",
    "        \n",
    "        thresholds, f1_list, best_T, best_f1 = compute_f1_vs_threshold(\n",
    "            genuine_dists, imposter_dists, num_thresholds=300\n",
    "        )\n",
    "        \n",
    "        fig = plot_f1_vs_threshold_return(thresholds, f1_list, best_T, best_f1)\n",
    "        writer.add_figure(f\"f1_vs_threshold_train_{metric}\", fig)\n",
    "        \n",
    "\n",
    "    # test\n",
    "    profile_embd, profile_ids, verify_embd, verify_ids = split_test_data_for_verification(\n",
    "        embd_test, np.array(y_test_encoded), profile_ratio=0.6\n",
    "    )\n",
    "    \n",
    "    test_user_profiles = create_user_profiles(profile_embd, profile_ids)\n",
    "    for metric in (\"euclidean\", \"cosine\"):\n",
    "    \n",
    "        genuine_dists, imposter_dists = compute_genuine_imposter_distances(\n",
    "            embeddings=verify_embd,\n",
    "            ids=verify_ids,\n",
    "            user_profiles=test_user_profiles,\n",
    "            distance_metric=metric\n",
    "        )\n",
    "        \n",
    "        (\n",
    "            test_thresholds, test_fnr_list, test_fpr_list, test_acc_list,\n",
    "            test_best_T, test_best_fnr, test_best_fpr, test_best_acc\n",
    "        ) = compute_threshold_metrics(genuine_dists, imposter_dists, num_thresholds=200)\n",
    "        \n",
    "        fig = plot_threshold_metrics_return(\n",
    "            test_thresholds, test_fnr_list, test_fpr_list, test_acc_list,\n",
    "            test_best_T, test_best_fnr, test_best_fpr, test_best_acc\n",
    "        )\n",
    "        writer.add_figure(f\"threshold_metrics_test_{metric}\", fig)\n",
    "        \n",
    "        test_thresholds_f1, test_f1_list, test_best_T_f1, test_best_f1 = compute_f1_vs_threshold(\n",
    "            genuine_dists, imposter_dists, num_thresholds=300\n",
    "        )\n",
    "        \n",
    "        fig = plot_f1_vs_threshold_return(test_thresholds_f1, test_f1_list, test_best_T_f1, test_best_f1)\n",
    "        writer.add_figure(f\"f1_vs_threshold_train_{metric}\", fig)\n",
    "    writer.close()                                                                                                                                 "
   ],
   "id": "43d69c0634536bb1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pretrain] Epoch 1/50  Loss=3.2380  Acc=0.0399\n",
      "[Pretrain] Epoch 2/50  Loss=3.1011  Acc=0.0715\n",
      "[Pretrain] Epoch 3/50  Loss=3.0403  Acc=0.0821\n",
      "[Pretrain] Epoch 4/50  Loss=2.9355  Acc=0.1083\n",
      "[Pretrain] Epoch 5/50  Loss=2.6598  Acc=0.1638\n",
      "[Pretrain] Epoch 6/50  Loss=2.4585  Acc=0.2087\n",
      "[Pretrain] Epoch 7/50  Loss=2.3121  Acc=0.2575\n",
      "[Pretrain] Epoch 8/50  Loss=2.2135  Acc=0.2732\n",
      "[Pretrain] Epoch 9/50  Loss=2.1406  Acc=0.3024\n",
      "[Pretrain] Epoch 10/50  Loss=2.0923  Acc=0.3211\n",
      "[Pretrain] Epoch 11/50  Loss=2.0305  Acc=0.3441\n",
      "[Pretrain] Epoch 12/50  Loss=2.0249  Acc=0.3429\n",
      "[Pretrain] Epoch 13/50  Loss=1.9673  Acc=0.3617\n",
      "[Pretrain] Epoch 14/50  Loss=1.9344  Acc=0.3750\n",
      "[Pretrain] Epoch 15/50  Loss=1.9191  Acc=0.3854\n",
      "[Pretrain] Epoch 16/50  Loss=1.8801  Acc=0.3935\n",
      "[Pretrain] Epoch 17/50  Loss=1.8636  Acc=0.3960\n",
      "[Pretrain] Epoch 18/50  Loss=1.8429  Acc=0.4032\n",
      "[Pretrain] Epoch 19/50  Loss=1.8170  Acc=0.4082\n",
      "[Pretrain] Epoch 20/50  Loss=1.7888  Acc=0.4190\n",
      "[Pretrain] Epoch 21/50  Loss=1.7682  Acc=0.4206\n",
      "[Pretrain] Epoch 22/50  Loss=1.7292  Acc=0.4402\n",
      "[Pretrain] Epoch 23/50  Loss=1.7293  Acc=0.4384\n",
      "[Pretrain] Epoch 24/50  Loss=1.7089  Acc=0.4438\n",
      "[Pretrain] Epoch 25/50  Loss=1.7037  Acc=0.4441\n",
      "[Pretrain] Epoch 26/50  Loss=1.6791  Acc=0.4540\n",
      "[Pretrain] Epoch 27/50  Loss=1.6718  Acc=0.4553\n",
      "[Pretrain] Epoch 28/50  Loss=1.6306  Acc=0.4749\n",
      "[Pretrain] Epoch 29/50  Loss=1.6342  Acc=0.4718\n",
      "[Pretrain] Epoch 30/50  Loss=1.6127  Acc=0.4783\n",
      "[Pretrain] Epoch 31/50  Loss=1.5966  Acc=0.4802\n",
      "[Pretrain] Epoch 32/50  Loss=1.6028  Acc=0.4842\n",
      "[Pretrain] Epoch 33/50  Loss=1.5720  Acc=0.4916\n",
      "[Pretrain] Epoch 34/50  Loss=1.5697  Acc=0.4880\n",
      "[Pretrain] Epoch 35/50  Loss=1.5521  Acc=0.4969\n",
      "[Pretrain] Epoch 36/50  Loss=1.5406  Acc=0.5018\n",
      "[Pretrain] Epoch 37/50  Loss=1.5386  Acc=0.5014\n",
      "[Pretrain] Epoch 38/50  Loss=1.5098  Acc=0.5075\n",
      "[Pretrain] Epoch 39/50  Loss=1.5052  Acc=0.5038\n",
      "[Pretrain] Epoch 40/50  Loss=1.4947  Acc=0.5140\n",
      "[Pretrain] Epoch 41/50  Loss=1.4798  Acc=0.5162\n",
      "[Pretrain] Epoch 42/50  Loss=1.4748  Acc=0.5239\n",
      "[Pretrain] Epoch 43/50  Loss=1.4612  Acc=0.5253\n",
      "[Pretrain] Epoch 44/50  Loss=1.4563  Acc=0.5239\n",
      "[Pretrain] Epoch 45/50  Loss=1.4233  Acc=0.5323\n",
      "[Pretrain] Epoch 46/50  Loss=1.4418  Acc=0.5307\n",
      "[Pretrain] Epoch 47/50  Loss=1.4348  Acc=0.5366\n",
      "[Pretrain] Epoch 48/50  Loss=1.4223  Acc=0.5363\n",
      "[Pretrain] Epoch 49/50  Loss=1.4013  Acc=0.5438\n",
      "[Pretrain] Epoch 50/50  Loss=1.4154  Acc=0.5343\n",
      "[Fine-tune] Epoch 1/50  Loss=2.7962\n",
      "[Fine-tune] Epoch 2/50  Loss=2.3491\n",
      "[Fine-tune] Epoch 3/50  Loss=2.1433\n",
      "[Fine-tune] Epoch 4/50  Loss=2.0559\n",
      "[Fine-tune] Epoch 5/50  Loss=1.9672\n",
      "[Fine-tune] Epoch 6/50  Loss=1.8947\n",
      "[Fine-tune] Epoch 7/50  Loss=1.8194\n",
      "[Fine-tune] Epoch 8/50  Loss=1.8007\n",
      "[Fine-tune] Epoch 9/50  Loss=1.7260\n",
      "[Fine-tune] Epoch 10/50  Loss=1.7024\n",
      "[Fine-tune] Epoch 11/50  Loss=1.6611\n",
      "[Fine-tune] Epoch 12/50  Loss=1.6660\n",
      "[Fine-tune] Epoch 13/50  Loss=1.5968\n",
      "[Fine-tune] Epoch 14/50  Loss=1.5915\n",
      "[Fine-tune] Epoch 15/50  Loss=1.5286\n",
      "[Fine-tune] Epoch 16/50  Loss=1.5007\n",
      "[Fine-tune] Epoch 17/50  Loss=1.4790\n",
      "[Fine-tune] Epoch 18/50  Loss=1.4601\n",
      "[Fine-tune] Epoch 19/50  Loss=1.4160\n",
      "[Fine-tune] Epoch 20/50  Loss=1.4169\n",
      "[Fine-tune] Epoch 21/50  Loss=1.3724\n",
      "[Fine-tune] Epoch 22/50  Loss=1.3419\n",
      "[Fine-tune] Epoch 23/50  Loss=1.3329\n",
      "[Fine-tune] Epoch 24/50  Loss=1.3046\n",
      "[Fine-tune] Epoch 25/50  Loss=1.3161\n",
      "[Fine-tune] Epoch 26/50  Loss=1.2833\n",
      "[Fine-tune] Epoch 27/50  Loss=1.2643\n",
      "[Fine-tune] Epoch 28/50  Loss=1.2387\n",
      "[Fine-tune] Epoch 29/50  Loss=1.2235\n",
      "[Fine-tune] Epoch 30/50  Loss=1.2071\n",
      "[Fine-tune] Epoch 31/50  Loss=1.1968\n",
      "[Fine-tune] Epoch 32/50  Loss=1.2052\n",
      "[Fine-tune] Epoch 33/50  Loss=1.1641\n",
      "[Fine-tune] Epoch 34/50  Loss=1.1592\n",
      "[Fine-tune] Epoch 35/50  Loss=1.1472\n",
      "[Fine-tune] Epoch 36/50  Loss=1.1450\n",
      "[Fine-tune] Epoch 37/50  Loss=1.1262\n",
      "[Fine-tune] Epoch 38/50  Loss=1.1141\n",
      "[Fine-tune] Epoch 39/50  Loss=1.1076\n",
      "[Fine-tune] Epoch 40/50  Loss=1.0956\n",
      "[Fine-tune] Epoch 41/50  Loss=1.0744\n",
      "[Fine-tune] Epoch 42/50  Loss=1.0782\n",
      "[Fine-tune] Epoch 43/50  Loss=1.0671\n",
      "[Fine-tune] Epoch 44/50  Loss=1.0587\n",
      "[Fine-tune] Epoch 45/50  Loss=1.0558\n",
      "[Fine-tune] Epoch 46/50  Loss=1.0484\n",
      "[Fine-tune] Epoch 47/50  Loss=1.0522\n",
      "[Fine-tune] Epoch 48/50  Loss=1.0476\n",
      "[Fine-tune] Epoch 49/50  Loss=1.0376\n",
      "[Fine-tune] Epoch 50/50  Loss=1.0339\n",
      "[Pretrain] Epoch 1/50  Loss=3.6373  Acc=0.0429\n",
      "[Pretrain] Epoch 2/50  Loss=3.2031  Acc=0.0483\n",
      "[Pretrain] Epoch 3/50  Loss=3.0282  Acc=0.0837\n",
      "[Pretrain] Epoch 4/50  Loss=2.7515  Acc=0.1343\n",
      "[Pretrain] Epoch 5/50  Loss=2.5734  Acc=0.1765\n",
      "[Pretrain] Epoch 6/50  Loss=2.4781  Acc=0.2031\n",
      "[Pretrain] Epoch 7/50  Loss=2.3716  Acc=0.2272\n",
      "[Pretrain] Epoch 8/50  Loss=2.3275  Acc=0.2491\n",
      "[Pretrain] Epoch 9/50  Loss=2.2997  Acc=0.2507\n",
      "[Pretrain] Epoch 10/50  Loss=2.2474  Acc=0.2710\n",
      "[Pretrain] Epoch 11/50  Loss=2.2300  Acc=0.2735\n",
      "[Pretrain] Epoch 12/50  Loss=2.1774  Acc=0.2953\n",
      "[Pretrain] Epoch 13/50  Loss=2.1300  Acc=0.3087\n",
      "[Pretrain] Epoch 14/50  Loss=2.1116  Acc=0.3116\n",
      "[Pretrain] Epoch 15/50  Loss=2.0704  Acc=0.3209\n",
      "[Pretrain] Epoch 16/50  Loss=2.0417  Acc=0.3412\n",
      "[Pretrain] Epoch 17/50  Loss=1.9893  Acc=0.3484\n",
      "[Pretrain] Epoch 18/50  Loss=1.9777  Acc=0.3628\n",
      "[Pretrain] Epoch 19/50  Loss=1.9483  Acc=0.3642\n",
      "[Pretrain] Epoch 20/50  Loss=1.9401  Acc=0.3653\n",
      "[Pretrain] Epoch 21/50  Loss=1.8847  Acc=0.3852\n",
      "[Pretrain] Epoch 22/50  Loss=1.8512  Acc=0.3957\n",
      "[Pretrain] Epoch 23/50  Loss=1.8370  Acc=0.4048\n",
      "[Pretrain] Epoch 24/50  Loss=1.8206  Acc=0.4172\n",
      "[Pretrain] Epoch 25/50  Loss=1.7753  Acc=0.4224\n",
      "[Pretrain] Epoch 26/50  Loss=1.7658  Acc=0.4312\n",
      "[Pretrain] Epoch 27/50  Loss=1.7591  Acc=0.4282\n",
      "[Pretrain] Epoch 28/50  Loss=1.7215  Acc=0.4436\n",
      "[Pretrain] Epoch 29/50  Loss=1.6932  Acc=0.4420\n",
      "[Pretrain] Epoch 30/50  Loss=1.6668  Acc=0.4567\n",
      "[Pretrain] Epoch 31/50  Loss=1.6414  Acc=0.4673\n",
      "[Pretrain] Epoch 32/50  Loss=1.6217  Acc=0.4688\n",
      "[Pretrain] Epoch 33/50  Loss=1.6011  Acc=0.4822\n",
      "[Pretrain] Epoch 34/50  Loss=1.5641  Acc=0.4903\n",
      "[Pretrain] Epoch 35/50  Loss=1.5837  Acc=0.4822\n",
      "[Pretrain] Epoch 36/50  Loss=1.5432  Acc=0.4957\n",
      "[Pretrain] Epoch 37/50  Loss=1.5005  Acc=0.5054\n",
      "[Pretrain] Epoch 38/50  Loss=1.5095  Acc=0.5088\n",
      "[Pretrain] Epoch 39/50  Loss=1.4837  Acc=0.5208\n",
      "[Pretrain] Epoch 40/50  Loss=1.4728  Acc=0.5246\n",
      "[Pretrain] Epoch 41/50  Loss=1.4459  Acc=0.5307\n",
      "[Pretrain] Epoch 42/50  Loss=1.4368  Acc=0.5291\n",
      "[Pretrain] Epoch 43/50  Loss=1.4273  Acc=0.5384\n",
      "[Pretrain] Epoch 44/50  Loss=1.4177  Acc=0.5409\n",
      "[Pretrain] Epoch 45/50  Loss=1.3750  Acc=0.5444\n",
      "[Pretrain] Epoch 46/50  Loss=1.3923  Acc=0.5426\n",
      "[Pretrain] Epoch 47/50  Loss=1.3635  Acc=0.5539\n",
      "[Pretrain] Epoch 48/50  Loss=1.3513  Acc=0.5580\n",
      "[Pretrain] Epoch 49/50  Loss=1.3326  Acc=0.5621\n",
      "[Pretrain] Epoch 50/50  Loss=1.3090  Acc=0.5709\n",
      "[Fine-tune] Epoch 1/50  Loss=3.0354\n",
      "[Fine-tune] Epoch 2/50  Loss=2.5281\n",
      "[Fine-tune] Epoch 3/50  Loss=2.3605\n",
      "[Fine-tune] Epoch 4/50  Loss=2.2588\n",
      "[Fine-tune] Epoch 5/50  Loss=2.1731\n",
      "[Fine-tune] Epoch 6/50  Loss=2.1220\n",
      "[Fine-tune] Epoch 7/50  Loss=2.0758\n",
      "[Fine-tune] Epoch 8/50  Loss=2.0449\n",
      "[Fine-tune] Epoch 9/50  Loss=2.0132\n",
      "[Fine-tune] Epoch 10/50  Loss=1.9907\n",
      "[Fine-tune] Epoch 11/50  Loss=1.9638\n",
      "[Fine-tune] Epoch 12/50  Loss=1.9467\n",
      "[Fine-tune] Epoch 13/50  Loss=1.9294\n",
      "[Fine-tune] Epoch 14/50  Loss=1.9008\n",
      "[Fine-tune] Epoch 15/50  Loss=1.8735\n",
      "[Fine-tune] Epoch 16/50  Loss=1.8694\n",
      "[Fine-tune] Epoch 17/50  Loss=1.8576\n",
      "[Fine-tune] Epoch 18/50  Loss=1.8442\n",
      "[Fine-tune] Epoch 19/50  Loss=1.8413\n",
      "[Fine-tune] Epoch 20/50  Loss=1.8194\n",
      "[Fine-tune] Epoch 21/50  Loss=1.8036\n",
      "[Fine-tune] Epoch 22/50  Loss=1.7977\n",
      "[Fine-tune] Epoch 23/50  Loss=1.7927\n",
      "[Fine-tune] Epoch 24/50  Loss=1.7901\n",
      "[Fine-tune] Epoch 25/50  Loss=1.7779\n",
      "[Fine-tune] Epoch 26/50  Loss=1.7633\n",
      "[Fine-tune] Epoch 27/50  Loss=1.7680\n",
      "[Fine-tune] Epoch 28/50  Loss=1.7558\n",
      "[Fine-tune] Epoch 29/50  Loss=1.7508\n",
      "[Fine-tune] Epoch 30/50  Loss=1.7316\n",
      "[Fine-tune] Epoch 31/50  Loss=1.7378\n",
      "[Fine-tune] Epoch 32/50  Loss=1.7302\n",
      "[Fine-tune] Epoch 33/50  Loss=1.7249\n",
      "[Fine-tune] Epoch 34/50  Loss=1.7164\n",
      "[Fine-tune] Epoch 35/50  Loss=1.7253\n",
      "[Fine-tune] Epoch 36/50  Loss=1.7108\n",
      "[Fine-tune] Epoch 37/50  Loss=1.7094\n",
      "[Fine-tune] Epoch 38/50  Loss=1.6893\n",
      "[Fine-tune] Epoch 39/50  Loss=1.7139\n",
      "[Fine-tune] Epoch 40/50  Loss=1.6986\n",
      "[Fine-tune] Epoch 41/50  Loss=1.6878\n",
      "[Fine-tune] Epoch 42/50  Loss=1.6904\n",
      "[Fine-tune] Epoch 43/50  Loss=1.7026\n",
      "[Fine-tune] Epoch 44/50  Loss=1.6779\n",
      "[Fine-tune] Epoch 45/50  Loss=1.6813\n",
      "[Fine-tune] Epoch 46/50  Loss=1.6923\n",
      "[Fine-tune] Epoch 47/50  Loss=1.6628\n",
      "[Fine-tune] Epoch 48/50  Loss=1.6758\n",
      "[Fine-tune] Epoch 49/50  Loss=1.6796\n",
      "[Fine-tune] Epoch 50/50  Loss=1.6615\n",
      "[Pretrain] Epoch 1/75  Loss=3.2155  Acc=0.0510\n",
      "[Pretrain] Epoch 2/75  Loss=3.0451  Acc=0.0803\n",
      "[Pretrain] Epoch 3/75  Loss=2.8340  Acc=0.1298\n",
      "[Pretrain] Epoch 4/75  Loss=2.6402  Acc=0.1613\n",
      "[Pretrain] Epoch 5/75  Loss=2.4804  Acc=0.1965\n",
      "[Pretrain] Epoch 6/75  Loss=2.3350  Acc=0.2608\n",
      "[Pretrain] Epoch 7/75  Loss=2.1823  Acc=0.3033\n",
      "[Pretrain] Epoch 8/75  Loss=2.1547  Acc=0.3069\n",
      "[Pretrain] Epoch 9/75  Loss=2.0745  Acc=0.3272\n",
      "[Pretrain] Epoch 10/75  Loss=2.0354  Acc=0.3387\n",
      "[Pretrain] Epoch 11/75  Loss=1.9999  Acc=0.3450\n",
      "[Pretrain] Epoch 12/75  Loss=1.9665  Acc=0.3588\n",
      "[Pretrain] Epoch 13/75  Loss=1.9493  Acc=0.3673\n",
      "[Pretrain] Epoch 14/75  Loss=1.9163  Acc=0.3788\n",
      "[Pretrain] Epoch 15/75  Loss=1.8910  Acc=0.3793\n",
      "[Pretrain] Epoch 16/75  Loss=1.8811  Acc=0.3847\n",
      "[Pretrain] Epoch 17/75  Loss=1.8426  Acc=0.4041\n",
      "[Pretrain] Epoch 18/75  Loss=1.8271  Acc=0.4093\n",
      "[Pretrain] Epoch 19/75  Loss=1.8051  Acc=0.4206\n",
      "[Pretrain] Epoch 20/75  Loss=1.7764  Acc=0.4213\n",
      "[Pretrain] Epoch 21/75  Loss=1.7355  Acc=0.4375\n",
      "[Pretrain] Epoch 22/75  Loss=1.7533  Acc=0.4334\n",
      "[Pretrain] Epoch 23/75  Loss=1.7178  Acc=0.4445\n",
      "[Pretrain] Epoch 24/75  Loss=1.6911  Acc=0.4526\n",
      "[Pretrain] Epoch 25/75  Loss=1.6724  Acc=0.4610\n",
      "[Pretrain] Epoch 26/75  Loss=1.6496  Acc=0.4707\n",
      "[Pretrain] Epoch 27/75  Loss=1.6434  Acc=0.4684\n",
      "[Pretrain] Epoch 28/75  Loss=1.6213  Acc=0.4704\n",
      "[Pretrain] Epoch 29/75  Loss=1.6099  Acc=0.4799\n",
      "[Pretrain] Epoch 30/75  Loss=1.5718  Acc=0.4930\n",
      "[Pretrain] Epoch 31/75  Loss=1.5694  Acc=0.4862\n",
      "[Pretrain] Epoch 32/75  Loss=1.5627  Acc=0.4890\n",
      "[Pretrain] Epoch 33/75  Loss=1.5332  Acc=0.5074\n",
      "[Pretrain] Epoch 34/75  Loss=1.5247  Acc=0.5029\n",
      "[Pretrain] Epoch 35/75  Loss=1.5390  Acc=0.5066\n",
      "[Pretrain] Epoch 36/75  Loss=1.5119  Acc=0.5084\n",
      "[Pretrain] Epoch 37/75  Loss=1.4827  Acc=0.5207\n",
      "[Pretrain] Epoch 38/75  Loss=1.4782  Acc=0.5241\n",
      "[Pretrain] Epoch 39/75  Loss=1.4780  Acc=0.5291\n",
      "[Pretrain] Epoch 40/75  Loss=1.4503  Acc=0.5293\n",
      "[Pretrain] Epoch 41/75  Loss=1.4477  Acc=0.5350\n",
      "[Pretrain] Epoch 42/75  Loss=1.4384  Acc=0.5305\n",
      "[Pretrain] Epoch 43/75  Loss=1.4168  Acc=0.5296\n",
      "[Pretrain] Epoch 44/75  Loss=1.4208  Acc=0.5368\n",
      "[Pretrain] Epoch 45/75  Loss=1.4003  Acc=0.5465\n",
      "[Pretrain] Epoch 46/75  Loss=1.4083  Acc=0.5386\n",
      "[Pretrain] Epoch 47/75  Loss=1.4177  Acc=0.5379\n",
      "[Pretrain] Epoch 48/75  Loss=1.3909  Acc=0.5469\n",
      "[Pretrain] Epoch 49/75  Loss=1.3671  Acc=0.5607\n",
      "[Pretrain] Epoch 50/75  Loss=1.3738  Acc=0.5492\n",
      "[Pretrain] Epoch 51/75  Loss=1.3596  Acc=0.5621\n",
      "[Pretrain] Epoch 52/75  Loss=1.3700  Acc=0.5539\n",
      "[Pretrain] Epoch 53/75  Loss=1.3657  Acc=0.5594\n",
      "[Pretrain] Epoch 54/75  Loss=1.3615  Acc=0.5506\n",
      "[Pretrain] Epoch 55/75  Loss=1.3400  Acc=0.5663\n",
      "[Pretrain] Epoch 56/75  Loss=1.3372  Acc=0.5641\n",
      "[Pretrain] Epoch 57/75  Loss=1.3277  Acc=0.5591\n",
      "[Pretrain] Epoch 58/75  Loss=1.3121  Acc=0.5661\n",
      "[Pretrain] Epoch 59/75  Loss=1.3374  Acc=0.5672\n",
      "[Pretrain] Epoch 60/75  Loss=1.3421  Acc=0.5643\n",
      "[Pretrain] Epoch 61/75  Loss=1.3326  Acc=0.5677\n",
      "[Pretrain] Epoch 62/75  Loss=1.3184  Acc=0.5711\n",
      "[Pretrain] Epoch 63/75  Loss=1.3072  Acc=0.5763\n",
      "[Pretrain] Epoch 64/75  Loss=1.3151  Acc=0.5744\n",
      "[Pretrain] Epoch 65/75  Loss=1.3098  Acc=0.5760\n",
      "[Pretrain] Epoch 66/75  Loss=1.3066  Acc=0.5749\n",
      "[Pretrain] Epoch 67/75  Loss=1.3016  Acc=0.5753\n",
      "[Pretrain] Epoch 68/75  Loss=1.3041  Acc=0.5790\n",
      "[Pretrain] Epoch 69/75  Loss=1.3052  Acc=0.5815\n",
      "[Pretrain] Epoch 70/75  Loss=1.2952  Acc=0.5783\n",
      "[Pretrain] Epoch 71/75  Loss=1.2995  Acc=0.5745\n",
      "[Pretrain] Epoch 72/75  Loss=1.2866  Acc=0.5824\n",
      "[Pretrain] Epoch 73/75  Loss=1.2920  Acc=0.5824\n",
      "[Pretrain] Epoch 74/75  Loss=1.2846  Acc=0.5832\n",
      "[Pretrain] Epoch 75/75  Loss=1.2796  Acc=0.5812\n",
      "[Fine-tune] Epoch 1/50  Loss=2.7049\n",
      "[Fine-tune] Epoch 2/50  Loss=2.2305\n",
      "[Fine-tune] Epoch 3/50  Loss=2.0933\n",
      "[Fine-tune] Epoch 4/50  Loss=2.0019\n",
      "[Fine-tune] Epoch 5/50  Loss=1.9092\n",
      "[Fine-tune] Epoch 6/50  Loss=1.8351\n",
      "[Fine-tune] Epoch 7/50  Loss=1.8076\n",
      "[Fine-tune] Epoch 8/50  Loss=1.7541\n",
      "[Fine-tune] Epoch 9/50  Loss=1.7052\n",
      "[Fine-tune] Epoch 10/50  Loss=1.6717\n",
      "[Fine-tune] Epoch 11/50  Loss=1.6161\n",
      "[Fine-tune] Epoch 12/50  Loss=1.6109\n",
      "[Fine-tune] Epoch 13/50  Loss=1.5540\n",
      "[Fine-tune] Epoch 14/50  Loss=1.5367\n",
      "[Fine-tune] Epoch 15/50  Loss=1.4974\n",
      "[Fine-tune] Epoch 16/50  Loss=1.4620\n",
      "[Fine-tune] Epoch 17/50  Loss=1.4544\n",
      "[Fine-tune] Epoch 18/50  Loss=1.4201\n",
      "[Fine-tune] Epoch 19/50  Loss=1.4066\n",
      "[Fine-tune] Epoch 20/50  Loss=1.3695\n",
      "[Fine-tune] Epoch 21/50  Loss=1.3439\n",
      "[Fine-tune] Epoch 22/50  Loss=1.3249\n",
      "[Fine-tune] Epoch 23/50  Loss=1.2980\n",
      "[Fine-tune] Epoch 24/50  Loss=1.2723\n",
      "[Fine-tune] Epoch 25/50  Loss=1.2612\n",
      "[Fine-tune] Epoch 26/50  Loss=1.2362\n",
      "[Fine-tune] Epoch 27/50  Loss=1.2324\n",
      "[Fine-tune] Epoch 28/50  Loss=1.2085\n",
      "[Fine-tune] Epoch 29/50  Loss=1.1989\n",
      "[Fine-tune] Epoch 30/50  Loss=1.1739\n",
      "[Fine-tune] Epoch 31/50  Loss=1.1814\n",
      "[Fine-tune] Epoch 32/50  Loss=1.1541\n",
      "[Fine-tune] Epoch 33/50  Loss=1.1398\n",
      "[Fine-tune] Epoch 34/50  Loss=1.1378\n",
      "[Fine-tune] Epoch 35/50  Loss=1.1216\n",
      "[Fine-tune] Epoch 36/50  Loss=1.1094\n",
      "[Fine-tune] Epoch 37/50  Loss=1.1165\n",
      "[Fine-tune] Epoch 38/50  Loss=1.0909\n",
      "[Fine-tune] Epoch 39/50  Loss=1.0806\n",
      "[Fine-tune] Epoch 40/50  Loss=1.0727\n",
      "[Fine-tune] Epoch 41/50  Loss=1.0719\n",
      "[Fine-tune] Epoch 42/50  Loss=1.0726\n",
      "[Fine-tune] Epoch 43/50  Loss=1.0657\n",
      "[Fine-tune] Epoch 44/50  Loss=1.0393\n",
      "[Fine-tune] Epoch 45/50  Loss=1.0270\n",
      "[Fine-tune] Epoch 46/50  Loss=1.0416\n",
      "[Fine-tune] Epoch 47/50  Loss=1.0324\n",
      "[Fine-tune] Epoch 48/50  Loss=1.0281\n",
      "[Fine-tune] Epoch 49/50  Loss=1.0182\n",
      "[Fine-tune] Epoch 50/50  Loss=1.0181\n",
      "[Pretrain] Epoch 1/75  Loss=3.7084  Acc=0.0406\n",
      "[Pretrain] Epoch 2/75  Loss=3.1558  Acc=0.0656\n",
      "[Pretrain] Epoch 3/75  Loss=3.0451  Acc=0.0860\n",
      "[Pretrain] Epoch 4/75  Loss=2.8918  Acc=0.1097\n",
      "[Pretrain] Epoch 5/75  Loss=2.7064  Acc=0.1440\n",
      "[Pretrain] Epoch 6/75  Loss=2.5123  Acc=0.2067\n",
      "[Pretrain] Epoch 7/75  Loss=2.3977  Acc=0.2315\n",
      "[Pretrain] Epoch 8/75  Loss=2.3209  Acc=0.2584\n",
      "[Pretrain] Epoch 9/75  Loss=2.2641  Acc=0.2750\n",
      "[Pretrain] Epoch 10/75  Loss=2.2076  Acc=0.2883\n",
      "[Pretrain] Epoch 11/75  Loss=2.1669  Acc=0.3035\n",
      "[Pretrain] Epoch 12/75  Loss=2.1550  Acc=0.3044\n",
      "[Pretrain] Epoch 13/75  Loss=2.1095  Acc=0.3148\n",
      "[Pretrain] Epoch 14/75  Loss=2.0498  Acc=0.3369\n",
      "[Pretrain] Epoch 15/75  Loss=2.0313  Acc=0.3421\n",
      "[Pretrain] Epoch 16/75  Loss=1.9959  Acc=0.3526\n",
      "[Pretrain] Epoch 17/75  Loss=1.9733  Acc=0.3579\n",
      "[Pretrain] Epoch 18/75  Loss=1.9491  Acc=0.3714\n",
      "[Pretrain] Epoch 19/75  Loss=1.9068  Acc=0.3775\n",
      "[Pretrain] Epoch 20/75  Loss=1.8804  Acc=0.3827\n",
      "[Pretrain] Epoch 21/75  Loss=1.9006  Acc=0.3766\n",
      "[Pretrain] Epoch 22/75  Loss=1.8571  Acc=0.3946\n",
      "[Pretrain] Epoch 23/75  Loss=1.8343  Acc=0.4005\n",
      "[Pretrain] Epoch 24/75  Loss=1.8185  Acc=0.4091\n",
      "[Pretrain] Epoch 25/75  Loss=1.7965  Acc=0.4131\n",
      "[Pretrain] Epoch 26/75  Loss=1.7783  Acc=0.4208\n",
      "[Pretrain] Epoch 27/75  Loss=1.7490  Acc=0.4357\n",
      "[Pretrain] Epoch 28/75  Loss=1.7208  Acc=0.4337\n",
      "[Pretrain] Epoch 29/75  Loss=1.6983  Acc=0.4434\n",
      "[Pretrain] Epoch 30/75  Loss=1.6789  Acc=0.4520\n",
      "[Pretrain] Epoch 31/75  Loss=1.6520  Acc=0.4562\n",
      "[Pretrain] Epoch 32/75  Loss=1.6414  Acc=0.4670\n",
      "[Pretrain] Epoch 33/75  Loss=1.6209  Acc=0.4655\n",
      "[Pretrain] Epoch 34/75  Loss=1.6076  Acc=0.4736\n",
      "[Pretrain] Epoch 35/75  Loss=1.5813  Acc=0.4806\n",
      "[Pretrain] Epoch 36/75  Loss=1.5709  Acc=0.4901\n",
      "[Pretrain] Epoch 37/75  Loss=1.5615  Acc=0.4894\n",
      "[Pretrain] Epoch 38/75  Loss=1.5430  Acc=0.4966\n",
      "[Pretrain] Epoch 39/75  Loss=1.5302  Acc=0.5031\n",
      "[Pretrain] Epoch 40/75  Loss=1.5095  Acc=0.5059\n",
      "[Pretrain] Epoch 41/75  Loss=1.4817  Acc=0.5074\n",
      "[Pretrain] Epoch 42/75  Loss=1.4751  Acc=0.5120\n",
      "[Pretrain] Epoch 43/75  Loss=1.4425  Acc=0.5341\n",
      "[Pretrain] Epoch 44/75  Loss=1.4406  Acc=0.5228\n",
      "[Pretrain] Epoch 45/75  Loss=1.4431  Acc=0.5293\n",
      "[Pretrain] Epoch 46/75  Loss=1.4201  Acc=0.5343\n",
      "[Pretrain] Epoch 47/75  Loss=1.4129  Acc=0.5347\n",
      "[Pretrain] Epoch 48/75  Loss=1.3900  Acc=0.5436\n",
      "[Pretrain] Epoch 49/75  Loss=1.3740  Acc=0.5551\n",
      "[Pretrain] Epoch 50/75  Loss=1.3747  Acc=0.5445\n",
      "[Pretrain] Epoch 51/75  Loss=1.3417  Acc=0.5648\n",
      "[Pretrain] Epoch 52/75  Loss=1.3319  Acc=0.5652\n",
      "[Pretrain] Epoch 53/75  Loss=1.3266  Acc=0.5656\n",
      "[Pretrain] Epoch 54/75  Loss=1.3264  Acc=0.5665\n",
      "[Pretrain] Epoch 55/75  Loss=1.3261  Acc=0.5627\n",
      "[Pretrain] Epoch 56/75  Loss=1.2993  Acc=0.5778\n",
      "[Pretrain] Epoch 57/75  Loss=1.3075  Acc=0.5691\n",
      "[Pretrain] Epoch 58/75  Loss=1.2881  Acc=0.5828\n",
      "[Pretrain] Epoch 59/75  Loss=1.2932  Acc=0.5821\n",
      "[Pretrain] Epoch 60/75  Loss=1.2838  Acc=0.5724\n",
      "[Pretrain] Epoch 61/75  Loss=1.2737  Acc=0.5819\n",
      "[Pretrain] Epoch 62/75  Loss=1.2594  Acc=0.5871\n",
      "[Pretrain] Epoch 63/75  Loss=1.2552  Acc=0.5907\n",
      "[Pretrain] Epoch 64/75  Loss=1.2561  Acc=0.5842\n",
      "[Pretrain] Epoch 65/75  Loss=1.2458  Acc=0.5907\n",
      "[Pretrain] Epoch 66/75  Loss=1.2253  Acc=0.5991\n",
      "[Pretrain] Epoch 67/75  Loss=1.2252  Acc=0.5991\n",
      "[Pretrain] Epoch 68/75  Loss=1.2271  Acc=0.5898\n",
      "[Pretrain] Epoch 69/75  Loss=1.2245  Acc=0.6015\n",
      "[Pretrain] Epoch 70/75  Loss=1.1979  Acc=0.6027\n",
      "[Pretrain] Epoch 71/75  Loss=1.2076  Acc=0.6006\n",
      "[Pretrain] Epoch 72/75  Loss=1.2189  Acc=0.6069\n",
      "[Pretrain] Epoch 73/75  Loss=1.1986  Acc=0.6061\n",
      "[Pretrain] Epoch 74/75  Loss=1.2065  Acc=0.6004\n",
      "[Pretrain] Epoch 75/75  Loss=1.1983  Acc=0.6063\n",
      "[Fine-tune] Epoch 1/50  Loss=3.1495\n",
      "[Fine-tune] Epoch 2/50  Loss=2.6973\n",
      "[Fine-tune] Epoch 3/50  Loss=2.4477\n",
      "[Fine-tune] Epoch 4/50  Loss=2.3089\n",
      "[Fine-tune] Epoch 5/50  Loss=2.2198\n",
      "[Fine-tune] Epoch 6/50  Loss=2.1399\n",
      "[Fine-tune] Epoch 7/50  Loss=2.1001\n",
      "[Fine-tune] Epoch 8/50  Loss=2.0731\n",
      "[Fine-tune] Epoch 9/50  Loss=2.0454\n",
      "[Fine-tune] Epoch 10/50  Loss=2.0155\n",
      "[Fine-tune] Epoch 11/50  Loss=1.9816\n",
      "[Fine-tune] Epoch 12/50  Loss=1.9626\n",
      "[Fine-tune] Epoch 13/50  Loss=1.9508\n",
      "[Fine-tune] Epoch 14/50  Loss=1.9450\n",
      "[Fine-tune] Epoch 15/50  Loss=1.9112\n",
      "[Fine-tune] Epoch 16/50  Loss=1.9204\n",
      "[Fine-tune] Epoch 17/50  Loss=1.8842\n",
      "[Fine-tune] Epoch 18/50  Loss=1.8814\n",
      "[Fine-tune] Epoch 19/50  Loss=1.8594\n",
      "[Fine-tune] Epoch 20/50  Loss=1.8419\n",
      "[Fine-tune] Epoch 21/50  Loss=1.8494\n",
      "[Fine-tune] Epoch 22/50  Loss=1.8341\n",
      "[Fine-tune] Epoch 23/50  Loss=1.8163\n",
      "[Fine-tune] Epoch 24/50  Loss=1.8177\n",
      "[Fine-tune] Epoch 25/50  Loss=1.7862\n",
      "[Fine-tune] Epoch 26/50  Loss=1.7889\n",
      "[Fine-tune] Epoch 27/50  Loss=1.7833\n",
      "[Fine-tune] Epoch 28/50  Loss=1.7935\n",
      "[Fine-tune] Epoch 29/50  Loss=1.7851\n",
      "[Fine-tune] Epoch 30/50  Loss=1.7708\n",
      "[Fine-tune] Epoch 31/50  Loss=1.7714\n",
      "[Fine-tune] Epoch 32/50  Loss=1.7558\n",
      "[Fine-tune] Epoch 33/50  Loss=1.7567\n",
      "[Fine-tune] Epoch 34/50  Loss=1.7432\n",
      "[Fine-tune] Epoch 35/50  Loss=1.7321\n",
      "[Fine-tune] Epoch 36/50  Loss=1.7338\n",
      "[Fine-tune] Epoch 37/50  Loss=1.7315\n",
      "[Fine-tune] Epoch 38/50  Loss=1.7271\n",
      "[Fine-tune] Epoch 39/50  Loss=1.7246\n",
      "[Fine-tune] Epoch 40/50  Loss=1.7312\n",
      "[Fine-tune] Epoch 41/50  Loss=1.7156\n",
      "[Fine-tune] Epoch 42/50  Loss=1.7146\n",
      "[Fine-tune] Epoch 43/50  Loss=1.7167\n",
      "[Fine-tune] Epoch 44/50  Loss=1.7119\n",
      "[Fine-tune] Epoch 45/50  Loss=1.7143\n",
      "[Fine-tune] Epoch 46/50  Loss=1.7092\n",
      "[Fine-tune] Epoch 47/50  Loss=1.6909\n",
      "[Fine-tune] Epoch 48/50  Loss=1.6921\n",
      "[Fine-tune] Epoch 49/50  Loss=1.7064\n",
      "[Fine-tune] Epoch 50/50  Loss=1.6934\n",
      "[Pretrain] Epoch 1/100  Loss=3.2426  Acc=0.0393\n",
      "[Pretrain] Epoch 2/100  Loss=3.0881  Acc=0.0796\n",
      "[Pretrain] Epoch 3/100  Loss=3.0505  Acc=0.0855\n",
      "[Pretrain] Epoch 4/100  Loss=2.9153  Acc=0.1020\n",
      "[Pretrain] Epoch 5/100  Loss=2.6321  Acc=0.1659\n",
      "[Pretrain] Epoch 6/100  Loss=2.5019  Acc=0.2042\n",
      "[Pretrain] Epoch 7/100  Loss=2.3982  Acc=0.2232\n",
      "[Pretrain] Epoch 8/100  Loss=2.3142  Acc=0.2448\n",
      "[Pretrain] Epoch 9/100  Loss=2.2569  Acc=0.2708\n",
      "[Pretrain] Epoch 10/100  Loss=2.1808  Acc=0.2924\n",
      "[Pretrain] Epoch 11/100  Loss=2.1650  Acc=0.2974\n",
      "[Pretrain] Epoch 12/100  Loss=2.0887  Acc=0.3233\n",
      "[Pretrain] Epoch 13/100  Loss=2.0346  Acc=0.3261\n",
      "[Pretrain] Epoch 14/100  Loss=1.9887  Acc=0.3556\n",
      "[Pretrain] Epoch 15/100  Loss=1.9536  Acc=0.3567\n",
      "[Pretrain] Epoch 16/100  Loss=1.9356  Acc=0.3737\n",
      "[Pretrain] Epoch 17/100  Loss=1.8823  Acc=0.3851\n",
      "[Pretrain] Epoch 18/100  Loss=1.8738  Acc=0.3969\n",
      "[Pretrain] Epoch 19/100  Loss=1.8668  Acc=0.3939\n",
      "[Pretrain] Epoch 20/100  Loss=1.8169  Acc=0.3980\n",
      "[Pretrain] Epoch 21/100  Loss=1.8025  Acc=0.4045\n",
      "[Pretrain] Epoch 22/100  Loss=1.7798  Acc=0.4190\n",
      "[Pretrain] Epoch 23/100  Loss=1.7556  Acc=0.4282\n",
      "[Pretrain] Epoch 24/100  Loss=1.7227  Acc=0.4447\n",
      "[Pretrain] Epoch 25/100  Loss=1.7157  Acc=0.4485\n",
      "[Pretrain] Epoch 26/100  Loss=1.7344  Acc=0.4422\n",
      "[Pretrain] Epoch 27/100  Loss=1.6776  Acc=0.4562\n",
      "[Pretrain] Epoch 28/100  Loss=1.6594  Acc=0.4652\n",
      "[Pretrain] Epoch 29/100  Loss=1.6426  Acc=0.4641\n",
      "[Pretrain] Epoch 30/100  Loss=1.6176  Acc=0.4743\n",
      "[Pretrain] Epoch 31/100  Loss=1.6260  Acc=0.4793\n",
      "[Pretrain] Epoch 32/100  Loss=1.5961  Acc=0.4792\n",
      "[Pretrain] Epoch 33/100  Loss=1.5875  Acc=0.4892\n",
      "[Pretrain] Epoch 34/100  Loss=1.5722  Acc=0.4883\n",
      "[Pretrain] Epoch 35/100  Loss=1.5604  Acc=0.4889\n",
      "[Pretrain] Epoch 36/100  Loss=1.5384  Acc=0.4998\n",
      "[Pretrain] Epoch 37/100  Loss=1.5223  Acc=0.5065\n",
      "[Pretrain] Epoch 38/100  Loss=1.5157  Acc=0.5022\n",
      "[Pretrain] Epoch 39/100  Loss=1.5029  Acc=0.5110\n",
      "[Pretrain] Epoch 40/100  Loss=1.4997  Acc=0.5128\n",
      "[Pretrain] Epoch 41/100  Loss=1.4676  Acc=0.5205\n",
      "[Pretrain] Epoch 42/100  Loss=1.4595  Acc=0.5216\n",
      "[Pretrain] Epoch 43/100  Loss=1.4736  Acc=0.5233\n",
      "[Pretrain] Epoch 44/100  Loss=1.4536  Acc=0.5295\n",
      "[Pretrain] Epoch 45/100  Loss=1.4488  Acc=0.5271\n",
      "[Pretrain] Epoch 46/100  Loss=1.4301  Acc=0.5334\n",
      "[Pretrain] Epoch 47/100  Loss=1.4342  Acc=0.5312\n",
      "[Pretrain] Epoch 48/100  Loss=1.4158  Acc=0.5345\n",
      "[Pretrain] Epoch 49/100  Loss=1.4213  Acc=0.5383\n",
      "[Pretrain] Epoch 50/100  Loss=1.4278  Acc=0.5363\n",
      "[Pretrain] Epoch 51/100  Loss=1.4101  Acc=0.5411\n",
      "[Pretrain] Epoch 52/100  Loss=1.3992  Acc=0.5528\n",
      "[Pretrain] Epoch 53/100  Loss=1.4078  Acc=0.5365\n",
      "[Pretrain] Epoch 54/100  Loss=1.3850  Acc=0.5514\n",
      "[Pretrain] Epoch 55/100  Loss=1.3808  Acc=0.5555\n",
      "[Pretrain] Epoch 56/100  Loss=1.3812  Acc=0.5546\n",
      "[Pretrain] Epoch 57/100  Loss=1.3698  Acc=0.5519\n",
      "[Pretrain] Epoch 58/100  Loss=1.3636  Acc=0.5566\n",
      "[Pretrain] Epoch 59/100  Loss=1.3663  Acc=0.5580\n",
      "[Pretrain] Epoch 60/100  Loss=1.3682  Acc=0.5551\n",
      "[Pretrain] Epoch 61/100  Loss=1.3562  Acc=0.5612\n",
      "[Pretrain] Epoch 62/100  Loss=1.3669  Acc=0.5544\n",
      "[Pretrain] Epoch 63/100  Loss=1.3585  Acc=0.5564\n",
      "[Pretrain] Epoch 64/100  Loss=1.3464  Acc=0.5616\n",
      "[Pretrain] Epoch 65/100  Loss=1.3597  Acc=0.5550\n",
      "[Pretrain] Epoch 66/100  Loss=1.3447  Acc=0.5657\n",
      "[Pretrain] Epoch 67/100  Loss=1.3459  Acc=0.5652\n",
      "[Pretrain] Epoch 68/100  Loss=1.3454  Acc=0.5578\n",
      "[Pretrain] Epoch 69/100  Loss=1.3421  Acc=0.5691\n",
      "[Pretrain] Epoch 70/100  Loss=1.3463  Acc=0.5584\n",
      "[Pretrain] Epoch 71/100  Loss=1.3228  Acc=0.5749\n",
      "[Pretrain] Epoch 72/100  Loss=1.3258  Acc=0.5706\n",
      "[Pretrain] Epoch 73/100  Loss=1.3246  Acc=0.5709\n",
      "[Pretrain] Epoch 74/100  Loss=1.3188  Acc=0.5756\n",
      "[Pretrain] Epoch 75/100  Loss=1.3303  Acc=0.5753\n",
      "[Pretrain] Epoch 76/100  Loss=1.3155  Acc=0.5618\n",
      "[Pretrain] Epoch 77/100  Loss=1.3074  Acc=0.5787\n",
      "[Pretrain] Epoch 78/100  Loss=1.3104  Acc=0.5704\n",
      "[Pretrain] Epoch 79/100  Loss=1.2990  Acc=0.5815\n",
      "[Pretrain] Epoch 80/100  Loss=1.3041  Acc=0.5781\n",
      "[Pretrain] Epoch 81/100  Loss=1.3168  Acc=0.5722\n",
      "[Pretrain] Epoch 82/100  Loss=1.3074  Acc=0.5754\n",
      "[Pretrain] Epoch 83/100  Loss=1.2933  Acc=0.5797\n",
      "[Pretrain] Epoch 84/100  Loss=1.3087  Acc=0.5704\n",
      "[Pretrain] Epoch 85/100  Loss=1.3124  Acc=0.5697\n",
      "[Pretrain] Epoch 86/100  Loss=1.3040  Acc=0.5753\n",
      "[Pretrain] Epoch 87/100  Loss=1.3105  Acc=0.5744\n",
      "[Pretrain] Epoch 88/100  Loss=1.3055  Acc=0.5774\n",
      "[Pretrain] Epoch 89/100  Loss=1.3080  Acc=0.5785\n",
      "[Pretrain] Epoch 90/100  Loss=1.2977  Acc=0.5801\n",
      "[Pretrain] Epoch 91/100  Loss=1.2958  Acc=0.5810\n",
      "[Pretrain] Epoch 92/100  Loss=1.3107  Acc=0.5744\n",
      "[Pretrain] Epoch 93/100  Loss=1.2904  Acc=0.5817\n",
      "[Pretrain] Epoch 94/100  Loss=1.2959  Acc=0.5803\n",
      "[Pretrain] Epoch 95/100  Loss=1.2840  Acc=0.5801\n",
      "[Pretrain] Epoch 96/100  Loss=1.3002  Acc=0.5736\n",
      "[Pretrain] Epoch 97/100  Loss=1.3044  Acc=0.5693\n",
      "[Pretrain] Epoch 98/100  Loss=1.2831  Acc=0.5853\n",
      "[Pretrain] Epoch 99/100  Loss=1.3048  Acc=0.5832\n",
      "[Pretrain] Epoch 100/100  Loss=1.2989  Acc=0.5787\n",
      "[Fine-tune] Epoch 1/50  Loss=2.7987\n",
      "[Fine-tune] Epoch 2/50  Loss=2.2986\n",
      "[Fine-tune] Epoch 3/50  Loss=2.0931\n",
      "[Fine-tune] Epoch 4/50  Loss=1.9980\n",
      "[Fine-tune] Epoch 5/50  Loss=1.8916\n",
      "[Fine-tune] Epoch 6/50  Loss=1.8433\n",
      "[Fine-tune] Epoch 7/50  Loss=1.8006\n",
      "[Fine-tune] Epoch 8/50  Loss=1.7175\n",
      "[Fine-tune] Epoch 9/50  Loss=1.6781\n",
      "[Fine-tune] Epoch 10/50  Loss=1.6307\n",
      "[Fine-tune] Epoch 11/50  Loss=1.6107\n",
      "[Fine-tune] Epoch 12/50  Loss=1.5464\n",
      "[Fine-tune] Epoch 13/50  Loss=1.5400\n",
      "[Fine-tune] Epoch 14/50  Loss=1.5276\n",
      "[Fine-tune] Epoch 15/50  Loss=1.4670\n",
      "[Fine-tune] Epoch 16/50  Loss=1.4345\n",
      "[Fine-tune] Epoch 17/50  Loss=1.4217\n",
      "[Fine-tune] Epoch 18/50  Loss=1.3973\n",
      "[Fine-tune] Epoch 19/50  Loss=1.3677\n",
      "[Fine-tune] Epoch 20/50  Loss=1.3491\n",
      "[Fine-tune] Epoch 21/50  Loss=1.3297\n",
      "[Fine-tune] Epoch 22/50  Loss=1.3162\n",
      "[Fine-tune] Epoch 23/50  Loss=1.2836\n",
      "[Fine-tune] Epoch 24/50  Loss=1.2587\n",
      "[Fine-tune] Epoch 25/50  Loss=1.2305\n",
      "[Fine-tune] Epoch 26/50  Loss=1.2292\n",
      "[Fine-tune] Epoch 27/50  Loss=1.2178\n",
      "[Fine-tune] Epoch 28/50  Loss=1.1931\n",
      "[Fine-tune] Epoch 29/50  Loss=1.1817\n",
      "[Fine-tune] Epoch 30/50  Loss=1.1545\n",
      "[Fine-tune] Epoch 31/50  Loss=1.1613\n",
      "[Fine-tune] Epoch 32/50  Loss=1.1517\n",
      "[Fine-tune] Epoch 33/50  Loss=1.1298\n",
      "[Fine-tune] Epoch 34/50  Loss=1.1222\n",
      "[Fine-tune] Epoch 35/50  Loss=1.1174\n",
      "[Fine-tune] Epoch 36/50  Loss=1.0849\n",
      "[Fine-tune] Epoch 37/50  Loss=1.0807\n",
      "[Fine-tune] Epoch 38/50  Loss=1.0823\n",
      "[Fine-tune] Epoch 39/50  Loss=1.0656\n",
      "[Fine-tune] Epoch 40/50  Loss=1.0624\n",
      "[Fine-tune] Epoch 41/50  Loss=1.0572\n",
      "[Fine-tune] Epoch 42/50  Loss=1.0497\n",
      "[Fine-tune] Epoch 43/50  Loss=1.0346\n",
      "[Fine-tune] Epoch 44/50  Loss=1.0232\n",
      "[Fine-tune] Epoch 45/50  Loss=1.0211\n",
      "[Fine-tune] Epoch 46/50  Loss=1.0306\n",
      "[Fine-tune] Epoch 47/50  Loss=1.0175\n",
      "[Fine-tune] Epoch 48/50  Loss=1.0209\n",
      "[Fine-tune] Epoch 49/50  Loss=0.9983\n",
      "[Fine-tune] Epoch 50/50  Loss=0.9968\n",
      "[Pretrain] Epoch 1/100  Loss=3.5964  Acc=0.0490\n",
      "[Pretrain] Epoch 2/100  Loss=3.0646  Acc=0.0785\n",
      "[Pretrain] Epoch 3/100  Loss=2.7907  Acc=0.1180\n",
      "[Pretrain] Epoch 4/100  Loss=2.6281  Acc=0.1573\n",
      "[Pretrain] Epoch 5/100  Loss=2.5501  Acc=0.1830\n",
      "[Pretrain] Epoch 6/100  Loss=2.4718  Acc=0.2107\n",
      "[Pretrain] Epoch 7/100  Loss=2.4138  Acc=0.2299\n",
      "[Pretrain] Epoch 8/100  Loss=2.3458  Acc=0.2557\n",
      "[Pretrain] Epoch 9/100  Loss=2.2911  Acc=0.2548\n",
      "[Pretrain] Epoch 10/100  Loss=2.2453  Acc=0.2699\n",
      "[Pretrain] Epoch 11/100  Loss=2.1987  Acc=0.2847\n",
      "[Pretrain] Epoch 12/100  Loss=2.1799  Acc=0.2886\n",
      "[Pretrain] Epoch 13/100  Loss=2.1318  Acc=0.3024\n",
      "[Pretrain] Epoch 14/100  Loss=2.1197  Acc=0.3139\n",
      "[Pretrain] Epoch 15/100  Loss=2.0883  Acc=0.3256\n",
      "[Pretrain] Epoch 16/100  Loss=2.0411  Acc=0.3306\n",
      "[Pretrain] Epoch 17/100  Loss=2.0207  Acc=0.3429\n",
      "[Pretrain] Epoch 18/100  Loss=1.9851  Acc=0.3513\n",
      "[Pretrain] Epoch 19/100  Loss=1.9841  Acc=0.3590\n",
      "[Pretrain] Epoch 20/100  Loss=1.9573  Acc=0.3606\n",
      "[Pretrain] Epoch 21/100  Loss=1.9035  Acc=0.3773\n",
      "[Pretrain] Epoch 22/100  Loss=1.8744  Acc=0.3895\n",
      "[Pretrain] Epoch 23/100  Loss=1.8517  Acc=0.4018\n",
      "[Pretrain] Epoch 24/100  Loss=1.8237  Acc=0.4032\n",
      "[Pretrain] Epoch 25/100  Loss=1.8108  Acc=0.4142\n",
      "[Pretrain] Epoch 26/100  Loss=1.8036  Acc=0.4167\n",
      "[Pretrain] Epoch 27/100  Loss=1.7576  Acc=0.4373\n",
      "[Pretrain] Epoch 28/100  Loss=1.7289  Acc=0.4400\n",
      "[Pretrain] Epoch 29/100  Loss=1.7133  Acc=0.4463\n",
      "[Pretrain] Epoch 30/100  Loss=1.6956  Acc=0.4486\n",
      "[Pretrain] Epoch 31/100  Loss=1.6789  Acc=0.4520\n",
      "[Pretrain] Epoch 32/100  Loss=1.6657  Acc=0.4639\n",
      "[Pretrain] Epoch 33/100  Loss=1.6354  Acc=0.4691\n",
      "[Pretrain] Epoch 34/100  Loss=1.6227  Acc=0.4750\n",
      "[Pretrain] Epoch 35/100  Loss=1.5950  Acc=0.4876\n",
      "[Pretrain] Epoch 36/100  Loss=1.5772  Acc=0.4817\n",
      "[Pretrain] Epoch 37/100  Loss=1.5601  Acc=0.4908\n",
      "[Pretrain] Epoch 38/100  Loss=1.5375  Acc=0.4998\n",
      "[Pretrain] Epoch 39/100  Loss=1.5354  Acc=0.5043\n",
      "[Pretrain] Epoch 40/100  Loss=1.4976  Acc=0.5106\n",
      "[Pretrain] Epoch 41/100  Loss=1.4709  Acc=0.5131\n",
      "[Pretrain] Epoch 42/100  Loss=1.4539  Acc=0.5246\n",
      "[Pretrain] Epoch 43/100  Loss=1.4539  Acc=0.5298\n",
      "[Pretrain] Epoch 44/100  Loss=1.4175  Acc=0.5314\n",
      "[Pretrain] Epoch 45/100  Loss=1.4132  Acc=0.5354\n",
      "[Pretrain] Epoch 46/100  Loss=1.3969  Acc=0.5440\n",
      "[Pretrain] Epoch 47/100  Loss=1.3764  Acc=0.5530\n",
      "[Pretrain] Epoch 48/100  Loss=1.3751  Acc=0.5505\n",
      "[Pretrain] Epoch 49/100  Loss=1.3322  Acc=0.5630\n",
      "[Pretrain] Epoch 50/100  Loss=1.3376  Acc=0.5634\n",
      "[Pretrain] Epoch 51/100  Loss=1.3244  Acc=0.5578\n",
      "[Pretrain] Epoch 52/100  Loss=1.3041  Acc=0.5733\n",
      "[Pretrain] Epoch 53/100  Loss=1.2992  Acc=0.5753\n",
      "[Pretrain] Epoch 54/100  Loss=1.2937  Acc=0.5756\n",
      "[Pretrain] Epoch 55/100  Loss=1.2725  Acc=0.5885\n",
      "[Pretrain] Epoch 56/100  Loss=1.2749  Acc=0.5806\n",
      "[Pretrain] Epoch 57/100  Loss=1.2619  Acc=0.5885\n",
      "[Pretrain] Epoch 58/100  Loss=1.2528  Acc=0.5853\n",
      "[Pretrain] Epoch 59/100  Loss=1.2361  Acc=0.5900\n",
      "[Pretrain] Epoch 60/100  Loss=1.2399  Acc=0.5939\n",
      "[Pretrain] Epoch 61/100  Loss=1.2076  Acc=0.6036\n",
      "[Pretrain] Epoch 62/100  Loss=1.2092  Acc=0.6056\n",
      "[Pretrain] Epoch 63/100  Loss=1.2062  Acc=0.6065\n",
      "[Pretrain] Epoch 64/100  Loss=1.2053  Acc=0.6081\n",
      "[Pretrain] Epoch 65/100  Loss=1.2064  Acc=0.6069\n",
      "[Pretrain] Epoch 66/100  Loss=1.1855  Acc=0.6137\n",
      "[Pretrain] Epoch 67/100  Loss=1.1721  Acc=0.6069\n",
      "[Pretrain] Epoch 68/100  Loss=1.1875  Acc=0.6137\n",
      "[Pretrain] Epoch 69/100  Loss=1.1680  Acc=0.6212\n",
      "[Pretrain] Epoch 70/100  Loss=1.1630  Acc=0.6173\n",
      "[Pretrain] Epoch 71/100  Loss=1.1808  Acc=0.6148\n",
      "[Pretrain] Epoch 72/100  Loss=1.1578  Acc=0.6196\n",
      "[Pretrain] Epoch 73/100  Loss=1.1525  Acc=0.6194\n",
      "[Pretrain] Epoch 74/100  Loss=1.1600  Acc=0.6200\n",
      "[Pretrain] Epoch 75/100  Loss=1.1468  Acc=0.6286\n",
      "[Pretrain] Epoch 76/100  Loss=1.1407  Acc=0.6257\n",
      "[Pretrain] Epoch 77/100  Loss=1.1347  Acc=0.6329\n",
      "[Pretrain] Epoch 78/100  Loss=1.1280  Acc=0.6295\n",
      "[Pretrain] Epoch 79/100  Loss=1.1377  Acc=0.6315\n",
      "[Pretrain] Epoch 80/100  Loss=1.1342  Acc=0.6273\n",
      "[Pretrain] Epoch 81/100  Loss=1.1367  Acc=0.6268\n",
      "[Pretrain] Epoch 82/100  Loss=1.1104  Acc=0.6347\n",
      "[Pretrain] Epoch 83/100  Loss=1.1294  Acc=0.6311\n",
      "[Pretrain] Epoch 84/100  Loss=1.1120  Acc=0.6315\n",
      "[Pretrain] Epoch 85/100  Loss=1.1329  Acc=0.6333\n",
      "[Pretrain] Epoch 86/100  Loss=1.1165  Acc=0.6352\n",
      "[Pretrain] Epoch 87/100  Loss=1.1134  Acc=0.6333\n",
      "[Pretrain] Epoch 88/100  Loss=1.1276  Acc=0.6318\n",
      "[Pretrain] Epoch 89/100  Loss=1.1178  Acc=0.6297\n",
      "[Pretrain] Epoch 90/100  Loss=1.1063  Acc=0.6367\n",
      "[Pretrain] Epoch 91/100  Loss=1.1129  Acc=0.6381\n",
      "[Pretrain] Epoch 92/100  Loss=1.1124  Acc=0.6325\n",
      "[Pretrain] Epoch 93/100  Loss=1.1104  Acc=0.6351\n",
      "[Pretrain] Epoch 94/100  Loss=1.0964  Acc=0.6480\n",
      "[Pretrain] Epoch 95/100  Loss=1.1106  Acc=0.6338\n",
      "[Pretrain] Epoch 96/100  Loss=1.1041  Acc=0.6367\n",
      "[Pretrain] Epoch 97/100  Loss=1.1043  Acc=0.6458\n",
      "[Pretrain] Epoch 98/100  Loss=1.1059  Acc=0.6378\n",
      "[Pretrain] Epoch 99/100  Loss=1.1008  Acc=0.6430\n",
      "[Pretrain] Epoch 100/100  Loss=1.0886  Acc=0.6421\n",
      "[Fine-tune] Epoch 1/50  Loss=3.0305\n",
      "[Fine-tune] Epoch 2/50  Loss=2.6275\n",
      "[Fine-tune] Epoch 3/50  Loss=2.4410\n",
      "[Fine-tune] Epoch 4/50  Loss=2.3201\n",
      "[Fine-tune] Epoch 5/50  Loss=2.2277\n",
      "[Fine-tune] Epoch 6/50  Loss=2.1580\n",
      "[Fine-tune] Epoch 7/50  Loss=2.1156\n",
      "[Fine-tune] Epoch 8/50  Loss=2.0611\n",
      "[Fine-tune] Epoch 9/50  Loss=2.0247\n",
      "[Fine-tune] Epoch 10/50  Loss=1.9992\n",
      "[Fine-tune] Epoch 11/50  Loss=1.9828\n",
      "[Fine-tune] Epoch 12/50  Loss=1.9498\n",
      "[Fine-tune] Epoch 13/50  Loss=1.9334\n",
      "[Fine-tune] Epoch 14/50  Loss=1.9165\n",
      "[Fine-tune] Epoch 15/50  Loss=1.8987\n",
      "[Fine-tune] Epoch 16/50  Loss=1.8894\n",
      "[Fine-tune] Epoch 17/50  Loss=1.8705\n",
      "[Fine-tune] Epoch 18/50  Loss=1.8701\n",
      "[Fine-tune] Epoch 19/50  Loss=1.8450\n",
      "[Fine-tune] Epoch 20/50  Loss=1.8351\n",
      "[Fine-tune] Epoch 21/50  Loss=1.8311\n",
      "[Fine-tune] Epoch 22/50  Loss=1.8245\n",
      "[Fine-tune] Epoch 23/50  Loss=1.8125\n",
      "[Fine-tune] Epoch 24/50  Loss=1.8136\n",
      "[Fine-tune] Epoch 25/50  Loss=1.7878\n",
      "[Fine-tune] Epoch 26/50  Loss=1.7962\n",
      "[Fine-tune] Epoch 27/50  Loss=1.7601\n",
      "[Fine-tune] Epoch 28/50  Loss=1.7615\n",
      "[Fine-tune] Epoch 29/50  Loss=1.7509\n",
      "[Fine-tune] Epoch 30/50  Loss=1.7549\n",
      "[Fine-tune] Epoch 31/50  Loss=1.7554\n",
      "[Fine-tune] Epoch 32/50  Loss=1.7449\n",
      "[Fine-tune] Epoch 33/50  Loss=1.7360\n",
      "[Fine-tune] Epoch 34/50  Loss=1.7262\n",
      "[Fine-tune] Epoch 35/50  Loss=1.7149\n",
      "[Fine-tune] Epoch 36/50  Loss=1.7231\n",
      "[Fine-tune] Epoch 37/50  Loss=1.7203\n",
      "[Fine-tune] Epoch 38/50  Loss=1.7142\n",
      "[Fine-tune] Epoch 39/50  Loss=1.7002\n",
      "[Fine-tune] Epoch 40/50  Loss=1.6921\n",
      "[Fine-tune] Epoch 41/50  Loss=1.7187\n",
      "[Fine-tune] Epoch 42/50  Loss=1.6996\n",
      "[Fine-tune] Epoch 43/50  Loss=1.7121\n",
      "[Fine-tune] Epoch 44/50  Loss=1.6847\n",
      "[Fine-tune] Epoch 45/50  Loss=1.6796\n",
      "[Fine-tune] Epoch 46/50  Loss=1.6795\n",
      "[Fine-tune] Epoch 47/50  Loss=1.6860\n",
      "[Fine-tune] Epoch 48/50  Loss=1.6694\n",
      "[Fine-tune] Epoch 49/50  Loss=1.6787\n",
      "[Fine-tune] Epoch 50/50  Loss=1.6780\n",
      "[Pretrain] Epoch 1/150  Loss=3.2641  Acc=0.0397\n",
      "[Pretrain] Epoch 2/150  Loss=3.1390  Acc=0.0691\n",
      "[Pretrain] Epoch 3/150  Loss=2.7862  Acc=0.1290\n",
      "[Pretrain] Epoch 4/150  Loss=2.5083  Acc=0.2083\n",
      "[Pretrain] Epoch 5/150  Loss=2.3497  Acc=0.2471\n",
      "[Pretrain] Epoch 6/150  Loss=2.2459  Acc=0.2701\n",
      "[Pretrain] Epoch 7/150  Loss=2.1495  Acc=0.3041\n",
      "[Pretrain] Epoch 8/150  Loss=2.1376  Acc=0.3147\n",
      "[Pretrain] Epoch 9/150  Loss=2.1078  Acc=0.3159\n",
      "[Pretrain] Epoch 10/150  Loss=2.0558  Acc=0.3258\n",
      "[Pretrain] Epoch 11/150  Loss=2.0197  Acc=0.3414\n",
      "[Pretrain] Epoch 12/150  Loss=1.9889  Acc=0.3552\n",
      "[Pretrain] Epoch 13/150  Loss=1.9655  Acc=0.3693\n",
      "[Pretrain] Epoch 14/150  Loss=1.9035  Acc=0.3752\n",
      "[Pretrain] Epoch 15/150  Loss=1.9174  Acc=0.3716\n",
      "[Pretrain] Epoch 16/150  Loss=1.8700  Acc=0.3960\n",
      "[Pretrain] Epoch 17/150  Loss=1.8660  Acc=0.3940\n",
      "[Pretrain] Epoch 18/150  Loss=1.8030  Acc=0.4204\n",
      "[Pretrain] Epoch 19/150  Loss=1.8266  Acc=0.4095\n",
      "[Pretrain] Epoch 20/150  Loss=1.7748  Acc=0.4265\n",
      "[Pretrain] Epoch 21/150  Loss=1.7478  Acc=0.4287\n",
      "[Pretrain] Epoch 22/150  Loss=1.7360  Acc=0.4373\n",
      "[Pretrain] Epoch 23/150  Loss=1.7129  Acc=0.4459\n",
      "[Pretrain] Epoch 24/150  Loss=1.6949  Acc=0.4555\n",
      "[Pretrain] Epoch 25/150  Loss=1.6597  Acc=0.4639\n",
      "[Pretrain] Epoch 26/150  Loss=1.6536  Acc=0.4625\n",
      "[Pretrain] Epoch 27/150  Loss=1.6465  Acc=0.4682\n",
      "[Pretrain] Epoch 28/150  Loss=1.6224  Acc=0.4704\n",
      "[Pretrain] Epoch 29/150  Loss=1.6016  Acc=0.4824\n",
      "[Pretrain] Epoch 30/150  Loss=1.5998  Acc=0.4806\n",
      "[Pretrain] Epoch 31/150  Loss=1.5692  Acc=0.4944\n",
      "[Pretrain] Epoch 32/150  Loss=1.5661  Acc=0.4923\n",
      "[Pretrain] Epoch 33/150  Loss=1.5511  Acc=0.4935\n",
      "[Pretrain] Epoch 34/150  Loss=1.5408  Acc=0.5066\n",
      "[Pretrain] Epoch 35/150  Loss=1.5227  Acc=0.5050\n",
      "[Pretrain] Epoch 36/150  Loss=1.4974  Acc=0.5187\n",
      "[Pretrain] Epoch 37/150  Loss=1.4907  Acc=0.5169\n",
      "[Pretrain] Epoch 38/150  Loss=1.4742  Acc=0.5189\n",
      "[Pretrain] Epoch 39/150  Loss=1.4690  Acc=0.5259\n",
      "[Pretrain] Epoch 40/150  Loss=1.4666  Acc=0.5153\n",
      "[Pretrain] Epoch 41/150  Loss=1.4668  Acc=0.5262\n",
      "[Pretrain] Epoch 42/150  Loss=1.4427  Acc=0.5350\n",
      "[Pretrain] Epoch 43/150  Loss=1.4361  Acc=0.5311\n",
      "[Pretrain] Epoch 44/150  Loss=1.4292  Acc=0.5383\n",
      "[Pretrain] Epoch 45/150  Loss=1.4239  Acc=0.5363\n",
      "[Pretrain] Epoch 46/150  Loss=1.4153  Acc=0.5397\n",
      "[Pretrain] Epoch 47/150  Loss=1.4081  Acc=0.5415\n",
      "[Pretrain] Epoch 48/150  Loss=1.3868  Acc=0.5496\n",
      "[Pretrain] Epoch 49/150  Loss=1.3868  Acc=0.5483\n",
      "[Pretrain] Epoch 50/150  Loss=1.3768  Acc=0.5587\n",
      "[Pretrain] Epoch 51/150  Loss=1.3592  Acc=0.5508\n",
      "[Pretrain] Epoch 52/150  Loss=1.3451  Acc=0.5562\n",
      "[Pretrain] Epoch 53/150  Loss=1.3526  Acc=0.5591\n",
      "[Pretrain] Epoch 54/150  Loss=1.3580  Acc=0.5573\n",
      "[Pretrain] Epoch 55/150  Loss=1.3447  Acc=0.5594\n",
      "[Pretrain] Epoch 56/150  Loss=1.3347  Acc=0.5621\n",
      "[Pretrain] Epoch 57/150  Loss=1.3410  Acc=0.5675\n",
      "[Pretrain] Epoch 58/150  Loss=1.3218  Acc=0.5702\n",
      "[Pretrain] Epoch 59/150  Loss=1.3486  Acc=0.5526\n",
      "[Pretrain] Epoch 60/150  Loss=1.3385  Acc=0.5614\n",
      "[Pretrain] Epoch 61/150  Loss=1.3264  Acc=0.5639\n",
      "[Pretrain] Epoch 62/150  Loss=1.3278  Acc=0.5666\n",
      "[Pretrain] Epoch 63/150  Loss=1.3187  Acc=0.5681\n",
      "[Pretrain] Epoch 64/150  Loss=1.3121  Acc=0.5709\n",
      "[Pretrain] Epoch 65/150  Loss=1.3137  Acc=0.5720\n",
      "[Pretrain] Epoch 66/150  Loss=1.3044  Acc=0.5779\n",
      "[Pretrain] Epoch 67/150  Loss=1.2999  Acc=0.5770\n",
      "[Pretrain] Epoch 68/150  Loss=1.3006  Acc=0.5801\n",
      "[Pretrain] Epoch 69/150  Loss=1.2966  Acc=0.5758\n",
      "[Pretrain] Epoch 70/150  Loss=1.2880  Acc=0.5824\n",
      "[Pretrain] Epoch 71/150  Loss=1.2974  Acc=0.5778\n",
      "[Pretrain] Epoch 72/150  Loss=1.2887  Acc=0.5819\n",
      "[Pretrain] Epoch 73/150  Loss=1.3009  Acc=0.5761\n",
      "[Pretrain] Epoch 74/150  Loss=1.2942  Acc=0.5742\n",
      "[Pretrain] Epoch 75/150  Loss=1.2773  Acc=0.5867\n",
      "[Pretrain] Epoch 76/150  Loss=1.2953  Acc=0.5781\n",
      "[Pretrain] Epoch 77/150  Loss=1.2725  Acc=0.5884\n",
      "[Pretrain] Epoch 78/150  Loss=1.2802  Acc=0.5828\n",
      "[Pretrain] Epoch 79/150  Loss=1.2823  Acc=0.5858\n",
      "[Pretrain] Epoch 80/150  Loss=1.2786  Acc=0.5826\n",
      "[Pretrain] Epoch 81/150  Loss=1.2744  Acc=0.5925\n",
      "[Pretrain] Epoch 82/150  Loss=1.2853  Acc=0.5832\n",
      "[Pretrain] Epoch 83/150  Loss=1.2695  Acc=0.5790\n",
      "[Pretrain] Epoch 84/150  Loss=1.2591  Acc=0.5911\n",
      "[Pretrain] Epoch 85/150  Loss=1.2787  Acc=0.5817\n",
      "[Pretrain] Epoch 86/150  Loss=1.2783  Acc=0.5835\n",
      "[Pretrain] Epoch 87/150  Loss=1.2687  Acc=0.5871\n",
      "[Pretrain] Epoch 88/150  Loss=1.2741  Acc=0.5848\n",
      "[Pretrain] Epoch 89/150  Loss=1.2780  Acc=0.5801\n",
      "[Pretrain] Epoch 90/150  Loss=1.2722  Acc=0.5841\n",
      "[Pretrain] Epoch 91/150  Loss=1.2595  Acc=0.5912\n",
      "[Pretrain] Epoch 92/150  Loss=1.2514  Acc=0.5911\n",
      "[Pretrain] Epoch 93/150  Loss=1.2781  Acc=0.5855\n",
      "[Pretrain] Epoch 94/150  Loss=1.2787  Acc=0.5832\n",
      "[Pretrain] Epoch 95/150  Loss=1.2643  Acc=0.5808\n",
      "[Pretrain] Epoch 96/150  Loss=1.2651  Acc=0.5898\n",
      "[Pretrain] Epoch 97/150  Loss=1.2736  Acc=0.5884\n",
      "[Pretrain] Epoch 98/150  Loss=1.2633  Acc=0.5921\n",
      "[Pretrain] Epoch 99/150  Loss=1.2604  Acc=0.5891\n",
      "[Pretrain] Epoch 100/150  Loss=1.2598  Acc=0.5905\n",
      "[Pretrain] Epoch 101/150  Loss=1.2673  Acc=0.5824\n",
      "[Pretrain] Epoch 102/150  Loss=1.2735  Acc=0.5864\n",
      "[Pretrain] Epoch 103/150  Loss=1.2734  Acc=0.5796\n",
      "[Pretrain] Epoch 104/150  Loss=1.2644  Acc=0.5898\n",
      "[Pretrain] Epoch 105/150  Loss=1.2607  Acc=0.5932\n",
      "[Pretrain] Epoch 106/150  Loss=1.2542  Acc=0.5862\n",
      "[Pretrain] Epoch 107/150  Loss=1.2798  Acc=0.5851\n",
      "[Pretrain] Epoch 108/150  Loss=1.2551  Acc=0.5923\n",
      "[Pretrain] Epoch 109/150  Loss=1.2712  Acc=0.5873\n",
      "[Pretrain] Epoch 110/150  Loss=1.2535  Acc=0.5948\n",
      "[Pretrain] Epoch 111/150  Loss=1.2533  Acc=0.5894\n",
      "[Pretrain] Epoch 112/150  Loss=1.2622  Acc=0.5880\n",
      "[Pretrain] Epoch 113/150  Loss=1.2701  Acc=0.5837\n",
      "[Pretrain] Epoch 114/150  Loss=1.2637  Acc=0.5896\n",
      "[Pretrain] Epoch 115/150  Loss=1.2581  Acc=0.5918\n",
      "[Pretrain] Epoch 116/150  Loss=1.2524  Acc=0.5882\n",
      "[Pretrain] Epoch 117/150  Loss=1.2613  Acc=0.5894\n",
      "[Pretrain] Epoch 118/150  Loss=1.2634  Acc=0.5875\n",
      "[Pretrain] Epoch 119/150  Loss=1.2497  Acc=0.5862\n",
      "[Pretrain] Epoch 120/150  Loss=1.2629  Acc=0.5830\n",
      "[Pretrain] Epoch 121/150  Loss=1.2508  Acc=0.5973\n",
      "[Pretrain] Epoch 122/150  Loss=1.2467  Acc=0.5878\n",
      "[Pretrain] Epoch 123/150  Loss=1.2663  Acc=0.5842\n",
      "[Pretrain] Epoch 124/150  Loss=1.2705  Acc=0.5867\n",
      "[Pretrain] Epoch 125/150  Loss=1.2520  Acc=0.5889\n",
      "[Pretrain] Epoch 126/150  Loss=1.2684  Acc=0.5862\n",
      "[Pretrain] Epoch 127/150  Loss=1.2490  Acc=0.5936\n",
      "[Pretrain] Epoch 128/150  Loss=1.2553  Acc=0.5912\n",
      "[Pretrain] Epoch 129/150  Loss=1.2595  Acc=0.5912\n",
      "[Pretrain] Epoch 130/150  Loss=1.2458  Acc=0.5923\n",
      "[Pretrain] Epoch 131/150  Loss=1.2363  Acc=0.5925\n",
      "[Pretrain] Epoch 132/150  Loss=1.2683  Acc=0.5828\n",
      "[Pretrain] Epoch 133/150  Loss=1.2481  Acc=0.5914\n",
      "[Pretrain] Epoch 134/150  Loss=1.2412  Acc=0.5943\n",
      "[Pretrain] Epoch 135/150  Loss=1.2564  Acc=0.5878\n",
      "[Pretrain] Epoch 136/150  Loss=1.2549  Acc=0.5923\n",
      "[Pretrain] Epoch 137/150  Loss=1.2422  Acc=0.5963\n",
      "[Pretrain] Epoch 138/150  Loss=1.2532  Acc=0.5993\n",
      "[Pretrain] Epoch 139/150  Loss=1.2659  Acc=0.5896\n",
      "[Pretrain] Epoch 140/150  Loss=1.2470  Acc=0.5988\n",
      "[Pretrain] Epoch 141/150  Loss=1.2635  Acc=0.5902\n",
      "[Pretrain] Epoch 142/150  Loss=1.2469  Acc=0.5968\n",
      "[Pretrain] Epoch 143/150  Loss=1.2565  Acc=0.5873\n",
      "[Pretrain] Epoch 144/150  Loss=1.2384  Acc=0.5957\n",
      "[Pretrain] Epoch 145/150  Loss=1.2464  Acc=0.5929\n",
      "[Pretrain] Epoch 146/150  Loss=1.2561  Acc=0.5914\n",
      "[Pretrain] Epoch 147/150  Loss=1.2493  Acc=0.5932\n",
      "[Pretrain] Epoch 148/150  Loss=1.2630  Acc=0.5817\n",
      "[Pretrain] Epoch 149/150  Loss=1.2466  Acc=0.5968\n",
      "[Pretrain] Epoch 150/150  Loss=1.2563  Acc=0.5905\n",
      "[Fine-tune] Epoch 1/50  Loss=2.7912\n",
      "[Fine-tune] Epoch 2/50  Loss=2.2744\n",
      "[Fine-tune] Epoch 3/50  Loss=2.1176\n",
      "[Fine-tune] Epoch 4/50  Loss=2.0395\n",
      "[Fine-tune] Epoch 5/50  Loss=1.9820\n",
      "[Fine-tune] Epoch 6/50  Loss=1.8962\n",
      "[Fine-tune] Epoch 7/50  Loss=1.8462\n",
      "[Fine-tune] Epoch 8/50  Loss=1.7880\n",
      "[Fine-tune] Epoch 9/50  Loss=1.7242\n",
      "[Fine-tune] Epoch 10/50  Loss=1.6973\n",
      "[Fine-tune] Epoch 11/50  Loss=1.6569\n",
      "[Fine-tune] Epoch 12/50  Loss=1.6310\n",
      "[Fine-tune] Epoch 13/50  Loss=1.5831\n",
      "[Fine-tune] Epoch 14/50  Loss=1.5419\n",
      "[Fine-tune] Epoch 15/50  Loss=1.4989\n",
      "[Fine-tune] Epoch 16/50  Loss=1.4993\n",
      "[Fine-tune] Epoch 17/50  Loss=1.4716\n",
      "[Fine-tune] Epoch 18/50  Loss=1.4183\n",
      "[Fine-tune] Epoch 19/50  Loss=1.4021\n",
      "[Fine-tune] Epoch 20/50  Loss=1.3722\n",
      "[Fine-tune] Epoch 21/50  Loss=1.3464\n",
      "[Fine-tune] Epoch 22/50  Loss=1.3306\n",
      "[Fine-tune] Epoch 23/50  Loss=1.3125\n",
      "[Fine-tune] Epoch 24/50  Loss=1.2818\n",
      "[Fine-tune] Epoch 25/50  Loss=1.2591\n",
      "[Fine-tune] Epoch 26/50  Loss=1.2506\n",
      "[Fine-tune] Epoch 27/50  Loss=1.2056\n",
      "[Fine-tune] Epoch 28/50  Loss=1.2246\n",
      "[Fine-tune] Epoch 29/50  Loss=1.1922\n",
      "[Fine-tune] Epoch 30/50  Loss=1.1984\n",
      "[Fine-tune] Epoch 31/50  Loss=1.1683\n",
      "[Fine-tune] Epoch 32/50  Loss=1.1679\n",
      "[Fine-tune] Epoch 33/50  Loss=1.1365\n",
      "[Fine-tune] Epoch 34/50  Loss=1.1203\n",
      "[Fine-tune] Epoch 35/50  Loss=1.1116\n",
      "[Fine-tune] Epoch 36/50  Loss=1.0957\n",
      "[Fine-tune] Epoch 37/50  Loss=1.0993\n",
      "[Fine-tune] Epoch 38/50  Loss=1.0882\n",
      "[Fine-tune] Epoch 39/50  Loss=1.0704\n",
      "[Fine-tune] Epoch 40/50  Loss=1.0724\n",
      "[Fine-tune] Epoch 41/50  Loss=1.0676\n",
      "[Fine-tune] Epoch 42/50  Loss=1.0428\n",
      "[Fine-tune] Epoch 43/50  Loss=1.0394\n",
      "[Fine-tune] Epoch 44/50  Loss=1.0469\n",
      "[Fine-tune] Epoch 45/50  Loss=1.0317\n",
      "[Fine-tune] Epoch 46/50  Loss=1.0136\n",
      "[Fine-tune] Epoch 47/50  Loss=1.0261\n",
      "[Fine-tune] Epoch 48/50  Loss=1.0071\n",
      "[Fine-tune] Epoch 49/50  Loss=1.0120\n",
      "[Fine-tune] Epoch 50/50  Loss=1.0065\n",
      "[Pretrain] Epoch 1/150  Loss=3.6567  Acc=0.0420\n",
      "[Pretrain] Epoch 2/150  Loss=3.1470  Acc=0.0641\n",
      "[Pretrain] Epoch 3/150  Loss=2.7696  Acc=0.1329\n",
      "[Pretrain] Epoch 4/150  Loss=2.6055  Acc=0.1740\n",
      "[Pretrain] Epoch 5/150  Loss=2.4352  Acc=0.2281\n",
      "[Pretrain] Epoch 6/150  Loss=2.3774  Acc=0.2421\n",
      "[Pretrain] Epoch 7/150  Loss=2.2902  Acc=0.2701\n",
      "[Pretrain] Epoch 8/150  Loss=2.2478  Acc=0.2820\n",
      "[Pretrain] Epoch 9/150  Loss=2.1844  Acc=0.2989\n",
      "[Pretrain] Epoch 10/150  Loss=2.1506  Acc=0.3033\n",
      "[Pretrain] Epoch 11/150  Loss=2.1298  Acc=0.3148\n",
      "[Pretrain] Epoch 12/150  Loss=2.0514  Acc=0.3278\n",
      "[Pretrain] Epoch 13/150  Loss=2.0465  Acc=0.3321\n",
      "[Pretrain] Epoch 14/150  Loss=1.9868  Acc=0.3517\n",
      "[Pretrain] Epoch 15/150  Loss=1.9611  Acc=0.3563\n",
      "[Pretrain] Epoch 16/150  Loss=1.9357  Acc=0.3637\n",
      "[Pretrain] Epoch 17/150  Loss=1.9245  Acc=0.3700\n",
      "[Pretrain] Epoch 18/150  Loss=1.9073  Acc=0.3861\n",
      "[Pretrain] Epoch 19/150  Loss=1.8674  Acc=0.3921\n",
      "[Pretrain] Epoch 20/150  Loss=1.8263  Acc=0.4014\n",
      "[Pretrain] Epoch 21/150  Loss=1.8111  Acc=0.4077\n",
      "[Pretrain] Epoch 22/150  Loss=1.8096  Acc=0.4097\n",
      "[Pretrain] Epoch 23/150  Loss=1.7731  Acc=0.4170\n",
      "[Pretrain] Epoch 24/150  Loss=1.7445  Acc=0.4296\n",
      "[Pretrain] Epoch 25/150  Loss=1.7127  Acc=0.4344\n",
      "[Pretrain] Epoch 26/150  Loss=1.6878  Acc=0.4461\n",
      "[Pretrain] Epoch 27/150  Loss=1.6730  Acc=0.4519\n",
      "[Pretrain] Epoch 28/150  Loss=1.6628  Acc=0.4531\n",
      "[Pretrain] Epoch 29/150  Loss=1.6517  Acc=0.4632\n",
      "[Pretrain] Epoch 30/150  Loss=1.6002  Acc=0.4772\n",
      "[Pretrain] Epoch 31/150  Loss=1.5642  Acc=0.4883\n",
      "[Pretrain] Epoch 32/150  Loss=1.5429  Acc=0.4975\n",
      "[Pretrain] Epoch 33/150  Loss=1.5308  Acc=0.4975\n",
      "[Pretrain] Epoch 34/150  Loss=1.5241  Acc=0.5007\n",
      "[Pretrain] Epoch 35/150  Loss=1.4874  Acc=0.5018\n",
      "[Pretrain] Epoch 36/150  Loss=1.4738  Acc=0.5151\n",
      "[Pretrain] Epoch 37/150  Loss=1.4532  Acc=0.5235\n",
      "[Pretrain] Epoch 38/150  Loss=1.4352  Acc=0.5321\n",
      "[Pretrain] Epoch 39/150  Loss=1.4130  Acc=0.5350\n",
      "[Pretrain] Epoch 40/150  Loss=1.3804  Acc=0.5395\n",
      "[Pretrain] Epoch 41/150  Loss=1.3806  Acc=0.5375\n",
      "[Pretrain] Epoch 42/150  Loss=1.3674  Acc=0.5454\n",
      "[Pretrain] Epoch 43/150  Loss=1.3674  Acc=0.5514\n",
      "[Pretrain] Epoch 44/150  Loss=1.3564  Acc=0.5537\n",
      "[Pretrain] Epoch 45/150  Loss=1.3268  Acc=0.5652\n",
      "[Pretrain] Epoch 46/150  Loss=1.2910  Acc=0.5763\n",
      "[Pretrain] Epoch 47/150  Loss=1.3002  Acc=0.5650\n",
      "[Pretrain] Epoch 48/150  Loss=1.3066  Acc=0.5769\n",
      "[Pretrain] Epoch 49/150  Loss=1.2552  Acc=0.5853\n",
      "[Pretrain] Epoch 50/150  Loss=1.2748  Acc=0.5821\n",
      "[Pretrain] Epoch 51/150  Loss=1.2639  Acc=0.5866\n",
      "[Pretrain] Epoch 52/150  Loss=1.2313  Acc=0.5990\n",
      "[Pretrain] Epoch 53/150  Loss=1.2183  Acc=0.6036\n",
      "[Pretrain] Epoch 54/150  Loss=1.2424  Acc=0.5984\n",
      "[Pretrain] Epoch 55/150  Loss=1.2168  Acc=0.5950\n",
      "[Pretrain] Epoch 56/150  Loss=1.2061  Acc=0.6090\n",
      "[Pretrain] Epoch 57/150  Loss=1.2050  Acc=0.6027\n",
      "[Pretrain] Epoch 58/150  Loss=1.1813  Acc=0.6103\n",
      "[Pretrain] Epoch 59/150  Loss=1.1844  Acc=0.6099\n",
      "[Pretrain] Epoch 60/150  Loss=1.1840  Acc=0.6133\n",
      "[Pretrain] Epoch 61/150  Loss=1.1613  Acc=0.6180\n",
      "[Pretrain] Epoch 62/150  Loss=1.1654  Acc=0.6221\n",
      "[Pretrain] Epoch 63/150  Loss=1.1535  Acc=0.6257\n",
      "[Pretrain] Epoch 64/150  Loss=1.1519  Acc=0.6191\n",
      "[Pretrain] Epoch 65/150  Loss=1.1443  Acc=0.6236\n",
      "[Pretrain] Epoch 66/150  Loss=1.1422  Acc=0.6288\n",
      "[Pretrain] Epoch 67/150  Loss=1.1318  Acc=0.6318\n",
      "[Pretrain] Epoch 68/150  Loss=1.1446  Acc=0.6291\n",
      "[Pretrain] Epoch 69/150  Loss=1.1237  Acc=0.6329\n",
      "[Pretrain] Epoch 70/150  Loss=1.1161  Acc=0.6325\n",
      "[Pretrain] Epoch 71/150  Loss=1.1168  Acc=0.6327\n",
      "[Pretrain] Epoch 72/150  Loss=1.1314  Acc=0.6331\n",
      "[Pretrain] Epoch 73/150  Loss=1.1126  Acc=0.6367\n",
      "[Pretrain] Epoch 74/150  Loss=1.1047  Acc=0.6395\n",
      "[Pretrain] Epoch 75/150  Loss=1.1180  Acc=0.6316\n",
      "[Pretrain] Epoch 76/150  Loss=1.0893  Acc=0.6374\n",
      "[Pretrain] Epoch 77/150  Loss=1.1018  Acc=0.6388\n",
      "[Pretrain] Epoch 78/150  Loss=1.0940  Acc=0.6390\n",
      "[Pretrain] Epoch 79/150  Loss=1.0906  Acc=0.6403\n",
      "[Pretrain] Epoch 80/150  Loss=1.0850  Acc=0.6431\n",
      "[Pretrain] Epoch 81/150  Loss=1.0895  Acc=0.6437\n",
      "[Pretrain] Epoch 82/150  Loss=1.0795  Acc=0.6485\n",
      "[Pretrain] Epoch 83/150  Loss=1.0885  Acc=0.6449\n",
      "[Pretrain] Epoch 84/150  Loss=1.0737  Acc=0.6492\n",
      "[Pretrain] Epoch 85/150  Loss=1.0695  Acc=0.6494\n",
      "[Pretrain] Epoch 86/150  Loss=1.0753  Acc=0.6527\n",
      "[Pretrain] Epoch 87/150  Loss=1.0754  Acc=0.6467\n",
      "[Pretrain] Epoch 88/150  Loss=1.0706  Acc=0.6521\n",
      "[Pretrain] Epoch 89/150  Loss=1.0601  Acc=0.6521\n",
      "[Pretrain] Epoch 90/150  Loss=1.0705  Acc=0.6500\n",
      "[Pretrain] Epoch 91/150  Loss=1.0553  Acc=0.6541\n",
      "[Pretrain] Epoch 92/150  Loss=1.0624  Acc=0.6555\n",
      "[Pretrain] Epoch 93/150  Loss=1.0562  Acc=0.6573\n",
      "[Pretrain] Epoch 94/150  Loss=1.0640  Acc=0.6584\n",
      "[Pretrain] Epoch 95/150  Loss=1.0551  Acc=0.6474\n",
      "[Pretrain] Epoch 96/150  Loss=1.0676  Acc=0.6491\n",
      "[Pretrain] Epoch 97/150  Loss=1.0645  Acc=0.6532\n",
      "[Pretrain] Epoch 98/150  Loss=1.0486  Acc=0.6625\n",
      "[Pretrain] Epoch 99/150  Loss=1.0595  Acc=0.6460\n",
      "[Pretrain] Epoch 100/150  Loss=1.0648  Acc=0.6548\n",
      "[Pretrain] Epoch 101/150  Loss=1.0590  Acc=0.6580\n",
      "[Pretrain] Epoch 102/150  Loss=1.0504  Acc=0.6580\n",
      "[Pretrain] Epoch 103/150  Loss=1.0516  Acc=0.6514\n",
      "[Pretrain] Epoch 104/150  Loss=1.0492  Acc=0.6575\n",
      "[Pretrain] Epoch 105/150  Loss=1.0617  Acc=0.6541\n",
      "[Pretrain] Epoch 106/150  Loss=1.0622  Acc=0.6530\n",
      "[Pretrain] Epoch 107/150  Loss=1.0577  Acc=0.6539\n",
      "[Pretrain] Epoch 108/150  Loss=1.0472  Acc=0.6548\n",
      "[Pretrain] Epoch 109/150  Loss=1.0633  Acc=0.6577\n",
      "[Pretrain] Epoch 110/150  Loss=1.0494  Acc=0.6543\n",
      "[Pretrain] Epoch 111/150  Loss=1.0414  Acc=0.6602\n",
      "[Pretrain] Epoch 112/150  Loss=1.0478  Acc=0.6575\n",
      "[Pretrain] Epoch 113/150  Loss=1.0642  Acc=0.6467\n",
      "[Pretrain] Epoch 114/150  Loss=1.0401  Acc=0.6625\n",
      "[Pretrain] Epoch 115/150  Loss=1.0570  Acc=0.6455\n",
      "[Pretrain] Epoch 116/150  Loss=1.0451  Acc=0.6564\n",
      "[Pretrain] Epoch 117/150  Loss=1.0355  Acc=0.6627\n",
      "[Pretrain] Epoch 118/150  Loss=1.0440  Acc=0.6624\n",
      "[Pretrain] Epoch 119/150  Loss=1.0512  Acc=0.6575\n",
      "[Pretrain] Epoch 120/150  Loss=1.0365  Acc=0.6634\n",
      "[Pretrain] Epoch 121/150  Loss=1.0560  Acc=0.6525\n",
      "[Pretrain] Epoch 122/150  Loss=1.0355  Acc=0.6652\n",
      "[Pretrain] Epoch 123/150  Loss=1.0554  Acc=0.6543\n",
      "[Pretrain] Epoch 124/150  Loss=1.0579  Acc=0.6579\n",
      "[Pretrain] Epoch 125/150  Loss=1.0373  Acc=0.6532\n",
      "[Pretrain] Epoch 126/150  Loss=1.0386  Acc=0.6577\n",
      "[Pretrain] Epoch 127/150  Loss=1.0517  Acc=0.6512\n",
      "[Pretrain] Epoch 128/150  Loss=1.0479  Acc=0.6602\n",
      "[Pretrain] Epoch 129/150  Loss=1.0400  Acc=0.6582\n",
      "[Pretrain] Epoch 130/150  Loss=1.0428  Acc=0.6527\n",
      "[Pretrain] Epoch 131/150  Loss=1.0410  Acc=0.6624\n",
      "[Pretrain] Epoch 132/150  Loss=1.0523  Acc=0.6564\n",
      "[Pretrain] Epoch 133/150  Loss=1.0557  Acc=0.6528\n",
      "[Pretrain] Epoch 134/150  Loss=1.0486  Acc=0.6571\n",
      "[Pretrain] Epoch 135/150  Loss=1.0431  Acc=0.6589\n",
      "[Pretrain] Epoch 136/150  Loss=1.0510  Acc=0.6548\n",
      "[Pretrain] Epoch 137/150  Loss=1.0386  Acc=0.6710\n",
      "[Pretrain] Epoch 138/150  Loss=1.0394  Acc=0.6607\n",
      "[Pretrain] Epoch 139/150  Loss=1.0331  Acc=0.6586\n",
      "[Pretrain] Epoch 140/150  Loss=1.0487  Acc=0.6523\n",
      "[Pretrain] Epoch 141/150  Loss=1.0334  Acc=0.6613\n",
      "[Pretrain] Epoch 142/150  Loss=1.0407  Acc=0.6622\n",
      "[Pretrain] Epoch 143/150  Loss=1.0347  Acc=0.6598\n",
      "[Pretrain] Epoch 144/150  Loss=1.0431  Acc=0.6580\n",
      "[Pretrain] Epoch 145/150  Loss=1.0419  Acc=0.6575\n",
      "[Pretrain] Epoch 146/150  Loss=1.0543  Acc=0.6537\n",
      "[Pretrain] Epoch 147/150  Loss=1.0441  Acc=0.6598\n",
      "[Pretrain] Epoch 148/150  Loss=1.0468  Acc=0.6577\n",
      "[Pretrain] Epoch 149/150  Loss=1.0411  Acc=0.6589\n",
      "[Pretrain] Epoch 150/150  Loss=1.0452  Acc=0.6629\n",
      "[Fine-tune] Epoch 1/50  Loss=3.0119\n",
      "[Fine-tune] Epoch 2/50  Loss=2.5251\n",
      "[Fine-tune] Epoch 3/50  Loss=2.3497\n",
      "[Fine-tune] Epoch 4/50  Loss=2.2508\n",
      "[Fine-tune] Epoch 5/50  Loss=2.1767\n",
      "[Fine-tune] Epoch 6/50  Loss=2.1357\n",
      "[Fine-tune] Epoch 7/50  Loss=2.0794\n",
      "[Fine-tune] Epoch 8/50  Loss=2.0406\n",
      "[Fine-tune] Epoch 9/50  Loss=2.0085\n",
      "[Fine-tune] Epoch 10/50  Loss=1.9799\n",
      "[Fine-tune] Epoch 11/50  Loss=1.9757\n",
      "[Fine-tune] Epoch 12/50  Loss=1.9465\n",
      "[Fine-tune] Epoch 13/50  Loss=1.9324\n",
      "[Fine-tune] Epoch 14/50  Loss=1.8946\n",
      "[Fine-tune] Epoch 15/50  Loss=1.8973\n",
      "[Fine-tune] Epoch 16/50  Loss=1.8724\n",
      "[Fine-tune] Epoch 17/50  Loss=1.8708\n",
      "[Fine-tune] Epoch 18/50  Loss=1.8552\n",
      "[Fine-tune] Epoch 19/50  Loss=1.8384\n",
      "[Fine-tune] Epoch 20/50  Loss=1.8229\n",
      "[Fine-tune] Epoch 21/50  Loss=1.8225\n",
      "[Fine-tune] Epoch 22/50  Loss=1.7951\n",
      "[Fine-tune] Epoch 23/50  Loss=1.8014\n",
      "[Fine-tune] Epoch 24/50  Loss=1.7861\n",
      "[Fine-tune] Epoch 25/50  Loss=1.7928\n",
      "[Fine-tune] Epoch 26/50  Loss=1.7767\n",
      "[Fine-tune] Epoch 27/50  Loss=1.7541\n",
      "[Fine-tune] Epoch 28/50  Loss=1.7654\n",
      "[Fine-tune] Epoch 29/50  Loss=1.7470\n",
      "[Fine-tune] Epoch 30/50  Loss=1.7368\n",
      "[Fine-tune] Epoch 31/50  Loss=1.7286\n",
      "[Fine-tune] Epoch 32/50  Loss=1.7373\n",
      "[Fine-tune] Epoch 33/50  Loss=1.7226\n",
      "[Fine-tune] Epoch 34/50  Loss=1.7247\n",
      "[Fine-tune] Epoch 35/50  Loss=1.7178\n",
      "[Fine-tune] Epoch 36/50  Loss=1.7126\n",
      "[Fine-tune] Epoch 37/50  Loss=1.7144\n",
      "[Fine-tune] Epoch 38/50  Loss=1.7070\n",
      "[Fine-tune] Epoch 39/50  Loss=1.6943\n",
      "[Fine-tune] Epoch 40/50  Loss=1.6873\n",
      "[Fine-tune] Epoch 41/50  Loss=1.6932\n",
      "[Fine-tune] Epoch 42/50  Loss=1.6914\n",
      "[Fine-tune] Epoch 43/50  Loss=1.6882\n",
      "[Fine-tune] Epoch 44/50  Loss=1.6801\n",
      "[Fine-tune] Epoch 45/50  Loss=1.6856\n",
      "[Fine-tune] Epoch 46/50  Loss=1.6806\n",
      "[Fine-tune] Epoch 47/50  Loss=1.6662\n",
      "[Fine-tune] Epoch 48/50  Loss=1.6696\n",
      "[Fine-tune] Epoch 49/50  Loss=1.6694\n",
      "[Fine-tune] Epoch 50/50  Loss=1.6587\n",
      "[Pretrain] Epoch 1/50  Loss=3.2499  Acc=0.0438\n",
      "[Pretrain] Epoch 2/50  Loss=2.9748  Acc=0.0855\n",
      "[Pretrain] Epoch 3/50  Loss=2.6588  Acc=0.1708\n",
      "[Pretrain] Epoch 4/50  Loss=2.4504  Acc=0.2078\n",
      "[Pretrain] Epoch 5/50  Loss=2.3297  Acc=0.2525\n",
      "[Pretrain] Epoch 6/50  Loss=2.2158  Acc=0.2915\n",
      "[Pretrain] Epoch 7/50  Loss=2.1755  Acc=0.2981\n",
      "[Pretrain] Epoch 8/50  Loss=2.1336  Acc=0.3103\n",
      "[Pretrain] Epoch 9/50  Loss=2.0521  Acc=0.3402\n",
      "[Pretrain] Epoch 10/50  Loss=2.0205  Acc=0.3446\n",
      "[Pretrain] Epoch 11/50  Loss=1.9863  Acc=0.3588\n",
      "[Pretrain] Epoch 12/50  Loss=1.9718  Acc=0.3594\n",
      "[Pretrain] Epoch 13/50  Loss=1.9404  Acc=0.3732\n",
      "[Pretrain] Epoch 14/50  Loss=1.8986  Acc=0.3847\n",
      "[Pretrain] Epoch 15/50  Loss=1.8771  Acc=0.3989\n",
      "[Pretrain] Epoch 16/50  Loss=1.8811  Acc=0.3983\n",
      "[Pretrain] Epoch 17/50  Loss=1.8318  Acc=0.4037\n",
      "[Pretrain] Epoch 18/50  Loss=1.8103  Acc=0.4136\n",
      "[Pretrain] Epoch 19/50  Loss=1.7788  Acc=0.4240\n",
      "[Pretrain] Epoch 20/50  Loss=1.7766  Acc=0.4240\n",
      "[Pretrain] Epoch 21/50  Loss=1.7172  Acc=0.4384\n",
      "[Pretrain] Epoch 22/50  Loss=1.7183  Acc=0.4427\n",
      "[Pretrain] Epoch 23/50  Loss=1.6931  Acc=0.4445\n",
      "[Pretrain] Epoch 24/50  Loss=1.6862  Acc=0.4555\n",
      "[Pretrain] Epoch 25/50  Loss=1.6668  Acc=0.4637\n",
      "[Pretrain] Epoch 26/50  Loss=1.6580  Acc=0.4679\n",
      "[Pretrain] Epoch 27/50  Loss=1.6229  Acc=0.4673\n",
      "[Pretrain] Epoch 28/50  Loss=1.5998  Acc=0.4781\n",
      "[Pretrain] Epoch 29/50  Loss=1.6150  Acc=0.4750\n",
      "[Pretrain] Epoch 30/50  Loss=1.5773  Acc=0.4865\n",
      "[Pretrain] Epoch 31/50  Loss=1.5399  Acc=0.5045\n",
      "[Pretrain] Epoch 32/50  Loss=1.5297  Acc=0.5063\n",
      "[Pretrain] Epoch 33/50  Loss=1.5453  Acc=0.4962\n",
      "[Pretrain] Epoch 34/50  Loss=1.5334  Acc=0.5056\n",
      "[Pretrain] Epoch 35/50  Loss=1.5025  Acc=0.5036\n",
      "[Pretrain] Epoch 36/50  Loss=1.4914  Acc=0.5194\n",
      "[Pretrain] Epoch 37/50  Loss=1.4859  Acc=0.5158\n",
      "[Pretrain] Epoch 38/50  Loss=1.4636  Acc=0.5287\n",
      "[Pretrain] Epoch 39/50  Loss=1.4473  Acc=0.5257\n",
      "[Pretrain] Epoch 40/50  Loss=1.4518  Acc=0.5269\n",
      "[Pretrain] Epoch 41/50  Loss=1.4354  Acc=0.5300\n",
      "[Pretrain] Epoch 42/50  Loss=1.4361  Acc=0.5320\n",
      "[Pretrain] Epoch 43/50  Loss=1.4293  Acc=0.5343\n",
      "[Pretrain] Epoch 44/50  Loss=1.3989  Acc=0.5392\n",
      "[Pretrain] Epoch 45/50  Loss=1.4046  Acc=0.5422\n",
      "[Pretrain] Epoch 46/50  Loss=1.3994  Acc=0.5383\n",
      "[Pretrain] Epoch 47/50  Loss=1.4005  Acc=0.5409\n",
      "[Pretrain] Epoch 48/50  Loss=1.3791  Acc=0.5530\n",
      "[Pretrain] Epoch 49/50  Loss=1.3705  Acc=0.5546\n",
      "[Pretrain] Epoch 50/50  Loss=1.3692  Acc=0.5514\n",
      "[Fine-tune] Epoch 1/50  Loss=3.3402\n",
      "[Fine-tune] Epoch 2/50  Loss=3.2107\n",
      "[Fine-tune] Epoch 3/50  Loss=3.1279\n",
      "[Fine-tune] Epoch 4/50  Loss=3.0687\n",
      "[Fine-tune] Epoch 5/50  Loss=3.0202\n",
      "[Fine-tune] Epoch 6/50  Loss=2.9326\n",
      "[Fine-tune] Epoch 7/50  Loss=2.8179\n",
      "[Fine-tune] Epoch 8/50  Loss=2.7467\n",
      "[Fine-tune] Epoch 9/50  Loss=2.7052\n",
      "[Fine-tune] Epoch 10/50  Loss=2.6347\n",
      "[Fine-tune] Epoch 11/50  Loss=2.5682\n",
      "[Fine-tune] Epoch 12/50  Loss=2.4942\n",
      "[Fine-tune] Epoch 13/50  Loss=2.4544\n",
      "[Fine-tune] Epoch 14/50  Loss=2.4115\n",
      "[Fine-tune] Epoch 15/50  Loss=2.3677\n",
      "[Fine-tune] Epoch 16/50  Loss=2.3268\n",
      "[Fine-tune] Epoch 17/50  Loss=2.2920\n",
      "[Fine-tune] Epoch 18/50  Loss=2.2412\n",
      "[Fine-tune] Epoch 19/50  Loss=2.2205\n",
      "[Fine-tune] Epoch 20/50  Loss=2.1653\n",
      "[Fine-tune] Epoch 21/50  Loss=2.1307\n",
      "[Fine-tune] Epoch 22/50  Loss=2.1184\n",
      "[Fine-tune] Epoch 23/50  Loss=2.0713\n",
      "[Fine-tune] Epoch 24/50  Loss=2.0589\n",
      "[Fine-tune] Epoch 25/50  Loss=2.0580\n",
      "[Fine-tune] Epoch 26/50  Loss=2.0128\n",
      "[Fine-tune] Epoch 27/50  Loss=1.9980\n",
      "[Fine-tune] Epoch 28/50  Loss=1.9764\n",
      "[Fine-tune] Epoch 29/50  Loss=1.9597\n",
      "[Fine-tune] Epoch 30/50  Loss=1.9489\n",
      "[Fine-tune] Epoch 31/50  Loss=1.9149\n",
      "[Fine-tune] Epoch 32/50  Loss=1.9076\n",
      "[Fine-tune] Epoch 33/50  Loss=1.8855\n",
      "[Fine-tune] Epoch 34/50  Loss=1.8813\n",
      "[Fine-tune] Epoch 35/50  Loss=1.8700\n",
      "[Fine-tune] Epoch 36/50  Loss=1.8587\n",
      "[Fine-tune] Epoch 37/50  Loss=1.8406\n",
      "[Fine-tune] Epoch 38/50  Loss=1.8218\n",
      "[Fine-tune] Epoch 39/50  Loss=1.7945\n",
      "[Fine-tune] Epoch 40/50  Loss=1.7968\n",
      "[Fine-tune] Epoch 41/50  Loss=1.7753\n",
      "[Fine-tune] Epoch 42/50  Loss=1.7655\n",
      "[Fine-tune] Epoch 43/50  Loss=1.7546\n",
      "[Fine-tune] Epoch 44/50  Loss=1.7503\n",
      "[Fine-tune] Epoch 45/50  Loss=1.7284\n",
      "[Fine-tune] Epoch 46/50  Loss=1.7208\n",
      "[Fine-tune] Epoch 47/50  Loss=1.7106\n",
      "[Fine-tune] Epoch 48/50  Loss=1.7211\n",
      "[Fine-tune] Epoch 49/50  Loss=1.7024\n",
      "[Fine-tune] Epoch 50/50  Loss=1.6917\n",
      "[Pretrain] Epoch 1/50  Loss=3.6519  Acc=0.0383\n",
      "[Pretrain] Epoch 2/50  Loss=3.1297  Acc=0.0665\n",
      "[Pretrain] Epoch 3/50  Loss=2.9174  Acc=0.1101\n",
      "[Pretrain] Epoch 4/50  Loss=2.7061  Acc=0.1413\n",
      "[Pretrain] Epoch 5/50  Loss=2.5740  Acc=0.1843\n",
      "[Pretrain] Epoch 6/50  Loss=2.4350  Acc=0.2232\n",
      "[Pretrain] Epoch 7/50  Loss=2.3542  Acc=0.2437\n",
      "[Pretrain] Epoch 8/50  Loss=2.2988  Acc=0.2647\n",
      "[Pretrain] Epoch 9/50  Loss=2.2459  Acc=0.2782\n",
      "[Pretrain] Epoch 10/50  Loss=2.2061  Acc=0.2890\n",
      "[Pretrain] Epoch 11/50  Loss=2.1485  Acc=0.3134\n",
      "[Pretrain] Epoch 12/50  Loss=2.1328  Acc=0.3098\n",
      "[Pretrain] Epoch 13/50  Loss=2.0782  Acc=0.3294\n",
      "[Pretrain] Epoch 14/50  Loss=2.0297  Acc=0.3405\n",
      "[Pretrain] Epoch 15/50  Loss=2.0122  Acc=0.3464\n",
      "[Pretrain] Epoch 16/50  Loss=1.9768  Acc=0.3583\n",
      "[Pretrain] Epoch 17/50  Loss=1.9466  Acc=0.3669\n",
      "[Pretrain] Epoch 18/50  Loss=1.9237  Acc=0.3728\n",
      "[Pretrain] Epoch 19/50  Loss=1.9072  Acc=0.3781\n",
      "[Pretrain] Epoch 20/50  Loss=1.8519  Acc=0.3966\n",
      "[Pretrain] Epoch 21/50  Loss=1.8404  Acc=0.4050\n",
      "[Pretrain] Epoch 22/50  Loss=1.8208  Acc=0.3980\n",
      "[Pretrain] Epoch 23/50  Loss=1.7902  Acc=0.4154\n",
      "[Pretrain] Epoch 24/50  Loss=1.7833  Acc=0.4143\n",
      "[Pretrain] Epoch 25/50  Loss=1.7570  Acc=0.4296\n",
      "[Pretrain] Epoch 26/50  Loss=1.7467  Acc=0.4253\n",
      "[Pretrain] Epoch 27/50  Loss=1.6983  Acc=0.4470\n",
      "[Pretrain] Epoch 28/50  Loss=1.6819  Acc=0.4504\n",
      "[Pretrain] Epoch 29/50  Loss=1.6552  Acc=0.4544\n",
      "[Pretrain] Epoch 30/50  Loss=1.6501  Acc=0.4598\n",
      "[Pretrain] Epoch 31/50  Loss=1.6247  Acc=0.4671\n",
      "[Pretrain] Epoch 32/50  Loss=1.5949  Acc=0.4759\n",
      "[Pretrain] Epoch 33/50  Loss=1.5924  Acc=0.4788\n",
      "[Pretrain] Epoch 34/50  Loss=1.5773  Acc=0.4788\n",
      "[Pretrain] Epoch 35/50  Loss=1.5410  Acc=0.4939\n",
      "[Pretrain] Epoch 36/50  Loss=1.5128  Acc=0.5023\n",
      "[Pretrain] Epoch 37/50  Loss=1.5138  Acc=0.5032\n",
      "[Pretrain] Epoch 38/50  Loss=1.4933  Acc=0.5065\n",
      "[Pretrain] Epoch 39/50  Loss=1.4859  Acc=0.5101\n",
      "[Pretrain] Epoch 40/50  Loss=1.4594  Acc=0.5178\n",
      "[Pretrain] Epoch 41/50  Loss=1.4471  Acc=0.5122\n",
      "[Pretrain] Epoch 42/50  Loss=1.4395  Acc=0.5260\n",
      "[Pretrain] Epoch 43/50  Loss=1.4209  Acc=0.5302\n",
      "[Pretrain] Epoch 44/50  Loss=1.4092  Acc=0.5356\n",
      "[Pretrain] Epoch 45/50  Loss=1.3892  Acc=0.5476\n",
      "[Pretrain] Epoch 46/50  Loss=1.3583  Acc=0.5553\n",
      "[Pretrain] Epoch 47/50  Loss=1.3556  Acc=0.5533\n",
      "[Pretrain] Epoch 48/50  Loss=1.3411  Acc=0.5611\n",
      "[Pretrain] Epoch 49/50  Loss=1.3471  Acc=0.5546\n",
      "[Pretrain] Epoch 50/50  Loss=1.3217  Acc=0.5666\n",
      "[Fine-tune] Epoch 1/50  Loss=3.2345\n",
      "[Fine-tune] Epoch 2/50  Loss=3.0707\n",
      "[Fine-tune] Epoch 3/50  Loss=2.9116\n",
      "[Fine-tune] Epoch 4/50  Loss=2.7284\n",
      "[Fine-tune] Epoch 5/50  Loss=2.6156\n",
      "[Fine-tune] Epoch 6/50  Loss=2.5292\n",
      "[Fine-tune] Epoch 7/50  Loss=2.4113\n",
      "[Fine-tune] Epoch 8/50  Loss=2.3337\n",
      "[Fine-tune] Epoch 9/50  Loss=2.2791\n",
      "[Fine-tune] Epoch 10/50  Loss=2.2392\n",
      "[Fine-tune] Epoch 11/50  Loss=2.1982\n",
      "[Fine-tune] Epoch 12/50  Loss=2.1504\n",
      "[Fine-tune] Epoch 13/50  Loss=2.1143\n",
      "[Fine-tune] Epoch 14/50  Loss=2.0934\n",
      "[Fine-tune] Epoch 15/50  Loss=2.0725\n",
      "[Fine-tune] Epoch 16/50  Loss=2.0404\n",
      "[Fine-tune] Epoch 17/50  Loss=2.0038\n",
      "[Fine-tune] Epoch 18/50  Loss=1.9676\n",
      "[Fine-tune] Epoch 19/50  Loss=1.9482\n",
      "[Fine-tune] Epoch 20/50  Loss=1.9136\n",
      "[Fine-tune] Epoch 21/50  Loss=1.8887\n",
      "[Fine-tune] Epoch 22/50  Loss=1.8829\n",
      "[Fine-tune] Epoch 23/50  Loss=1.8528\n",
      "[Fine-tune] Epoch 24/50  Loss=1.8522\n",
      "[Fine-tune] Epoch 25/50  Loss=1.8195\n",
      "[Fine-tune] Epoch 26/50  Loss=1.8081\n",
      "[Fine-tune] Epoch 27/50  Loss=1.7977\n",
      "[Fine-tune] Epoch 28/50  Loss=1.7764\n",
      "[Fine-tune] Epoch 29/50  Loss=1.7620\n",
      "[Fine-tune] Epoch 30/50  Loss=1.7432\n",
      "[Fine-tune] Epoch 31/50  Loss=1.7338\n",
      "[Fine-tune] Epoch 32/50  Loss=1.7169\n",
      "[Fine-tune] Epoch 33/50  Loss=1.7005\n",
      "[Fine-tune] Epoch 34/50  Loss=1.6937\n",
      "[Fine-tune] Epoch 35/50  Loss=1.6917\n",
      "[Fine-tune] Epoch 36/50  Loss=1.6781\n",
      "[Fine-tune] Epoch 37/50  Loss=1.6571\n",
      "[Fine-tune] Epoch 38/50  Loss=1.6379\n",
      "[Fine-tune] Epoch 39/50  Loss=1.6566\n",
      "[Fine-tune] Epoch 40/50  Loss=1.6175\n",
      "[Fine-tune] Epoch 41/50  Loss=1.6225\n",
      "[Fine-tune] Epoch 42/50  Loss=1.6181\n",
      "[Fine-tune] Epoch 43/50  Loss=1.6019\n",
      "[Fine-tune] Epoch 44/50  Loss=1.6098\n",
      "[Fine-tune] Epoch 45/50  Loss=1.5944\n",
      "[Fine-tune] Epoch 46/50  Loss=1.5993\n",
      "[Fine-tune] Epoch 47/50  Loss=1.5927\n",
      "[Fine-tune] Epoch 48/50  Loss=1.5693\n",
      "[Fine-tune] Epoch 49/50  Loss=1.5633\n",
      "[Fine-tune] Epoch 50/50  Loss=1.5738\n",
      "[Pretrain] Epoch 1/75  Loss=3.2513  Acc=0.0427\n",
      "[Pretrain] Epoch 2/75  Loss=3.1211  Acc=0.0686\n",
      "[Pretrain] Epoch 3/75  Loss=2.9229  Acc=0.1083\n",
      "[Pretrain] Epoch 4/75  Loss=2.6477  Acc=0.1652\n",
      "[Pretrain] Epoch 5/75  Loss=2.4459  Acc=0.2200\n",
      "[Pretrain] Epoch 6/75  Loss=2.3538  Acc=0.2448\n",
      "[Pretrain] Epoch 7/75  Loss=2.2091  Acc=0.2888\n",
      "[Pretrain] Epoch 8/75  Loss=2.1404  Acc=0.3166\n",
      "[Pretrain] Epoch 9/75  Loss=2.0871  Acc=0.3211\n",
      "[Pretrain] Epoch 10/75  Loss=2.0583  Acc=0.3306\n",
      "[Pretrain] Epoch 11/75  Loss=2.0217  Acc=0.3432\n",
      "[Pretrain] Epoch 12/75  Loss=1.9889  Acc=0.3518\n",
      "[Pretrain] Epoch 13/75  Loss=1.9660  Acc=0.3570\n",
      "[Pretrain] Epoch 14/75  Loss=1.9225  Acc=0.3755\n",
      "[Pretrain] Epoch 15/75  Loss=1.9118  Acc=0.3786\n",
      "[Pretrain] Epoch 16/75  Loss=1.8874  Acc=0.3822\n",
      "[Pretrain] Epoch 17/75  Loss=1.8685  Acc=0.3845\n",
      "[Pretrain] Epoch 18/75  Loss=1.8297  Acc=0.4050\n",
      "[Pretrain] Epoch 19/75  Loss=1.8370  Acc=0.4057\n",
      "[Pretrain] Epoch 20/75  Loss=1.7978  Acc=0.4210\n",
      "[Pretrain] Epoch 21/75  Loss=1.7616  Acc=0.4274\n",
      "[Pretrain] Epoch 22/75  Loss=1.7602  Acc=0.4355\n",
      "[Pretrain] Epoch 23/75  Loss=1.7324  Acc=0.4377\n",
      "[Pretrain] Epoch 24/75  Loss=1.7552  Acc=0.4237\n",
      "[Pretrain] Epoch 25/75  Loss=1.6970  Acc=0.4503\n",
      "[Pretrain] Epoch 26/75  Loss=1.6916  Acc=0.4520\n",
      "[Pretrain] Epoch 27/75  Loss=1.6606  Acc=0.4641\n",
      "[Pretrain] Epoch 28/75  Loss=1.6603  Acc=0.4634\n",
      "[Pretrain] Epoch 29/75  Loss=1.6397  Acc=0.4680\n",
      "[Pretrain] Epoch 30/75  Loss=1.6218  Acc=0.4723\n",
      "[Pretrain] Epoch 31/75  Loss=1.5869  Acc=0.4835\n",
      "[Pretrain] Epoch 32/75  Loss=1.6073  Acc=0.4750\n",
      "[Pretrain] Epoch 33/75  Loss=1.5650  Acc=0.4899\n",
      "[Pretrain] Epoch 34/75  Loss=1.5760  Acc=0.4883\n",
      "[Pretrain] Epoch 35/75  Loss=1.5552  Acc=0.4937\n",
      "[Pretrain] Epoch 36/75  Loss=1.5490  Acc=0.4986\n",
      "[Pretrain] Epoch 37/75  Loss=1.5287  Acc=0.5041\n",
      "[Pretrain] Epoch 38/75  Loss=1.5392  Acc=0.4977\n",
      "[Pretrain] Epoch 39/75  Loss=1.5049  Acc=0.5124\n",
      "[Pretrain] Epoch 40/75  Loss=1.5102  Acc=0.5106\n",
      "[Pretrain] Epoch 41/75  Loss=1.4842  Acc=0.5162\n",
      "[Pretrain] Epoch 42/75  Loss=1.4929  Acc=0.5122\n",
      "[Pretrain] Epoch 43/75  Loss=1.4717  Acc=0.5269\n",
      "[Pretrain] Epoch 44/75  Loss=1.4562  Acc=0.5350\n",
      "[Pretrain] Epoch 45/75  Loss=1.4529  Acc=0.5293\n",
      "[Pretrain] Epoch 46/75  Loss=1.4467  Acc=0.5235\n",
      "[Pretrain] Epoch 47/75  Loss=1.4298  Acc=0.5318\n",
      "[Pretrain] Epoch 48/75  Loss=1.4278  Acc=0.5352\n",
      "[Pretrain] Epoch 49/75  Loss=1.4317  Acc=0.5366\n",
      "[Pretrain] Epoch 50/75  Loss=1.4170  Acc=0.5411\n",
      "[Pretrain] Epoch 51/75  Loss=1.4217  Acc=0.5366\n",
      "[Pretrain] Epoch 52/75  Loss=1.3984  Acc=0.5501\n",
      "[Pretrain] Epoch 53/75  Loss=1.4070  Acc=0.5440\n",
      "[Pretrain] Epoch 54/75  Loss=1.3779  Acc=0.5521\n",
      "[Pretrain] Epoch 55/75  Loss=1.3779  Acc=0.5483\n",
      "[Pretrain] Epoch 56/75  Loss=1.3838  Acc=0.5503\n",
      "[Pretrain] Epoch 57/75  Loss=1.3739  Acc=0.5514\n",
      "[Pretrain] Epoch 58/75  Loss=1.3687  Acc=0.5512\n",
      "[Pretrain] Epoch 59/75  Loss=1.3727  Acc=0.5548\n",
      "[Pretrain] Epoch 60/75  Loss=1.3715  Acc=0.5510\n",
      "[Pretrain] Epoch 61/75  Loss=1.3703  Acc=0.5506\n",
      "[Pretrain] Epoch 62/75  Loss=1.3491  Acc=0.5571\n",
      "[Pretrain] Epoch 63/75  Loss=1.3535  Acc=0.5641\n",
      "[Pretrain] Epoch 64/75  Loss=1.3490  Acc=0.5625\n",
      "[Pretrain] Epoch 65/75  Loss=1.3764  Acc=0.5503\n",
      "[Pretrain] Epoch 66/75  Loss=1.3516  Acc=0.5557\n",
      "[Pretrain] Epoch 67/75  Loss=1.3409  Acc=0.5627\n",
      "[Pretrain] Epoch 68/75  Loss=1.3508  Acc=0.5616\n",
      "[Pretrain] Epoch 69/75  Loss=1.3499  Acc=0.5654\n",
      "[Pretrain] Epoch 70/75  Loss=1.3444  Acc=0.5596\n",
      "[Pretrain] Epoch 71/75  Loss=1.3429  Acc=0.5665\n",
      "[Pretrain] Epoch 72/75  Loss=1.3394  Acc=0.5686\n",
      "[Pretrain] Epoch 73/75  Loss=1.3428  Acc=0.5636\n",
      "[Pretrain] Epoch 74/75  Loss=1.3322  Acc=0.5665\n",
      "[Pretrain] Epoch 75/75  Loss=1.3367  Acc=0.5625\n",
      "[Fine-tune] Epoch 1/50  Loss=3.3059\n",
      "[Fine-tune] Epoch 2/50  Loss=3.1784\n",
      "[Fine-tune] Epoch 3/50  Loss=3.0792\n",
      "[Fine-tune] Epoch 4/50  Loss=3.0452\n",
      "[Fine-tune] Epoch 5/50  Loss=2.9234\n",
      "[Fine-tune] Epoch 6/50  Loss=2.7434\n",
      "[Fine-tune] Epoch 7/50  Loss=2.5966\n",
      "[Fine-tune] Epoch 8/50  Loss=2.5041\n",
      "[Fine-tune] Epoch 9/50  Loss=2.4673\n",
      "[Fine-tune] Epoch 10/50  Loss=2.4056\n",
      "[Fine-tune] Epoch 11/50  Loss=2.3749\n",
      "[Fine-tune] Epoch 12/50  Loss=2.3095\n",
      "[Fine-tune] Epoch 13/50  Loss=2.2847\n",
      "[Fine-tune] Epoch 14/50  Loss=2.2417\n",
      "[Fine-tune] Epoch 15/50  Loss=2.2415\n",
      "[Fine-tune] Epoch 16/50  Loss=2.1793\n",
      "[Fine-tune] Epoch 17/50  Loss=2.1728\n",
      "[Fine-tune] Epoch 18/50  Loss=2.1292\n",
      "[Fine-tune] Epoch 19/50  Loss=2.1045\n",
      "[Fine-tune] Epoch 20/50  Loss=2.0539\n",
      "[Fine-tune] Epoch 21/50  Loss=2.0503\n",
      "[Fine-tune] Epoch 22/50  Loss=2.0505\n",
      "[Fine-tune] Epoch 23/50  Loss=2.0015\n",
      "[Fine-tune] Epoch 24/50  Loss=1.9884\n",
      "[Fine-tune] Epoch 25/50  Loss=1.9594\n",
      "[Fine-tune] Epoch 26/50  Loss=1.9206\n",
      "[Fine-tune] Epoch 27/50  Loss=1.9081\n",
      "[Fine-tune] Epoch 28/50  Loss=1.9094\n",
      "[Fine-tune] Epoch 29/50  Loss=1.8680\n",
      "[Fine-tune] Epoch 30/50  Loss=1.8521\n",
      "[Fine-tune] Epoch 31/50  Loss=1.8362\n",
      "[Fine-tune] Epoch 32/50  Loss=1.8120\n",
      "[Fine-tune] Epoch 33/50  Loss=1.8087\n",
      "[Fine-tune] Epoch 34/50  Loss=1.7919\n",
      "[Fine-tune] Epoch 35/50  Loss=1.7646\n",
      "[Fine-tune] Epoch 36/50  Loss=1.7534\n",
      "[Fine-tune] Epoch 37/50  Loss=1.7159\n",
      "[Fine-tune] Epoch 38/50  Loss=1.7396\n",
      "[Fine-tune] Epoch 39/50  Loss=1.7148\n",
      "[Fine-tune] Epoch 40/50  Loss=1.6968\n",
      "[Fine-tune] Epoch 41/50  Loss=1.6812\n",
      "[Fine-tune] Epoch 42/50  Loss=1.6709\n",
      "[Fine-tune] Epoch 43/50  Loss=1.6507\n",
      "[Fine-tune] Epoch 44/50  Loss=1.6456\n",
      "[Fine-tune] Epoch 45/50  Loss=1.6365\n",
      "[Fine-tune] Epoch 46/50  Loss=1.6240\n",
      "[Fine-tune] Epoch 47/50  Loss=1.6010\n",
      "[Fine-tune] Epoch 48/50  Loss=1.5976\n",
      "[Fine-tune] Epoch 49/50  Loss=1.5887\n",
      "[Fine-tune] Epoch 50/50  Loss=1.5727\n",
      "[Pretrain] Epoch 1/75  Loss=3.7016  Acc=0.0462\n",
      "[Pretrain] Epoch 2/75  Loss=3.1083  Acc=0.0769\n",
      "[Pretrain] Epoch 3/75  Loss=3.0455  Acc=0.0916\n",
      "[Pretrain] Epoch 4/75  Loss=2.8247  Acc=0.1351\n",
      "[Pretrain] Epoch 5/75  Loss=2.6213  Acc=0.1731\n",
      "[Pretrain] Epoch 6/75  Loss=2.4812  Acc=0.2101\n",
      "[Pretrain] Epoch 7/75  Loss=2.4054  Acc=0.2340\n",
      "[Pretrain] Epoch 8/75  Loss=2.3304  Acc=0.2658\n",
      "[Pretrain] Epoch 9/75  Loss=2.2559  Acc=0.2773\n",
      "[Pretrain] Epoch 10/75  Loss=2.2314  Acc=0.2847\n",
      "[Pretrain] Epoch 11/75  Loss=2.1874  Acc=0.2963\n",
      "[Pretrain] Epoch 12/75  Loss=2.1342  Acc=0.3145\n",
      "[Pretrain] Epoch 13/75  Loss=2.0968  Acc=0.3199\n",
      "[Pretrain] Epoch 14/75  Loss=2.0780  Acc=0.3276\n",
      "[Pretrain] Epoch 15/75  Loss=2.0493  Acc=0.3346\n",
      "[Pretrain] Epoch 16/75  Loss=2.0137  Acc=0.3527\n",
      "[Pretrain] Epoch 17/75  Loss=1.9901  Acc=0.3506\n",
      "[Pretrain] Epoch 18/75  Loss=1.9630  Acc=0.3684\n",
      "[Pretrain] Epoch 19/75  Loss=1.9370  Acc=0.3689\n",
      "[Pretrain] Epoch 20/75  Loss=1.9336  Acc=0.3667\n",
      "[Pretrain] Epoch 21/75  Loss=1.8975  Acc=0.3865\n",
      "[Pretrain] Epoch 22/75  Loss=1.8546  Acc=0.4000\n",
      "[Pretrain] Epoch 23/75  Loss=1.8418  Acc=0.3982\n",
      "[Pretrain] Epoch 24/75  Loss=1.8291  Acc=0.4003\n",
      "[Pretrain] Epoch 25/75  Loss=1.7962  Acc=0.4133\n",
      "[Pretrain] Epoch 26/75  Loss=1.7770  Acc=0.4149\n",
      "[Pretrain] Epoch 27/75  Loss=1.7667  Acc=0.4210\n",
      "[Pretrain] Epoch 28/75  Loss=1.7593  Acc=0.4278\n",
      "[Pretrain] Epoch 29/75  Loss=1.7215  Acc=0.4327\n",
      "[Pretrain] Epoch 30/75  Loss=1.7143  Acc=0.4409\n",
      "[Pretrain] Epoch 31/75  Loss=1.6812  Acc=0.4540\n",
      "[Pretrain] Epoch 32/75  Loss=1.6830  Acc=0.4474\n",
      "[Pretrain] Epoch 33/75  Loss=1.6478  Acc=0.4646\n",
      "[Pretrain] Epoch 34/75  Loss=1.6426  Acc=0.4720\n",
      "[Pretrain] Epoch 35/75  Loss=1.6083  Acc=0.4729\n",
      "[Pretrain] Epoch 36/75  Loss=1.5951  Acc=0.4745\n",
      "[Pretrain] Epoch 37/75  Loss=1.5650  Acc=0.4925\n",
      "[Pretrain] Epoch 38/75  Loss=1.5638  Acc=0.4878\n",
      "[Pretrain] Epoch 39/75  Loss=1.5426  Acc=0.4939\n",
      "[Pretrain] Epoch 40/75  Loss=1.5180  Acc=0.5045\n",
      "[Pretrain] Epoch 41/75  Loss=1.5084  Acc=0.5043\n",
      "[Pretrain] Epoch 42/75  Loss=1.5066  Acc=0.4996\n",
      "[Pretrain] Epoch 43/75  Loss=1.4819  Acc=0.5171\n",
      "[Pretrain] Epoch 44/75  Loss=1.4822  Acc=0.5074\n",
      "[Pretrain] Epoch 45/75  Loss=1.4543  Acc=0.5192\n",
      "[Pretrain] Epoch 46/75  Loss=1.4421  Acc=0.5284\n",
      "[Pretrain] Epoch 47/75  Loss=1.4187  Acc=0.5295\n",
      "[Pretrain] Epoch 48/75  Loss=1.4209  Acc=0.5291\n",
      "[Pretrain] Epoch 49/75  Loss=1.4101  Acc=0.5330\n",
      "[Pretrain] Epoch 50/75  Loss=1.3913  Acc=0.5415\n",
      "[Pretrain] Epoch 51/75  Loss=1.3892  Acc=0.5431\n",
      "[Pretrain] Epoch 52/75  Loss=1.3733  Acc=0.5515\n",
      "[Pretrain] Epoch 53/75  Loss=1.3468  Acc=0.5542\n",
      "[Pretrain] Epoch 54/75  Loss=1.3509  Acc=0.5490\n",
      "[Pretrain] Epoch 55/75  Loss=1.3598  Acc=0.5533\n",
      "[Pretrain] Epoch 56/75  Loss=1.3508  Acc=0.5555\n",
      "[Pretrain] Epoch 57/75  Loss=1.3368  Acc=0.5668\n",
      "[Pretrain] Epoch 58/75  Loss=1.3232  Acc=0.5650\n",
      "[Pretrain] Epoch 59/75  Loss=1.3247  Acc=0.5656\n",
      "[Pretrain] Epoch 60/75  Loss=1.3088  Acc=0.5618\n",
      "[Pretrain] Epoch 61/75  Loss=1.2998  Acc=0.5751\n",
      "[Pretrain] Epoch 62/75  Loss=1.2957  Acc=0.5769\n",
      "[Pretrain] Epoch 63/75  Loss=1.3080  Acc=0.5652\n",
      "[Pretrain] Epoch 64/75  Loss=1.2926  Acc=0.5722\n",
      "[Pretrain] Epoch 65/75  Loss=1.2870  Acc=0.5808\n",
      "[Pretrain] Epoch 66/75  Loss=1.2716  Acc=0.5823\n",
      "[Pretrain] Epoch 67/75  Loss=1.2671  Acc=0.5823\n",
      "[Pretrain] Epoch 68/75  Loss=1.2671  Acc=0.5855\n",
      "[Pretrain] Epoch 69/75  Loss=1.2579  Acc=0.5905\n",
      "[Pretrain] Epoch 70/75  Loss=1.2593  Acc=0.5815\n",
      "[Pretrain] Epoch 71/75  Loss=1.2568  Acc=0.5849\n",
      "[Pretrain] Epoch 72/75  Loss=1.2543  Acc=0.5839\n",
      "[Pretrain] Epoch 73/75  Loss=1.2332  Acc=0.5864\n",
      "[Pretrain] Epoch 74/75  Loss=1.2597  Acc=0.5860\n",
      "[Pretrain] Epoch 75/75  Loss=1.2384  Acc=0.5907\n",
      "[Fine-tune] Epoch 1/50  Loss=3.2400\n",
      "[Fine-tune] Epoch 2/50  Loss=3.0122\n",
      "[Fine-tune] Epoch 3/50  Loss=2.7796\n",
      "[Fine-tune] Epoch 4/50  Loss=2.6152\n",
      "[Fine-tune] Epoch 5/50  Loss=2.5011\n",
      "[Fine-tune] Epoch 6/50  Loss=2.3651\n",
      "[Fine-tune] Epoch 7/50  Loss=2.3117\n",
      "[Fine-tune] Epoch 8/50  Loss=2.2759\n",
      "[Fine-tune] Epoch 9/50  Loss=2.2122\n",
      "[Fine-tune] Epoch 10/50  Loss=2.1834\n",
      "[Fine-tune] Epoch 11/50  Loss=2.1327\n",
      "[Fine-tune] Epoch 12/50  Loss=2.1004\n",
      "[Fine-tune] Epoch 13/50  Loss=2.0725\n",
      "[Fine-tune] Epoch 14/50  Loss=2.0501\n",
      "[Fine-tune] Epoch 15/50  Loss=2.0151\n",
      "[Fine-tune] Epoch 16/50  Loss=2.0019\n",
      "[Fine-tune] Epoch 17/50  Loss=1.9747\n",
      "[Fine-tune] Epoch 18/50  Loss=1.9394\n",
      "[Fine-tune] Epoch 19/50  Loss=1.9226\n",
      "[Fine-tune] Epoch 20/50  Loss=1.9087\n",
      "[Fine-tune] Epoch 21/50  Loss=1.8824\n",
      "[Fine-tune] Epoch 22/50  Loss=1.8519\n",
      "[Fine-tune] Epoch 23/50  Loss=1.8419\n",
      "[Fine-tune] Epoch 24/50  Loss=1.8242\n",
      "[Fine-tune] Epoch 25/50  Loss=1.8038\n",
      "[Fine-tune] Epoch 26/50  Loss=1.7904\n",
      "[Fine-tune] Epoch 27/50  Loss=1.7834\n",
      "[Fine-tune] Epoch 28/50  Loss=1.7752\n",
      "[Fine-tune] Epoch 29/50  Loss=1.7526\n",
      "[Fine-tune] Epoch 30/50  Loss=1.7397\n",
      "[Fine-tune] Epoch 31/50  Loss=1.7245\n",
      "[Fine-tune] Epoch 32/50  Loss=1.7130\n",
      "[Fine-tune] Epoch 33/50  Loss=1.6910\n",
      "[Fine-tune] Epoch 34/50  Loss=1.6911\n",
      "[Fine-tune] Epoch 35/50  Loss=1.6655\n",
      "[Fine-tune] Epoch 36/50  Loss=1.6567\n",
      "[Fine-tune] Epoch 37/50  Loss=1.6379\n",
      "[Fine-tune] Epoch 38/50  Loss=1.6322\n",
      "[Fine-tune] Epoch 39/50  Loss=1.6352\n",
      "[Fine-tune] Epoch 40/50  Loss=1.6045\n",
      "[Fine-tune] Epoch 41/50  Loss=1.6137\n",
      "[Fine-tune] Epoch 42/50  Loss=1.5914\n",
      "[Fine-tune] Epoch 43/50  Loss=1.5738\n",
      "[Fine-tune] Epoch 44/50  Loss=1.5729\n",
      "[Fine-tune] Epoch 45/50  Loss=1.5616\n",
      "[Fine-tune] Epoch 46/50  Loss=1.5608\n",
      "[Fine-tune] Epoch 47/50  Loss=1.5572\n",
      "[Fine-tune] Epoch 48/50  Loss=1.5361\n",
      "[Fine-tune] Epoch 49/50  Loss=1.5449\n",
      "[Fine-tune] Epoch 50/50  Loss=1.5399\n",
      "[Pretrain] Epoch 1/100  Loss=3.2525  Acc=0.0402\n",
      "[Pretrain] Epoch 2/100  Loss=3.1289  Acc=0.0661\n",
      "[Pretrain] Epoch 3/100  Loss=3.0464  Acc=0.0806\n",
      "[Pretrain] Epoch 4/100  Loss=3.0034  Acc=0.0948\n",
      "[Pretrain] Epoch 5/100  Loss=2.9271  Acc=0.1160\n",
      "[Pretrain] Epoch 6/100  Loss=2.7159  Acc=0.1480\n",
      "[Pretrain] Epoch 7/100  Loss=2.4901  Acc=0.2168\n",
      "[Pretrain] Epoch 8/100  Loss=2.3181  Acc=0.2624\n",
      "[Pretrain] Epoch 9/100  Loss=2.2263  Acc=0.2848\n",
      "[Pretrain] Epoch 10/100  Loss=2.1626  Acc=0.3050\n",
      "[Pretrain] Epoch 11/100  Loss=2.0906  Acc=0.3224\n",
      "[Pretrain] Epoch 12/100  Loss=2.0574  Acc=0.3364\n",
      "[Pretrain] Epoch 13/100  Loss=2.0312  Acc=0.3459\n",
      "[Pretrain] Epoch 14/100  Loss=1.9874  Acc=0.3621\n",
      "[Pretrain] Epoch 15/100  Loss=1.9502  Acc=0.3718\n",
      "[Pretrain] Epoch 16/100  Loss=1.8987  Acc=0.3822\n",
      "[Pretrain] Epoch 17/100  Loss=1.8996  Acc=0.3870\n",
      "[Pretrain] Epoch 18/100  Loss=1.8364  Acc=0.3994\n",
      "[Pretrain] Epoch 19/100  Loss=1.8613  Acc=0.3940\n",
      "[Pretrain] Epoch 20/100  Loss=1.8225  Acc=0.4152\n",
      "[Pretrain] Epoch 21/100  Loss=1.8014  Acc=0.4149\n",
      "[Pretrain] Epoch 22/100  Loss=1.7791  Acc=0.4246\n",
      "[Pretrain] Epoch 23/100  Loss=1.7619  Acc=0.4355\n",
      "[Pretrain] Epoch 24/100  Loss=1.7301  Acc=0.4377\n",
      "[Pretrain] Epoch 25/100  Loss=1.7302  Acc=0.4422\n",
      "[Pretrain] Epoch 26/100  Loss=1.7076  Acc=0.4486\n",
      "[Pretrain] Epoch 27/100  Loss=1.6797  Acc=0.4485\n",
      "[Pretrain] Epoch 28/100  Loss=1.6748  Acc=0.4553\n",
      "[Pretrain] Epoch 29/100  Loss=1.6572  Acc=0.4632\n",
      "[Pretrain] Epoch 30/100  Loss=1.6534  Acc=0.4612\n",
      "[Pretrain] Epoch 31/100  Loss=1.6277  Acc=0.4802\n",
      "[Pretrain] Epoch 32/100  Loss=1.6199  Acc=0.4820\n",
      "[Pretrain] Epoch 33/100  Loss=1.6023  Acc=0.4758\n",
      "[Pretrain] Epoch 34/100  Loss=1.6043  Acc=0.4750\n",
      "[Pretrain] Epoch 35/100  Loss=1.5958  Acc=0.4820\n",
      "[Pretrain] Epoch 36/100  Loss=1.5898  Acc=0.4788\n",
      "[Pretrain] Epoch 37/100  Loss=1.5458  Acc=0.4960\n",
      "[Pretrain] Epoch 38/100  Loss=1.5566  Acc=0.4964\n",
      "[Pretrain] Epoch 39/100  Loss=1.5458  Acc=0.5036\n",
      "[Pretrain] Epoch 40/100  Loss=1.5450  Acc=0.4950\n",
      "[Pretrain] Epoch 41/100  Loss=1.5191  Acc=0.5136\n",
      "[Pretrain] Epoch 42/100  Loss=1.4957  Acc=0.5149\n",
      "[Pretrain] Epoch 43/100  Loss=1.4971  Acc=0.5140\n",
      "[Pretrain] Epoch 44/100  Loss=1.4988  Acc=0.5122\n",
      "[Pretrain] Epoch 45/100  Loss=1.4680  Acc=0.5199\n",
      "[Pretrain] Epoch 46/100  Loss=1.4771  Acc=0.5183\n",
      "[Pretrain] Epoch 47/100  Loss=1.4713  Acc=0.5210\n",
      "[Pretrain] Epoch 48/100  Loss=1.4787  Acc=0.5207\n",
      "[Pretrain] Epoch 49/100  Loss=1.4558  Acc=0.5309\n",
      "[Pretrain] Epoch 50/100  Loss=1.4557  Acc=0.5291\n",
      "[Pretrain] Epoch 51/100  Loss=1.4472  Acc=0.5235\n",
      "[Pretrain] Epoch 52/100  Loss=1.4444  Acc=0.5350\n",
      "[Pretrain] Epoch 53/100  Loss=1.4355  Acc=0.5318\n",
      "[Pretrain] Epoch 54/100  Loss=1.4337  Acc=0.5282\n",
      "[Pretrain] Epoch 55/100  Loss=1.4213  Acc=0.5418\n",
      "[Pretrain] Epoch 56/100  Loss=1.4289  Acc=0.5329\n",
      "[Pretrain] Epoch 57/100  Loss=1.4210  Acc=0.5318\n",
      "[Pretrain] Epoch 58/100  Loss=1.4003  Acc=0.5476\n",
      "[Pretrain] Epoch 59/100  Loss=1.4146  Acc=0.5383\n",
      "[Pretrain] Epoch 60/100  Loss=1.4021  Acc=0.5462\n",
      "[Pretrain] Epoch 61/100  Loss=1.3940  Acc=0.5445\n",
      "[Pretrain] Epoch 62/100  Loss=1.3991  Acc=0.5524\n",
      "[Pretrain] Epoch 63/100  Loss=1.3940  Acc=0.5415\n",
      "[Pretrain] Epoch 64/100  Loss=1.4010  Acc=0.5424\n",
      "[Pretrain] Epoch 65/100  Loss=1.3886  Acc=0.5469\n",
      "[Pretrain] Epoch 66/100  Loss=1.3806  Acc=0.5515\n",
      "[Pretrain] Epoch 67/100  Loss=1.3795  Acc=0.5472\n",
      "[Pretrain] Epoch 68/100  Loss=1.3986  Acc=0.5463\n",
      "[Pretrain] Epoch 69/100  Loss=1.3754  Acc=0.5557\n",
      "[Pretrain] Epoch 70/100  Loss=1.3772  Acc=0.5528\n",
      "[Pretrain] Epoch 71/100  Loss=1.3695  Acc=0.5569\n",
      "[Pretrain] Epoch 72/100  Loss=1.3580  Acc=0.5530\n",
      "[Pretrain] Epoch 73/100  Loss=1.3697  Acc=0.5609\n",
      "[Pretrain] Epoch 74/100  Loss=1.3863  Acc=0.5532\n",
      "[Pretrain] Epoch 75/100  Loss=1.3605  Acc=0.5555\n",
      "[Pretrain] Epoch 76/100  Loss=1.3598  Acc=0.5598\n",
      "[Pretrain] Epoch 77/100  Loss=1.3580  Acc=0.5578\n",
      "[Pretrain] Epoch 78/100  Loss=1.3539  Acc=0.5636\n",
      "[Pretrain] Epoch 79/100  Loss=1.3559  Acc=0.5609\n",
      "[Pretrain] Epoch 80/100  Loss=1.3536  Acc=0.5575\n",
      "[Pretrain] Epoch 81/100  Loss=1.3580  Acc=0.5560\n",
      "[Pretrain] Epoch 82/100  Loss=1.3566  Acc=0.5639\n",
      "[Pretrain] Epoch 83/100  Loss=1.3662  Acc=0.5553\n",
      "[Pretrain] Epoch 84/100  Loss=1.3593  Acc=0.5550\n",
      "[Pretrain] Epoch 85/100  Loss=1.3594  Acc=0.5627\n",
      "[Pretrain] Epoch 86/100  Loss=1.3481  Acc=0.5571\n",
      "[Pretrain] Epoch 87/100  Loss=1.3452  Acc=0.5620\n",
      "[Pretrain] Epoch 88/100  Loss=1.3439  Acc=0.5623\n",
      "[Pretrain] Epoch 89/100  Loss=1.3407  Acc=0.5699\n",
      "[Pretrain] Epoch 90/100  Loss=1.3399  Acc=0.5616\n",
      "[Pretrain] Epoch 91/100  Loss=1.3505  Acc=0.5652\n",
      "[Pretrain] Epoch 92/100  Loss=1.3351  Acc=0.5663\n",
      "[Pretrain] Epoch 93/100  Loss=1.3378  Acc=0.5564\n",
      "[Pretrain] Epoch 94/100  Loss=1.3515  Acc=0.5593\n",
      "[Pretrain] Epoch 95/100  Loss=1.3427  Acc=0.5594\n",
      "[Pretrain] Epoch 96/100  Loss=1.3261  Acc=0.5706\n",
      "[Pretrain] Epoch 97/100  Loss=1.3499  Acc=0.5596\n",
      "[Pretrain] Epoch 98/100  Loss=1.3449  Acc=0.5575\n",
      "[Pretrain] Epoch 99/100  Loss=1.3403  Acc=0.5708\n",
      "[Pretrain] Epoch 100/100  Loss=1.3273  Acc=0.5693\n",
      "[Fine-tune] Epoch 1/50  Loss=3.3017\n",
      "[Fine-tune] Epoch 2/50  Loss=3.1972\n",
      "[Fine-tune] Epoch 3/50  Loss=3.1014\n",
      "[Fine-tune] Epoch 4/50  Loss=3.0626\n",
      "[Fine-tune] Epoch 5/50  Loss=3.0198\n",
      "[Fine-tune] Epoch 6/50  Loss=2.9057\n",
      "[Fine-tune] Epoch 7/50  Loss=2.7944\n",
      "[Fine-tune] Epoch 8/50  Loss=2.7581\n",
      "[Fine-tune] Epoch 9/50  Loss=2.6898\n",
      "[Fine-tune] Epoch 10/50  Loss=2.6690\n",
      "[Fine-tune] Epoch 11/50  Loss=2.5800\n",
      "[Fine-tune] Epoch 12/50  Loss=2.5152\n",
      "[Fine-tune] Epoch 13/50  Loss=2.4537\n",
      "[Fine-tune] Epoch 14/50  Loss=2.3962\n",
      "[Fine-tune] Epoch 15/50  Loss=2.3278\n",
      "[Fine-tune] Epoch 16/50  Loss=2.2673\n",
      "[Fine-tune] Epoch 17/50  Loss=2.2331\n",
      "[Fine-tune] Epoch 18/50  Loss=2.1558\n",
      "[Fine-tune] Epoch 19/50  Loss=2.1380\n",
      "[Fine-tune] Epoch 20/50  Loss=2.1079\n",
      "[Fine-tune] Epoch 21/50  Loss=2.0913\n",
      "[Fine-tune] Epoch 22/50  Loss=2.0506\n",
      "[Fine-tune] Epoch 23/50  Loss=2.0488\n",
      "[Fine-tune] Epoch 24/50  Loss=2.0243\n",
      "[Fine-tune] Epoch 25/50  Loss=1.9991\n",
      "[Fine-tune] Epoch 26/50  Loss=1.9776\n",
      "[Fine-tune] Epoch 27/50  Loss=1.9587\n",
      "[Fine-tune] Epoch 28/50  Loss=1.9529\n",
      "[Fine-tune] Epoch 29/50  Loss=1.9303\n",
      "[Fine-tune] Epoch 30/50  Loss=1.9098\n",
      "[Fine-tune] Epoch 31/50  Loss=1.9042\n",
      "[Fine-tune] Epoch 32/50  Loss=1.8731\n",
      "[Fine-tune] Epoch 33/50  Loss=1.8594\n",
      "[Fine-tune] Epoch 34/50  Loss=1.8473\n",
      "[Fine-tune] Epoch 35/50  Loss=1.8306\n",
      "[Fine-tune] Epoch 36/50  Loss=1.8196\n",
      "[Fine-tune] Epoch 37/50  Loss=1.8007\n",
      "[Fine-tune] Epoch 38/50  Loss=1.8047\n",
      "[Fine-tune] Epoch 39/50  Loss=1.7830\n",
      "[Fine-tune] Epoch 40/50  Loss=1.7650\n",
      "[Fine-tune] Epoch 41/50  Loss=1.7692\n",
      "[Fine-tune] Epoch 42/50  Loss=1.7255\n",
      "[Fine-tune] Epoch 43/50  Loss=1.7317\n",
      "[Fine-tune] Epoch 44/50  Loss=1.7215\n",
      "[Fine-tune] Epoch 45/50  Loss=1.7039\n",
      "[Fine-tune] Epoch 46/50  Loss=1.7067\n",
      "[Fine-tune] Epoch 47/50  Loss=1.7001\n",
      "[Fine-tune] Epoch 48/50  Loss=1.6734\n",
      "[Fine-tune] Epoch 49/50  Loss=1.6784\n",
      "[Fine-tune] Epoch 50/50  Loss=1.6593\n",
      "[Pretrain] Epoch 1/100  Loss=3.7488  Acc=0.0438\n",
      "[Pretrain] Epoch 2/100  Loss=3.0987  Acc=0.0677\n",
      "[Pretrain] Epoch 3/100  Loss=2.8195  Acc=0.1142\n",
      "[Pretrain] Epoch 4/100  Loss=2.6985  Acc=0.1288\n",
      "[Pretrain] Epoch 5/100  Loss=2.6465  Acc=0.1406\n",
      "[Pretrain] Epoch 6/100  Loss=2.5710  Acc=0.1758\n",
      "[Pretrain] Epoch 7/100  Loss=2.5019  Acc=0.1803\n",
      "[Pretrain] Epoch 8/100  Loss=2.4561  Acc=0.2144\n",
      "[Pretrain] Epoch 9/100  Loss=2.3849  Acc=0.2369\n",
      "[Pretrain] Epoch 10/100  Loss=2.2742  Acc=0.2631\n",
      "[Pretrain] Epoch 11/100  Loss=2.2708  Acc=0.2687\n",
      "[Pretrain] Epoch 12/100  Loss=2.2115  Acc=0.2884\n",
      "[Pretrain] Epoch 13/100  Loss=2.1514  Acc=0.3051\n",
      "[Pretrain] Epoch 14/100  Loss=2.1072  Acc=0.3132\n",
      "[Pretrain] Epoch 15/100  Loss=2.0808  Acc=0.3218\n",
      "[Pretrain] Epoch 16/100  Loss=2.0634  Acc=0.3285\n",
      "[Pretrain] Epoch 17/100  Loss=2.0337  Acc=0.3367\n",
      "[Pretrain] Epoch 18/100  Loss=1.9792  Acc=0.3549\n",
      "[Pretrain] Epoch 19/100  Loss=1.9784  Acc=0.3522\n",
      "[Pretrain] Epoch 20/100  Loss=1.9300  Acc=0.3588\n",
      "[Pretrain] Epoch 21/100  Loss=1.9110  Acc=0.3678\n",
      "[Pretrain] Epoch 22/100  Loss=1.9036  Acc=0.3757\n",
      "[Pretrain] Epoch 23/100  Loss=1.8879  Acc=0.3795\n",
      "[Pretrain] Epoch 24/100  Loss=1.8568  Acc=0.3901\n",
      "[Pretrain] Epoch 25/100  Loss=1.8227  Acc=0.4091\n",
      "[Pretrain] Epoch 26/100  Loss=1.7945  Acc=0.4149\n",
      "[Pretrain] Epoch 27/100  Loss=1.7777  Acc=0.4145\n",
      "[Pretrain] Epoch 28/100  Loss=1.7639  Acc=0.4244\n",
      "[Pretrain] Epoch 29/100  Loss=1.7591  Acc=0.4251\n",
      "[Pretrain] Epoch 30/100  Loss=1.7283  Acc=0.4291\n",
      "[Pretrain] Epoch 31/100  Loss=1.7024  Acc=0.4492\n",
      "[Pretrain] Epoch 32/100  Loss=1.6877  Acc=0.4459\n",
      "[Pretrain] Epoch 33/100  Loss=1.6446  Acc=0.4655\n",
      "[Pretrain] Epoch 34/100  Loss=1.6398  Acc=0.4583\n",
      "[Pretrain] Epoch 35/100  Loss=1.6146  Acc=0.4754\n",
      "[Pretrain] Epoch 36/100  Loss=1.5905  Acc=0.4824\n",
      "[Pretrain] Epoch 37/100  Loss=1.5951  Acc=0.4743\n",
      "[Pretrain] Epoch 38/100  Loss=1.5645  Acc=0.4883\n",
      "[Pretrain] Epoch 39/100  Loss=1.5436  Acc=0.4923\n",
      "[Pretrain] Epoch 40/100  Loss=1.5245  Acc=0.5016\n",
      "[Pretrain] Epoch 41/100  Loss=1.5170  Acc=0.5031\n",
      "[Pretrain] Epoch 42/100  Loss=1.4735  Acc=0.5110\n",
      "[Pretrain] Epoch 43/100  Loss=1.4943  Acc=0.5133\n",
      "[Pretrain] Epoch 44/100  Loss=1.4589  Acc=0.5187\n",
      "[Pretrain] Epoch 45/100  Loss=1.4544  Acc=0.5251\n",
      "[Pretrain] Epoch 46/100  Loss=1.4485  Acc=0.5268\n",
      "[Pretrain] Epoch 47/100  Loss=1.4222  Acc=0.5320\n",
      "[Pretrain] Epoch 48/100  Loss=1.4045  Acc=0.5384\n",
      "[Pretrain] Epoch 49/100  Loss=1.3943  Acc=0.5411\n",
      "[Pretrain] Epoch 50/100  Loss=1.3746  Acc=0.5444\n",
      "[Pretrain] Epoch 51/100  Loss=1.3621  Acc=0.5544\n",
      "[Pretrain] Epoch 52/100  Loss=1.3730  Acc=0.5503\n",
      "[Pretrain] Epoch 53/100  Loss=1.3453  Acc=0.5620\n",
      "[Pretrain] Epoch 54/100  Loss=1.3400  Acc=0.5598\n",
      "[Pretrain] Epoch 55/100  Loss=1.3241  Acc=0.5632\n",
      "[Pretrain] Epoch 56/100  Loss=1.3272  Acc=0.5650\n",
      "[Pretrain] Epoch 57/100  Loss=1.2930  Acc=0.5736\n",
      "[Pretrain] Epoch 58/100  Loss=1.3041  Acc=0.5652\n",
      "[Pretrain] Epoch 59/100  Loss=1.2992  Acc=0.5774\n",
      "[Pretrain] Epoch 60/100  Loss=1.2858  Acc=0.5758\n",
      "[Pretrain] Epoch 61/100  Loss=1.2853  Acc=0.5842\n",
      "[Pretrain] Epoch 62/100  Loss=1.2684  Acc=0.5788\n",
      "[Pretrain] Epoch 63/100  Loss=1.2758  Acc=0.5760\n",
      "[Pretrain] Epoch 64/100  Loss=1.2481  Acc=0.5905\n",
      "[Pretrain] Epoch 65/100  Loss=1.2434  Acc=0.5955\n",
      "[Pretrain] Epoch 66/100  Loss=1.2478  Acc=0.5862\n",
      "[Pretrain] Epoch 67/100  Loss=1.2622  Acc=0.5801\n",
      "[Pretrain] Epoch 68/100  Loss=1.2338  Acc=0.5952\n",
      "[Pretrain] Epoch 69/100  Loss=1.2308  Acc=0.5934\n",
      "[Pretrain] Epoch 70/100  Loss=1.2209  Acc=0.5938\n",
      "[Pretrain] Epoch 71/100  Loss=1.2295  Acc=0.5966\n",
      "[Pretrain] Epoch 72/100  Loss=1.2215  Acc=0.5997\n",
      "[Pretrain] Epoch 73/100  Loss=1.2159  Acc=0.5948\n",
      "[Pretrain] Epoch 74/100  Loss=1.2088  Acc=0.6034\n",
      "[Pretrain] Epoch 75/100  Loss=1.2042  Acc=0.6036\n",
      "[Pretrain] Epoch 76/100  Loss=1.1917  Acc=0.6101\n",
      "[Pretrain] Epoch 77/100  Loss=1.1956  Acc=0.6131\n",
      "[Pretrain] Epoch 78/100  Loss=1.1912  Acc=0.6106\n",
      "[Pretrain] Epoch 79/100  Loss=1.1916  Acc=0.6137\n",
      "[Pretrain] Epoch 80/100  Loss=1.1747  Acc=0.6149\n",
      "[Pretrain] Epoch 81/100  Loss=1.1905  Acc=0.6101\n",
      "[Pretrain] Epoch 82/100  Loss=1.1887  Acc=0.6094\n",
      "[Pretrain] Epoch 83/100  Loss=1.1966  Acc=0.5979\n",
      "[Pretrain] Epoch 84/100  Loss=1.1888  Acc=0.6088\n",
      "[Pretrain] Epoch 85/100  Loss=1.1604  Acc=0.6128\n",
      "[Pretrain] Epoch 86/100  Loss=1.1854  Acc=0.6020\n",
      "[Pretrain] Epoch 87/100  Loss=1.1737  Acc=0.6112\n",
      "[Pretrain] Epoch 88/100  Loss=1.1877  Acc=0.6038\n",
      "[Pretrain] Epoch 89/100  Loss=1.1505  Acc=0.6227\n",
      "[Pretrain] Epoch 90/100  Loss=1.1645  Acc=0.6176\n",
      "[Pretrain] Epoch 91/100  Loss=1.1680  Acc=0.6212\n",
      "[Pretrain] Epoch 92/100  Loss=1.1564  Acc=0.6166\n",
      "[Pretrain] Epoch 93/100  Loss=1.1584  Acc=0.6209\n",
      "[Pretrain] Epoch 94/100  Loss=1.1606  Acc=0.6166\n",
      "[Pretrain] Epoch 95/100  Loss=1.1604  Acc=0.6223\n",
      "[Pretrain] Epoch 96/100  Loss=1.1647  Acc=0.6205\n",
      "[Pretrain] Epoch 97/100  Loss=1.1540  Acc=0.6187\n",
      "[Pretrain] Epoch 98/100  Loss=1.1456  Acc=0.6187\n",
      "[Pretrain] Epoch 99/100  Loss=1.1524  Acc=0.6245\n",
      "[Pretrain] Epoch 100/100  Loss=1.1566  Acc=0.6200\n",
      "[Fine-tune] Epoch 1/50  Loss=3.2786\n",
      "[Fine-tune] Epoch 2/50  Loss=3.0895\n",
      "[Fine-tune] Epoch 3/50  Loss=2.8647\n",
      "[Fine-tune] Epoch 4/50  Loss=2.7541\n",
      "[Fine-tune] Epoch 5/50  Loss=2.7120\n",
      "[Fine-tune] Epoch 6/50  Loss=2.5982\n",
      "[Fine-tune] Epoch 7/50  Loss=2.5454\n",
      "[Fine-tune] Epoch 8/50  Loss=2.4731\n",
      "[Fine-tune] Epoch 9/50  Loss=2.4111\n",
      "[Fine-tune] Epoch 10/50  Loss=2.3702\n",
      "[Fine-tune] Epoch 11/50  Loss=2.3256\n",
      "[Fine-tune] Epoch 12/50  Loss=2.2876\n",
      "[Fine-tune] Epoch 13/50  Loss=2.2503\n",
      "[Fine-tune] Epoch 14/50  Loss=2.2130\n",
      "[Fine-tune] Epoch 15/50  Loss=2.1574\n",
      "[Fine-tune] Epoch 16/50  Loss=2.1329\n",
      "[Fine-tune] Epoch 17/50  Loss=2.0902\n",
      "[Fine-tune] Epoch 18/50  Loss=2.0482\n",
      "[Fine-tune] Epoch 19/50  Loss=2.0487\n",
      "[Fine-tune] Epoch 20/50  Loss=2.0225\n",
      "[Fine-tune] Epoch 21/50  Loss=1.9961\n",
      "[Fine-tune] Epoch 22/50  Loss=1.9878\n",
      "[Fine-tune] Epoch 23/50  Loss=1.9501\n",
      "[Fine-tune] Epoch 24/50  Loss=1.9251\n",
      "[Fine-tune] Epoch 25/50  Loss=1.9146\n",
      "[Fine-tune] Epoch 26/50  Loss=1.9099\n",
      "[Fine-tune] Epoch 27/50  Loss=1.8850\n",
      "[Fine-tune] Epoch 28/50  Loss=1.8644\n",
      "[Fine-tune] Epoch 29/50  Loss=1.8607\n",
      "[Fine-tune] Epoch 30/50  Loss=1.8428\n",
      "[Fine-tune] Epoch 31/50  Loss=1.8385\n",
      "[Fine-tune] Epoch 32/50  Loss=1.8221\n",
      "[Fine-tune] Epoch 33/50  Loss=1.8089\n",
      "[Fine-tune] Epoch 34/50  Loss=1.8100\n",
      "[Fine-tune] Epoch 35/50  Loss=1.7855\n",
      "[Fine-tune] Epoch 36/50  Loss=1.7766\n",
      "[Fine-tune] Epoch 37/50  Loss=1.7623\n",
      "[Fine-tune] Epoch 38/50  Loss=1.7527\n",
      "[Fine-tune] Epoch 39/50  Loss=1.7533\n",
      "[Fine-tune] Epoch 40/50  Loss=1.7348\n",
      "[Fine-tune] Epoch 41/50  Loss=1.7253\n",
      "[Fine-tune] Epoch 42/50  Loss=1.7285\n",
      "[Fine-tune] Epoch 43/50  Loss=1.7137\n",
      "[Fine-tune] Epoch 44/50  Loss=1.7153\n",
      "[Fine-tune] Epoch 45/50  Loss=1.7093\n",
      "[Fine-tune] Epoch 46/50  Loss=1.6986\n",
      "[Fine-tune] Epoch 47/50  Loss=1.6885\n",
      "[Fine-tune] Epoch 48/50  Loss=1.6607\n",
      "[Fine-tune] Epoch 49/50  Loss=1.6752\n",
      "[Fine-tune] Epoch 50/50  Loss=1.6723\n",
      "[Pretrain] Epoch 1/150  Loss=3.2305  Acc=0.0501\n",
      "[Pretrain] Epoch 2/150  Loss=2.9355  Acc=0.0950\n",
      "[Pretrain] Epoch 3/150  Loss=2.6980  Acc=0.1376\n",
      "[Pretrain] Epoch 4/150  Loss=2.5495  Acc=0.1798\n",
      "[Pretrain] Epoch 5/150  Loss=2.4421  Acc=0.2173\n",
      "[Pretrain] Epoch 6/150  Loss=2.3247  Acc=0.2477\n",
      "[Pretrain] Epoch 7/150  Loss=2.3127  Acc=0.2608\n",
      "[Pretrain] Epoch 8/150  Loss=2.2429  Acc=0.2708\n",
      "[Pretrain] Epoch 9/150  Loss=2.1582  Acc=0.2999\n",
      "[Pretrain] Epoch 10/150  Loss=2.0966  Acc=0.3276\n",
      "[Pretrain] Epoch 11/150  Loss=2.0608  Acc=0.3274\n",
      "[Pretrain] Epoch 12/150  Loss=2.0081  Acc=0.3481\n",
      "[Pretrain] Epoch 13/150  Loss=2.0341  Acc=0.3432\n",
      "[Pretrain] Epoch 14/150  Loss=1.9684  Acc=0.3696\n",
      "[Pretrain] Epoch 15/150  Loss=1.9405  Acc=0.3739\n",
      "[Pretrain] Epoch 16/150  Loss=1.9346  Acc=0.3689\n",
      "[Pretrain] Epoch 17/150  Loss=1.8856  Acc=0.3915\n",
      "[Pretrain] Epoch 18/150  Loss=1.8592  Acc=0.3912\n",
      "[Pretrain] Epoch 19/150  Loss=1.8246  Acc=0.4086\n",
      "[Pretrain] Epoch 20/150  Loss=1.7969  Acc=0.4183\n",
      "[Pretrain] Epoch 21/150  Loss=1.7805  Acc=0.4246\n",
      "[Pretrain] Epoch 22/150  Loss=1.7676  Acc=0.4291\n",
      "[Pretrain] Epoch 23/150  Loss=1.7569  Acc=0.4291\n",
      "[Pretrain] Epoch 24/150  Loss=1.7190  Acc=0.4429\n",
      "[Pretrain] Epoch 25/150  Loss=1.6971  Acc=0.4549\n",
      "[Pretrain] Epoch 26/150  Loss=1.6885  Acc=0.4542\n",
      "[Pretrain] Epoch 27/150  Loss=1.6589  Acc=0.4635\n",
      "[Pretrain] Epoch 28/150  Loss=1.6496  Acc=0.4709\n",
      "[Pretrain] Epoch 29/150  Loss=1.6395  Acc=0.4713\n",
      "[Pretrain] Epoch 30/150  Loss=1.6125  Acc=0.4765\n",
      "[Pretrain] Epoch 31/150  Loss=1.6120  Acc=0.4704\n",
      "[Pretrain] Epoch 32/150  Loss=1.5837  Acc=0.4867\n",
      "[Pretrain] Epoch 33/150  Loss=1.5658  Acc=0.4944\n",
      "[Pretrain] Epoch 34/150  Loss=1.5520  Acc=0.5023\n",
      "[Pretrain] Epoch 35/150  Loss=1.5424  Acc=0.5057\n",
      "[Pretrain] Epoch 36/150  Loss=1.5303  Acc=0.5041\n",
      "[Pretrain] Epoch 37/150  Loss=1.5030  Acc=0.5192\n",
      "[Pretrain] Epoch 38/150  Loss=1.5016  Acc=0.5126\n",
      "[Pretrain] Epoch 39/150  Loss=1.5011  Acc=0.5176\n",
      "[Pretrain] Epoch 40/150  Loss=1.4808  Acc=0.5169\n",
      "[Pretrain] Epoch 41/150  Loss=1.4671  Acc=0.5250\n",
      "[Pretrain] Epoch 42/150  Loss=1.4612  Acc=0.5260\n",
      "[Pretrain] Epoch 43/150  Loss=1.4407  Acc=0.5330\n",
      "[Pretrain] Epoch 44/150  Loss=1.4515  Acc=0.5278\n",
      "[Pretrain] Epoch 45/150  Loss=1.4388  Acc=0.5327\n",
      "[Pretrain] Epoch 46/150  Loss=1.4251  Acc=0.5377\n",
      "[Pretrain] Epoch 47/150  Loss=1.4214  Acc=0.5397\n",
      "[Pretrain] Epoch 48/150  Loss=1.4120  Acc=0.5449\n",
      "[Pretrain] Epoch 49/150  Loss=1.4064  Acc=0.5404\n",
      "[Pretrain] Epoch 50/150  Loss=1.4149  Acc=0.5420\n",
      "[Pretrain] Epoch 51/150  Loss=1.3959  Acc=0.5431\n",
      "[Pretrain] Epoch 52/150  Loss=1.3885  Acc=0.5476\n",
      "[Pretrain] Epoch 53/150  Loss=1.3845  Acc=0.5510\n",
      "[Pretrain] Epoch 54/150  Loss=1.3736  Acc=0.5602\n",
      "[Pretrain] Epoch 55/150  Loss=1.3676  Acc=0.5503\n",
      "[Pretrain] Epoch 56/150  Loss=1.3676  Acc=0.5594\n",
      "[Pretrain] Epoch 57/150  Loss=1.3583  Acc=0.5539\n",
      "[Pretrain] Epoch 58/150  Loss=1.3575  Acc=0.5632\n",
      "[Pretrain] Epoch 59/150  Loss=1.3512  Acc=0.5562\n",
      "[Pretrain] Epoch 60/150  Loss=1.3391  Acc=0.5690\n",
      "[Pretrain] Epoch 61/150  Loss=1.3399  Acc=0.5666\n",
      "[Pretrain] Epoch 62/150  Loss=1.3466  Acc=0.5641\n",
      "[Pretrain] Epoch 63/150  Loss=1.3305  Acc=0.5704\n",
      "[Pretrain] Epoch 64/150  Loss=1.3353  Acc=0.5630\n",
      "[Pretrain] Epoch 65/150  Loss=1.3376  Acc=0.5639\n",
      "[Pretrain] Epoch 66/150  Loss=1.3300  Acc=0.5657\n",
      "[Pretrain] Epoch 67/150  Loss=1.3220  Acc=0.5673\n",
      "[Pretrain] Epoch 68/150  Loss=1.3303  Acc=0.5709\n",
      "[Pretrain] Epoch 69/150  Loss=1.3310  Acc=0.5670\n",
      "[Pretrain] Epoch 70/150  Loss=1.3266  Acc=0.5702\n",
      "[Pretrain] Epoch 71/150  Loss=1.3084  Acc=0.5720\n",
      "[Pretrain] Epoch 72/150  Loss=1.3080  Acc=0.5709\n",
      "[Pretrain] Epoch 73/150  Loss=1.3191  Acc=0.5733\n",
      "[Pretrain] Epoch 74/150  Loss=1.2973  Acc=0.5799\n",
      "[Pretrain] Epoch 75/150  Loss=1.2988  Acc=0.5853\n",
      "[Pretrain] Epoch 76/150  Loss=1.2935  Acc=0.5774\n",
      "[Pretrain] Epoch 77/150  Loss=1.3140  Acc=0.5720\n",
      "[Pretrain] Epoch 78/150  Loss=1.3009  Acc=0.5808\n",
      "[Pretrain] Epoch 79/150  Loss=1.2922  Acc=0.5796\n",
      "[Pretrain] Epoch 80/150  Loss=1.3203  Acc=0.5770\n",
      "[Pretrain] Epoch 81/150  Loss=1.2993  Acc=0.5760\n",
      "[Pretrain] Epoch 82/150  Loss=1.2939  Acc=0.5858\n",
      "[Pretrain] Epoch 83/150  Loss=1.2919  Acc=0.5824\n",
      "[Pretrain] Epoch 84/150  Loss=1.3040  Acc=0.5778\n",
      "[Pretrain] Epoch 85/150  Loss=1.2902  Acc=0.5814\n",
      "[Pretrain] Epoch 86/150  Loss=1.2962  Acc=0.5839\n",
      "[Pretrain] Epoch 87/150  Loss=1.2919  Acc=0.5767\n",
      "[Pretrain] Epoch 88/150  Loss=1.2908  Acc=0.5781\n",
      "[Pretrain] Epoch 89/150  Loss=1.2898  Acc=0.5796\n",
      "[Pretrain] Epoch 90/150  Loss=1.2984  Acc=0.5788\n",
      "[Pretrain] Epoch 91/150  Loss=1.3091  Acc=0.5724\n",
      "[Pretrain] Epoch 92/150  Loss=1.2864  Acc=0.5790\n",
      "[Pretrain] Epoch 93/150  Loss=1.3055  Acc=0.5758\n",
      "[Pretrain] Epoch 94/150  Loss=1.2925  Acc=0.5684\n",
      "[Pretrain] Epoch 95/150  Loss=1.2920  Acc=0.5774\n",
      "[Pretrain] Epoch 96/150  Loss=1.2871  Acc=0.5713\n",
      "[Pretrain] Epoch 97/150  Loss=1.2812  Acc=0.5878\n",
      "[Pretrain] Epoch 98/150  Loss=1.2869  Acc=0.5900\n",
      "[Pretrain] Epoch 99/150  Loss=1.2807  Acc=0.5832\n",
      "[Pretrain] Epoch 100/150  Loss=1.2843  Acc=0.5830\n",
      "[Pretrain] Epoch 101/150  Loss=1.2899  Acc=0.5711\n",
      "[Pretrain] Epoch 102/150  Loss=1.2918  Acc=0.5781\n",
      "[Pretrain] Epoch 103/150  Loss=1.2837  Acc=0.5806\n",
      "[Pretrain] Epoch 104/150  Loss=1.2763  Acc=0.5916\n",
      "[Pretrain] Epoch 105/150  Loss=1.2665  Acc=0.5889\n",
      "[Pretrain] Epoch 106/150  Loss=1.2899  Acc=0.5832\n",
      "[Pretrain] Epoch 107/150  Loss=1.2730  Acc=0.5839\n",
      "[Pretrain] Epoch 108/150  Loss=1.2863  Acc=0.5801\n",
      "[Pretrain] Epoch 109/150  Loss=1.2816  Acc=0.5828\n",
      "[Pretrain] Epoch 110/150  Loss=1.2846  Acc=0.5916\n",
      "[Pretrain] Epoch 111/150  Loss=1.2779  Acc=0.5824\n",
      "[Pretrain] Epoch 112/150  Loss=1.2834  Acc=0.5796\n",
      "[Pretrain] Epoch 113/150  Loss=1.2817  Acc=0.5835\n",
      "[Pretrain] Epoch 114/150  Loss=1.2631  Acc=0.5893\n",
      "[Pretrain] Epoch 115/150  Loss=1.2839  Acc=0.5835\n",
      "[Pretrain] Epoch 116/150  Loss=1.2925  Acc=0.5805\n",
      "[Pretrain] Epoch 117/150  Loss=1.2651  Acc=0.5889\n",
      "[Pretrain] Epoch 118/150  Loss=1.2756  Acc=0.5839\n",
      "[Pretrain] Epoch 119/150  Loss=1.2788  Acc=0.5896\n",
      "[Pretrain] Epoch 120/150  Loss=1.2626  Acc=0.5929\n",
      "[Pretrain] Epoch 121/150  Loss=1.2949  Acc=0.5774\n",
      "[Pretrain] Epoch 122/150  Loss=1.2696  Acc=0.5903\n",
      "[Pretrain] Epoch 123/150  Loss=1.2746  Acc=0.5909\n",
      "[Pretrain] Epoch 124/150  Loss=1.2648  Acc=0.5815\n",
      "[Pretrain] Epoch 125/150  Loss=1.2732  Acc=0.5828\n",
      "[Pretrain] Epoch 126/150  Loss=1.2805  Acc=0.5733\n",
      "[Pretrain] Epoch 127/150  Loss=1.2786  Acc=0.5871\n",
      "[Pretrain] Epoch 128/150  Loss=1.2690  Acc=0.5878\n",
      "[Pretrain] Epoch 129/150  Loss=1.2824  Acc=0.5862\n",
      "[Pretrain] Epoch 130/150  Loss=1.2717  Acc=0.5824\n",
      "[Pretrain] Epoch 131/150  Loss=1.2754  Acc=0.5943\n",
      "[Pretrain] Epoch 132/150  Loss=1.2667  Acc=0.5788\n",
      "[Pretrain] Epoch 133/150  Loss=1.2746  Acc=0.5903\n",
      "[Pretrain] Epoch 134/150  Loss=1.2719  Acc=0.5905\n",
      "[Pretrain] Epoch 135/150  Loss=1.2755  Acc=0.5853\n",
      "[Pretrain] Epoch 136/150  Loss=1.2839  Acc=0.5842\n",
      "[Pretrain] Epoch 137/150  Loss=1.2773  Acc=0.5875\n",
      "[Pretrain] Epoch 138/150  Loss=1.2729  Acc=0.5844\n",
      "[Pretrain] Epoch 139/150  Loss=1.2792  Acc=0.5803\n",
      "[Pretrain] Epoch 140/150  Loss=1.2769  Acc=0.5898\n",
      "[Pretrain] Epoch 141/150  Loss=1.2784  Acc=0.5846\n",
      "[Pretrain] Epoch 142/150  Loss=1.2686  Acc=0.5889\n",
      "[Pretrain] Epoch 143/150  Loss=1.2745  Acc=0.5801\n",
      "[Pretrain] Epoch 144/150  Loss=1.2768  Acc=0.5875\n",
      "[Pretrain] Epoch 145/150  Loss=1.2840  Acc=0.5790\n",
      "[Pretrain] Epoch 146/150  Loss=1.2656  Acc=0.5896\n",
      "[Pretrain] Epoch 147/150  Loss=1.2783  Acc=0.5912\n",
      "[Pretrain] Epoch 148/150  Loss=1.2877  Acc=0.5830\n",
      "[Pretrain] Epoch 149/150  Loss=1.2798  Acc=0.5882\n",
      "[Pretrain] Epoch 150/150  Loss=1.2837  Acc=0.5788\n",
      "[Fine-tune] Epoch 1/50  Loss=3.3120\n",
      "[Fine-tune] Epoch 2/50  Loss=3.1896\n",
      "[Fine-tune] Epoch 3/50  Loss=3.1039\n",
      "[Fine-tune] Epoch 4/50  Loss=3.0637\n",
      "[Fine-tune] Epoch 5/50  Loss=3.0304\n",
      "[Fine-tune] Epoch 6/50  Loss=2.9119\n",
      "[Fine-tune] Epoch 7/50  Loss=2.7590\n",
      "[Fine-tune] Epoch 8/50  Loss=2.6123\n",
      "[Fine-tune] Epoch 9/50  Loss=2.5430\n",
      "[Fine-tune] Epoch 10/50  Loss=2.4965\n",
      "[Fine-tune] Epoch 11/50  Loss=2.4552\n",
      "[Fine-tune] Epoch 12/50  Loss=2.4225\n",
      "[Fine-tune] Epoch 13/50  Loss=2.4125\n",
      "[Fine-tune] Epoch 14/50  Loss=2.3722\n",
      "[Fine-tune] Epoch 15/50  Loss=2.3427\n",
      "[Fine-tune] Epoch 16/50  Loss=2.2879\n",
      "[Fine-tune] Epoch 17/50  Loss=2.2534\n",
      "[Fine-tune] Epoch 18/50  Loss=2.2271\n",
      "[Fine-tune] Epoch 19/50  Loss=2.1919\n",
      "[Fine-tune] Epoch 20/50  Loss=2.1744\n",
      "[Fine-tune] Epoch 21/50  Loss=2.1407\n",
      "[Fine-tune] Epoch 22/50  Loss=2.1112\n",
      "[Fine-tune] Epoch 23/50  Loss=2.1369\n",
      "[Fine-tune] Epoch 24/50  Loss=2.1129\n",
      "[Fine-tune] Epoch 25/50  Loss=2.0860\n",
      "[Fine-tune] Epoch 26/50  Loss=2.0450\n",
      "[Fine-tune] Epoch 27/50  Loss=2.0330\n",
      "[Fine-tune] Epoch 28/50  Loss=2.0263\n",
      "[Fine-tune] Epoch 29/50  Loss=2.0138\n",
      "[Fine-tune] Epoch 30/50  Loss=1.9954\n",
      "[Fine-tune] Epoch 31/50  Loss=1.9689\n",
      "[Fine-tune] Epoch 32/50  Loss=1.9585\n",
      "[Fine-tune] Epoch 33/50  Loss=1.9416\n",
      "[Fine-tune] Epoch 34/50  Loss=1.9287\n",
      "[Fine-tune] Epoch 35/50  Loss=1.9094\n",
      "[Fine-tune] Epoch 36/50  Loss=1.8919\n",
      "[Fine-tune] Epoch 37/50  Loss=1.8861\n",
      "[Fine-tune] Epoch 38/50  Loss=1.8552\n",
      "[Fine-tune] Epoch 39/50  Loss=1.8659\n",
      "[Fine-tune] Epoch 40/50  Loss=1.8594\n",
      "[Fine-tune] Epoch 41/50  Loss=1.8251\n",
      "[Fine-tune] Epoch 42/50  Loss=1.8175\n",
      "[Fine-tune] Epoch 43/50  Loss=1.8192\n",
      "[Fine-tune] Epoch 44/50  Loss=1.8165\n",
      "[Fine-tune] Epoch 45/50  Loss=1.7826\n",
      "[Fine-tune] Epoch 46/50  Loss=1.7806\n",
      "[Fine-tune] Epoch 47/50  Loss=1.7652\n",
      "[Fine-tune] Epoch 48/50  Loss=1.7689\n",
      "[Fine-tune] Epoch 49/50  Loss=1.7477\n",
      "[Fine-tune] Epoch 50/50  Loss=1.7455\n",
      "[Pretrain] Epoch 1/150  Loss=3.7457  Acc=0.0427\n",
      "[Pretrain] Epoch 2/150  Loss=3.0982  Acc=0.0814\n",
      "[Pretrain] Epoch 3/150  Loss=2.8163  Acc=0.1322\n",
      "[Pretrain] Epoch 4/150  Loss=2.5770  Acc=0.1852\n",
      "[Pretrain] Epoch 5/150  Loss=2.4445  Acc=0.2189\n",
      "[Pretrain] Epoch 6/150  Loss=2.3771  Acc=0.2342\n",
      "[Pretrain] Epoch 7/150  Loss=2.3185  Acc=0.2541\n",
      "[Pretrain] Epoch 8/150  Loss=2.2654  Acc=0.2689\n",
      "[Pretrain] Epoch 9/150  Loss=2.2313  Acc=0.2857\n",
      "[Pretrain] Epoch 10/150  Loss=2.2000  Acc=0.2956\n",
      "[Pretrain] Epoch 11/150  Loss=2.1150  Acc=0.3172\n",
      "[Pretrain] Epoch 12/150  Loss=2.0878  Acc=0.3224\n",
      "[Pretrain] Epoch 13/150  Loss=2.0545  Acc=0.3260\n",
      "[Pretrain] Epoch 14/150  Loss=1.9905  Acc=0.3551\n",
      "[Pretrain] Epoch 15/150  Loss=1.9769  Acc=0.3583\n",
      "[Pretrain] Epoch 16/150  Loss=1.9908  Acc=0.3491\n",
      "[Pretrain] Epoch 17/150  Loss=1.9358  Acc=0.3766\n",
      "[Pretrain] Epoch 18/150  Loss=1.9318  Acc=0.3716\n",
      "[Pretrain] Epoch 19/150  Loss=1.8616  Acc=0.3924\n",
      "[Pretrain] Epoch 20/150  Loss=1.8706  Acc=0.4043\n",
      "[Pretrain] Epoch 21/150  Loss=1.8299  Acc=0.4054\n",
      "[Pretrain] Epoch 22/150  Loss=1.8163  Acc=0.4046\n",
      "[Pretrain] Epoch 23/150  Loss=1.7798  Acc=0.4222\n",
      "[Pretrain] Epoch 24/150  Loss=1.7777  Acc=0.4231\n",
      "[Pretrain] Epoch 25/150  Loss=1.7444  Acc=0.4310\n",
      "[Pretrain] Epoch 26/150  Loss=1.7065  Acc=0.4404\n",
      "[Pretrain] Epoch 27/150  Loss=1.7103  Acc=0.4328\n",
      "[Pretrain] Epoch 28/150  Loss=1.6679  Acc=0.4555\n",
      "[Pretrain] Epoch 29/150  Loss=1.6677  Acc=0.4573\n",
      "[Pretrain] Epoch 30/150  Loss=1.6341  Acc=0.4643\n",
      "[Pretrain] Epoch 31/150  Loss=1.6200  Acc=0.4693\n",
      "[Pretrain] Epoch 32/150  Loss=1.6067  Acc=0.4720\n",
      "[Pretrain] Epoch 33/150  Loss=1.5957  Acc=0.4754\n",
      "[Pretrain] Epoch 34/150  Loss=1.5661  Acc=0.4881\n",
      "[Pretrain] Epoch 35/150  Loss=1.5513  Acc=0.4923\n",
      "[Pretrain] Epoch 36/150  Loss=1.5312  Acc=0.4991\n",
      "[Pretrain] Epoch 37/150  Loss=1.5175  Acc=0.5065\n",
      "[Pretrain] Epoch 38/150  Loss=1.5058  Acc=0.5171\n",
      "[Pretrain] Epoch 39/150  Loss=1.4867  Acc=0.5115\n",
      "[Pretrain] Epoch 40/150  Loss=1.4571  Acc=0.5233\n",
      "[Pretrain] Epoch 41/150  Loss=1.4387  Acc=0.5255\n",
      "[Pretrain] Epoch 42/150  Loss=1.4248  Acc=0.5329\n",
      "[Pretrain] Epoch 43/150  Loss=1.4066  Acc=0.5474\n",
      "[Pretrain] Epoch 44/150  Loss=1.4006  Acc=0.5390\n",
      "[Pretrain] Epoch 45/150  Loss=1.3843  Acc=0.5469\n",
      "[Pretrain] Epoch 46/150  Loss=1.3695  Acc=0.5444\n",
      "[Pretrain] Epoch 47/150  Loss=1.3644  Acc=0.5532\n",
      "[Pretrain] Epoch 48/150  Loss=1.3538  Acc=0.5589\n",
      "[Pretrain] Epoch 49/150  Loss=1.3372  Acc=0.5560\n",
      "[Pretrain] Epoch 50/150  Loss=1.3247  Acc=0.5681\n",
      "[Pretrain] Epoch 51/150  Loss=1.2900  Acc=0.5736\n",
      "[Pretrain] Epoch 52/150  Loss=1.2916  Acc=0.5749\n",
      "[Pretrain] Epoch 53/150  Loss=1.2718  Acc=0.5839\n",
      "[Pretrain] Epoch 54/150  Loss=1.2778  Acc=0.5740\n",
      "[Pretrain] Epoch 55/150  Loss=1.2677  Acc=0.5815\n",
      "[Pretrain] Epoch 56/150  Loss=1.2590  Acc=0.5869\n",
      "[Pretrain] Epoch 57/150  Loss=1.2418  Acc=0.5911\n",
      "[Pretrain] Epoch 58/150  Loss=1.2603  Acc=0.5927\n",
      "[Pretrain] Epoch 59/150  Loss=1.2272  Acc=0.5966\n",
      "[Pretrain] Epoch 60/150  Loss=1.2312  Acc=0.5932\n",
      "[Pretrain] Epoch 61/150  Loss=1.2275  Acc=0.5946\n",
      "[Pretrain] Epoch 62/150  Loss=1.2105  Acc=0.5999\n",
      "[Pretrain] Epoch 63/150  Loss=1.1875  Acc=0.6083\n",
      "[Pretrain] Epoch 64/150  Loss=1.1943  Acc=0.6119\n",
      "[Pretrain] Epoch 65/150  Loss=1.2070  Acc=0.6056\n",
      "[Pretrain] Epoch 66/150  Loss=1.1919  Acc=0.6101\n",
      "[Pretrain] Epoch 67/150  Loss=1.1747  Acc=0.6131\n",
      "[Pretrain] Epoch 68/150  Loss=1.1975  Acc=0.6085\n",
      "[Pretrain] Epoch 69/150  Loss=1.1857  Acc=0.6119\n",
      "[Pretrain] Epoch 70/150  Loss=1.1645  Acc=0.6202\n",
      "[Pretrain] Epoch 71/150  Loss=1.1583  Acc=0.6275\n",
      "[Pretrain] Epoch 72/150  Loss=1.1569  Acc=0.6193\n",
      "[Pretrain] Epoch 73/150  Loss=1.1546  Acc=0.6182\n",
      "[Pretrain] Epoch 74/150  Loss=1.1527  Acc=0.6189\n",
      "[Pretrain] Epoch 75/150  Loss=1.1428  Acc=0.6261\n",
      "[Pretrain] Epoch 76/150  Loss=1.1466  Acc=0.6210\n",
      "[Pretrain] Epoch 77/150  Loss=1.1386  Acc=0.6266\n",
      "[Pretrain] Epoch 78/150  Loss=1.1440  Acc=0.6263\n",
      "[Pretrain] Epoch 79/150  Loss=1.1378  Acc=0.6290\n",
      "[Pretrain] Epoch 80/150  Loss=1.1050  Acc=0.6327\n",
      "[Pretrain] Epoch 81/150  Loss=1.1373  Acc=0.6245\n",
      "[Pretrain] Epoch 82/150  Loss=1.1099  Acc=0.6342\n",
      "[Pretrain] Epoch 83/150  Loss=1.1440  Acc=0.6239\n",
      "[Pretrain] Epoch 84/150  Loss=1.1254  Acc=0.6270\n",
      "[Pretrain] Epoch 85/150  Loss=1.1216  Acc=0.6410\n",
      "[Pretrain] Epoch 86/150  Loss=1.1193  Acc=0.6257\n",
      "[Pretrain] Epoch 87/150  Loss=1.1244  Acc=0.6263\n",
      "[Pretrain] Epoch 88/150  Loss=1.1088  Acc=0.6356\n",
      "[Pretrain] Epoch 89/150  Loss=1.1354  Acc=0.6302\n",
      "[Pretrain] Epoch 90/150  Loss=1.0936  Acc=0.6386\n",
      "[Pretrain] Epoch 91/150  Loss=1.1131  Acc=0.6383\n",
      "[Pretrain] Epoch 92/150  Loss=1.1099  Acc=0.6372\n",
      "[Pretrain] Epoch 93/150  Loss=1.1125  Acc=0.6376\n",
      "[Pretrain] Epoch 94/150  Loss=1.0998  Acc=0.6379\n",
      "[Pretrain] Epoch 95/150  Loss=1.1127  Acc=0.6338\n",
      "[Pretrain] Epoch 96/150  Loss=1.0825  Acc=0.6491\n",
      "[Pretrain] Epoch 97/150  Loss=1.0948  Acc=0.6401\n",
      "[Pretrain] Epoch 98/150  Loss=1.1016  Acc=0.6315\n",
      "[Pretrain] Epoch 99/150  Loss=1.0915  Acc=0.6397\n",
      "[Pretrain] Epoch 100/150  Loss=1.0957  Acc=0.6469\n",
      "[Pretrain] Epoch 101/150  Loss=1.1063  Acc=0.6334\n",
      "[Pretrain] Epoch 102/150  Loss=1.0922  Acc=0.6430\n",
      "[Pretrain] Epoch 103/150  Loss=1.1080  Acc=0.6333\n",
      "[Pretrain] Epoch 104/150  Loss=1.0822  Acc=0.6489\n",
      "[Pretrain] Epoch 105/150  Loss=1.0935  Acc=0.6489\n",
      "[Pretrain] Epoch 106/150  Loss=1.0935  Acc=0.6422\n",
      "[Pretrain] Epoch 107/150  Loss=1.0858  Acc=0.6485\n",
      "[Pretrain] Epoch 108/150  Loss=1.0877  Acc=0.6464\n",
      "[Pretrain] Epoch 109/150  Loss=1.0942  Acc=0.6433\n",
      "[Pretrain] Epoch 110/150  Loss=1.0867  Acc=0.6395\n",
      "[Pretrain] Epoch 111/150  Loss=1.0886  Acc=0.6412\n",
      "[Pretrain] Epoch 112/150  Loss=1.0867  Acc=0.6433\n",
      "[Pretrain] Epoch 113/150  Loss=1.0848  Acc=0.6458\n",
      "[Pretrain] Epoch 114/150  Loss=1.0892  Acc=0.6453\n",
      "[Pretrain] Epoch 115/150  Loss=1.0951  Acc=0.6395\n",
      "[Pretrain] Epoch 116/150  Loss=1.0757  Acc=0.6448\n",
      "[Pretrain] Epoch 117/150  Loss=1.0803  Acc=0.6469\n",
      "[Pretrain] Epoch 118/150  Loss=1.0810  Acc=0.6498\n",
      "[Pretrain] Epoch 119/150  Loss=1.1026  Acc=0.6401\n",
      "[Pretrain] Epoch 120/150  Loss=1.0858  Acc=0.6408\n",
      "[Pretrain] Epoch 121/150  Loss=1.0661  Acc=0.6509\n",
      "[Pretrain] Epoch 122/150  Loss=1.0857  Acc=0.6462\n",
      "[Pretrain] Epoch 123/150  Loss=1.0819  Acc=0.6403\n",
      "[Pretrain] Epoch 124/150  Loss=1.0904  Acc=0.6369\n",
      "[Pretrain] Epoch 125/150  Loss=1.0909  Acc=0.6403\n",
      "[Pretrain] Epoch 126/150  Loss=1.0948  Acc=0.6392\n",
      "[Pretrain] Epoch 127/150  Loss=1.0886  Acc=0.6419\n",
      "[Pretrain] Epoch 128/150  Loss=1.0815  Acc=0.6415\n",
      "[Pretrain] Epoch 129/150  Loss=1.0749  Acc=0.6460\n",
      "[Pretrain] Epoch 130/150  Loss=1.0858  Acc=0.6406\n",
      "[Pretrain] Epoch 131/150  Loss=1.0812  Acc=0.6482\n",
      "[Pretrain] Epoch 132/150  Loss=1.0827  Acc=0.6460\n",
      "[Pretrain] Epoch 133/150  Loss=1.0713  Acc=0.6510\n",
      "[Pretrain] Epoch 134/150  Loss=1.0887  Acc=0.6397\n",
      "[Pretrain] Epoch 135/150  Loss=1.0939  Acc=0.6390\n",
      "[Pretrain] Epoch 136/150  Loss=1.0772  Acc=0.6471\n",
      "[Pretrain] Epoch 137/150  Loss=1.0915  Acc=0.6421\n",
      "[Pretrain] Epoch 138/150  Loss=1.0768  Acc=0.6471\n",
      "[Pretrain] Epoch 139/150  Loss=1.0766  Acc=0.6449\n",
      "[Pretrain] Epoch 140/150  Loss=1.0890  Acc=0.6415\n",
      "[Pretrain] Epoch 141/150  Loss=1.0797  Acc=0.6410\n",
      "[Pretrain] Epoch 142/150  Loss=1.0869  Acc=0.6487\n",
      "[Pretrain] Epoch 143/150  Loss=1.0734  Acc=0.6455\n",
      "[Pretrain] Epoch 144/150  Loss=1.0886  Acc=0.6431\n",
      "[Pretrain] Epoch 145/150  Loss=1.0698  Acc=0.6480\n",
      "[Pretrain] Epoch 146/150  Loss=1.0633  Acc=0.6458\n",
      "[Pretrain] Epoch 147/150  Loss=1.0874  Acc=0.6406\n",
      "[Pretrain] Epoch 148/150  Loss=1.0901  Acc=0.6388\n",
      "[Pretrain] Epoch 149/150  Loss=1.0890  Acc=0.6466\n",
      "[Pretrain] Epoch 150/150  Loss=1.0775  Acc=0.6491\n",
      "[Fine-tune] Epoch 1/50  Loss=3.2649\n",
      "[Fine-tune] Epoch 2/50  Loss=2.9790\n",
      "[Fine-tune] Epoch 3/50  Loss=2.7583\n",
      "[Fine-tune] Epoch 4/50  Loss=2.6419\n",
      "[Fine-tune] Epoch 5/50  Loss=2.5689\n",
      "[Fine-tune] Epoch 6/50  Loss=2.4980\n",
      "[Fine-tune] Epoch 7/50  Loss=2.4225\n",
      "[Fine-tune] Epoch 8/50  Loss=2.3995\n",
      "[Fine-tune] Epoch 9/50  Loss=2.3377\n",
      "[Fine-tune] Epoch 10/50  Loss=2.2827\n",
      "[Fine-tune] Epoch 11/50  Loss=2.2530\n",
      "[Fine-tune] Epoch 12/50  Loss=2.2171\n",
      "[Fine-tune] Epoch 13/50  Loss=2.1709\n",
      "[Fine-tune] Epoch 14/50  Loss=2.1576\n",
      "[Fine-tune] Epoch 15/50  Loss=2.1240\n",
      "[Fine-tune] Epoch 16/50  Loss=2.0873\n",
      "[Fine-tune] Epoch 17/50  Loss=2.0603\n",
      "[Fine-tune] Epoch 18/50  Loss=2.0287\n",
      "[Fine-tune] Epoch 19/50  Loss=2.0079\n",
      "[Fine-tune] Epoch 20/50  Loss=2.0138\n",
      "[Fine-tune] Epoch 21/50  Loss=1.9777\n",
      "[Fine-tune] Epoch 22/50  Loss=1.9570\n",
      "[Fine-tune] Epoch 23/50  Loss=1.9290\n",
      "[Fine-tune] Epoch 24/50  Loss=1.8991\n",
      "[Fine-tune] Epoch 25/50  Loss=1.8846\n",
      "[Fine-tune] Epoch 26/50  Loss=1.8777\n",
      "[Fine-tune] Epoch 27/50  Loss=1.8643\n",
      "[Fine-tune] Epoch 28/50  Loss=1.8378\n",
      "[Fine-tune] Epoch 29/50  Loss=1.8316\n",
      "[Fine-tune] Epoch 30/50  Loss=1.8254\n",
      "[Fine-tune] Epoch 31/50  Loss=1.8003\n",
      "[Fine-tune] Epoch 32/50  Loss=1.7865\n",
      "[Fine-tune] Epoch 33/50  Loss=1.7651\n",
      "[Fine-tune] Epoch 34/50  Loss=1.7488\n",
      "[Fine-tune] Epoch 35/50  Loss=1.7475\n",
      "[Fine-tune] Epoch 36/50  Loss=1.7256\n",
      "[Fine-tune] Epoch 37/50  Loss=1.7287\n",
      "[Fine-tune] Epoch 38/50  Loss=1.7058\n",
      "[Fine-tune] Epoch 39/50  Loss=1.7044\n",
      "[Fine-tune] Epoch 40/50  Loss=1.6836\n",
      "[Fine-tune] Epoch 41/50  Loss=1.6802\n",
      "[Fine-tune] Epoch 42/50  Loss=1.6770\n",
      "[Fine-tune] Epoch 43/50  Loss=1.6678\n",
      "[Fine-tune] Epoch 44/50  Loss=1.6439\n",
      "[Fine-tune] Epoch 45/50  Loss=1.6408\n",
      "[Fine-tune] Epoch 46/50  Loss=1.6099\n",
      "[Fine-tune] Epoch 47/50  Loss=1.6308\n",
      "[Fine-tune] Epoch 48/50  Loss=1.6099\n",
      "[Fine-tune] Epoch 49/50  Loss=1.6283\n",
      "[Fine-tune] Epoch 50/50  Loss=1.6129\n",
      "[Pretrain] Epoch 1/50  Loss=3.2539  Acc=0.0392\n",
      "[Pretrain] Epoch 2/50  Loss=3.0826  Acc=0.0772\n",
      "[Pretrain] Epoch 3/50  Loss=2.9087  Acc=0.0934\n",
      "[Pretrain] Epoch 4/50  Loss=2.7130  Acc=0.1369\n",
      "[Pretrain] Epoch 5/50  Loss=2.5716  Acc=0.1651\n",
      "[Pretrain] Epoch 6/50  Loss=2.4833  Acc=0.1961\n",
      "[Pretrain] Epoch 7/50  Loss=2.3840  Acc=0.2405\n",
      "[Pretrain] Epoch 8/50  Loss=2.2112  Acc=0.2751\n",
      "[Pretrain] Epoch 9/50  Loss=2.1704  Acc=0.3001\n",
      "[Pretrain] Epoch 10/50  Loss=2.1229  Acc=0.3111\n",
      "[Pretrain] Epoch 11/50  Loss=2.0686  Acc=0.3242\n",
      "[Pretrain] Epoch 12/50  Loss=2.0442  Acc=0.3366\n",
      "[Pretrain] Epoch 13/50  Loss=1.9896  Acc=0.3558\n",
      "[Pretrain] Epoch 14/50  Loss=1.9531  Acc=0.3694\n",
      "[Pretrain] Epoch 15/50  Loss=1.9011  Acc=0.3843\n",
      "[Pretrain] Epoch 16/50  Loss=1.9067  Acc=0.3802\n",
      "[Pretrain] Epoch 17/50  Loss=1.8706  Acc=0.3890\n",
      "[Pretrain] Epoch 18/50  Loss=1.8310  Acc=0.4061\n",
      "[Pretrain] Epoch 19/50  Loss=1.8341  Acc=0.4080\n",
      "[Pretrain] Epoch 20/50  Loss=1.7979  Acc=0.4070\n",
      "[Pretrain] Epoch 21/50  Loss=1.7662  Acc=0.4222\n",
      "[Pretrain] Epoch 22/50  Loss=1.7670  Acc=0.4226\n",
      "[Pretrain] Epoch 23/50  Loss=1.7395  Acc=0.4368\n",
      "[Pretrain] Epoch 24/50  Loss=1.7121  Acc=0.4494\n",
      "[Pretrain] Epoch 25/50  Loss=1.6865  Acc=0.4576\n",
      "[Pretrain] Epoch 26/50  Loss=1.6690  Acc=0.4621\n",
      "[Pretrain] Epoch 27/50  Loss=1.6541  Acc=0.4612\n",
      "[Pretrain] Epoch 28/50  Loss=1.6210  Acc=0.4815\n",
      "[Pretrain] Epoch 29/50  Loss=1.6101  Acc=0.4835\n",
      "[Pretrain] Epoch 30/50  Loss=1.6087  Acc=0.4795\n",
      "[Pretrain] Epoch 31/50  Loss=1.5843  Acc=0.4908\n",
      "[Pretrain] Epoch 32/50  Loss=1.5574  Acc=0.4944\n",
      "[Pretrain] Epoch 33/50  Loss=1.5577  Acc=0.5007\n",
      "[Pretrain] Epoch 34/50  Loss=1.5332  Acc=0.5075\n",
      "[Pretrain] Epoch 35/50  Loss=1.5470  Acc=0.5045\n",
      "[Pretrain] Epoch 36/50  Loss=1.5318  Acc=0.5070\n",
      "[Pretrain] Epoch 37/50  Loss=1.5132  Acc=0.5079\n",
      "[Pretrain] Epoch 38/50  Loss=1.4937  Acc=0.5154\n",
      "[Pretrain] Epoch 39/50  Loss=1.4844  Acc=0.5156\n",
      "[Pretrain] Epoch 40/50  Loss=1.4833  Acc=0.5226\n",
      "[Pretrain] Epoch 41/50  Loss=1.4613  Acc=0.5280\n",
      "[Pretrain] Epoch 42/50  Loss=1.4679  Acc=0.5235\n",
      "[Pretrain] Epoch 43/50  Loss=1.4555  Acc=0.5257\n",
      "[Pretrain] Epoch 44/50  Loss=1.4390  Acc=0.5408\n",
      "[Pretrain] Epoch 45/50  Loss=1.4278  Acc=0.5379\n",
      "[Pretrain] Epoch 46/50  Loss=1.4226  Acc=0.5343\n",
      "[Pretrain] Epoch 47/50  Loss=1.4010  Acc=0.5431\n",
      "[Pretrain] Epoch 48/50  Loss=1.4097  Acc=0.5440\n",
      "[Pretrain] Epoch 49/50  Loss=1.4093  Acc=0.5406\n",
      "[Pretrain] Epoch 50/50  Loss=1.3920  Acc=0.5456\n",
      "[Fine-tune] Epoch 1/50  Loss=3.2455\n",
      "[Fine-tune] Epoch 2/50  Loss=3.1275\n",
      "[Fine-tune] Epoch 3/50  Loss=3.0564\n",
      "[Fine-tune] Epoch 4/50  Loss=2.9125\n",
      "[Fine-tune] Epoch 5/50  Loss=2.6851\n",
      "[Fine-tune] Epoch 6/50  Loss=2.5931\n",
      "[Fine-tune] Epoch 7/50  Loss=2.4838\n",
      "[Fine-tune] Epoch 8/50  Loss=2.4506\n",
      "[Fine-tune] Epoch 9/50  Loss=2.4074\n",
      "[Fine-tune] Epoch 10/50  Loss=2.3403\n",
      "[Fine-tune] Epoch 11/50  Loss=2.3050\n",
      "[Fine-tune] Epoch 12/50  Loss=2.2740\n",
      "[Fine-tune] Epoch 13/50  Loss=2.2209\n",
      "[Fine-tune] Epoch 14/50  Loss=2.1890\n",
      "[Fine-tune] Epoch 15/50  Loss=2.1529\n",
      "[Fine-tune] Epoch 16/50  Loss=2.1379\n",
      "[Fine-tune] Epoch 17/50  Loss=2.0971\n",
      "[Fine-tune] Epoch 18/50  Loss=2.0681\n",
      "[Fine-tune] Epoch 19/50  Loss=2.0481\n",
      "[Fine-tune] Epoch 20/50  Loss=2.0188\n",
      "[Fine-tune] Epoch 21/50  Loss=2.0093\n",
      "[Fine-tune] Epoch 22/50  Loss=1.9985\n",
      "[Fine-tune] Epoch 23/50  Loss=1.9694\n",
      "[Fine-tune] Epoch 24/50  Loss=1.9439\n",
      "[Fine-tune] Epoch 25/50  Loss=1.9234\n",
      "[Fine-tune] Epoch 26/50  Loss=1.9117\n",
      "[Fine-tune] Epoch 27/50  Loss=1.8868\n",
      "[Fine-tune] Epoch 28/50  Loss=1.8770\n",
      "[Fine-tune] Epoch 29/50  Loss=1.8520\n",
      "[Fine-tune] Epoch 30/50  Loss=1.8444\n",
      "[Fine-tune] Epoch 31/50  Loss=1.8244\n",
      "[Fine-tune] Epoch 32/50  Loss=1.8149\n",
      "[Fine-tune] Epoch 33/50  Loss=1.7824\n",
      "[Fine-tune] Epoch 34/50  Loss=1.7745\n",
      "[Fine-tune] Epoch 35/50  Loss=1.7692\n",
      "[Fine-tune] Epoch 36/50  Loss=1.7492\n",
      "[Fine-tune] Epoch 37/50  Loss=1.7338\n",
      "[Fine-tune] Epoch 38/50  Loss=1.7286\n",
      "[Fine-tune] Epoch 39/50  Loss=1.7142\n",
      "[Fine-tune] Epoch 40/50  Loss=1.6967\n",
      "[Fine-tune] Epoch 41/50  Loss=1.6947\n",
      "[Fine-tune] Epoch 42/50  Loss=1.6827\n",
      "[Fine-tune] Epoch 43/50  Loss=1.6654\n",
      "[Fine-tune] Epoch 44/50  Loss=1.6596\n",
      "[Fine-tune] Epoch 45/50  Loss=1.6709\n",
      "[Fine-tune] Epoch 46/50  Loss=1.6467\n",
      "[Fine-tune] Epoch 47/50  Loss=1.6462\n",
      "[Fine-tune] Epoch 48/50  Loss=1.6431\n",
      "[Fine-tune] Epoch 49/50  Loss=1.6291\n",
      "[Fine-tune] Epoch 50/50  Loss=1.6149\n",
      "[Pretrain] Epoch 1/50  Loss=3.8208  Acc=0.0424\n",
      "[Pretrain] Epoch 2/50  Loss=3.2098  Acc=0.0465\n",
      "[Pretrain] Epoch 3/50  Loss=3.0542  Acc=0.0867\n",
      "[Pretrain] Epoch 4/50  Loss=2.7498  Acc=0.1458\n",
      "[Pretrain] Epoch 5/50  Loss=2.5901  Acc=0.1844\n",
      "[Pretrain] Epoch 6/50  Loss=2.4301  Acc=0.2356\n",
      "[Pretrain] Epoch 7/50  Loss=2.3465  Acc=0.2547\n",
      "[Pretrain] Epoch 8/50  Loss=2.2693  Acc=0.2710\n",
      "[Pretrain] Epoch 9/50  Loss=2.2249  Acc=0.2847\n",
      "[Pretrain] Epoch 10/50  Loss=2.1800  Acc=0.3005\n",
      "[Pretrain] Epoch 11/50  Loss=2.1452  Acc=0.3071\n",
      "[Pretrain] Epoch 12/50  Loss=2.1103  Acc=0.3186\n",
      "[Pretrain] Epoch 13/50  Loss=2.0663  Acc=0.3312\n",
      "[Pretrain] Epoch 14/50  Loss=2.0350  Acc=0.3335\n",
      "[Pretrain] Epoch 15/50  Loss=2.0077  Acc=0.3436\n",
      "[Pretrain] Epoch 16/50  Loss=1.9981  Acc=0.3475\n",
      "[Pretrain] Epoch 17/50  Loss=1.9434  Acc=0.3633\n",
      "[Pretrain] Epoch 18/50  Loss=1.9235  Acc=0.3730\n",
      "[Pretrain] Epoch 19/50  Loss=1.9017  Acc=0.3761\n",
      "[Pretrain] Epoch 20/50  Loss=1.8705  Acc=0.3860\n",
      "[Pretrain] Epoch 21/50  Loss=1.8690  Acc=0.3879\n",
      "[Pretrain] Epoch 22/50  Loss=1.8399  Acc=0.3971\n",
      "[Pretrain] Epoch 23/50  Loss=1.7868  Acc=0.4235\n",
      "[Pretrain] Epoch 24/50  Loss=1.8098  Acc=0.4073\n",
      "[Pretrain] Epoch 25/50  Loss=1.7797  Acc=0.4161\n",
      "[Pretrain] Epoch 26/50  Loss=1.7429  Acc=0.4312\n",
      "[Pretrain] Epoch 27/50  Loss=1.7335  Acc=0.4296\n",
      "[Pretrain] Epoch 28/50  Loss=1.7077  Acc=0.4393\n",
      "[Pretrain] Epoch 29/50  Loss=1.6663  Acc=0.4549\n",
      "[Pretrain] Epoch 30/50  Loss=1.6635  Acc=0.4526\n",
      "[Pretrain] Epoch 31/50  Loss=1.6383  Acc=0.4556\n",
      "[Pretrain] Epoch 32/50  Loss=1.6080  Acc=0.4637\n",
      "[Pretrain] Epoch 33/50  Loss=1.6044  Acc=0.4736\n",
      "[Pretrain] Epoch 34/50  Loss=1.5666  Acc=0.4880\n",
      "[Pretrain] Epoch 35/50  Loss=1.5628  Acc=0.4871\n",
      "[Pretrain] Epoch 36/50  Loss=1.5253  Acc=0.4952\n",
      "[Pretrain] Epoch 37/50  Loss=1.5249  Acc=0.5022\n",
      "[Pretrain] Epoch 38/50  Loss=1.4968  Acc=0.5154\n",
      "[Pretrain] Epoch 39/50  Loss=1.4775  Acc=0.5115\n",
      "[Pretrain] Epoch 40/50  Loss=1.4748  Acc=0.5163\n",
      "[Pretrain] Epoch 41/50  Loss=1.4583  Acc=0.5185\n",
      "[Pretrain] Epoch 42/50  Loss=1.4128  Acc=0.5302\n",
      "[Pretrain] Epoch 43/50  Loss=1.3987  Acc=0.5318\n",
      "[Pretrain] Epoch 44/50  Loss=1.4292  Acc=0.5300\n",
      "[Pretrain] Epoch 45/50  Loss=1.3888  Acc=0.5395\n",
      "[Pretrain] Epoch 46/50  Loss=1.3750  Acc=0.5492\n",
      "[Pretrain] Epoch 47/50  Loss=1.3490  Acc=0.5476\n",
      "[Pretrain] Epoch 48/50  Loss=1.3477  Acc=0.5562\n",
      "[Pretrain] Epoch 49/50  Loss=1.3388  Acc=0.5553\n",
      "[Pretrain] Epoch 50/50  Loss=1.3237  Acc=0.5695\n",
      "[Fine-tune] Epoch 1/50  Loss=3.0741\n",
      "[Fine-tune] Epoch 2/50  Loss=2.4738\n",
      "[Fine-tune] Epoch 3/50  Loss=2.3018\n",
      "[Fine-tune] Epoch 4/50  Loss=2.1806\n",
      "[Fine-tune] Epoch 5/50  Loss=2.1217\n",
      "[Fine-tune] Epoch 6/50  Loss=2.0417\n",
      "[Fine-tune] Epoch 7/50  Loss=1.9909\n",
      "[Fine-tune] Epoch 8/50  Loss=1.9568\n",
      "[Fine-tune] Epoch 9/50  Loss=1.9009\n",
      "[Fine-tune] Epoch 10/50  Loss=1.8780\n",
      "[Fine-tune] Epoch 11/50  Loss=1.8308\n",
      "[Fine-tune] Epoch 12/50  Loss=1.7972\n",
      "[Fine-tune] Epoch 13/50  Loss=1.7733\n",
      "[Fine-tune] Epoch 14/50  Loss=1.7409\n",
      "[Fine-tune] Epoch 15/50  Loss=1.7171\n",
      "[Fine-tune] Epoch 16/50  Loss=1.6671\n",
      "[Fine-tune] Epoch 17/50  Loss=1.6605\n",
      "[Fine-tune] Epoch 18/50  Loss=1.6364\n",
      "[Fine-tune] Epoch 19/50  Loss=1.6005\n",
      "[Fine-tune] Epoch 20/50  Loss=1.5673\n",
      "[Fine-tune] Epoch 21/50  Loss=1.5396\n",
      "[Fine-tune] Epoch 22/50  Loss=1.5326\n",
      "[Fine-tune] Epoch 23/50  Loss=1.5090\n",
      "[Fine-tune] Epoch 24/50  Loss=1.4810\n",
      "[Fine-tune] Epoch 25/50  Loss=1.4552\n",
      "[Fine-tune] Epoch 26/50  Loss=1.4332\n",
      "[Fine-tune] Epoch 27/50  Loss=1.4058\n",
      "[Fine-tune] Epoch 28/50  Loss=1.4042\n",
      "[Fine-tune] Epoch 29/50  Loss=1.3799\n",
      "[Fine-tune] Epoch 30/50  Loss=1.3472\n",
      "[Fine-tune] Epoch 31/50  Loss=1.3337\n",
      "[Fine-tune] Epoch 32/50  Loss=1.3172\n",
      "[Fine-tune] Epoch 33/50  Loss=1.3013\n",
      "[Fine-tune] Epoch 34/50  Loss=1.2845\n",
      "[Fine-tune] Epoch 35/50  Loss=1.2880\n",
      "[Fine-tune] Epoch 36/50  Loss=1.2481\n",
      "[Fine-tune] Epoch 37/50  Loss=1.2571\n",
      "[Fine-tune] Epoch 38/50  Loss=1.2487\n",
      "[Fine-tune] Epoch 39/50  Loss=1.2406\n",
      "[Fine-tune] Epoch 40/50  Loss=1.2234\n",
      "[Fine-tune] Epoch 41/50  Loss=1.2130\n",
      "[Fine-tune] Epoch 42/50  Loss=1.2082\n",
      "[Fine-tune] Epoch 43/50  Loss=1.2014\n",
      "[Fine-tune] Epoch 44/50  Loss=1.1867\n",
      "[Fine-tune] Epoch 45/50  Loss=1.1894\n",
      "[Fine-tune] Epoch 46/50  Loss=1.1722\n",
      "[Fine-tune] Epoch 47/50  Loss=1.1779\n",
      "[Fine-tune] Epoch 48/50  Loss=1.1578\n",
      "[Fine-tune] Epoch 49/50  Loss=1.1421\n",
      "[Fine-tune] Epoch 50/50  Loss=1.1532\n",
      "[Pretrain] Epoch 1/75  Loss=3.1940  Acc=0.0600\n",
      "[Pretrain] Epoch 2/75  Loss=3.0571  Acc=0.0785\n",
      "[Pretrain] Epoch 3/75  Loss=2.8261  Acc=0.1397\n",
      "[Pretrain] Epoch 4/75  Loss=2.5470  Acc=0.1994\n",
      "[Pretrain] Epoch 5/75  Loss=2.4615  Acc=0.2250\n",
      "[Pretrain] Epoch 6/75  Loss=2.3319  Acc=0.2419\n",
      "[Pretrain] Epoch 7/75  Loss=2.2481  Acc=0.2733\n",
      "[Pretrain] Epoch 8/75  Loss=2.1377  Acc=0.3035\n",
      "[Pretrain] Epoch 9/75  Loss=2.0810  Acc=0.3213\n",
      "[Pretrain] Epoch 10/75  Loss=2.0216  Acc=0.3357\n",
      "[Pretrain] Epoch 11/75  Loss=1.9970  Acc=0.3463\n",
      "[Pretrain] Epoch 12/75  Loss=1.9491  Acc=0.3700\n",
      "[Pretrain] Epoch 13/75  Loss=1.9141  Acc=0.3782\n",
      "[Pretrain] Epoch 14/75  Loss=1.9208  Acc=0.3703\n",
      "[Pretrain] Epoch 15/75  Loss=1.8832  Acc=0.3852\n",
      "[Pretrain] Epoch 16/75  Loss=1.8588  Acc=0.4039\n",
      "[Pretrain] Epoch 17/75  Loss=1.8325  Acc=0.4016\n",
      "[Pretrain] Epoch 18/75  Loss=1.8000  Acc=0.4177\n",
      "[Pretrain] Epoch 19/75  Loss=1.7743  Acc=0.4292\n",
      "[Pretrain] Epoch 20/75  Loss=1.7660  Acc=0.4309\n",
      "[Pretrain] Epoch 21/75  Loss=1.7227  Acc=0.4447\n",
      "[Pretrain] Epoch 22/75  Loss=1.7087  Acc=0.4391\n",
      "[Pretrain] Epoch 23/75  Loss=1.6966  Acc=0.4501\n",
      "[Pretrain] Epoch 24/75  Loss=1.6617  Acc=0.4605\n",
      "[Pretrain] Epoch 25/75  Loss=1.6375  Acc=0.4734\n",
      "[Pretrain] Epoch 26/75  Loss=1.6344  Acc=0.4768\n",
      "[Pretrain] Epoch 27/75  Loss=1.5987  Acc=0.4844\n",
      "[Pretrain] Epoch 28/75  Loss=1.5941  Acc=0.4781\n",
      "[Pretrain] Epoch 29/75  Loss=1.5773  Acc=0.4889\n",
      "[Pretrain] Epoch 30/75  Loss=1.5485  Acc=0.5045\n",
      "[Pretrain] Epoch 31/75  Loss=1.5279  Acc=0.5061\n",
      "[Pretrain] Epoch 32/75  Loss=1.5369  Acc=0.5074\n",
      "[Pretrain] Epoch 33/75  Loss=1.4986  Acc=0.5119\n",
      "[Pretrain] Epoch 34/75  Loss=1.4991  Acc=0.5149\n",
      "[Pretrain] Epoch 35/75  Loss=1.4701  Acc=0.5187\n",
      "[Pretrain] Epoch 36/75  Loss=1.4601  Acc=0.5255\n",
      "[Pretrain] Epoch 37/75  Loss=1.4444  Acc=0.5284\n",
      "[Pretrain] Epoch 38/75  Loss=1.4553  Acc=0.5305\n",
      "[Pretrain] Epoch 39/75  Loss=1.4066  Acc=0.5442\n",
      "[Pretrain] Epoch 40/75  Loss=1.4193  Acc=0.5440\n",
      "[Pretrain] Epoch 41/75  Loss=1.4067  Acc=0.5445\n",
      "[Pretrain] Epoch 42/75  Loss=1.3940  Acc=0.5512\n",
      "[Pretrain] Epoch 43/75  Loss=1.3968  Acc=0.5463\n",
      "[Pretrain] Epoch 44/75  Loss=1.3812  Acc=0.5548\n",
      "[Pretrain] Epoch 45/75  Loss=1.3713  Acc=0.5546\n",
      "[Pretrain] Epoch 46/75  Loss=1.3745  Acc=0.5573\n",
      "[Pretrain] Epoch 47/75  Loss=1.3556  Acc=0.5659\n",
      "[Pretrain] Epoch 48/75  Loss=1.3408  Acc=0.5603\n",
      "[Pretrain] Epoch 49/75  Loss=1.3389  Acc=0.5699\n",
      "[Pretrain] Epoch 50/75  Loss=1.3357  Acc=0.5607\n",
      "[Pretrain] Epoch 51/75  Loss=1.3400  Acc=0.5668\n",
      "[Pretrain] Epoch 52/75  Loss=1.3218  Acc=0.5736\n",
      "[Pretrain] Epoch 53/75  Loss=1.3030  Acc=0.5796\n",
      "[Pretrain] Epoch 54/75  Loss=1.3068  Acc=0.5776\n",
      "[Pretrain] Epoch 55/75  Loss=1.3153  Acc=0.5704\n",
      "[Pretrain] Epoch 56/75  Loss=1.2920  Acc=0.5749\n",
      "[Pretrain] Epoch 57/75  Loss=1.3074  Acc=0.5803\n",
      "[Pretrain] Epoch 58/75  Loss=1.2922  Acc=0.5788\n",
      "[Pretrain] Epoch 59/75  Loss=1.2793  Acc=0.5828\n",
      "[Pretrain] Epoch 60/75  Loss=1.2807  Acc=0.5839\n",
      "[Pretrain] Epoch 61/75  Loss=1.2830  Acc=0.5849\n",
      "[Pretrain] Epoch 62/75  Loss=1.2849  Acc=0.5878\n",
      "[Pretrain] Epoch 63/75  Loss=1.2655  Acc=0.5929\n",
      "[Pretrain] Epoch 64/75  Loss=1.2730  Acc=0.5810\n",
      "[Pretrain] Epoch 65/75  Loss=1.2717  Acc=0.5823\n",
      "[Pretrain] Epoch 66/75  Loss=1.2516  Acc=0.5927\n",
      "[Pretrain] Epoch 67/75  Loss=1.2589  Acc=0.5882\n",
      "[Pretrain] Epoch 68/75  Loss=1.2395  Acc=0.5986\n",
      "[Pretrain] Epoch 69/75  Loss=1.2569  Acc=0.5860\n",
      "[Pretrain] Epoch 70/75  Loss=1.2395  Acc=0.5891\n",
      "[Pretrain] Epoch 71/75  Loss=1.2496  Acc=0.5959\n",
      "[Pretrain] Epoch 72/75  Loss=1.2587  Acc=0.5945\n",
      "[Pretrain] Epoch 73/75  Loss=1.2671  Acc=0.5821\n",
      "[Pretrain] Epoch 74/75  Loss=1.2509  Acc=0.5939\n",
      "[Pretrain] Epoch 75/75  Loss=1.2316  Acc=0.6024\n",
      "[Fine-tune] Epoch 1/50  Loss=3.2519\n",
      "[Fine-tune] Epoch 2/50  Loss=3.1224\n",
      "[Fine-tune] Epoch 3/50  Loss=3.0664\n",
      "[Fine-tune] Epoch 4/50  Loss=3.0118\n",
      "[Fine-tune] Epoch 5/50  Loss=2.8623\n",
      "[Fine-tune] Epoch 6/50  Loss=2.6460\n",
      "[Fine-tune] Epoch 7/50  Loss=2.5272\n",
      "[Fine-tune] Epoch 8/50  Loss=2.4588\n",
      "[Fine-tune] Epoch 9/50  Loss=2.3941\n",
      "[Fine-tune] Epoch 10/50  Loss=2.3297\n",
      "[Fine-tune] Epoch 11/50  Loss=2.2826\n",
      "[Fine-tune] Epoch 12/50  Loss=2.2806\n",
      "[Fine-tune] Epoch 13/50  Loss=2.2399\n",
      "[Fine-tune] Epoch 14/50  Loss=2.1920\n",
      "[Fine-tune] Epoch 15/50  Loss=2.1915\n",
      "[Fine-tune] Epoch 16/50  Loss=2.1465\n",
      "[Fine-tune] Epoch 17/50  Loss=2.1069\n",
      "[Fine-tune] Epoch 18/50  Loss=2.0832\n",
      "[Fine-tune] Epoch 19/50  Loss=2.0591\n",
      "[Fine-tune] Epoch 20/50  Loss=2.0349\n",
      "[Fine-tune] Epoch 21/50  Loss=2.0079\n",
      "[Fine-tune] Epoch 22/50  Loss=1.9889\n",
      "[Fine-tune] Epoch 23/50  Loss=1.9669\n",
      "[Fine-tune] Epoch 24/50  Loss=1.9342\n",
      "[Fine-tune] Epoch 25/50  Loss=1.9241\n",
      "[Fine-tune] Epoch 26/50  Loss=1.9061\n",
      "[Fine-tune] Epoch 27/50  Loss=1.8840\n",
      "[Fine-tune] Epoch 28/50  Loss=1.8667\n",
      "[Fine-tune] Epoch 29/50  Loss=1.8565\n",
      "[Fine-tune] Epoch 30/50  Loss=1.8145\n",
      "[Fine-tune] Epoch 31/50  Loss=1.8215\n",
      "[Fine-tune] Epoch 32/50  Loss=1.8079\n",
      "[Fine-tune] Epoch 33/50  Loss=1.7838\n",
      "[Fine-tune] Epoch 34/50  Loss=1.7830\n",
      "[Fine-tune] Epoch 35/50  Loss=1.7538\n",
      "[Fine-tune] Epoch 36/50  Loss=1.7439\n",
      "[Fine-tune] Epoch 37/50  Loss=1.7383\n",
      "[Fine-tune] Epoch 38/50  Loss=1.7380\n",
      "[Fine-tune] Epoch 39/50  Loss=1.7161\n",
      "[Fine-tune] Epoch 40/50  Loss=1.7022\n",
      "[Fine-tune] Epoch 41/50  Loss=1.6727\n",
      "[Fine-tune] Epoch 42/50  Loss=1.6856\n",
      "[Fine-tune] Epoch 43/50  Loss=1.6732\n",
      "[Fine-tune] Epoch 44/50  Loss=1.6649\n",
      "[Fine-tune] Epoch 45/50  Loss=1.6607\n",
      "[Fine-tune] Epoch 46/50  Loss=1.6373\n",
      "[Fine-tune] Epoch 47/50  Loss=1.6316\n",
      "[Fine-tune] Epoch 48/50  Loss=1.6290\n",
      "[Fine-tune] Epoch 49/50  Loss=1.6261\n",
      "[Fine-tune] Epoch 50/50  Loss=1.6124\n",
      "[Pretrain] Epoch 1/75  Loss=3.7364  Acc=0.0449\n",
      "[Pretrain] Epoch 2/75  Loss=3.2197  Acc=0.0341\n",
      "[Pretrain] Epoch 3/75  Loss=3.0382  Acc=0.0781\n",
      "[Pretrain] Epoch 4/75  Loss=2.7456  Acc=0.1257\n",
      "[Pretrain] Epoch 5/75  Loss=2.6512  Acc=0.1528\n",
      "[Pretrain] Epoch 6/75  Loss=2.5755  Acc=0.1704\n",
      "[Pretrain] Epoch 7/75  Loss=2.4928  Acc=0.1979\n",
      "[Pretrain] Epoch 8/75  Loss=2.4471  Acc=0.2092\n",
      "[Pretrain] Epoch 9/75  Loss=2.3532  Acc=0.2421\n",
      "[Pretrain] Epoch 10/75  Loss=2.3007  Acc=0.2550\n",
      "[Pretrain] Epoch 11/75  Loss=2.2392  Acc=0.2719\n",
      "[Pretrain] Epoch 12/75  Loss=2.2019  Acc=0.2795\n",
      "[Pretrain] Epoch 13/75  Loss=2.1300  Acc=0.3050\n",
      "[Pretrain] Epoch 14/75  Loss=2.1362  Acc=0.3014\n",
      "[Pretrain] Epoch 15/75  Loss=2.0825  Acc=0.3191\n",
      "[Pretrain] Epoch 16/75  Loss=2.0438  Acc=0.3240\n",
      "[Pretrain] Epoch 17/75  Loss=2.0196  Acc=0.3373\n",
      "[Pretrain] Epoch 18/75  Loss=1.9895  Acc=0.3463\n",
      "[Pretrain] Epoch 19/75  Loss=1.9595  Acc=0.3570\n",
      "[Pretrain] Epoch 20/75  Loss=1.9301  Acc=0.3651\n",
      "[Pretrain] Epoch 21/75  Loss=1.9022  Acc=0.3750\n",
      "[Pretrain] Epoch 22/75  Loss=1.8939  Acc=0.3790\n",
      "[Pretrain] Epoch 23/75  Loss=1.8665  Acc=0.3948\n",
      "[Pretrain] Epoch 24/75  Loss=1.8465  Acc=0.3982\n",
      "[Pretrain] Epoch 25/75  Loss=1.8280  Acc=0.4023\n",
      "[Pretrain] Epoch 26/75  Loss=1.8093  Acc=0.4138\n",
      "[Pretrain] Epoch 27/75  Loss=1.7696  Acc=0.4167\n",
      "[Pretrain] Epoch 28/75  Loss=1.7511  Acc=0.4273\n",
      "[Pretrain] Epoch 29/75  Loss=1.7068  Acc=0.4388\n",
      "[Pretrain] Epoch 30/75  Loss=1.6962  Acc=0.4438\n",
      "[Pretrain] Epoch 31/75  Loss=1.6878  Acc=0.4506\n",
      "[Pretrain] Epoch 32/75  Loss=1.6629  Acc=0.4544\n",
      "[Pretrain] Epoch 33/75  Loss=1.6269  Acc=0.4734\n",
      "[Pretrain] Epoch 34/75  Loss=1.6278  Acc=0.4675\n",
      "[Pretrain] Epoch 35/75  Loss=1.6007  Acc=0.4738\n",
      "[Pretrain] Epoch 36/75  Loss=1.5701  Acc=0.4874\n",
      "[Pretrain] Epoch 37/75  Loss=1.5639  Acc=0.4856\n",
      "[Pretrain] Epoch 38/75  Loss=1.5470  Acc=0.4952\n",
      "[Pretrain] Epoch 39/75  Loss=1.5336  Acc=0.4950\n",
      "[Pretrain] Epoch 40/75  Loss=1.5016  Acc=0.5050\n",
      "[Pretrain] Epoch 41/75  Loss=1.4920  Acc=0.5126\n",
      "[Pretrain] Epoch 42/75  Loss=1.4938  Acc=0.5036\n",
      "[Pretrain] Epoch 43/75  Loss=1.4739  Acc=0.5237\n",
      "[Pretrain] Epoch 44/75  Loss=1.4655  Acc=0.5160\n",
      "[Pretrain] Epoch 45/75  Loss=1.4430  Acc=0.5282\n",
      "[Pretrain] Epoch 46/75  Loss=1.4319  Acc=0.5257\n",
      "[Pretrain] Epoch 47/75  Loss=1.4115  Acc=0.5323\n",
      "[Pretrain] Epoch 48/75  Loss=1.4073  Acc=0.5433\n",
      "[Pretrain] Epoch 49/75  Loss=1.3764  Acc=0.5415\n",
      "[Pretrain] Epoch 50/75  Loss=1.3809  Acc=0.5393\n",
      "[Pretrain] Epoch 51/75  Loss=1.3788  Acc=0.5426\n",
      "[Pretrain] Epoch 52/75  Loss=1.3661  Acc=0.5519\n",
      "[Pretrain] Epoch 53/75  Loss=1.3556  Acc=0.5528\n",
      "[Pretrain] Epoch 54/75  Loss=1.3464  Acc=0.5555\n",
      "[Pretrain] Epoch 55/75  Loss=1.3208  Acc=0.5605\n",
      "[Pretrain] Epoch 56/75  Loss=1.3090  Acc=0.5663\n",
      "[Pretrain] Epoch 57/75  Loss=1.2940  Acc=0.5668\n",
      "[Pretrain] Epoch 58/75  Loss=1.3189  Acc=0.5679\n",
      "[Pretrain] Epoch 59/75  Loss=1.2883  Acc=0.5815\n",
      "[Pretrain] Epoch 60/75  Loss=1.2741  Acc=0.5787\n",
      "[Pretrain] Epoch 61/75  Loss=1.2862  Acc=0.5744\n",
      "[Pretrain] Epoch 62/75  Loss=1.2738  Acc=0.5814\n",
      "[Pretrain] Epoch 63/75  Loss=1.2693  Acc=0.5756\n",
      "[Pretrain] Epoch 64/75  Loss=1.2710  Acc=0.5788\n",
      "[Pretrain] Epoch 65/75  Loss=1.2610  Acc=0.5918\n",
      "[Pretrain] Epoch 66/75  Loss=1.2454  Acc=0.5866\n",
      "[Pretrain] Epoch 67/75  Loss=1.2478  Acc=0.5896\n",
      "[Pretrain] Epoch 68/75  Loss=1.2578  Acc=0.5826\n",
      "[Pretrain] Epoch 69/75  Loss=1.2404  Acc=0.5961\n",
      "[Pretrain] Epoch 70/75  Loss=1.2218  Acc=0.6006\n",
      "[Pretrain] Epoch 71/75  Loss=1.2366  Acc=0.5911\n",
      "[Pretrain] Epoch 72/75  Loss=1.2188  Acc=0.5896\n",
      "[Pretrain] Epoch 73/75  Loss=1.2015  Acc=0.6034\n",
      "[Pretrain] Epoch 74/75  Loss=1.2077  Acc=0.5993\n",
      "[Pretrain] Epoch 75/75  Loss=1.2275  Acc=0.5959\n",
      "[Fine-tune] Epoch 1/50  Loss=2.8568\n",
      "[Fine-tune] Epoch 2/50  Loss=2.4620\n",
      "[Fine-tune] Epoch 3/50  Loss=2.3069\n",
      "[Fine-tune] Epoch 4/50  Loss=2.1976\n",
      "[Fine-tune] Epoch 5/50  Loss=2.1573\n",
      "[Fine-tune] Epoch 6/50  Loss=2.0906\n",
      "[Fine-tune] Epoch 7/50  Loss=2.0265\n",
      "[Fine-tune] Epoch 8/50  Loss=1.9808\n",
      "[Fine-tune] Epoch 9/50  Loss=1.9607\n",
      "[Fine-tune] Epoch 10/50  Loss=1.9078\n",
      "[Fine-tune] Epoch 11/50  Loss=1.8673\n",
      "[Fine-tune] Epoch 12/50  Loss=1.8198\n",
      "[Fine-tune] Epoch 13/50  Loss=1.7930\n",
      "[Fine-tune] Epoch 14/50  Loss=1.7737\n",
      "[Fine-tune] Epoch 15/50  Loss=1.7196\n",
      "[Fine-tune] Epoch 16/50  Loss=1.7051\n",
      "[Fine-tune] Epoch 17/50  Loss=1.6812\n",
      "[Fine-tune] Epoch 18/50  Loss=1.6505\n",
      "[Fine-tune] Epoch 19/50  Loss=1.6331\n",
      "[Fine-tune] Epoch 20/50  Loss=1.5997\n",
      "[Fine-tune] Epoch 21/50  Loss=1.5798\n",
      "[Fine-tune] Epoch 22/50  Loss=1.5459\n",
      "[Fine-tune] Epoch 23/50  Loss=1.5334\n",
      "[Fine-tune] Epoch 24/50  Loss=1.5050\n",
      "[Fine-tune] Epoch 25/50  Loss=1.4851\n",
      "[Fine-tune] Epoch 26/50  Loss=1.4623\n",
      "[Fine-tune] Epoch 27/50  Loss=1.4469\n",
      "[Fine-tune] Epoch 28/50  Loss=1.4426\n",
      "[Fine-tune] Epoch 29/50  Loss=1.4075\n",
      "[Fine-tune] Epoch 30/50  Loss=1.3912\n",
      "[Fine-tune] Epoch 31/50  Loss=1.3547\n",
      "[Fine-tune] Epoch 32/50  Loss=1.3446\n",
      "[Fine-tune] Epoch 33/50  Loss=1.3609\n",
      "[Fine-tune] Epoch 34/50  Loss=1.3298\n",
      "[Fine-tune] Epoch 35/50  Loss=1.3147\n",
      "[Fine-tune] Epoch 36/50  Loss=1.3015\n",
      "[Fine-tune] Epoch 37/50  Loss=1.2877\n",
      "[Fine-tune] Epoch 38/50  Loss=1.2739\n",
      "[Fine-tune] Epoch 39/50  Loss=1.2600\n",
      "[Fine-tune] Epoch 40/50  Loss=1.2621\n",
      "[Fine-tune] Epoch 41/50  Loss=1.2528\n",
      "[Fine-tune] Epoch 42/50  Loss=1.2272\n",
      "[Fine-tune] Epoch 43/50  Loss=1.2222\n",
      "[Fine-tune] Epoch 44/50  Loss=1.2348\n",
      "[Fine-tune] Epoch 45/50  Loss=1.2176\n",
      "[Fine-tune] Epoch 46/50  Loss=1.2179\n",
      "[Fine-tune] Epoch 47/50  Loss=1.2038\n",
      "[Fine-tune] Epoch 48/50  Loss=1.1796\n",
      "[Fine-tune] Epoch 49/50  Loss=1.1917\n",
      "[Fine-tune] Epoch 50/50  Loss=1.1835\n",
      "[Pretrain] Epoch 1/100  Loss=3.2448  Acc=0.0462\n",
      "[Pretrain] Epoch 2/100  Loss=3.1083  Acc=0.0729\n",
      "[Pretrain] Epoch 3/100  Loss=3.0377  Acc=0.0900\n",
      "[Pretrain] Epoch 4/100  Loss=2.9547  Acc=0.1049\n",
      "[Pretrain] Epoch 5/100  Loss=2.6223  Acc=0.1819\n",
      "[Pretrain] Epoch 6/100  Loss=2.4122  Acc=0.2385\n",
      "[Pretrain] Epoch 7/100  Loss=2.2796  Acc=0.2687\n",
      "[Pretrain] Epoch 8/100  Loss=2.2010  Acc=0.2936\n",
      "[Pretrain] Epoch 9/100  Loss=2.1207  Acc=0.3150\n",
      "[Pretrain] Epoch 10/100  Loss=2.1060  Acc=0.3191\n",
      "[Pretrain] Epoch 11/100  Loss=2.0340  Acc=0.3420\n",
      "[Pretrain] Epoch 12/100  Loss=2.0159  Acc=0.3423\n",
      "[Pretrain] Epoch 13/100  Loss=2.0004  Acc=0.3581\n",
      "[Pretrain] Epoch 14/100  Loss=1.9666  Acc=0.3626\n",
      "[Pretrain] Epoch 15/100  Loss=1.9005  Acc=0.3899\n",
      "[Pretrain] Epoch 16/100  Loss=1.8836  Acc=0.3942\n",
      "[Pretrain] Epoch 17/100  Loss=1.8675  Acc=0.3940\n",
      "[Pretrain] Epoch 18/100  Loss=1.8447  Acc=0.4032\n",
      "[Pretrain] Epoch 19/100  Loss=1.8251  Acc=0.4127\n",
      "[Pretrain] Epoch 20/100  Loss=1.7926  Acc=0.4194\n",
      "[Pretrain] Epoch 21/100  Loss=1.7775  Acc=0.4228\n",
      "[Pretrain] Epoch 22/100  Loss=1.7553  Acc=0.4303\n",
      "[Pretrain] Epoch 23/100  Loss=1.7554  Acc=0.4334\n",
      "[Pretrain] Epoch 24/100  Loss=1.7176  Acc=0.4398\n",
      "[Pretrain] Epoch 25/100  Loss=1.7032  Acc=0.4503\n",
      "[Pretrain] Epoch 26/100  Loss=1.6830  Acc=0.4546\n",
      "[Pretrain] Epoch 27/100  Loss=1.6644  Acc=0.4603\n",
      "[Pretrain] Epoch 28/100  Loss=1.6694  Acc=0.4630\n",
      "[Pretrain] Epoch 29/100  Loss=1.6213  Acc=0.4722\n",
      "[Pretrain] Epoch 30/100  Loss=1.6298  Acc=0.4756\n",
      "[Pretrain] Epoch 31/100  Loss=1.6108  Acc=0.4792\n",
      "[Pretrain] Epoch 32/100  Loss=1.5991  Acc=0.4820\n",
      "[Pretrain] Epoch 33/100  Loss=1.5688  Acc=0.4921\n",
      "[Pretrain] Epoch 34/100  Loss=1.5770  Acc=0.4898\n",
      "[Pretrain] Epoch 35/100  Loss=1.5595  Acc=0.4880\n",
      "[Pretrain] Epoch 36/100  Loss=1.5541  Acc=0.4962\n",
      "[Pretrain] Epoch 37/100  Loss=1.5350  Acc=0.5054\n",
      "[Pretrain] Epoch 38/100  Loss=1.5232  Acc=0.5102\n",
      "[Pretrain] Epoch 39/100  Loss=1.5058  Acc=0.5099\n",
      "[Pretrain] Epoch 40/100  Loss=1.4877  Acc=0.5119\n",
      "[Pretrain] Epoch 41/100  Loss=1.5026  Acc=0.5101\n",
      "[Pretrain] Epoch 42/100  Loss=1.4901  Acc=0.5131\n",
      "[Pretrain] Epoch 43/100  Loss=1.4713  Acc=0.5221\n",
      "[Pretrain] Epoch 44/100  Loss=1.4844  Acc=0.5145\n",
      "[Pretrain] Epoch 45/100  Loss=1.4576  Acc=0.5219\n",
      "[Pretrain] Epoch 46/100  Loss=1.4512  Acc=0.5300\n",
      "[Pretrain] Epoch 47/100  Loss=1.4438  Acc=0.5321\n",
      "[Pretrain] Epoch 48/100  Loss=1.4428  Acc=0.5363\n",
      "[Pretrain] Epoch 49/100  Loss=1.4259  Acc=0.5406\n",
      "[Pretrain] Epoch 50/100  Loss=1.4483  Acc=0.5330\n",
      "[Pretrain] Epoch 51/100  Loss=1.4155  Acc=0.5357\n",
      "[Pretrain] Epoch 52/100  Loss=1.4052  Acc=0.5449\n",
      "[Pretrain] Epoch 53/100  Loss=1.4097  Acc=0.5463\n",
      "[Pretrain] Epoch 54/100  Loss=1.4012  Acc=0.5444\n",
      "[Pretrain] Epoch 55/100  Loss=1.3933  Acc=0.5480\n",
      "[Pretrain] Epoch 56/100  Loss=1.3998  Acc=0.5417\n",
      "[Pretrain] Epoch 57/100  Loss=1.3947  Acc=0.5537\n",
      "[Pretrain] Epoch 58/100  Loss=1.3797  Acc=0.5492\n",
      "[Pretrain] Epoch 59/100  Loss=1.3919  Acc=0.5512\n",
      "[Pretrain] Epoch 60/100  Loss=1.3682  Acc=0.5501\n",
      "[Pretrain] Epoch 61/100  Loss=1.3773  Acc=0.5505\n",
      "[Pretrain] Epoch 62/100  Loss=1.3666  Acc=0.5600\n",
      "[Pretrain] Epoch 63/100  Loss=1.3830  Acc=0.5510\n",
      "[Pretrain] Epoch 64/100  Loss=1.3708  Acc=0.5533\n",
      "[Pretrain] Epoch 65/100  Loss=1.3584  Acc=0.5553\n",
      "[Pretrain] Epoch 66/100  Loss=1.3568  Acc=0.5602\n",
      "[Pretrain] Epoch 67/100  Loss=1.3573  Acc=0.5521\n",
      "[Pretrain] Epoch 68/100  Loss=1.3501  Acc=0.5627\n",
      "[Pretrain] Epoch 69/100  Loss=1.3434  Acc=0.5657\n",
      "[Pretrain] Epoch 70/100  Loss=1.3559  Acc=0.5553\n",
      "[Pretrain] Epoch 71/100  Loss=1.3414  Acc=0.5612\n",
      "[Pretrain] Epoch 72/100  Loss=1.3565  Acc=0.5551\n",
      "[Pretrain] Epoch 73/100  Loss=1.3401  Acc=0.5611\n",
      "[Pretrain] Epoch 74/100  Loss=1.3405  Acc=0.5661\n",
      "[Pretrain] Epoch 75/100  Loss=1.3303  Acc=0.5650\n",
      "[Pretrain] Epoch 76/100  Loss=1.3278  Acc=0.5636\n",
      "[Pretrain] Epoch 77/100  Loss=1.3292  Acc=0.5611\n",
      "[Pretrain] Epoch 78/100  Loss=1.3270  Acc=0.5690\n",
      "[Pretrain] Epoch 79/100  Loss=1.3170  Acc=0.5686\n",
      "[Pretrain] Epoch 80/100  Loss=1.3324  Acc=0.5607\n",
      "[Pretrain] Epoch 81/100  Loss=1.3319  Acc=0.5603\n",
      "[Pretrain] Epoch 82/100  Loss=1.3305  Acc=0.5654\n",
      "[Pretrain] Epoch 83/100  Loss=1.3365  Acc=0.5700\n",
      "[Pretrain] Epoch 84/100  Loss=1.3344  Acc=0.5634\n",
      "[Pretrain] Epoch 85/100  Loss=1.3390  Acc=0.5643\n",
      "[Pretrain] Epoch 86/100  Loss=1.3325  Acc=0.5702\n",
      "[Pretrain] Epoch 87/100  Loss=1.3252  Acc=0.5695\n",
      "[Pretrain] Epoch 88/100  Loss=1.3280  Acc=0.5722\n",
      "[Pretrain] Epoch 89/100  Loss=1.3261  Acc=0.5699\n",
      "[Pretrain] Epoch 90/100  Loss=1.3278  Acc=0.5677\n",
      "[Pretrain] Epoch 91/100  Loss=1.3090  Acc=0.5706\n",
      "[Pretrain] Epoch 92/100  Loss=1.3314  Acc=0.5616\n",
      "[Pretrain] Epoch 93/100  Loss=1.3349  Acc=0.5656\n",
      "[Pretrain] Epoch 94/100  Loss=1.3190  Acc=0.5670\n",
      "[Pretrain] Epoch 95/100  Loss=1.3251  Acc=0.5657\n",
      "[Pretrain] Epoch 96/100  Loss=1.3021  Acc=0.5815\n",
      "[Pretrain] Epoch 97/100  Loss=1.3106  Acc=0.5753\n",
      "[Pretrain] Epoch 98/100  Loss=1.3195  Acc=0.5742\n",
      "[Pretrain] Epoch 99/100  Loss=1.3307  Acc=0.5717\n",
      "[Pretrain] Epoch 100/100  Loss=1.3174  Acc=0.5720\n",
      "[Fine-tune] Epoch 1/50  Loss=3.2504\n",
      "[Fine-tune] Epoch 2/50  Loss=3.1404\n",
      "[Fine-tune] Epoch 3/50  Loss=3.0638\n",
      "[Fine-tune] Epoch 4/50  Loss=3.0369\n",
      "[Fine-tune] Epoch 5/50  Loss=2.9435\n",
      "[Fine-tune] Epoch 6/50  Loss=2.7733\n",
      "[Fine-tune] Epoch 7/50  Loss=2.6722\n",
      "[Fine-tune] Epoch 8/50  Loss=2.5876\n",
      "[Fine-tune] Epoch 9/50  Loss=2.5284\n",
      "[Fine-tune] Epoch 10/50  Loss=2.4683\n",
      "[Fine-tune] Epoch 11/50  Loss=2.4163\n",
      "[Fine-tune] Epoch 12/50  Loss=2.3882\n",
      "[Fine-tune] Epoch 13/50  Loss=2.3348\n",
      "[Fine-tune] Epoch 14/50  Loss=2.2934\n",
      "[Fine-tune] Epoch 15/50  Loss=2.2343\n",
      "[Fine-tune] Epoch 16/50  Loss=2.1989\n",
      "[Fine-tune] Epoch 17/50  Loss=2.1695\n",
      "[Fine-tune] Epoch 18/50  Loss=2.1393\n",
      "[Fine-tune] Epoch 19/50  Loss=2.1052\n",
      "[Fine-tune] Epoch 20/50  Loss=2.1031\n",
      "[Fine-tune] Epoch 21/50  Loss=2.0802\n",
      "[Fine-tune] Epoch 22/50  Loss=2.0491\n",
      "[Fine-tune] Epoch 23/50  Loss=2.0212\n",
      "[Fine-tune] Epoch 24/50  Loss=2.0150\n",
      "[Fine-tune] Epoch 25/50  Loss=1.9849\n",
      "[Fine-tune] Epoch 26/50  Loss=1.9851\n",
      "[Fine-tune] Epoch 27/50  Loss=1.9427\n",
      "[Fine-tune] Epoch 28/50  Loss=1.9295\n",
      "[Fine-tune] Epoch 29/50  Loss=1.9186\n",
      "[Fine-tune] Epoch 30/50  Loss=1.8924\n",
      "[Fine-tune] Epoch 31/50  Loss=1.8875\n",
      "[Fine-tune] Epoch 32/50  Loss=1.8628\n",
      "[Fine-tune] Epoch 33/50  Loss=1.8433\n",
      "[Fine-tune] Epoch 34/50  Loss=1.8370\n",
      "[Fine-tune] Epoch 35/50  Loss=1.8139\n",
      "[Fine-tune] Epoch 36/50  Loss=1.8094\n",
      "[Fine-tune] Epoch 37/50  Loss=1.7992\n",
      "[Fine-tune] Epoch 38/50  Loss=1.7699\n",
      "[Fine-tune] Epoch 39/50  Loss=1.7597\n",
      "[Fine-tune] Epoch 40/50  Loss=1.7504\n",
      "[Fine-tune] Epoch 41/50  Loss=1.7474\n",
      "[Fine-tune] Epoch 42/50  Loss=1.7315\n",
      "[Fine-tune] Epoch 43/50  Loss=1.7197\n",
      "[Fine-tune] Epoch 44/50  Loss=1.7152\n",
      "[Fine-tune] Epoch 45/50  Loss=1.6995\n",
      "[Fine-tune] Epoch 46/50  Loss=1.7032\n",
      "[Fine-tune] Epoch 47/50  Loss=1.6619\n",
      "[Fine-tune] Epoch 48/50  Loss=1.6769\n",
      "[Fine-tune] Epoch 49/50  Loss=1.6707\n",
      "[Fine-tune] Epoch 50/50  Loss=1.6590\n",
      "[Pretrain] Epoch 1/100  Loss=3.8404  Acc=0.0427\n",
      "[Pretrain] Epoch 2/100  Loss=3.0865  Acc=0.0751\n",
      "[Pretrain] Epoch 3/100  Loss=2.8373  Acc=0.1225\n",
      "[Pretrain] Epoch 4/100  Loss=2.6649  Acc=0.1532\n",
      "[Pretrain] Epoch 5/100  Loss=2.5388  Acc=0.1812\n",
      "[Pretrain] Epoch 6/100  Loss=2.4829  Acc=0.1974\n",
      "[Pretrain] Epoch 7/100  Loss=2.4330  Acc=0.2186\n",
      "[Pretrain] Epoch 8/100  Loss=2.3710  Acc=0.2387\n",
      "[Pretrain] Epoch 9/100  Loss=2.2858  Acc=0.2759\n",
      "[Pretrain] Epoch 10/100  Loss=2.2188  Acc=0.2847\n",
      "[Pretrain] Epoch 11/100  Loss=2.1648  Acc=0.2971\n",
      "[Pretrain] Epoch 12/100  Loss=2.1171  Acc=0.3132\n",
      "[Pretrain] Epoch 13/100  Loss=2.0844  Acc=0.3283\n",
      "[Pretrain] Epoch 14/100  Loss=2.0407  Acc=0.3382\n",
      "[Pretrain] Epoch 15/100  Loss=2.0374  Acc=0.3411\n",
      "[Pretrain] Epoch 16/100  Loss=1.9775  Acc=0.3599\n",
      "[Pretrain] Epoch 17/100  Loss=1.9714  Acc=0.3612\n",
      "[Pretrain] Epoch 18/100  Loss=1.9533  Acc=0.3608\n",
      "[Pretrain] Epoch 19/100  Loss=1.9130  Acc=0.3860\n",
      "[Pretrain] Epoch 20/100  Loss=1.8664  Acc=0.3960\n",
      "[Pretrain] Epoch 21/100  Loss=1.8546  Acc=0.4057\n",
      "[Pretrain] Epoch 22/100  Loss=1.8245  Acc=0.3948\n",
      "[Pretrain] Epoch 23/100  Loss=1.7925  Acc=0.4199\n",
      "[Pretrain] Epoch 24/100  Loss=1.7823  Acc=0.4213\n",
      "[Pretrain] Epoch 25/100  Loss=1.7596  Acc=0.4327\n",
      "[Pretrain] Epoch 26/100  Loss=1.7325  Acc=0.4395\n",
      "[Pretrain] Epoch 27/100  Loss=1.7155  Acc=0.4447\n",
      "[Pretrain] Epoch 28/100  Loss=1.6732  Acc=0.4576\n",
      "[Pretrain] Epoch 29/100  Loss=1.6562  Acc=0.4625\n",
      "[Pretrain] Epoch 30/100  Loss=1.6319  Acc=0.4700\n",
      "[Pretrain] Epoch 31/100  Loss=1.6081  Acc=0.4826\n",
      "[Pretrain] Epoch 32/100  Loss=1.5670  Acc=0.4874\n",
      "[Pretrain] Epoch 33/100  Loss=1.5490  Acc=0.4890\n",
      "[Pretrain] Epoch 34/100  Loss=1.5654  Acc=0.4802\n",
      "[Pretrain] Epoch 35/100  Loss=1.5394  Acc=0.4898\n",
      "[Pretrain] Epoch 36/100  Loss=1.5129  Acc=0.5040\n",
      "[Pretrain] Epoch 37/100  Loss=1.4862  Acc=0.5135\n",
      "[Pretrain] Epoch 38/100  Loss=1.4830  Acc=0.5169\n",
      "[Pretrain] Epoch 39/100  Loss=1.4337  Acc=0.5334\n",
      "[Pretrain] Epoch 40/100  Loss=1.4484  Acc=0.5341\n",
      "[Pretrain] Epoch 41/100  Loss=1.4004  Acc=0.5395\n",
      "[Pretrain] Epoch 42/100  Loss=1.3943  Acc=0.5481\n",
      "[Pretrain] Epoch 43/100  Loss=1.3735  Acc=0.5476\n",
      "[Pretrain] Epoch 44/100  Loss=1.3708  Acc=0.5532\n",
      "[Pretrain] Epoch 45/100  Loss=1.3532  Acc=0.5605\n",
      "[Pretrain] Epoch 46/100  Loss=1.3267  Acc=0.5690\n",
      "[Pretrain] Epoch 47/100  Loss=1.3591  Acc=0.5573\n",
      "[Pretrain] Epoch 48/100  Loss=1.3060  Acc=0.5769\n",
      "[Pretrain] Epoch 49/100  Loss=1.2955  Acc=0.5806\n",
      "[Pretrain] Epoch 50/100  Loss=1.2812  Acc=0.5765\n",
      "[Pretrain] Epoch 51/100  Loss=1.2633  Acc=0.5842\n",
      "[Pretrain] Epoch 52/100  Loss=1.2480  Acc=0.5867\n",
      "[Pretrain] Epoch 53/100  Loss=1.2389  Acc=0.5925\n",
      "[Pretrain] Epoch 54/100  Loss=1.2154  Acc=0.5991\n",
      "[Pretrain] Epoch 55/100  Loss=1.2322  Acc=0.5939\n",
      "[Pretrain] Epoch 56/100  Loss=1.2035  Acc=0.6063\n",
      "[Pretrain] Epoch 57/100  Loss=1.1978  Acc=0.6033\n",
      "[Pretrain] Epoch 58/100  Loss=1.2174  Acc=0.5946\n",
      "[Pretrain] Epoch 59/100  Loss=1.1999  Acc=0.6087\n",
      "[Pretrain] Epoch 60/100  Loss=1.1870  Acc=0.6072\n",
      "[Pretrain] Epoch 61/100  Loss=1.1901  Acc=0.6061\n",
      "[Pretrain] Epoch 62/100  Loss=1.1600  Acc=0.6175\n",
      "[Pretrain] Epoch 63/100  Loss=1.1593  Acc=0.6223\n",
      "[Pretrain] Epoch 64/100  Loss=1.1350  Acc=0.6266\n",
      "[Pretrain] Epoch 65/100  Loss=1.1323  Acc=0.6237\n",
      "[Pretrain] Epoch 66/100  Loss=1.1383  Acc=0.6306\n",
      "[Pretrain] Epoch 67/100  Loss=1.1277  Acc=0.6306\n",
      "[Pretrain] Epoch 68/100  Loss=1.1286  Acc=0.6293\n",
      "[Pretrain] Epoch 69/100  Loss=1.1273  Acc=0.6318\n",
      "[Pretrain] Epoch 70/100  Loss=1.1215  Acc=0.6316\n",
      "[Pretrain] Epoch 71/100  Loss=1.1254  Acc=0.6338\n",
      "[Pretrain] Epoch 72/100  Loss=1.1179  Acc=0.6322\n",
      "[Pretrain] Epoch 73/100  Loss=1.1064  Acc=0.6460\n",
      "[Pretrain] Epoch 74/100  Loss=1.1083  Acc=0.6315\n",
      "[Pretrain] Epoch 75/100  Loss=1.1087  Acc=0.6381\n",
      "[Pretrain] Epoch 76/100  Loss=1.0928  Acc=0.6352\n",
      "[Pretrain] Epoch 77/100  Loss=1.1058  Acc=0.6374\n",
      "[Pretrain] Epoch 78/100  Loss=1.1042  Acc=0.6309\n",
      "[Pretrain] Epoch 79/100  Loss=1.0947  Acc=0.6449\n",
      "[Pretrain] Epoch 80/100  Loss=1.0926  Acc=0.6406\n",
      "[Pretrain] Epoch 81/100  Loss=1.0866  Acc=0.6462\n",
      "[Pretrain] Epoch 82/100  Loss=1.0655  Acc=0.6500\n",
      "[Pretrain] Epoch 83/100  Loss=1.0702  Acc=0.6482\n",
      "[Pretrain] Epoch 84/100  Loss=1.0926  Acc=0.6347\n",
      "[Pretrain] Epoch 85/100  Loss=1.0734  Acc=0.6482\n",
      "[Pretrain] Epoch 86/100  Loss=1.0613  Acc=0.6489\n",
      "[Pretrain] Epoch 87/100  Loss=1.0799  Acc=0.6446\n",
      "[Pretrain] Epoch 88/100  Loss=1.0557  Acc=0.6494\n",
      "[Pretrain] Epoch 89/100  Loss=1.0633  Acc=0.6489\n",
      "[Pretrain] Epoch 90/100  Loss=1.0662  Acc=0.6483\n",
      "[Pretrain] Epoch 91/100  Loss=1.0713  Acc=0.6537\n",
      "[Pretrain] Epoch 92/100  Loss=1.0652  Acc=0.6437\n",
      "[Pretrain] Epoch 93/100  Loss=1.0678  Acc=0.6440\n",
      "[Pretrain] Epoch 94/100  Loss=1.0604  Acc=0.6521\n",
      "[Pretrain] Epoch 95/100  Loss=1.0533  Acc=0.6546\n",
      "[Pretrain] Epoch 96/100  Loss=1.0485  Acc=0.6622\n",
      "[Pretrain] Epoch 97/100  Loss=1.0555  Acc=0.6503\n",
      "[Pretrain] Epoch 98/100  Loss=1.0665  Acc=0.6480\n",
      "[Pretrain] Epoch 99/100  Loss=1.0547  Acc=0.6575\n",
      "[Pretrain] Epoch 100/100  Loss=1.0520  Acc=0.6559\n",
      "[Fine-tune] Epoch 1/50  Loss=2.8185\n",
      "[Fine-tune] Epoch 2/50  Loss=2.4117\n",
      "[Fine-tune] Epoch 3/50  Loss=2.2440\n",
      "[Fine-tune] Epoch 4/50  Loss=2.1554\n",
      "[Fine-tune] Epoch 5/50  Loss=2.0804\n",
      "[Fine-tune] Epoch 6/50  Loss=2.0126\n",
      "[Fine-tune] Epoch 7/50  Loss=1.9689\n",
      "[Fine-tune] Epoch 8/50  Loss=1.9436\n",
      "[Fine-tune] Epoch 9/50  Loss=1.8593\n",
      "[Fine-tune] Epoch 10/50  Loss=1.8388\n",
      "[Fine-tune] Epoch 11/50  Loss=1.8129\n",
      "[Fine-tune] Epoch 12/50  Loss=1.7664\n",
      "[Fine-tune] Epoch 13/50  Loss=1.7235\n",
      "[Fine-tune] Epoch 14/50  Loss=1.7105\n",
      "[Fine-tune] Epoch 15/50  Loss=1.6554\n",
      "[Fine-tune] Epoch 16/50  Loss=1.6358\n",
      "[Fine-tune] Epoch 17/50  Loss=1.6028\n",
      "[Fine-tune] Epoch 18/50  Loss=1.5531\n",
      "[Fine-tune] Epoch 19/50  Loss=1.5465\n",
      "[Fine-tune] Epoch 20/50  Loss=1.5133\n",
      "[Fine-tune] Epoch 21/50  Loss=1.4756\n",
      "[Fine-tune] Epoch 22/50  Loss=1.4738\n",
      "[Fine-tune] Epoch 23/50  Loss=1.4262\n",
      "[Fine-tune] Epoch 24/50  Loss=1.4100\n",
      "[Fine-tune] Epoch 25/50  Loss=1.3724\n",
      "[Fine-tune] Epoch 26/50  Loss=1.3703\n",
      "[Fine-tune] Epoch 27/50  Loss=1.3472\n",
      "[Fine-tune] Epoch 28/50  Loss=1.3171\n",
      "[Fine-tune] Epoch 29/50  Loss=1.2952\n",
      "[Fine-tune] Epoch 30/50  Loss=1.2915\n",
      "[Fine-tune] Epoch 31/50  Loss=1.2600\n",
      "[Fine-tune] Epoch 32/50  Loss=1.2536\n",
      "[Fine-tune] Epoch 33/50  Loss=1.2210\n",
      "[Fine-tune] Epoch 34/50  Loss=1.2168\n",
      "[Fine-tune] Epoch 35/50  Loss=1.2076\n",
      "[Fine-tune] Epoch 36/50  Loss=1.1924\n",
      "[Fine-tune] Epoch 37/50  Loss=1.1902\n",
      "[Fine-tune] Epoch 38/50  Loss=1.1705\n",
      "[Fine-tune] Epoch 39/50  Loss=1.1648\n",
      "[Fine-tune] Epoch 40/50  Loss=1.1529\n",
      "[Fine-tune] Epoch 41/50  Loss=1.1248\n",
      "[Fine-tune] Epoch 42/50  Loss=1.1361\n",
      "[Fine-tune] Epoch 43/50  Loss=1.1297\n",
      "[Fine-tune] Epoch 44/50  Loss=1.1032\n",
      "[Fine-tune] Epoch 45/50  Loss=1.1035\n",
      "[Fine-tune] Epoch 46/50  Loss=1.1022\n",
      "[Fine-tune] Epoch 47/50  Loss=1.1003\n",
      "[Fine-tune] Epoch 48/50  Loss=1.0751\n",
      "[Fine-tune] Epoch 49/50  Loss=1.0792\n",
      "[Fine-tune] Epoch 50/50  Loss=1.0660\n",
      "[Pretrain] Epoch 1/150  Loss=3.2546  Acc=0.0392\n",
      "[Pretrain] Epoch 2/150  Loss=3.1839  Acc=0.0476\n",
      "[Pretrain] Epoch 3/150  Loss=2.9083  Acc=0.1033\n",
      "[Pretrain] Epoch 4/150  Loss=2.6269  Acc=0.1712\n",
      "[Pretrain] Epoch 5/150  Loss=2.4467  Acc=0.2225\n",
      "[Pretrain] Epoch 6/150  Loss=2.3073  Acc=0.2586\n",
      "[Pretrain] Epoch 7/150  Loss=2.2277  Acc=0.2732\n",
      "[Pretrain] Epoch 8/150  Loss=2.1664  Acc=0.3057\n",
      "[Pretrain] Epoch 9/150  Loss=2.1279  Acc=0.3111\n",
      "[Pretrain] Epoch 10/150  Loss=2.1028  Acc=0.3168\n",
      "[Pretrain] Epoch 11/150  Loss=2.0626  Acc=0.3231\n",
      "[Pretrain] Epoch 12/150  Loss=2.0583  Acc=0.3297\n",
      "[Pretrain] Epoch 13/150  Loss=1.9877  Acc=0.3472\n",
      "[Pretrain] Epoch 14/150  Loss=1.9647  Acc=0.3633\n",
      "[Pretrain] Epoch 15/150  Loss=1.9432  Acc=0.3723\n",
      "[Pretrain] Epoch 16/150  Loss=1.9144  Acc=0.3696\n",
      "[Pretrain] Epoch 17/150  Loss=1.8908  Acc=0.3843\n",
      "[Pretrain] Epoch 18/150  Loss=1.8853  Acc=0.3885\n",
      "[Pretrain] Epoch 19/150  Loss=1.8451  Acc=0.3974\n",
      "[Pretrain] Epoch 20/150  Loss=1.8200  Acc=0.4018\n",
      "[Pretrain] Epoch 21/150  Loss=1.7959  Acc=0.4256\n",
      "[Pretrain] Epoch 22/150  Loss=1.7802  Acc=0.4301\n",
      "[Pretrain] Epoch 23/150  Loss=1.7460  Acc=0.4350\n",
      "[Pretrain] Epoch 24/150  Loss=1.7320  Acc=0.4328\n",
      "[Pretrain] Epoch 25/150  Loss=1.7161  Acc=0.4366\n",
      "[Pretrain] Epoch 26/150  Loss=1.6824  Acc=0.4540\n",
      "[Pretrain] Epoch 27/150  Loss=1.6644  Acc=0.4643\n",
      "[Pretrain] Epoch 28/150  Loss=1.6468  Acc=0.4637\n",
      "[Pretrain] Epoch 29/150  Loss=1.6365  Acc=0.4677\n",
      "[Pretrain] Epoch 30/150  Loss=1.6128  Acc=0.4756\n",
      "[Pretrain] Epoch 31/150  Loss=1.6037  Acc=0.4763\n",
      "[Pretrain] Epoch 32/150  Loss=1.5995  Acc=0.4797\n",
      "[Pretrain] Epoch 33/150  Loss=1.5831  Acc=0.4817\n",
      "[Pretrain] Epoch 34/150  Loss=1.5463  Acc=0.4984\n",
      "[Pretrain] Epoch 35/150  Loss=1.5507  Acc=0.4934\n",
      "[Pretrain] Epoch 36/150  Loss=1.5386  Acc=0.4921\n",
      "[Pretrain] Epoch 37/150  Loss=1.5178  Acc=0.5057\n",
      "[Pretrain] Epoch 38/150  Loss=1.5182  Acc=0.5052\n",
      "[Pretrain] Epoch 39/150  Loss=1.5070  Acc=0.5102\n",
      "[Pretrain] Epoch 40/150  Loss=1.4894  Acc=0.5097\n",
      "[Pretrain] Epoch 41/150  Loss=1.4686  Acc=0.5232\n",
      "[Pretrain] Epoch 42/150  Loss=1.4818  Acc=0.5131\n",
      "[Pretrain] Epoch 43/150  Loss=1.4753  Acc=0.5165\n",
      "[Pretrain] Epoch 44/150  Loss=1.4450  Acc=0.5257\n",
      "[Pretrain] Epoch 45/150  Loss=1.4488  Acc=0.5239\n",
      "[Pretrain] Epoch 46/150  Loss=1.4512  Acc=0.5314\n",
      "[Pretrain] Epoch 47/150  Loss=1.4297  Acc=0.5321\n",
      "[Pretrain] Epoch 48/150  Loss=1.4234  Acc=0.5357\n",
      "[Pretrain] Epoch 49/150  Loss=1.4119  Acc=0.5399\n",
      "[Pretrain] Epoch 50/150  Loss=1.4010  Acc=0.5476\n",
      "[Pretrain] Epoch 51/150  Loss=1.3962  Acc=0.5456\n",
      "[Pretrain] Epoch 52/150  Loss=1.4000  Acc=0.5454\n",
      "[Pretrain] Epoch 53/150  Loss=1.3837  Acc=0.5506\n",
      "[Pretrain] Epoch 54/150  Loss=1.3784  Acc=0.5456\n",
      "[Pretrain] Epoch 55/150  Loss=1.3767  Acc=0.5483\n",
      "[Pretrain] Epoch 56/150  Loss=1.3817  Acc=0.5462\n",
      "[Pretrain] Epoch 57/150  Loss=1.3838  Acc=0.5494\n",
      "[Pretrain] Epoch 58/150  Loss=1.3695  Acc=0.5515\n",
      "[Pretrain] Epoch 59/150  Loss=1.3706  Acc=0.5580\n",
      "[Pretrain] Epoch 60/150  Loss=1.3561  Acc=0.5562\n",
      "[Pretrain] Epoch 61/150  Loss=1.3353  Acc=0.5643\n",
      "[Pretrain] Epoch 62/150  Loss=1.3370  Acc=0.5724\n",
      "[Pretrain] Epoch 63/150  Loss=1.3433  Acc=0.5602\n",
      "[Pretrain] Epoch 64/150  Loss=1.3654  Acc=0.5533\n",
      "[Pretrain] Epoch 65/150  Loss=1.3299  Acc=0.5691\n",
      "[Pretrain] Epoch 66/150  Loss=1.3429  Acc=0.5562\n",
      "[Pretrain] Epoch 67/150  Loss=1.3253  Acc=0.5665\n",
      "[Pretrain] Epoch 68/150  Loss=1.3386  Acc=0.5605\n",
      "[Pretrain] Epoch 69/150  Loss=1.3394  Acc=0.5695\n",
      "[Pretrain] Epoch 70/150  Loss=1.3233  Acc=0.5684\n",
      "[Pretrain] Epoch 71/150  Loss=1.3242  Acc=0.5677\n",
      "[Pretrain] Epoch 72/150  Loss=1.3337  Acc=0.5571\n",
      "[Pretrain] Epoch 73/150  Loss=1.3100  Acc=0.5691\n",
      "[Pretrain] Epoch 74/150  Loss=1.3238  Acc=0.5659\n",
      "[Pretrain] Epoch 75/150  Loss=1.3142  Acc=0.5709\n",
      "[Pretrain] Epoch 76/150  Loss=1.3270  Acc=0.5736\n",
      "[Pretrain] Epoch 77/150  Loss=1.3098  Acc=0.5699\n",
      "[Pretrain] Epoch 78/150  Loss=1.3056  Acc=0.5769\n",
      "[Pretrain] Epoch 79/150  Loss=1.3004  Acc=0.5806\n",
      "[Pretrain] Epoch 80/150  Loss=1.3134  Acc=0.5747\n",
      "[Pretrain] Epoch 81/150  Loss=1.3018  Acc=0.5787\n",
      "[Pretrain] Epoch 82/150  Loss=1.2947  Acc=0.5824\n",
      "[Pretrain] Epoch 83/150  Loss=1.3194  Acc=0.5670\n",
      "[Pretrain] Epoch 84/150  Loss=1.3123  Acc=0.5665\n",
      "[Pretrain] Epoch 85/150  Loss=1.2954  Acc=0.5758\n",
      "[Pretrain] Epoch 86/150  Loss=1.2958  Acc=0.5806\n",
      "[Pretrain] Epoch 87/150  Loss=1.2841  Acc=0.5808\n",
      "[Pretrain] Epoch 88/150  Loss=1.2996  Acc=0.5749\n",
      "[Pretrain] Epoch 89/150  Loss=1.3064  Acc=0.5747\n",
      "[Pretrain] Epoch 90/150  Loss=1.2900  Acc=0.5785\n",
      "[Pretrain] Epoch 91/150  Loss=1.2856  Acc=0.5833\n",
      "[Pretrain] Epoch 92/150  Loss=1.2891  Acc=0.5774\n",
      "[Pretrain] Epoch 93/150  Loss=1.3001  Acc=0.5781\n",
      "[Pretrain] Epoch 94/150  Loss=1.3042  Acc=0.5810\n",
      "[Pretrain] Epoch 95/150  Loss=1.2968  Acc=0.5796\n",
      "[Pretrain] Epoch 96/150  Loss=1.2943  Acc=0.5742\n",
      "[Pretrain] Epoch 97/150  Loss=1.2863  Acc=0.5774\n",
      "[Pretrain] Epoch 98/150  Loss=1.2949  Acc=0.5756\n",
      "[Pretrain] Epoch 99/150  Loss=1.2793  Acc=0.5849\n",
      "[Pretrain] Epoch 100/150  Loss=1.2908  Acc=0.5812\n",
      "[Pretrain] Epoch 101/150  Loss=1.2713  Acc=0.5799\n",
      "[Pretrain] Epoch 102/150  Loss=1.2879  Acc=0.5769\n",
      "[Pretrain] Epoch 103/150  Loss=1.2910  Acc=0.5846\n",
      "[Pretrain] Epoch 104/150  Loss=1.2921  Acc=0.5776\n",
      "[Pretrain] Epoch 105/150  Loss=1.2924  Acc=0.5803\n",
      "[Pretrain] Epoch 106/150  Loss=1.2886  Acc=0.5853\n",
      "[Pretrain] Epoch 107/150  Loss=1.2877  Acc=0.5823\n",
      "[Pretrain] Epoch 108/150  Loss=1.2825  Acc=0.5812\n",
      "[Pretrain] Epoch 109/150  Loss=1.2961  Acc=0.5772\n",
      "[Pretrain] Epoch 110/150  Loss=1.2969  Acc=0.5835\n",
      "[Pretrain] Epoch 111/150  Loss=1.2799  Acc=0.5830\n",
      "[Pretrain] Epoch 112/150  Loss=1.2824  Acc=0.5783\n",
      "[Pretrain] Epoch 113/150  Loss=1.2880  Acc=0.5776\n",
      "[Pretrain] Epoch 114/150  Loss=1.2853  Acc=0.5787\n",
      "[Pretrain] Epoch 115/150  Loss=1.2918  Acc=0.5796\n",
      "[Pretrain] Epoch 116/150  Loss=1.2930  Acc=0.5792\n",
      "[Pretrain] Epoch 117/150  Loss=1.2937  Acc=0.5805\n",
      "[Pretrain] Epoch 118/150  Loss=1.2763  Acc=0.5878\n",
      "[Pretrain] Epoch 119/150  Loss=1.2758  Acc=0.5860\n",
      "[Pretrain] Epoch 120/150  Loss=1.2875  Acc=0.5787\n",
      "[Pretrain] Epoch 121/150  Loss=1.2876  Acc=0.5849\n",
      "[Pretrain] Epoch 122/150  Loss=1.2905  Acc=0.5747\n",
      "[Pretrain] Epoch 123/150  Loss=1.2717  Acc=0.5803\n",
      "[Pretrain] Epoch 124/150  Loss=1.2958  Acc=0.5738\n",
      "[Pretrain] Epoch 125/150  Loss=1.2790  Acc=0.5841\n",
      "[Pretrain] Epoch 126/150  Loss=1.2797  Acc=0.5835\n",
      "[Pretrain] Epoch 127/150  Loss=1.2770  Acc=0.5776\n",
      "[Pretrain] Epoch 128/150  Loss=1.2930  Acc=0.5778\n",
      "[Pretrain] Epoch 129/150  Loss=1.2977  Acc=0.5751\n",
      "[Pretrain] Epoch 130/150  Loss=1.2799  Acc=0.5785\n",
      "[Pretrain] Epoch 131/150  Loss=1.2883  Acc=0.5796\n",
      "[Pretrain] Epoch 132/150  Loss=1.2644  Acc=0.5921\n",
      "[Pretrain] Epoch 133/150  Loss=1.2833  Acc=0.5729\n",
      "[Pretrain] Epoch 134/150  Loss=1.2934  Acc=0.5842\n",
      "[Pretrain] Epoch 135/150  Loss=1.2741  Acc=0.5864\n",
      "[Pretrain] Epoch 136/150  Loss=1.2824  Acc=0.5815\n",
      "[Pretrain] Epoch 137/150  Loss=1.3004  Acc=0.5761\n",
      "[Pretrain] Epoch 138/150  Loss=1.2919  Acc=0.5794\n",
      "[Pretrain] Epoch 139/150  Loss=1.2796  Acc=0.5781\n",
      "[Pretrain] Epoch 140/150  Loss=1.2861  Acc=0.5684\n",
      "[Pretrain] Epoch 141/150  Loss=1.2838  Acc=0.5878\n",
      "[Pretrain] Epoch 142/150  Loss=1.2918  Acc=0.5812\n",
      "[Pretrain] Epoch 143/150  Loss=1.2987  Acc=0.5738\n",
      "[Pretrain] Epoch 144/150  Loss=1.2730  Acc=0.5866\n",
      "[Pretrain] Epoch 145/150  Loss=1.2832  Acc=0.5841\n",
      "[Pretrain] Epoch 146/150  Loss=1.2799  Acc=0.5885\n",
      "[Pretrain] Epoch 147/150  Loss=1.2870  Acc=0.5826\n",
      "[Pretrain] Epoch 148/150  Loss=1.2787  Acc=0.5799\n",
      "[Pretrain] Epoch 149/150  Loss=1.2841  Acc=0.5805\n",
      "[Pretrain] Epoch 150/150  Loss=1.2894  Acc=0.5815\n",
      "[Fine-tune] Epoch 1/50  Loss=3.2187\n",
      "[Fine-tune] Epoch 2/50  Loss=3.0823\n",
      "[Fine-tune] Epoch 3/50  Loss=3.0372\n",
      "[Fine-tune] Epoch 4/50  Loss=2.9674\n",
      "[Fine-tune] Epoch 5/50  Loss=2.7401\n",
      "[Fine-tune] Epoch 6/50  Loss=2.5213\n",
      "[Fine-tune] Epoch 7/50  Loss=2.3890\n",
      "[Fine-tune] Epoch 8/50  Loss=2.3072\n",
      "[Fine-tune] Epoch 9/50  Loss=2.2804\n",
      "[Fine-tune] Epoch 10/50  Loss=2.2031\n",
      "[Fine-tune] Epoch 11/50  Loss=2.1901\n",
      "[Fine-tune] Epoch 12/50  Loss=2.1298\n",
      "[Fine-tune] Epoch 13/50  Loss=2.1278\n",
      "[Fine-tune] Epoch 14/50  Loss=2.0779\n",
      "[Fine-tune] Epoch 15/50  Loss=2.0324\n",
      "[Fine-tune] Epoch 16/50  Loss=2.0173\n",
      "[Fine-tune] Epoch 17/50  Loss=1.9760\n",
      "[Fine-tune] Epoch 18/50  Loss=1.9580\n",
      "[Fine-tune] Epoch 19/50  Loss=1.9394\n",
      "[Fine-tune] Epoch 20/50  Loss=1.8912\n",
      "[Fine-tune] Epoch 21/50  Loss=1.8899\n",
      "[Fine-tune] Epoch 22/50  Loss=1.8559\n",
      "[Fine-tune] Epoch 23/50  Loss=1.8269\n",
      "[Fine-tune] Epoch 24/50  Loss=1.8107\n",
      "[Fine-tune] Epoch 25/50  Loss=1.7901\n",
      "[Fine-tune] Epoch 26/50  Loss=1.7535\n",
      "[Fine-tune] Epoch 27/50  Loss=1.7500\n",
      "[Fine-tune] Epoch 28/50  Loss=1.7353\n",
      "[Fine-tune] Epoch 29/50  Loss=1.6996\n",
      "[Fine-tune] Epoch 30/50  Loss=1.7061\n",
      "[Fine-tune] Epoch 31/50  Loss=1.6738\n",
      "[Fine-tune] Epoch 32/50  Loss=1.6739\n",
      "[Fine-tune] Epoch 33/50  Loss=1.6583\n",
      "[Fine-tune] Epoch 34/50  Loss=1.6309\n",
      "[Fine-tune] Epoch 35/50  Loss=1.6226\n",
      "[Fine-tune] Epoch 36/50  Loss=1.6196\n",
      "[Fine-tune] Epoch 37/50  Loss=1.6012\n",
      "[Fine-tune] Epoch 38/50  Loss=1.6012\n",
      "[Fine-tune] Epoch 39/50  Loss=1.5685\n",
      "[Fine-tune] Epoch 40/50  Loss=1.5700\n",
      "[Fine-tune] Epoch 41/50  Loss=1.5530\n",
      "[Fine-tune] Epoch 42/50  Loss=1.5469\n",
      "[Fine-tune] Epoch 43/50  Loss=1.5264\n",
      "[Fine-tune] Epoch 44/50  Loss=1.5258\n",
      "[Fine-tune] Epoch 45/50  Loss=1.5268\n",
      "[Fine-tune] Epoch 46/50  Loss=1.5139\n",
      "[Fine-tune] Epoch 47/50  Loss=1.5251\n",
      "[Fine-tune] Epoch 48/50  Loss=1.5002\n",
      "[Fine-tune] Epoch 49/50  Loss=1.4989\n",
      "[Fine-tune] Epoch 50/50  Loss=1.4851\n",
      "[Pretrain] Epoch 1/150  Loss=3.6763  Acc=0.0404\n",
      "[Pretrain] Epoch 2/150  Loss=3.2251  Acc=0.0408\n",
      "[Pretrain] Epoch 3/150  Loss=2.9709  Acc=0.0835\n",
      "[Pretrain] Epoch 4/150  Loss=2.7828  Acc=0.1196\n",
      "[Pretrain] Epoch 5/150  Loss=2.6262  Acc=0.1701\n",
      "[Pretrain] Epoch 6/150  Loss=2.5510  Acc=0.1818\n",
      "[Pretrain] Epoch 7/150  Loss=2.4553  Acc=0.2058\n",
      "[Pretrain] Epoch 8/150  Loss=2.4093  Acc=0.2231\n",
      "[Pretrain] Epoch 9/150  Loss=2.3568  Acc=0.2351\n",
      "[Pretrain] Epoch 10/150  Loss=2.3053  Acc=0.2559\n",
      "[Pretrain] Epoch 11/150  Loss=2.2975  Acc=0.2590\n",
      "[Pretrain] Epoch 12/150  Loss=2.2072  Acc=0.2726\n",
      "[Pretrain] Epoch 13/150  Loss=2.2086  Acc=0.2746\n",
      "[Pretrain] Epoch 14/150  Loss=2.1347  Acc=0.2989\n",
      "[Pretrain] Epoch 15/150  Loss=2.1485  Acc=0.2965\n",
      "[Pretrain] Epoch 16/150  Loss=2.1069  Acc=0.3107\n",
      "[Pretrain] Epoch 17/150  Loss=2.0644  Acc=0.3253\n",
      "[Pretrain] Epoch 18/150  Loss=2.0264  Acc=0.3394\n",
      "[Pretrain] Epoch 19/150  Loss=1.9928  Acc=0.3429\n",
      "[Pretrain] Epoch 20/150  Loss=1.9925  Acc=0.3472\n",
      "[Pretrain] Epoch 21/150  Loss=1.9433  Acc=0.3669\n",
      "[Pretrain] Epoch 22/150  Loss=1.9301  Acc=0.3660\n",
      "[Pretrain] Epoch 23/150  Loss=1.8867  Acc=0.3924\n",
      "[Pretrain] Epoch 24/150  Loss=1.8545  Acc=0.3946\n",
      "[Pretrain] Epoch 25/150  Loss=1.8624  Acc=0.3912\n",
      "[Pretrain] Epoch 26/150  Loss=1.8233  Acc=0.4039\n",
      "[Pretrain] Epoch 27/150  Loss=1.8021  Acc=0.4080\n",
      "[Pretrain] Epoch 28/150  Loss=1.7779  Acc=0.4197\n",
      "[Pretrain] Epoch 29/150  Loss=1.7455  Acc=0.4226\n",
      "[Pretrain] Epoch 30/150  Loss=1.7208  Acc=0.4341\n",
      "[Pretrain] Epoch 31/150  Loss=1.7009  Acc=0.4445\n",
      "[Pretrain] Epoch 32/150  Loss=1.6879  Acc=0.4463\n",
      "[Pretrain] Epoch 33/150  Loss=1.6615  Acc=0.4531\n",
      "[Pretrain] Epoch 34/150  Loss=1.6390  Acc=0.4585\n",
      "[Pretrain] Epoch 35/150  Loss=1.6087  Acc=0.4707\n",
      "[Pretrain] Epoch 36/150  Loss=1.5987  Acc=0.4793\n",
      "[Pretrain] Epoch 37/150  Loss=1.6006  Acc=0.4776\n",
      "[Pretrain] Epoch 38/150  Loss=1.5713  Acc=0.4876\n",
      "[Pretrain] Epoch 39/150  Loss=1.5260  Acc=0.4964\n",
      "[Pretrain] Epoch 40/150  Loss=1.5177  Acc=0.5072\n",
      "[Pretrain] Epoch 41/150  Loss=1.5114  Acc=0.5043\n",
      "[Pretrain] Epoch 42/150  Loss=1.4785  Acc=0.5207\n",
      "[Pretrain] Epoch 43/150  Loss=1.4580  Acc=0.5203\n",
      "[Pretrain] Epoch 44/150  Loss=1.4477  Acc=0.5203\n",
      "[Pretrain] Epoch 45/150  Loss=1.4358  Acc=0.5338\n",
      "[Pretrain] Epoch 46/150  Loss=1.4234  Acc=0.5361\n",
      "[Pretrain] Epoch 47/150  Loss=1.4155  Acc=0.5366\n",
      "[Pretrain] Epoch 48/150  Loss=1.3879  Acc=0.5490\n",
      "[Pretrain] Epoch 49/150  Loss=1.3994  Acc=0.5334\n",
      "[Pretrain] Epoch 50/150  Loss=1.3761  Acc=0.5517\n",
      "[Pretrain] Epoch 51/150  Loss=1.3405  Acc=0.5607\n",
      "[Pretrain] Epoch 52/150  Loss=1.3345  Acc=0.5638\n",
      "[Pretrain] Epoch 53/150  Loss=1.3299  Acc=0.5668\n",
      "[Pretrain] Epoch 54/150  Loss=1.3142  Acc=0.5690\n",
      "[Pretrain] Epoch 55/150  Loss=1.2974  Acc=0.5745\n",
      "[Pretrain] Epoch 56/150  Loss=1.3126  Acc=0.5747\n",
      "[Pretrain] Epoch 57/150  Loss=1.2755  Acc=0.5778\n",
      "[Pretrain] Epoch 58/150  Loss=1.2824  Acc=0.5830\n",
      "[Pretrain] Epoch 59/150  Loss=1.2784  Acc=0.5828\n",
      "[Pretrain] Epoch 60/150  Loss=1.2565  Acc=0.5821\n",
      "[Pretrain] Epoch 61/150  Loss=1.2578  Acc=0.5833\n",
      "[Pretrain] Epoch 62/150  Loss=1.2638  Acc=0.5815\n",
      "[Pretrain] Epoch 63/150  Loss=1.2374  Acc=0.5923\n",
      "[Pretrain] Epoch 64/150  Loss=1.2344  Acc=0.5936\n",
      "[Pretrain] Epoch 65/150  Loss=1.2193  Acc=0.5991\n",
      "[Pretrain] Epoch 66/150  Loss=1.2097  Acc=0.6047\n",
      "[Pretrain] Epoch 67/150  Loss=1.2143  Acc=0.5963\n",
      "[Pretrain] Epoch 68/150  Loss=1.2101  Acc=0.6085\n",
      "[Pretrain] Epoch 69/150  Loss=1.2042  Acc=0.6085\n",
      "[Pretrain] Epoch 70/150  Loss=1.2206  Acc=0.6020\n",
      "[Pretrain] Epoch 71/150  Loss=1.1931  Acc=0.6049\n",
      "[Pretrain] Epoch 72/150  Loss=1.1938  Acc=0.6097\n",
      "[Pretrain] Epoch 73/150  Loss=1.1844  Acc=0.6106\n",
      "[Pretrain] Epoch 74/150  Loss=1.1730  Acc=0.6146\n",
      "[Pretrain] Epoch 75/150  Loss=1.2005  Acc=0.6051\n",
      "[Pretrain] Epoch 76/150  Loss=1.1776  Acc=0.6151\n",
      "[Pretrain] Epoch 77/150  Loss=1.1858  Acc=0.6133\n",
      "[Pretrain] Epoch 78/150  Loss=1.1688  Acc=0.6124\n",
      "[Pretrain] Epoch 79/150  Loss=1.1755  Acc=0.6074\n",
      "[Pretrain] Epoch 80/150  Loss=1.1665  Acc=0.6219\n",
      "[Pretrain] Epoch 81/150  Loss=1.1698  Acc=0.6167\n",
      "[Pretrain] Epoch 82/150  Loss=1.1419  Acc=0.6316\n",
      "[Pretrain] Epoch 83/150  Loss=1.1630  Acc=0.6223\n",
      "[Pretrain] Epoch 84/150  Loss=1.1591  Acc=0.6228\n",
      "[Pretrain] Epoch 85/150  Loss=1.1543  Acc=0.6169\n",
      "[Pretrain] Epoch 86/150  Loss=1.1385  Acc=0.6263\n",
      "[Pretrain] Epoch 87/150  Loss=1.1470  Acc=0.6176\n",
      "[Pretrain] Epoch 88/150  Loss=1.1352  Acc=0.6259\n",
      "[Pretrain] Epoch 89/150  Loss=1.1468  Acc=0.6246\n",
      "[Pretrain] Epoch 90/150  Loss=1.1571  Acc=0.6194\n",
      "[Pretrain] Epoch 91/150  Loss=1.1483  Acc=0.6234\n",
      "[Pretrain] Epoch 92/150  Loss=1.1354  Acc=0.6331\n",
      "[Pretrain] Epoch 93/150  Loss=1.1433  Acc=0.6187\n",
      "[Pretrain] Epoch 94/150  Loss=1.1385  Acc=0.6261\n",
      "[Pretrain] Epoch 95/150  Loss=1.1385  Acc=0.6304\n",
      "[Pretrain] Epoch 96/150  Loss=1.1396  Acc=0.6241\n",
      "[Pretrain] Epoch 97/150  Loss=1.1223  Acc=0.6270\n",
      "[Pretrain] Epoch 98/150  Loss=1.1237  Acc=0.6334\n",
      "[Pretrain] Epoch 99/150  Loss=1.1137  Acc=0.6363\n",
      "[Pretrain] Epoch 100/150  Loss=1.1327  Acc=0.6277\n",
      "[Pretrain] Epoch 101/150  Loss=1.1379  Acc=0.6320\n",
      "[Pretrain] Epoch 102/150  Loss=1.1117  Acc=0.6334\n",
      "[Pretrain] Epoch 103/150  Loss=1.1288  Acc=0.6306\n",
      "[Pretrain] Epoch 104/150  Loss=1.1211  Acc=0.6273\n",
      "[Pretrain] Epoch 105/150  Loss=1.1093  Acc=0.6376\n",
      "[Pretrain] Epoch 106/150  Loss=1.1313  Acc=0.6336\n",
      "[Pretrain] Epoch 107/150  Loss=1.1276  Acc=0.6327\n",
      "[Pretrain] Epoch 108/150  Loss=1.1288  Acc=0.6311\n",
      "[Pretrain] Epoch 109/150  Loss=1.1385  Acc=0.6234\n",
      "[Pretrain] Epoch 110/150  Loss=1.1328  Acc=0.6187\n",
      "[Pretrain] Epoch 111/150  Loss=1.1249  Acc=0.6325\n",
      "[Pretrain] Epoch 112/150  Loss=1.1178  Acc=0.6386\n",
      "[Pretrain] Epoch 113/150  Loss=1.1174  Acc=0.6345\n",
      "[Pretrain] Epoch 114/150  Loss=1.1178  Acc=0.6293\n",
      "[Pretrain] Epoch 115/150  Loss=1.1255  Acc=0.6257\n",
      "[Pretrain] Epoch 116/150  Loss=1.1034  Acc=0.6399\n",
      "[Pretrain] Epoch 117/150  Loss=1.1207  Acc=0.6329\n",
      "[Pretrain] Epoch 118/150  Loss=1.1110  Acc=0.6358\n",
      "[Pretrain] Epoch 119/150  Loss=1.1115  Acc=0.6311\n",
      "[Pretrain] Epoch 120/150  Loss=1.1055  Acc=0.6410\n",
      "[Pretrain] Epoch 121/150  Loss=1.1090  Acc=0.6320\n",
      "[Pretrain] Epoch 122/150  Loss=1.1237  Acc=0.6343\n",
      "[Pretrain] Epoch 123/150  Loss=1.1066  Acc=0.6406\n",
      "[Pretrain] Epoch 124/150  Loss=1.1181  Acc=0.6336\n",
      "[Pretrain] Epoch 125/150  Loss=1.0897  Acc=0.6395\n",
      "[Pretrain] Epoch 126/150  Loss=1.1099  Acc=0.6333\n",
      "[Pretrain] Epoch 127/150  Loss=1.1186  Acc=0.6309\n",
      "[Pretrain] Epoch 128/150  Loss=1.1042  Acc=0.6309\n",
      "[Pretrain] Epoch 129/150  Loss=1.1285  Acc=0.6268\n",
      "[Pretrain] Epoch 130/150  Loss=1.1050  Acc=0.6356\n",
      "[Pretrain] Epoch 131/150  Loss=1.1099  Acc=0.6379\n",
      "[Pretrain] Epoch 132/150  Loss=1.1078  Acc=0.6345\n",
      "[Pretrain] Epoch 133/150  Loss=1.1205  Acc=0.6349\n",
      "[Pretrain] Epoch 134/150  Loss=1.1004  Acc=0.6390\n",
      "[Pretrain] Epoch 135/150  Loss=1.1113  Acc=0.6370\n",
      "[Pretrain] Epoch 136/150  Loss=1.1201  Acc=0.6324\n",
      "[Pretrain] Epoch 137/150  Loss=1.0939  Acc=0.6451\n",
      "[Pretrain] Epoch 138/150  Loss=1.1039  Acc=0.6417\n",
      "[Pretrain] Epoch 139/150  Loss=1.1011  Acc=0.6365\n",
      "[Pretrain] Epoch 140/150  Loss=1.1068  Acc=0.6356\n",
      "[Pretrain] Epoch 141/150  Loss=1.1141  Acc=0.6311\n",
      "[Pretrain] Epoch 142/150  Loss=1.1001  Acc=0.6261\n",
      "[Pretrain] Epoch 143/150  Loss=1.1151  Acc=0.6412\n",
      "[Pretrain] Epoch 144/150  Loss=1.1119  Acc=0.6279\n",
      "[Pretrain] Epoch 145/150  Loss=1.1208  Acc=0.6286\n",
      "[Pretrain] Epoch 146/150  Loss=1.1309  Acc=0.6304\n",
      "[Pretrain] Epoch 147/150  Loss=1.1005  Acc=0.6345\n",
      "[Pretrain] Epoch 148/150  Loss=1.1248  Acc=0.6342\n",
      "[Pretrain] Epoch 149/150  Loss=1.0905  Acc=0.6417\n",
      "[Pretrain] Epoch 150/150  Loss=1.1281  Acc=0.6273\n",
      "[Fine-tune] Epoch 1/50  Loss=3.1206\n",
      "[Fine-tune] Epoch 2/50  Loss=2.6253\n",
      "[Fine-tune] Epoch 3/50  Loss=2.3690\n",
      "[Fine-tune] Epoch 4/50  Loss=2.2444\n",
      "[Fine-tune] Epoch 5/50  Loss=2.1676\n",
      "[Fine-tune] Epoch 6/50  Loss=2.1156\n",
      "[Fine-tune] Epoch 7/50  Loss=2.0317\n",
      "[Fine-tune] Epoch 8/50  Loss=2.0018\n",
      "[Fine-tune] Epoch 9/50  Loss=1.9260\n",
      "[Fine-tune] Epoch 10/50  Loss=1.9250\n",
      "[Fine-tune] Epoch 11/50  Loss=1.8900\n",
      "[Fine-tune] Epoch 12/50  Loss=1.8222\n",
      "[Fine-tune] Epoch 13/50  Loss=1.8180\n",
      "[Fine-tune] Epoch 14/50  Loss=1.7733\n",
      "[Fine-tune] Epoch 15/50  Loss=1.7378\n",
      "[Fine-tune] Epoch 16/50  Loss=1.6932\n",
      "[Fine-tune] Epoch 17/50  Loss=1.6774\n",
      "[Fine-tune] Epoch 18/50  Loss=1.6397\n",
      "[Fine-tune] Epoch 19/50  Loss=1.6245\n",
      "[Fine-tune] Epoch 20/50  Loss=1.6139\n",
      "[Fine-tune] Epoch 21/50  Loss=1.5773\n",
      "[Fine-tune] Epoch 22/50  Loss=1.5443\n",
      "[Fine-tune] Epoch 23/50  Loss=1.5179\n",
      "[Fine-tune] Epoch 24/50  Loss=1.4957\n",
      "[Fine-tune] Epoch 25/50  Loss=1.4779\n",
      "[Fine-tune] Epoch 26/50  Loss=1.4480\n",
      "[Fine-tune] Epoch 27/50  Loss=1.4321\n",
      "[Fine-tune] Epoch 28/50  Loss=1.4157\n",
      "[Fine-tune] Epoch 29/50  Loss=1.4003\n",
      "[Fine-tune] Epoch 30/50  Loss=1.3800\n",
      "[Fine-tune] Epoch 31/50  Loss=1.3667\n",
      "[Fine-tune] Epoch 32/50  Loss=1.3432\n",
      "[Fine-tune] Epoch 33/50  Loss=1.3421\n",
      "[Fine-tune] Epoch 34/50  Loss=1.3253\n",
      "[Fine-tune] Epoch 35/50  Loss=1.3187\n",
      "[Fine-tune] Epoch 36/50  Loss=1.2810\n",
      "[Fine-tune] Epoch 37/50  Loss=1.2832\n",
      "[Fine-tune] Epoch 38/50  Loss=1.2705\n",
      "[Fine-tune] Epoch 39/50  Loss=1.2497\n",
      "[Fine-tune] Epoch 40/50  Loss=1.2405\n",
      "[Fine-tune] Epoch 41/50  Loss=1.2339\n",
      "[Fine-tune] Epoch 42/50  Loss=1.2313\n",
      "[Fine-tune] Epoch 43/50  Loss=1.2320\n",
      "[Fine-tune] Epoch 44/50  Loss=1.2121\n",
      "[Fine-tune] Epoch 45/50  Loss=1.2152\n",
      "[Fine-tune] Epoch 46/50  Loss=1.2026\n",
      "[Fine-tune] Epoch 47/50  Loss=1.1928\n",
      "[Fine-tune] Epoch 48/50  Loss=1.1827\n",
      "[Fine-tune] Epoch 49/50  Loss=1.1761\n",
      "[Fine-tune] Epoch 50/50  Loss=1.1674\n",
      "[Pretrain] Epoch 1/50  Loss=3.2342  Acc=0.0417\n",
      "[Pretrain] Epoch 2/50  Loss=2.8620  Acc=0.1117\n",
      "[Pretrain] Epoch 3/50  Loss=2.6065  Acc=0.1760\n",
      "[Pretrain] Epoch 4/50  Loss=2.5151  Acc=0.1906\n",
      "[Pretrain] Epoch 5/50  Loss=2.4439  Acc=0.2175\n",
      "[Pretrain] Epoch 6/50  Loss=2.3121  Acc=0.2489\n",
      "[Pretrain] Epoch 7/50  Loss=2.2257  Acc=0.2782\n",
      "[Pretrain] Epoch 8/50  Loss=2.1852  Acc=0.2888\n",
      "[Pretrain] Epoch 9/50  Loss=2.1154  Acc=0.3163\n",
      "[Pretrain] Epoch 10/50  Loss=2.0461  Acc=0.3398\n",
      "[Pretrain] Epoch 11/50  Loss=2.0260  Acc=0.3385\n",
      "[Pretrain] Epoch 12/50  Loss=2.0098  Acc=0.3393\n",
      "[Pretrain] Epoch 13/50  Loss=1.9698  Acc=0.3615\n",
      "[Pretrain] Epoch 14/50  Loss=1.9287  Acc=0.3773\n",
      "[Pretrain] Epoch 15/50  Loss=1.8827  Acc=0.3904\n",
      "[Pretrain] Epoch 16/50  Loss=1.8825  Acc=0.3924\n",
      "[Pretrain] Epoch 17/50  Loss=1.8918  Acc=0.3809\n",
      "[Pretrain] Epoch 18/50  Loss=1.8318  Acc=0.4095\n",
      "[Pretrain] Epoch 19/50  Loss=1.8156  Acc=0.4142\n",
      "[Pretrain] Epoch 20/50  Loss=1.7739  Acc=0.4280\n",
      "[Pretrain] Epoch 21/50  Loss=1.7538  Acc=0.4321\n",
      "[Pretrain] Epoch 22/50  Loss=1.7478  Acc=0.4402\n",
      "[Pretrain] Epoch 23/50  Loss=1.7228  Acc=0.4441\n",
      "[Pretrain] Epoch 24/50  Loss=1.6971  Acc=0.4495\n",
      "[Pretrain] Epoch 25/50  Loss=1.6726  Acc=0.4634\n",
      "[Pretrain] Epoch 26/50  Loss=1.6343  Acc=0.4616\n",
      "[Pretrain] Epoch 27/50  Loss=1.6226  Acc=0.4652\n",
      "[Pretrain] Epoch 28/50  Loss=1.5953  Acc=0.4788\n",
      "[Pretrain] Epoch 29/50  Loss=1.5991  Acc=0.4788\n",
      "[Pretrain] Epoch 30/50  Loss=1.5729  Acc=0.4851\n",
      "[Pretrain] Epoch 31/50  Loss=1.5524  Acc=0.4971\n",
      "[Pretrain] Epoch 32/50  Loss=1.5395  Acc=0.5047\n",
      "[Pretrain] Epoch 33/50  Loss=1.5158  Acc=0.5088\n",
      "[Pretrain] Epoch 34/50  Loss=1.5152  Acc=0.5129\n",
      "[Pretrain] Epoch 35/50  Loss=1.5006  Acc=0.5136\n",
      "[Pretrain] Epoch 36/50  Loss=1.4702  Acc=0.5138\n",
      "[Pretrain] Epoch 37/50  Loss=1.4675  Acc=0.5278\n",
      "[Pretrain] Epoch 38/50  Loss=1.4592  Acc=0.5199\n",
      "[Pretrain] Epoch 39/50  Loss=1.4493  Acc=0.5293\n",
      "[Pretrain] Epoch 40/50  Loss=1.4327  Acc=0.5327\n",
      "[Pretrain] Epoch 41/50  Loss=1.4407  Acc=0.5341\n",
      "[Pretrain] Epoch 42/50  Loss=1.4147  Acc=0.5417\n",
      "[Pretrain] Epoch 43/50  Loss=1.4136  Acc=0.5397\n",
      "[Pretrain] Epoch 44/50  Loss=1.4006  Acc=0.5422\n",
      "[Pretrain] Epoch 45/50  Loss=1.4035  Acc=0.5411\n",
      "[Pretrain] Epoch 46/50  Loss=1.3774  Acc=0.5501\n",
      "[Pretrain] Epoch 47/50  Loss=1.3759  Acc=0.5530\n",
      "[Pretrain] Epoch 48/50  Loss=1.3751  Acc=0.5496\n",
      "[Pretrain] Epoch 49/50  Loss=1.3717  Acc=0.5584\n",
      "[Pretrain] Epoch 50/50  Loss=1.3676  Acc=0.5550\n",
      "[Fine-tune] Epoch 1/75  Loss=2.7375\n",
      "[Fine-tune] Epoch 2/75  Loss=2.2813\n",
      "[Fine-tune] Epoch 3/75  Loss=2.1158\n",
      "[Fine-tune] Epoch 4/75  Loss=2.0427\n",
      "[Fine-tune] Epoch 5/75  Loss=1.9207\n",
      "[Fine-tune] Epoch 6/75  Loss=1.8629\n",
      "[Fine-tune] Epoch 7/75  Loss=1.8255\n",
      "[Fine-tune] Epoch 8/75  Loss=1.7716\n",
      "[Fine-tune] Epoch 9/75  Loss=1.7357\n",
      "[Fine-tune] Epoch 10/75  Loss=1.6850\n",
      "[Fine-tune] Epoch 11/75  Loss=1.6568\n",
      "[Fine-tune] Epoch 12/75  Loss=1.6335\n",
      "[Fine-tune] Epoch 13/75  Loss=1.5964\n",
      "[Fine-tune] Epoch 14/75  Loss=1.5495\n",
      "[Fine-tune] Epoch 15/75  Loss=1.5206\n",
      "[Fine-tune] Epoch 16/75  Loss=1.5010\n",
      "[Fine-tune] Epoch 17/75  Loss=1.4783\n",
      "[Fine-tune] Epoch 18/75  Loss=1.4333\n",
      "[Fine-tune] Epoch 19/75  Loss=1.4238\n",
      "[Fine-tune] Epoch 20/75  Loss=1.4032\n",
      "[Fine-tune] Epoch 21/75  Loss=1.3776\n",
      "[Fine-tune] Epoch 22/75  Loss=1.3430\n",
      "[Fine-tune] Epoch 23/75  Loss=1.3315\n",
      "[Fine-tune] Epoch 24/75  Loss=1.3025\n",
      "[Fine-tune] Epoch 25/75  Loss=1.2971\n",
      "[Fine-tune] Epoch 26/75  Loss=1.2605\n",
      "[Fine-tune] Epoch 27/75  Loss=1.2528\n",
      "[Fine-tune] Epoch 28/75  Loss=1.2466\n",
      "[Fine-tune] Epoch 29/75  Loss=1.2337\n",
      "[Fine-tune] Epoch 30/75  Loss=1.1955\n",
      "[Fine-tune] Epoch 31/75  Loss=1.1798\n",
      "[Fine-tune] Epoch 32/75  Loss=1.1733\n",
      "[Fine-tune] Epoch 33/75  Loss=1.1609\n",
      "[Fine-tune] Epoch 34/75  Loss=1.1642\n",
      "[Fine-tune] Epoch 35/75  Loss=1.1404\n",
      "[Fine-tune] Epoch 36/75  Loss=1.1342\n",
      "[Fine-tune] Epoch 37/75  Loss=1.1274\n",
      "[Fine-tune] Epoch 38/75  Loss=1.1079\n",
      "[Fine-tune] Epoch 39/75  Loss=1.1033\n",
      "[Fine-tune] Epoch 40/75  Loss=1.0916\n",
      "[Fine-tune] Epoch 41/75  Loss=1.0979\n",
      "[Fine-tune] Epoch 42/75  Loss=1.0709\n",
      "[Fine-tune] Epoch 43/75  Loss=1.0626\n",
      "[Fine-tune] Epoch 44/75  Loss=1.0565\n",
      "[Fine-tune] Epoch 45/75  Loss=1.0566\n",
      "[Fine-tune] Epoch 46/75  Loss=1.0445\n",
      "[Fine-tune] Epoch 47/75  Loss=1.0327\n",
      "[Fine-tune] Epoch 48/75  Loss=1.0372\n",
      "[Fine-tune] Epoch 49/75  Loss=1.0335\n",
      "[Fine-tune] Epoch 50/75  Loss=1.0191\n",
      "[Fine-tune] Epoch 51/75  Loss=1.0262\n",
      "[Fine-tune] Epoch 52/75  Loss=1.0005\n",
      "[Fine-tune] Epoch 53/75  Loss=1.0151\n",
      "[Fine-tune] Epoch 54/75  Loss=0.9973\n",
      "[Fine-tune] Epoch 55/75  Loss=0.9845\n",
      "[Fine-tune] Epoch 56/75  Loss=0.9995\n",
      "[Fine-tune] Epoch 57/75  Loss=1.0019\n",
      "[Fine-tune] Epoch 58/75  Loss=0.9974\n",
      "[Fine-tune] Epoch 59/75  Loss=0.9854\n",
      "[Fine-tune] Epoch 60/75  Loss=0.9882\n",
      "[Fine-tune] Epoch 61/75  Loss=0.9738\n",
      "[Fine-tune] Epoch 62/75  Loss=0.9865\n",
      "[Fine-tune] Epoch 63/75  Loss=0.9814\n",
      "[Fine-tune] Epoch 64/75  Loss=0.9735\n",
      "[Fine-tune] Epoch 65/75  Loss=0.9808\n",
      "[Fine-tune] Epoch 66/75  Loss=0.9637\n",
      "[Fine-tune] Epoch 67/75  Loss=0.9661\n",
      "[Fine-tune] Epoch 68/75  Loss=0.9573\n",
      "[Fine-tune] Epoch 69/75  Loss=0.9729\n",
      "[Fine-tune] Epoch 70/75  Loss=0.9547\n",
      "[Fine-tune] Epoch 71/75  Loss=0.9490\n",
      "[Fine-tune] Epoch 72/75  Loss=0.9484\n",
      "[Fine-tune] Epoch 73/75  Loss=0.9523\n",
      "[Fine-tune] Epoch 74/75  Loss=0.9610\n",
      "[Fine-tune] Epoch 75/75  Loss=0.9511\n",
      "[Pretrain] Epoch 1/50  Loss=3.7438  Acc=0.0381\n",
      "[Pretrain] Epoch 2/50  Loss=3.1760  Acc=0.0544\n",
      "[Pretrain] Epoch 3/50  Loss=3.0741  Acc=0.0673\n",
      "[Pretrain] Epoch 4/50  Loss=2.9917  Acc=0.0993\n",
      "[Pretrain] Epoch 5/50  Loss=2.7257  Acc=0.1358\n",
      "[Pretrain] Epoch 6/50  Loss=2.5656  Acc=0.1846\n",
      "[Pretrain] Epoch 7/50  Loss=2.4378  Acc=0.2123\n",
      "[Pretrain] Epoch 8/50  Loss=2.3595  Acc=0.2376\n",
      "[Pretrain] Epoch 9/50  Loss=2.2754  Acc=0.2726\n",
      "[Pretrain] Epoch 10/50  Loss=2.2298  Acc=0.2823\n",
      "[Pretrain] Epoch 11/50  Loss=2.1690  Acc=0.3003\n",
      "[Pretrain] Epoch 12/50  Loss=2.1494  Acc=0.3102\n",
      "[Pretrain] Epoch 13/50  Loss=2.0790  Acc=0.3220\n",
      "[Pretrain] Epoch 14/50  Loss=2.0874  Acc=0.3208\n",
      "[Pretrain] Epoch 15/50  Loss=2.0061  Acc=0.3434\n",
      "[Pretrain] Epoch 16/50  Loss=2.0208  Acc=0.3364\n",
      "[Pretrain] Epoch 17/50  Loss=1.9791  Acc=0.3506\n",
      "[Pretrain] Epoch 18/50  Loss=1.9543  Acc=0.3633\n",
      "[Pretrain] Epoch 19/50  Loss=1.9306  Acc=0.3761\n",
      "[Pretrain] Epoch 20/50  Loss=1.8969  Acc=0.3838\n",
      "[Pretrain] Epoch 21/50  Loss=1.8814  Acc=0.3784\n",
      "[Pretrain] Epoch 22/50  Loss=1.8439  Acc=0.4009\n",
      "[Pretrain] Epoch 23/50  Loss=1.8387  Acc=0.4009\n",
      "[Pretrain] Epoch 24/50  Loss=1.8144  Acc=0.4010\n",
      "[Pretrain] Epoch 25/50  Loss=1.7901  Acc=0.4147\n",
      "[Pretrain] Epoch 26/50  Loss=1.7823  Acc=0.4188\n",
      "[Pretrain] Epoch 27/50  Loss=1.7548  Acc=0.4265\n",
      "[Pretrain] Epoch 28/50  Loss=1.7204  Acc=0.4373\n",
      "[Pretrain] Epoch 29/50  Loss=1.7004  Acc=0.4490\n",
      "[Pretrain] Epoch 30/50  Loss=1.6868  Acc=0.4565\n",
      "[Pretrain] Epoch 31/50  Loss=1.6791  Acc=0.4578\n",
      "[Pretrain] Epoch 32/50  Loss=1.6481  Acc=0.4610\n",
      "[Pretrain] Epoch 33/50  Loss=1.6270  Acc=0.4621\n",
      "[Pretrain] Epoch 34/50  Loss=1.6063  Acc=0.4792\n",
      "[Pretrain] Epoch 35/50  Loss=1.5909  Acc=0.4754\n",
      "[Pretrain] Epoch 36/50  Loss=1.5670  Acc=0.4885\n",
      "[Pretrain] Epoch 37/50  Loss=1.5475  Acc=0.4964\n",
      "[Pretrain] Epoch 38/50  Loss=1.5203  Acc=0.5061\n",
      "[Pretrain] Epoch 39/50  Loss=1.5234  Acc=0.5119\n",
      "[Pretrain] Epoch 40/50  Loss=1.4817  Acc=0.5115\n",
      "[Pretrain] Epoch 41/50  Loss=1.4844  Acc=0.5081\n",
      "[Pretrain] Epoch 42/50  Loss=1.4672  Acc=0.5165\n",
      "[Pretrain] Epoch 43/50  Loss=1.4486  Acc=0.5228\n",
      "[Pretrain] Epoch 44/50  Loss=1.4249  Acc=0.5305\n",
      "[Pretrain] Epoch 45/50  Loss=1.4175  Acc=0.5363\n",
      "[Pretrain] Epoch 46/50  Loss=1.4188  Acc=0.5384\n",
      "[Pretrain] Epoch 47/50  Loss=1.3958  Acc=0.5438\n",
      "[Pretrain] Epoch 48/50  Loss=1.3926  Acc=0.5521\n",
      "[Pretrain] Epoch 49/50  Loss=1.3790  Acc=0.5512\n",
      "[Pretrain] Epoch 50/50  Loss=1.3532  Acc=0.5530\n",
      "[Fine-tune] Epoch 1/75  Loss=3.0340\n",
      "[Fine-tune] Epoch 2/75  Loss=2.5611\n",
      "[Fine-tune] Epoch 3/75  Loss=2.3571\n",
      "[Fine-tune] Epoch 4/75  Loss=2.2478\n",
      "[Fine-tune] Epoch 5/75  Loss=2.1804\n",
      "[Fine-tune] Epoch 6/75  Loss=2.1304\n",
      "[Fine-tune] Epoch 7/75  Loss=2.0762\n",
      "[Fine-tune] Epoch 8/75  Loss=2.0502\n",
      "[Fine-tune] Epoch 9/75  Loss=2.0152\n",
      "[Fine-tune] Epoch 10/75  Loss=1.9880\n",
      "[Fine-tune] Epoch 11/75  Loss=1.9689\n",
      "[Fine-tune] Epoch 12/75  Loss=1.9420\n",
      "[Fine-tune] Epoch 13/75  Loss=1.9402\n",
      "[Fine-tune] Epoch 14/75  Loss=1.9197\n",
      "[Fine-tune] Epoch 15/75  Loss=1.9078\n",
      "[Fine-tune] Epoch 16/75  Loss=1.8849\n",
      "[Fine-tune] Epoch 17/75  Loss=1.8732\n",
      "[Fine-tune] Epoch 18/75  Loss=1.8640\n",
      "[Fine-tune] Epoch 19/75  Loss=1.8460\n",
      "[Fine-tune] Epoch 20/75  Loss=1.8333\n",
      "[Fine-tune] Epoch 21/75  Loss=1.8338\n",
      "[Fine-tune] Epoch 22/75  Loss=1.8326\n",
      "[Fine-tune] Epoch 23/75  Loss=1.8175\n",
      "[Fine-tune] Epoch 24/75  Loss=1.8105\n",
      "[Fine-tune] Epoch 25/75  Loss=1.7880\n",
      "[Fine-tune] Epoch 26/75  Loss=1.7963\n",
      "[Fine-tune] Epoch 27/75  Loss=1.7761\n",
      "[Fine-tune] Epoch 28/75  Loss=1.7759\n",
      "[Fine-tune] Epoch 29/75  Loss=1.7648\n",
      "[Fine-tune] Epoch 30/75  Loss=1.7593\n",
      "[Fine-tune] Epoch 31/75  Loss=1.7521\n",
      "[Fine-tune] Epoch 32/75  Loss=1.7591\n",
      "[Fine-tune] Epoch 33/75  Loss=1.7446\n",
      "[Fine-tune] Epoch 34/75  Loss=1.7435\n",
      "[Fine-tune] Epoch 35/75  Loss=1.7241\n",
      "[Fine-tune] Epoch 36/75  Loss=1.7324\n",
      "[Fine-tune] Epoch 37/75  Loss=1.7226\n",
      "[Fine-tune] Epoch 38/75  Loss=1.7257\n",
      "[Fine-tune] Epoch 39/75  Loss=1.7207\n",
      "[Fine-tune] Epoch 40/75  Loss=1.7070\n",
      "[Fine-tune] Epoch 41/75  Loss=1.7015\n",
      "[Fine-tune] Epoch 42/75  Loss=1.7049\n",
      "[Fine-tune] Epoch 43/75  Loss=1.7008\n",
      "[Fine-tune] Epoch 44/75  Loss=1.6968\n",
      "[Fine-tune] Epoch 45/75  Loss=1.7016\n",
      "[Fine-tune] Epoch 46/75  Loss=1.7081\n",
      "[Fine-tune] Epoch 47/75  Loss=1.6930\n",
      "[Fine-tune] Epoch 48/75  Loss=1.6947\n",
      "[Fine-tune] Epoch 49/75  Loss=1.6904\n",
      "[Fine-tune] Epoch 50/75  Loss=1.6754\n",
      "[Fine-tune] Epoch 51/75  Loss=1.6835\n",
      "[Fine-tune] Epoch 52/75  Loss=1.6774\n",
      "[Fine-tune] Epoch 53/75  Loss=1.6780\n",
      "[Fine-tune] Epoch 54/75  Loss=1.6793\n",
      "[Fine-tune] Epoch 55/75  Loss=1.6867\n",
      "[Fine-tune] Epoch 56/75  Loss=1.6582\n",
      "[Fine-tune] Epoch 57/75  Loss=1.6658\n",
      "[Fine-tune] Epoch 58/75  Loss=1.6746\n",
      "[Fine-tune] Epoch 59/75  Loss=1.6665\n",
      "[Fine-tune] Epoch 60/75  Loss=1.6712\n",
      "[Fine-tune] Epoch 61/75  Loss=1.6723\n",
      "[Fine-tune] Epoch 62/75  Loss=1.6844\n",
      "[Fine-tune] Epoch 63/75  Loss=1.6586\n",
      "[Fine-tune] Epoch 64/75  Loss=1.6553\n",
      "[Fine-tune] Epoch 65/75  Loss=1.6653\n",
      "[Fine-tune] Epoch 66/75  Loss=1.6545\n",
      "[Fine-tune] Epoch 67/75  Loss=1.6638\n",
      "[Fine-tune] Epoch 68/75  Loss=1.6616\n",
      "[Fine-tune] Epoch 69/75  Loss=1.6489\n",
      "[Fine-tune] Epoch 70/75  Loss=1.6664\n",
      "[Fine-tune] Epoch 71/75  Loss=1.6637\n",
      "[Fine-tune] Epoch 72/75  Loss=1.6664\n",
      "[Fine-tune] Epoch 73/75  Loss=1.6582\n",
      "[Fine-tune] Epoch 74/75  Loss=1.6509\n",
      "[Fine-tune] Epoch 75/75  Loss=1.6586\n",
      "[Pretrain] Epoch 1/75  Loss=3.2549  Acc=0.0418\n",
      "[Pretrain] Epoch 2/75  Loss=3.1177  Acc=0.0668\n",
      "[Pretrain] Epoch 3/75  Loss=2.9724  Acc=0.0898\n",
      "[Pretrain] Epoch 4/75  Loss=2.6874  Acc=0.1399\n",
      "[Pretrain] Epoch 5/75  Loss=2.5622  Acc=0.1832\n",
      "[Pretrain] Epoch 6/75  Loss=2.4024  Acc=0.2331\n",
      "[Pretrain] Epoch 7/75  Loss=2.2442  Acc=0.2782\n",
      "[Pretrain] Epoch 8/75  Loss=2.1383  Acc=0.3042\n",
      "[Pretrain] Epoch 9/75  Loss=2.1115  Acc=0.3215\n",
      "[Pretrain] Epoch 10/75  Loss=2.0433  Acc=0.3341\n",
      "[Pretrain] Epoch 11/75  Loss=1.9981  Acc=0.3500\n",
      "[Pretrain] Epoch 12/75  Loss=1.9733  Acc=0.3538\n",
      "[Pretrain] Epoch 13/75  Loss=1.9394  Acc=0.3671\n",
      "[Pretrain] Epoch 14/75  Loss=1.9378  Acc=0.3725\n",
      "[Pretrain] Epoch 15/75  Loss=1.9162  Acc=0.3727\n",
      "[Pretrain] Epoch 16/75  Loss=1.8730  Acc=0.3904\n",
      "[Pretrain] Epoch 17/75  Loss=1.8296  Acc=0.4100\n",
      "[Pretrain] Epoch 18/75  Loss=1.8320  Acc=0.4066\n",
      "[Pretrain] Epoch 19/75  Loss=1.7993  Acc=0.4156\n",
      "[Pretrain] Epoch 20/75  Loss=1.7857  Acc=0.4242\n",
      "[Pretrain] Epoch 21/75  Loss=1.7480  Acc=0.4321\n",
      "[Pretrain] Epoch 22/75  Loss=1.7463  Acc=0.4310\n",
      "[Pretrain] Epoch 23/75  Loss=1.7169  Acc=0.4449\n",
      "[Pretrain] Epoch 24/75  Loss=1.7036  Acc=0.4404\n",
      "[Pretrain] Epoch 25/75  Loss=1.7114  Acc=0.4467\n",
      "[Pretrain] Epoch 26/75  Loss=1.6666  Acc=0.4560\n",
      "[Pretrain] Epoch 27/75  Loss=1.6529  Acc=0.4689\n",
      "[Pretrain] Epoch 28/75  Loss=1.6460  Acc=0.4653\n",
      "[Pretrain] Epoch 29/75  Loss=1.6485  Acc=0.4671\n",
      "[Pretrain] Epoch 30/75  Loss=1.6212  Acc=0.4774\n",
      "[Pretrain] Epoch 31/75  Loss=1.6129  Acc=0.4749\n",
      "[Pretrain] Epoch 32/75  Loss=1.5660  Acc=0.4881\n",
      "[Pretrain] Epoch 33/75  Loss=1.5641  Acc=0.4910\n",
      "[Pretrain] Epoch 34/75  Loss=1.5530  Acc=0.5002\n",
      "[Pretrain] Epoch 35/75  Loss=1.5330  Acc=0.5032\n",
      "[Pretrain] Epoch 36/75  Loss=1.5392  Acc=0.5005\n",
      "[Pretrain] Epoch 37/75  Loss=1.5094  Acc=0.5101\n",
      "[Pretrain] Epoch 38/75  Loss=1.4952  Acc=0.5066\n",
      "[Pretrain] Epoch 39/75  Loss=1.5021  Acc=0.5122\n",
      "[Pretrain] Epoch 40/75  Loss=1.4697  Acc=0.5205\n",
      "[Pretrain] Epoch 41/75  Loss=1.4661  Acc=0.5230\n",
      "[Pretrain] Epoch 42/75  Loss=1.4506  Acc=0.5266\n",
      "[Pretrain] Epoch 43/75  Loss=1.4503  Acc=0.5300\n",
      "[Pretrain] Epoch 44/75  Loss=1.4348  Acc=0.5361\n",
      "[Pretrain] Epoch 45/75  Loss=1.4381  Acc=0.5262\n",
      "[Pretrain] Epoch 46/75  Loss=1.4251  Acc=0.5370\n",
      "[Pretrain] Epoch 47/75  Loss=1.4140  Acc=0.5435\n",
      "[Pretrain] Epoch 48/75  Loss=1.4239  Acc=0.5411\n",
      "[Pretrain] Epoch 49/75  Loss=1.4038  Acc=0.5453\n",
      "[Pretrain] Epoch 50/75  Loss=1.3885  Acc=0.5453\n",
      "[Pretrain] Epoch 51/75  Loss=1.3771  Acc=0.5569\n",
      "[Pretrain] Epoch 52/75  Loss=1.4013  Acc=0.5404\n",
      "[Pretrain] Epoch 53/75  Loss=1.3737  Acc=0.5530\n",
      "[Pretrain] Epoch 54/75  Loss=1.3726  Acc=0.5476\n",
      "[Pretrain] Epoch 55/75  Loss=1.3662  Acc=0.5594\n",
      "[Pretrain] Epoch 56/75  Loss=1.3447  Acc=0.5643\n",
      "[Pretrain] Epoch 57/75  Loss=1.3418  Acc=0.5609\n",
      "[Pretrain] Epoch 58/75  Loss=1.3594  Acc=0.5611\n",
      "[Pretrain] Epoch 59/75  Loss=1.3488  Acc=0.5648\n",
      "[Pretrain] Epoch 60/75  Loss=1.3449  Acc=0.5645\n",
      "[Pretrain] Epoch 61/75  Loss=1.3387  Acc=0.5681\n",
      "[Pretrain] Epoch 62/75  Loss=1.3385  Acc=0.5654\n",
      "[Pretrain] Epoch 63/75  Loss=1.3378  Acc=0.5659\n",
      "[Pretrain] Epoch 64/75  Loss=1.3292  Acc=0.5614\n",
      "[Pretrain] Epoch 65/75  Loss=1.3324  Acc=0.5686\n",
      "[Pretrain] Epoch 66/75  Loss=1.3186  Acc=0.5668\n",
      "[Pretrain] Epoch 67/75  Loss=1.3264  Acc=0.5616\n",
      "[Pretrain] Epoch 68/75  Loss=1.3248  Acc=0.5690\n",
      "[Pretrain] Epoch 69/75  Loss=1.3284  Acc=0.5643\n",
      "[Pretrain] Epoch 70/75  Loss=1.3190  Acc=0.5726\n",
      "[Pretrain] Epoch 71/75  Loss=1.3093  Acc=0.5727\n",
      "[Pretrain] Epoch 72/75  Loss=1.3099  Acc=0.5724\n",
      "[Pretrain] Epoch 73/75  Loss=1.3010  Acc=0.5753\n",
      "[Pretrain] Epoch 74/75  Loss=1.3111  Acc=0.5733\n",
      "[Pretrain] Epoch 75/75  Loss=1.2984  Acc=0.5763\n",
      "[Fine-tune] Epoch 1/75  Loss=2.8971\n",
      "[Fine-tune] Epoch 2/75  Loss=2.3399\n",
      "[Fine-tune] Epoch 3/75  Loss=2.1749\n",
      "[Fine-tune] Epoch 4/75  Loss=2.0706\n",
      "[Fine-tune] Epoch 5/75  Loss=1.9915\n",
      "[Fine-tune] Epoch 6/75  Loss=1.9484\n",
      "[Fine-tune] Epoch 7/75  Loss=1.8959\n",
      "[Fine-tune] Epoch 8/75  Loss=1.8505\n",
      "[Fine-tune] Epoch 9/75  Loss=1.8127\n",
      "[Fine-tune] Epoch 10/75  Loss=1.7613\n",
      "[Fine-tune] Epoch 11/75  Loss=1.7345\n",
      "[Fine-tune] Epoch 12/75  Loss=1.6858\n",
      "[Fine-tune] Epoch 13/75  Loss=1.6368\n",
      "[Fine-tune] Epoch 14/75  Loss=1.6093\n",
      "[Fine-tune] Epoch 15/75  Loss=1.5645\n",
      "[Fine-tune] Epoch 16/75  Loss=1.5522\n",
      "[Fine-tune] Epoch 17/75  Loss=1.5156\n",
      "[Fine-tune] Epoch 18/75  Loss=1.4937\n",
      "[Fine-tune] Epoch 19/75  Loss=1.4851\n",
      "[Fine-tune] Epoch 20/75  Loss=1.4526\n",
      "[Fine-tune] Epoch 21/75  Loss=1.4153\n",
      "[Fine-tune] Epoch 22/75  Loss=1.4000\n",
      "[Fine-tune] Epoch 23/75  Loss=1.3721\n",
      "[Fine-tune] Epoch 24/75  Loss=1.3651\n",
      "[Fine-tune] Epoch 25/75  Loss=1.3551\n",
      "[Fine-tune] Epoch 26/75  Loss=1.3141\n",
      "[Fine-tune] Epoch 27/75  Loss=1.3092\n",
      "[Fine-tune] Epoch 28/75  Loss=1.2712\n",
      "[Fine-tune] Epoch 29/75  Loss=1.2641\n",
      "[Fine-tune] Epoch 30/75  Loss=1.2427\n",
      "[Fine-tune] Epoch 31/75  Loss=1.2401\n",
      "[Fine-tune] Epoch 32/75  Loss=1.2165\n",
      "[Fine-tune] Epoch 33/75  Loss=1.2015\n",
      "[Fine-tune] Epoch 34/75  Loss=1.2033\n",
      "[Fine-tune] Epoch 35/75  Loss=1.2051\n",
      "[Fine-tune] Epoch 36/75  Loss=1.1655\n",
      "[Fine-tune] Epoch 37/75  Loss=1.1600\n",
      "[Fine-tune] Epoch 38/75  Loss=1.1389\n",
      "[Fine-tune] Epoch 39/75  Loss=1.1390\n",
      "[Fine-tune] Epoch 40/75  Loss=1.1327\n",
      "[Fine-tune] Epoch 41/75  Loss=1.1236\n",
      "[Fine-tune] Epoch 42/75  Loss=1.1155\n",
      "[Fine-tune] Epoch 43/75  Loss=1.1021\n",
      "[Fine-tune] Epoch 44/75  Loss=1.1012\n",
      "[Fine-tune] Epoch 45/75  Loss=1.0907\n",
      "[Fine-tune] Epoch 46/75  Loss=1.0808\n",
      "[Fine-tune] Epoch 47/75  Loss=1.0909\n",
      "[Fine-tune] Epoch 48/75  Loss=1.0744\n",
      "[Fine-tune] Epoch 49/75  Loss=1.0617\n",
      "[Fine-tune] Epoch 50/75  Loss=1.0693\n",
      "[Fine-tune] Epoch 51/75  Loss=1.0741\n",
      "[Fine-tune] Epoch 52/75  Loss=1.0514\n",
      "[Fine-tune] Epoch 53/75  Loss=1.0492\n",
      "[Fine-tune] Epoch 54/75  Loss=1.0610\n",
      "[Fine-tune] Epoch 55/75  Loss=1.0456\n",
      "[Fine-tune] Epoch 56/75  Loss=1.0409\n",
      "[Fine-tune] Epoch 57/75  Loss=1.0388\n",
      "[Fine-tune] Epoch 58/75  Loss=1.0254\n",
      "[Fine-tune] Epoch 59/75  Loss=1.0243\n",
      "[Fine-tune] Epoch 60/75  Loss=1.0214\n",
      "[Fine-tune] Epoch 61/75  Loss=1.0272\n",
      "[Fine-tune] Epoch 62/75  Loss=0.9996\n",
      "[Fine-tune] Epoch 63/75  Loss=1.0174\n",
      "[Fine-tune] Epoch 64/75  Loss=1.0112\n",
      "[Fine-tune] Epoch 65/75  Loss=1.0117\n",
      "[Fine-tune] Epoch 66/75  Loss=1.0011\n",
      "[Fine-tune] Epoch 67/75  Loss=1.0060\n",
      "[Fine-tune] Epoch 68/75  Loss=1.0138\n",
      "[Fine-tune] Epoch 69/75  Loss=1.0064\n",
      "[Fine-tune] Epoch 70/75  Loss=0.9997\n",
      "[Fine-tune] Epoch 71/75  Loss=1.0052\n",
      "[Fine-tune] Epoch 72/75  Loss=1.0086\n",
      "[Fine-tune] Epoch 73/75  Loss=0.9898\n",
      "[Fine-tune] Epoch 74/75  Loss=1.0033\n",
      "[Fine-tune] Epoch 75/75  Loss=0.9808\n",
      "[Pretrain] Epoch 1/75  Loss=3.5973  Acc=0.0506\n",
      "[Pretrain] Epoch 2/75  Loss=3.1008  Acc=0.0824\n",
      "[Pretrain] Epoch 3/75  Loss=3.0443  Acc=0.0889\n",
      "[Pretrain] Epoch 4/75  Loss=2.8495  Acc=0.1248\n",
      "[Pretrain] Epoch 5/75  Loss=2.6335  Acc=0.1719\n",
      "[Pretrain] Epoch 6/75  Loss=2.5058  Acc=0.2071\n",
      "[Pretrain] Epoch 7/75  Loss=2.4151  Acc=0.2340\n",
      "[Pretrain] Epoch 8/75  Loss=2.3456  Acc=0.2525\n",
      "[Pretrain] Epoch 9/75  Loss=2.2749  Acc=0.2748\n",
      "[Pretrain] Epoch 10/75  Loss=2.2009  Acc=0.2911\n",
      "[Pretrain] Epoch 11/75  Loss=2.1468  Acc=0.3098\n",
      "[Pretrain] Epoch 12/75  Loss=2.1207  Acc=0.3145\n",
      "[Pretrain] Epoch 13/75  Loss=2.0771  Acc=0.3296\n",
      "[Pretrain] Epoch 14/75  Loss=2.0585  Acc=0.3360\n",
      "[Pretrain] Epoch 15/75  Loss=2.0009  Acc=0.3464\n",
      "[Pretrain] Epoch 16/75  Loss=1.9917  Acc=0.3533\n",
      "[Pretrain] Epoch 17/75  Loss=1.9593  Acc=0.3680\n",
      "[Pretrain] Epoch 18/75  Loss=1.9399  Acc=0.3779\n",
      "[Pretrain] Epoch 19/75  Loss=1.9045  Acc=0.3842\n",
      "[Pretrain] Epoch 20/75  Loss=1.8987  Acc=0.3890\n",
      "[Pretrain] Epoch 21/75  Loss=1.8606  Acc=0.3881\n",
      "[Pretrain] Epoch 22/75  Loss=1.8362  Acc=0.4068\n",
      "[Pretrain] Epoch 23/75  Loss=1.8135  Acc=0.4127\n",
      "[Pretrain] Epoch 24/75  Loss=1.8088  Acc=0.4118\n",
      "[Pretrain] Epoch 25/75  Loss=1.7708  Acc=0.4168\n",
      "[Pretrain] Epoch 26/75  Loss=1.7410  Acc=0.4291\n",
      "[Pretrain] Epoch 27/75  Loss=1.7207  Acc=0.4359\n",
      "[Pretrain] Epoch 28/75  Loss=1.7041  Acc=0.4371\n",
      "[Pretrain] Epoch 29/75  Loss=1.6848  Acc=0.4529\n",
      "[Pretrain] Epoch 30/75  Loss=1.6744  Acc=0.4468\n",
      "[Pretrain] Epoch 31/75  Loss=1.6800  Acc=0.4438\n",
      "[Pretrain] Epoch 32/75  Loss=1.6184  Acc=0.4709\n",
      "[Pretrain] Epoch 33/75  Loss=1.6190  Acc=0.4644\n",
      "[Pretrain] Epoch 34/75  Loss=1.6010  Acc=0.4806\n",
      "[Pretrain] Epoch 35/75  Loss=1.5762  Acc=0.4691\n",
      "[Pretrain] Epoch 36/75  Loss=1.5570  Acc=0.4855\n",
      "[Pretrain] Epoch 37/75  Loss=1.5637  Acc=0.4826\n",
      "[Pretrain] Epoch 38/75  Loss=1.5230  Acc=0.5007\n",
      "[Pretrain] Epoch 39/75  Loss=1.5255  Acc=0.4973\n",
      "[Pretrain] Epoch 40/75  Loss=1.5173  Acc=0.4955\n",
      "[Pretrain] Epoch 41/75  Loss=1.4821  Acc=0.5104\n",
      "[Pretrain] Epoch 42/75  Loss=1.4717  Acc=0.5136\n",
      "[Pretrain] Epoch 43/75  Loss=1.4493  Acc=0.5233\n",
      "[Pretrain] Epoch 44/75  Loss=1.4676  Acc=0.5221\n",
      "[Pretrain] Epoch 45/75  Loss=1.4374  Acc=0.5300\n",
      "[Pretrain] Epoch 46/75  Loss=1.4266  Acc=0.5237\n",
      "[Pretrain] Epoch 47/75  Loss=1.4081  Acc=0.5318\n",
      "[Pretrain] Epoch 48/75  Loss=1.3877  Acc=0.5456\n",
      "[Pretrain] Epoch 49/75  Loss=1.4025  Acc=0.5409\n",
      "[Pretrain] Epoch 50/75  Loss=1.3742  Acc=0.5465\n",
      "[Pretrain] Epoch 51/75  Loss=1.3582  Acc=0.5519\n",
      "[Pretrain] Epoch 52/75  Loss=1.3515  Acc=0.5489\n",
      "[Pretrain] Epoch 53/75  Loss=1.3500  Acc=0.5598\n",
      "[Pretrain] Epoch 54/75  Loss=1.3423  Acc=0.5618\n",
      "[Pretrain] Epoch 55/75  Loss=1.3285  Acc=0.5616\n",
      "[Pretrain] Epoch 56/75  Loss=1.3235  Acc=0.5666\n",
      "[Pretrain] Epoch 57/75  Loss=1.3035  Acc=0.5745\n",
      "[Pretrain] Epoch 58/75  Loss=1.3112  Acc=0.5639\n",
      "[Pretrain] Epoch 59/75  Loss=1.2954  Acc=0.5779\n",
      "[Pretrain] Epoch 60/75  Loss=1.3039  Acc=0.5717\n",
      "[Pretrain] Epoch 61/75  Loss=1.2929  Acc=0.5756\n",
      "[Pretrain] Epoch 62/75  Loss=1.2673  Acc=0.5864\n",
      "[Pretrain] Epoch 63/75  Loss=1.2801  Acc=0.5878\n",
      "[Pretrain] Epoch 64/75  Loss=1.2644  Acc=0.5792\n",
      "[Pretrain] Epoch 65/75  Loss=1.2718  Acc=0.5806\n",
      "[Pretrain] Epoch 66/75  Loss=1.2645  Acc=0.5835\n",
      "[Pretrain] Epoch 67/75  Loss=1.2641  Acc=0.5853\n",
      "[Pretrain] Epoch 68/75  Loss=1.2347  Acc=0.5878\n",
      "[Pretrain] Epoch 69/75  Loss=1.2424  Acc=0.6002\n",
      "[Pretrain] Epoch 70/75  Loss=1.2530  Acc=0.5887\n",
      "[Pretrain] Epoch 71/75  Loss=1.2451  Acc=0.5909\n",
      "[Pretrain] Epoch 72/75  Loss=1.2373  Acc=0.5964\n",
      "[Pretrain] Epoch 73/75  Loss=1.2260  Acc=0.6018\n",
      "[Pretrain] Epoch 74/75  Loss=1.2219  Acc=0.5914\n",
      "[Pretrain] Epoch 75/75  Loss=1.2361  Acc=0.5948\n",
      "[Fine-tune] Epoch 1/75  Loss=3.0124\n",
      "[Fine-tune] Epoch 2/75  Loss=2.6333\n",
      "[Fine-tune] Epoch 3/75  Loss=2.4684\n",
      "[Fine-tune] Epoch 4/75  Loss=2.3108\n",
      "[Fine-tune] Epoch 5/75  Loss=2.2358\n",
      "[Fine-tune] Epoch 6/75  Loss=2.1794\n",
      "[Fine-tune] Epoch 7/75  Loss=2.1125\n",
      "[Fine-tune] Epoch 8/75  Loss=2.0923\n",
      "[Fine-tune] Epoch 9/75  Loss=2.0566\n",
      "[Fine-tune] Epoch 10/75  Loss=2.0175\n",
      "[Fine-tune] Epoch 11/75  Loss=2.0138\n",
      "[Fine-tune] Epoch 12/75  Loss=1.9885\n",
      "[Fine-tune] Epoch 13/75  Loss=1.9578\n",
      "[Fine-tune] Epoch 14/75  Loss=1.9498\n",
      "[Fine-tune] Epoch 15/75  Loss=1.9190\n",
      "[Fine-tune] Epoch 16/75  Loss=1.9082\n",
      "[Fine-tune] Epoch 17/75  Loss=1.8961\n",
      "[Fine-tune] Epoch 18/75  Loss=1.8951\n",
      "[Fine-tune] Epoch 19/75  Loss=1.8750\n",
      "[Fine-tune] Epoch 20/75  Loss=1.8539\n",
      "[Fine-tune] Epoch 21/75  Loss=1.8640\n",
      "[Fine-tune] Epoch 22/75  Loss=1.8446\n",
      "[Fine-tune] Epoch 23/75  Loss=1.8443\n",
      "[Fine-tune] Epoch 24/75  Loss=1.8296\n",
      "[Fine-tune] Epoch 25/75  Loss=1.8223\n",
      "[Fine-tune] Epoch 26/75  Loss=1.8156\n",
      "[Fine-tune] Epoch 27/75  Loss=1.8007\n",
      "[Fine-tune] Epoch 28/75  Loss=1.8138\n",
      "[Fine-tune] Epoch 29/75  Loss=1.8008\n",
      "[Fine-tune] Epoch 30/75  Loss=1.8002\n",
      "[Fine-tune] Epoch 31/75  Loss=1.7886\n",
      "[Fine-tune] Epoch 32/75  Loss=1.7759\n",
      "[Fine-tune] Epoch 33/75  Loss=1.7669\n",
      "[Fine-tune] Epoch 34/75  Loss=1.7624\n",
      "[Fine-tune] Epoch 35/75  Loss=1.7487\n",
      "[Fine-tune] Epoch 36/75  Loss=1.7591\n",
      "[Fine-tune] Epoch 37/75  Loss=1.7585\n",
      "[Fine-tune] Epoch 38/75  Loss=1.7357\n",
      "[Fine-tune] Epoch 39/75  Loss=1.7396\n",
      "[Fine-tune] Epoch 40/75  Loss=1.7525\n",
      "[Fine-tune] Epoch 41/75  Loss=1.7370\n",
      "[Fine-tune] Epoch 42/75  Loss=1.7320\n",
      "[Fine-tune] Epoch 43/75  Loss=1.7352\n",
      "[Fine-tune] Epoch 44/75  Loss=1.7410\n",
      "[Fine-tune] Epoch 45/75  Loss=1.7179\n",
      "[Fine-tune] Epoch 46/75  Loss=1.7380\n",
      "[Fine-tune] Epoch 47/75  Loss=1.7171\n",
      "[Fine-tune] Epoch 48/75  Loss=1.7280\n",
      "[Fine-tune] Epoch 49/75  Loss=1.7220\n",
      "[Fine-tune] Epoch 50/75  Loss=1.7164\n",
      "[Fine-tune] Epoch 51/75  Loss=1.7101\n",
      "[Fine-tune] Epoch 52/75  Loss=1.6993\n",
      "[Fine-tune] Epoch 53/75  Loss=1.7209\n",
      "[Fine-tune] Epoch 54/75  Loss=1.7028\n",
      "[Fine-tune] Epoch 55/75  Loss=1.7152\n",
      "[Fine-tune] Epoch 56/75  Loss=1.7083\n",
      "[Fine-tune] Epoch 57/75  Loss=1.7058\n",
      "[Fine-tune] Epoch 58/75  Loss=1.6945\n",
      "[Fine-tune] Epoch 59/75  Loss=1.7005\n",
      "[Fine-tune] Epoch 60/75  Loss=1.7016\n",
      "[Fine-tune] Epoch 61/75  Loss=1.7104\n",
      "[Fine-tune] Epoch 62/75  Loss=1.7023\n",
      "[Fine-tune] Epoch 63/75  Loss=1.6916\n",
      "[Fine-tune] Epoch 64/75  Loss=1.7040\n",
      "[Fine-tune] Epoch 65/75  Loss=1.6980\n",
      "[Fine-tune] Epoch 66/75  Loss=1.6889\n",
      "[Fine-tune] Epoch 67/75  Loss=1.6980\n",
      "[Fine-tune] Epoch 68/75  Loss=1.6948\n",
      "[Fine-tune] Epoch 69/75  Loss=1.6955\n",
      "[Fine-tune] Epoch 70/75  Loss=1.6903\n",
      "[Fine-tune] Epoch 71/75  Loss=1.6985\n",
      "[Fine-tune] Epoch 72/75  Loss=1.6995\n",
      "[Fine-tune] Epoch 73/75  Loss=1.6959\n",
      "[Fine-tune] Epoch 74/75  Loss=1.6866\n",
      "[Fine-tune] Epoch 75/75  Loss=1.6958\n",
      "[Pretrain] Epoch 1/100  Loss=3.2346  Acc=0.0503\n",
      "[Pretrain] Epoch 2/100  Loss=2.9267  Acc=0.0997\n",
      "[Pretrain] Epoch 3/100  Loss=2.5601  Acc=0.1909\n",
      "[Pretrain] Epoch 4/100  Loss=2.4041  Acc=0.2310\n",
      "[Pretrain] Epoch 5/100  Loss=2.2882  Acc=0.2645\n",
      "[Pretrain] Epoch 6/100  Loss=2.2080  Acc=0.2994\n",
      "[Pretrain] Epoch 7/100  Loss=2.1653  Acc=0.2980\n",
      "[Pretrain] Epoch 8/100  Loss=2.1253  Acc=0.3170\n",
      "[Pretrain] Epoch 9/100  Loss=2.0586  Acc=0.3269\n",
      "[Pretrain] Epoch 10/100  Loss=2.0087  Acc=0.3421\n",
      "[Pretrain] Epoch 11/100  Loss=1.9802  Acc=0.3522\n",
      "[Pretrain] Epoch 12/100  Loss=1.9657  Acc=0.3687\n",
      "[Pretrain] Epoch 13/100  Loss=1.9189  Acc=0.3775\n",
      "[Pretrain] Epoch 14/100  Loss=1.9015  Acc=0.3820\n",
      "[Pretrain] Epoch 15/100  Loss=1.8874  Acc=0.3933\n",
      "[Pretrain] Epoch 16/100  Loss=1.8551  Acc=0.4003\n",
      "[Pretrain] Epoch 17/100  Loss=1.8487  Acc=0.4052\n",
      "[Pretrain] Epoch 18/100  Loss=1.7845  Acc=0.4222\n",
      "[Pretrain] Epoch 19/100  Loss=1.7868  Acc=0.4194\n",
      "[Pretrain] Epoch 20/100  Loss=1.7844  Acc=0.4305\n",
      "[Pretrain] Epoch 21/100  Loss=1.7500  Acc=0.4370\n",
      "[Pretrain] Epoch 22/100  Loss=1.7112  Acc=0.4503\n",
      "[Pretrain] Epoch 23/100  Loss=1.7109  Acc=0.4515\n",
      "[Pretrain] Epoch 24/100  Loss=1.6717  Acc=0.4565\n",
      "[Pretrain] Epoch 25/100  Loss=1.6800  Acc=0.4619\n",
      "[Pretrain] Epoch 26/100  Loss=1.6430  Acc=0.4691\n",
      "[Pretrain] Epoch 27/100  Loss=1.6439  Acc=0.4635\n",
      "[Pretrain] Epoch 28/100  Loss=1.6172  Acc=0.4722\n",
      "[Pretrain] Epoch 29/100  Loss=1.5949  Acc=0.4784\n",
      "[Pretrain] Epoch 30/100  Loss=1.5983  Acc=0.4811\n",
      "[Pretrain] Epoch 31/100  Loss=1.5646  Acc=0.4928\n",
      "[Pretrain] Epoch 32/100  Loss=1.5501  Acc=0.5000\n",
      "[Pretrain] Epoch 33/100  Loss=1.5527  Acc=0.4959\n",
      "[Pretrain] Epoch 34/100  Loss=1.5119  Acc=0.5072\n",
      "[Pretrain] Epoch 35/100  Loss=1.5010  Acc=0.5129\n",
      "[Pretrain] Epoch 36/100  Loss=1.5098  Acc=0.5113\n",
      "[Pretrain] Epoch 37/100  Loss=1.4879  Acc=0.5099\n",
      "[Pretrain] Epoch 38/100  Loss=1.4648  Acc=0.5286\n",
      "[Pretrain] Epoch 39/100  Loss=1.4603  Acc=0.5269\n",
      "[Pretrain] Epoch 40/100  Loss=1.4344  Acc=0.5379\n",
      "[Pretrain] Epoch 41/100  Loss=1.4394  Acc=0.5291\n",
      "[Pretrain] Epoch 42/100  Loss=1.4571  Acc=0.5298\n",
      "[Pretrain] Epoch 43/100  Loss=1.4317  Acc=0.5377\n",
      "[Pretrain] Epoch 44/100  Loss=1.4230  Acc=0.5386\n",
      "[Pretrain] Epoch 45/100  Loss=1.4180  Acc=0.5406\n",
      "[Pretrain] Epoch 46/100  Loss=1.4071  Acc=0.5445\n",
      "[Pretrain] Epoch 47/100  Loss=1.3809  Acc=0.5523\n",
      "[Pretrain] Epoch 48/100  Loss=1.3874  Acc=0.5519\n",
      "[Pretrain] Epoch 49/100  Loss=1.3825  Acc=0.5515\n",
      "[Pretrain] Epoch 50/100  Loss=1.3630  Acc=0.5535\n",
      "[Pretrain] Epoch 51/100  Loss=1.3667  Acc=0.5557\n",
      "[Pretrain] Epoch 52/100  Loss=1.3499  Acc=0.5578\n",
      "[Pretrain] Epoch 53/100  Loss=1.3463  Acc=0.5618\n",
      "[Pretrain] Epoch 54/100  Loss=1.3391  Acc=0.5620\n",
      "[Pretrain] Epoch 55/100  Loss=1.3364  Acc=0.5603\n",
      "[Pretrain] Epoch 56/100  Loss=1.3348  Acc=0.5688\n",
      "[Pretrain] Epoch 57/100  Loss=1.3357  Acc=0.5643\n",
      "[Pretrain] Epoch 58/100  Loss=1.3259  Acc=0.5621\n",
      "[Pretrain] Epoch 59/100  Loss=1.3244  Acc=0.5672\n",
      "[Pretrain] Epoch 60/100  Loss=1.3209  Acc=0.5754\n",
      "[Pretrain] Epoch 61/100  Loss=1.3206  Acc=0.5720\n",
      "[Pretrain] Epoch 62/100  Loss=1.3141  Acc=0.5688\n",
      "[Pretrain] Epoch 63/100  Loss=1.3046  Acc=0.5736\n",
      "[Pretrain] Epoch 64/100  Loss=1.2950  Acc=0.5832\n",
      "[Pretrain] Epoch 65/100  Loss=1.2953  Acc=0.5855\n",
      "[Pretrain] Epoch 66/100  Loss=1.2868  Acc=0.5824\n",
      "[Pretrain] Epoch 67/100  Loss=1.2781  Acc=0.5794\n",
      "[Pretrain] Epoch 68/100  Loss=1.2880  Acc=0.5790\n",
      "[Pretrain] Epoch 69/100  Loss=1.2825  Acc=0.5785\n",
      "[Pretrain] Epoch 70/100  Loss=1.2883  Acc=0.5765\n",
      "[Pretrain] Epoch 71/100  Loss=1.2793  Acc=0.5781\n",
      "[Pretrain] Epoch 72/100  Loss=1.2951  Acc=0.5770\n",
      "[Pretrain] Epoch 73/100  Loss=1.2869  Acc=0.5787\n",
      "[Pretrain] Epoch 74/100  Loss=1.2764  Acc=0.5855\n",
      "[Pretrain] Epoch 75/100  Loss=1.2672  Acc=0.5884\n",
      "[Pretrain] Epoch 76/100  Loss=1.2766  Acc=0.5824\n",
      "[Pretrain] Epoch 77/100  Loss=1.2753  Acc=0.5849\n",
      "[Pretrain] Epoch 78/100  Loss=1.2656  Acc=0.5857\n",
      "[Pretrain] Epoch 79/100  Loss=1.2835  Acc=0.5862\n",
      "[Pretrain] Epoch 80/100  Loss=1.2606  Acc=0.5839\n",
      "[Pretrain] Epoch 81/100  Loss=1.2643  Acc=0.5857\n",
      "[Pretrain] Epoch 82/100  Loss=1.2684  Acc=0.5839\n",
      "[Pretrain] Epoch 83/100  Loss=1.2515  Acc=0.5880\n",
      "[Pretrain] Epoch 84/100  Loss=1.2700  Acc=0.5832\n",
      "[Pretrain] Epoch 85/100  Loss=1.2757  Acc=0.5832\n",
      "[Pretrain] Epoch 86/100  Loss=1.2660  Acc=0.5803\n",
      "[Pretrain] Epoch 87/100  Loss=1.2615  Acc=0.5848\n",
      "[Pretrain] Epoch 88/100  Loss=1.2678  Acc=0.5862\n",
      "[Pretrain] Epoch 89/100  Loss=1.2566  Acc=0.5887\n",
      "[Pretrain] Epoch 90/100  Loss=1.2547  Acc=0.5943\n",
      "[Pretrain] Epoch 91/100  Loss=1.2670  Acc=0.5851\n",
      "[Pretrain] Epoch 92/100  Loss=1.2444  Acc=0.5896\n",
      "[Pretrain] Epoch 93/100  Loss=1.2467  Acc=0.5943\n",
      "[Pretrain] Epoch 94/100  Loss=1.2694  Acc=0.5790\n",
      "[Pretrain] Epoch 95/100  Loss=1.2529  Acc=0.5878\n",
      "[Pretrain] Epoch 96/100  Loss=1.2415  Acc=0.5941\n",
      "[Pretrain] Epoch 97/100  Loss=1.2527  Acc=0.5941\n",
      "[Pretrain] Epoch 98/100  Loss=1.2441  Acc=0.5959\n",
      "[Pretrain] Epoch 99/100  Loss=1.2552  Acc=0.5878\n",
      "[Pretrain] Epoch 100/100  Loss=1.2560  Acc=0.5862\n",
      "[Fine-tune] Epoch 1/75  Loss=2.6545\n",
      "[Fine-tune] Epoch 2/75  Loss=2.2602\n",
      "[Fine-tune] Epoch 3/75  Loss=2.1195\n",
      "[Fine-tune] Epoch 4/75  Loss=1.9862\n",
      "[Fine-tune] Epoch 5/75  Loss=1.9240\n",
      "[Fine-tune] Epoch 6/75  Loss=1.8490\n",
      "[Fine-tune] Epoch 7/75  Loss=1.8204\n",
      "[Fine-tune] Epoch 8/75  Loss=1.7479\n",
      "[Fine-tune] Epoch 9/75  Loss=1.7081\n",
      "[Fine-tune] Epoch 10/75  Loss=1.6599\n",
      "[Fine-tune] Epoch 11/75  Loss=1.6233\n",
      "[Fine-tune] Epoch 12/75  Loss=1.5837\n",
      "[Fine-tune] Epoch 13/75  Loss=1.5710\n",
      "[Fine-tune] Epoch 14/75  Loss=1.5320\n",
      "[Fine-tune] Epoch 15/75  Loss=1.4833\n",
      "[Fine-tune] Epoch 16/75  Loss=1.4638\n",
      "[Fine-tune] Epoch 17/75  Loss=1.4287\n",
      "[Fine-tune] Epoch 18/75  Loss=1.3971\n",
      "[Fine-tune] Epoch 19/75  Loss=1.3923\n",
      "[Fine-tune] Epoch 20/75  Loss=1.3615\n",
      "[Fine-tune] Epoch 21/75  Loss=1.3311\n",
      "[Fine-tune] Epoch 22/75  Loss=1.3114\n",
      "[Fine-tune] Epoch 23/75  Loss=1.2908\n",
      "[Fine-tune] Epoch 24/75  Loss=1.2679\n",
      "[Fine-tune] Epoch 25/75  Loss=1.2346\n",
      "[Fine-tune] Epoch 26/75  Loss=1.2246\n",
      "[Fine-tune] Epoch 27/75  Loss=1.2033\n",
      "[Fine-tune] Epoch 28/75  Loss=1.2005\n",
      "[Fine-tune] Epoch 29/75  Loss=1.1863\n",
      "[Fine-tune] Epoch 30/75  Loss=1.1700\n",
      "[Fine-tune] Epoch 31/75  Loss=1.1505\n",
      "[Fine-tune] Epoch 32/75  Loss=1.1385\n",
      "[Fine-tune] Epoch 33/75  Loss=1.1181\n",
      "[Fine-tune] Epoch 34/75  Loss=1.1007\n",
      "[Fine-tune] Epoch 35/75  Loss=1.0955\n",
      "[Fine-tune] Epoch 36/75  Loss=1.0838\n",
      "[Fine-tune] Epoch 37/75  Loss=1.0884\n",
      "[Fine-tune] Epoch 38/75  Loss=1.0581\n",
      "[Fine-tune] Epoch 39/75  Loss=1.0660\n",
      "[Fine-tune] Epoch 40/75  Loss=1.0584\n",
      "[Fine-tune] Epoch 41/75  Loss=1.0362\n",
      "[Fine-tune] Epoch 42/75  Loss=1.0422\n",
      "[Fine-tune] Epoch 43/75  Loss=1.0276\n",
      "[Fine-tune] Epoch 44/75  Loss=1.0240\n",
      "[Fine-tune] Epoch 45/75  Loss=1.0134\n",
      "[Fine-tune] Epoch 46/75  Loss=1.0113\n",
      "[Fine-tune] Epoch 47/75  Loss=1.0102\n",
      "[Fine-tune] Epoch 48/75  Loss=0.9897\n",
      "[Fine-tune] Epoch 49/75  Loss=0.9917\n",
      "[Fine-tune] Epoch 50/75  Loss=1.0015\n",
      "[Fine-tune] Epoch 51/75  Loss=0.9829\n",
      "[Fine-tune] Epoch 52/75  Loss=0.9810\n",
      "[Fine-tune] Epoch 53/75  Loss=0.9771\n",
      "[Fine-tune] Epoch 54/75  Loss=0.9744\n",
      "[Fine-tune] Epoch 55/75  Loss=0.9639\n",
      "[Fine-tune] Epoch 56/75  Loss=0.9712\n",
      "[Fine-tune] Epoch 57/75  Loss=0.9496\n",
      "[Fine-tune] Epoch 58/75  Loss=0.9561\n",
      "[Fine-tune] Epoch 59/75  Loss=0.9542\n",
      "[Fine-tune] Epoch 60/75  Loss=0.9622\n",
      "[Fine-tune] Epoch 61/75  Loss=0.9555\n",
      "[Fine-tune] Epoch 62/75  Loss=0.9333\n",
      "[Fine-tune] Epoch 63/75  Loss=0.9404\n",
      "[Fine-tune] Epoch 64/75  Loss=0.9404\n",
      "[Fine-tune] Epoch 65/75  Loss=0.9311\n",
      "[Fine-tune] Epoch 66/75  Loss=0.9515\n",
      "[Fine-tune] Epoch 67/75  Loss=0.9271\n",
      "[Fine-tune] Epoch 68/75  Loss=0.9299\n",
      "[Fine-tune] Epoch 69/75  Loss=0.9264\n",
      "[Fine-tune] Epoch 70/75  Loss=0.9291\n",
      "[Fine-tune] Epoch 71/75  Loss=0.9121\n",
      "[Fine-tune] Epoch 72/75  Loss=0.9303\n",
      "[Fine-tune] Epoch 73/75  Loss=0.9297\n",
      "[Fine-tune] Epoch 74/75  Loss=0.9204\n",
      "[Fine-tune] Epoch 75/75  Loss=0.9148\n",
      "[Pretrain] Epoch 1/100  Loss=3.6731  Acc=0.0417\n",
      "[Pretrain] Epoch 2/100  Loss=3.0722  Acc=0.0736\n",
      "[Pretrain] Epoch 3/100  Loss=2.8290  Acc=0.1061\n",
      "[Pretrain] Epoch 4/100  Loss=2.6273  Acc=0.1568\n",
      "[Pretrain] Epoch 5/100  Loss=2.5391  Acc=0.1850\n",
      "[Pretrain] Epoch 6/100  Loss=2.4787  Acc=0.2006\n",
      "[Pretrain] Epoch 7/100  Loss=2.3960  Acc=0.2238\n",
      "[Pretrain] Epoch 8/100  Loss=2.2926  Acc=0.2505\n",
      "[Pretrain] Epoch 9/100  Loss=2.2750  Acc=0.2557\n",
      "[Pretrain] Epoch 10/100  Loss=2.2092  Acc=0.2768\n",
      "[Pretrain] Epoch 11/100  Loss=2.1774  Acc=0.2942\n",
      "[Pretrain] Epoch 12/100  Loss=2.1481  Acc=0.3017\n",
      "[Pretrain] Epoch 13/100  Loss=2.0984  Acc=0.3177\n",
      "[Pretrain] Epoch 14/100  Loss=2.0520  Acc=0.3297\n",
      "[Pretrain] Epoch 15/100  Loss=2.0310  Acc=0.3341\n",
      "[Pretrain] Epoch 16/100  Loss=2.0110  Acc=0.3425\n",
      "[Pretrain] Epoch 17/100  Loss=1.9658  Acc=0.3594\n",
      "[Pretrain] Epoch 18/100  Loss=1.9396  Acc=0.3666\n",
      "[Pretrain] Epoch 19/100  Loss=1.9253  Acc=0.3667\n",
      "[Pretrain] Epoch 20/100  Loss=1.8869  Acc=0.3851\n",
      "[Pretrain] Epoch 21/100  Loss=1.8698  Acc=0.3903\n",
      "[Pretrain] Epoch 22/100  Loss=1.8363  Acc=0.4045\n",
      "[Pretrain] Epoch 23/100  Loss=1.8138  Acc=0.4054\n",
      "[Pretrain] Epoch 24/100  Loss=1.7918  Acc=0.4167\n",
      "[Pretrain] Epoch 25/100  Loss=1.7735  Acc=0.4217\n",
      "[Pretrain] Epoch 26/100  Loss=1.7261  Acc=0.4300\n",
      "[Pretrain] Epoch 27/100  Loss=1.7374  Acc=0.4278\n",
      "[Pretrain] Epoch 28/100  Loss=1.6757  Acc=0.4533\n",
      "[Pretrain] Epoch 29/100  Loss=1.6709  Acc=0.4585\n",
      "[Pretrain] Epoch 30/100  Loss=1.6447  Acc=0.4598\n",
      "[Pretrain] Epoch 31/100  Loss=1.6183  Acc=0.4632\n",
      "[Pretrain] Epoch 32/100  Loss=1.5950  Acc=0.4747\n",
      "[Pretrain] Epoch 33/100  Loss=1.5685  Acc=0.4908\n",
      "[Pretrain] Epoch 34/100  Loss=1.5703  Acc=0.4837\n",
      "[Pretrain] Epoch 35/100  Loss=1.5398  Acc=0.4995\n",
      "[Pretrain] Epoch 36/100  Loss=1.5082  Acc=0.5104\n",
      "[Pretrain] Epoch 37/100  Loss=1.5087  Acc=0.5065\n",
      "[Pretrain] Epoch 38/100  Loss=1.4873  Acc=0.5142\n",
      "[Pretrain] Epoch 39/100  Loss=1.4661  Acc=0.5135\n",
      "[Pretrain] Epoch 40/100  Loss=1.4500  Acc=0.5273\n",
      "[Pretrain] Epoch 41/100  Loss=1.4476  Acc=0.5226\n",
      "[Pretrain] Epoch 42/100  Loss=1.4032  Acc=0.5424\n",
      "[Pretrain] Epoch 43/100  Loss=1.3975  Acc=0.5431\n",
      "[Pretrain] Epoch 44/100  Loss=1.3801  Acc=0.5492\n",
      "[Pretrain] Epoch 45/100  Loss=1.3590  Acc=0.5483\n",
      "[Pretrain] Epoch 46/100  Loss=1.3348  Acc=0.5641\n",
      "[Pretrain] Epoch 47/100  Loss=1.3279  Acc=0.5666\n",
      "[Pretrain] Epoch 48/100  Loss=1.3031  Acc=0.5708\n",
      "[Pretrain] Epoch 49/100  Loss=1.3080  Acc=0.5715\n",
      "[Pretrain] Epoch 50/100  Loss=1.2956  Acc=0.5729\n",
      "[Pretrain] Epoch 51/100  Loss=1.2858  Acc=0.5869\n",
      "[Pretrain] Epoch 52/100  Loss=1.2713  Acc=0.5844\n",
      "[Pretrain] Epoch 53/100  Loss=1.2678  Acc=0.5867\n",
      "[Pretrain] Epoch 54/100  Loss=1.2669  Acc=0.5905\n",
      "[Pretrain] Epoch 55/100  Loss=1.2315  Acc=0.5981\n",
      "[Pretrain] Epoch 56/100  Loss=1.2402  Acc=0.5932\n",
      "[Pretrain] Epoch 57/100  Loss=1.2298  Acc=0.5979\n",
      "[Pretrain] Epoch 58/100  Loss=1.2180  Acc=0.5964\n",
      "[Pretrain] Epoch 59/100  Loss=1.2177  Acc=0.6000\n",
      "[Pretrain] Epoch 60/100  Loss=1.2048  Acc=0.6042\n",
      "[Pretrain] Epoch 61/100  Loss=1.2034  Acc=0.6045\n",
      "[Pretrain] Epoch 62/100  Loss=1.2001  Acc=0.6078\n",
      "[Pretrain] Epoch 63/100  Loss=1.2071  Acc=0.6047\n",
      "[Pretrain] Epoch 64/100  Loss=1.1779  Acc=0.6166\n",
      "[Pretrain] Epoch 65/100  Loss=1.1764  Acc=0.6124\n",
      "[Pretrain] Epoch 66/100  Loss=1.1828  Acc=0.6157\n",
      "[Pretrain] Epoch 67/100  Loss=1.1485  Acc=0.6191\n",
      "[Pretrain] Epoch 68/100  Loss=1.1623  Acc=0.6166\n",
      "[Pretrain] Epoch 69/100  Loss=1.1613  Acc=0.6313\n",
      "[Pretrain] Epoch 70/100  Loss=1.1473  Acc=0.6264\n",
      "[Pretrain] Epoch 71/100  Loss=1.1461  Acc=0.6210\n",
      "[Pretrain] Epoch 72/100  Loss=1.1631  Acc=0.6263\n",
      "[Pretrain] Epoch 73/100  Loss=1.1517  Acc=0.6193\n",
      "[Pretrain] Epoch 74/100  Loss=1.1343  Acc=0.6325\n",
      "[Pretrain] Epoch 75/100  Loss=1.1326  Acc=0.6291\n",
      "[Pretrain] Epoch 76/100  Loss=1.1338  Acc=0.6324\n",
      "[Pretrain] Epoch 77/100  Loss=1.1260  Acc=0.6298\n",
      "[Pretrain] Epoch 78/100  Loss=1.1126  Acc=0.6345\n",
      "[Pretrain] Epoch 79/100  Loss=1.1182  Acc=0.6360\n",
      "[Pretrain] Epoch 80/100  Loss=1.1192  Acc=0.6327\n",
      "[Pretrain] Epoch 81/100  Loss=1.1115  Acc=0.6354\n",
      "[Pretrain] Epoch 82/100  Loss=1.1107  Acc=0.6338\n",
      "[Pretrain] Epoch 83/100  Loss=1.1011  Acc=0.6446\n",
      "[Pretrain] Epoch 84/100  Loss=1.1022  Acc=0.6426\n",
      "[Pretrain] Epoch 85/100  Loss=1.1038  Acc=0.6397\n",
      "[Pretrain] Epoch 86/100  Loss=1.0883  Acc=0.6404\n",
      "[Pretrain] Epoch 87/100  Loss=1.1104  Acc=0.6365\n",
      "[Pretrain] Epoch 88/100  Loss=1.0992  Acc=0.6329\n",
      "[Pretrain] Epoch 89/100  Loss=1.1037  Acc=0.6437\n",
      "[Pretrain] Epoch 90/100  Loss=1.0968  Acc=0.6403\n",
      "[Pretrain] Epoch 91/100  Loss=1.0936  Acc=0.6388\n",
      "[Pretrain] Epoch 92/100  Loss=1.1104  Acc=0.6381\n",
      "[Pretrain] Epoch 93/100  Loss=1.0943  Acc=0.6394\n",
      "[Pretrain] Epoch 94/100  Loss=1.0964  Acc=0.6439\n",
      "[Pretrain] Epoch 95/100  Loss=1.1080  Acc=0.6431\n",
      "[Pretrain] Epoch 96/100  Loss=1.0992  Acc=0.6381\n",
      "[Pretrain] Epoch 97/100  Loss=1.0791  Acc=0.6464\n",
      "[Pretrain] Epoch 98/100  Loss=1.1002  Acc=0.6410\n",
      "[Pretrain] Epoch 99/100  Loss=1.0803  Acc=0.6496\n",
      "[Pretrain] Epoch 100/100  Loss=1.0869  Acc=0.6431\n",
      "[Fine-tune] Epoch 1/75  Loss=3.1458\n",
      "[Fine-tune] Epoch 2/75  Loss=2.6713\n",
      "[Fine-tune] Epoch 3/75  Loss=2.4534\n",
      "[Fine-tune] Epoch 4/75  Loss=2.3255\n",
      "[Fine-tune] Epoch 5/75  Loss=2.2654\n",
      "[Fine-tune] Epoch 6/75  Loss=2.1908\n",
      "[Fine-tune] Epoch 7/75  Loss=2.1745\n",
      "[Fine-tune] Epoch 8/75  Loss=2.1262\n",
      "[Fine-tune] Epoch 9/75  Loss=2.0904\n",
      "[Fine-tune] Epoch 10/75  Loss=2.0605\n",
      "[Fine-tune] Epoch 11/75  Loss=2.0268\n",
      "[Fine-tune] Epoch 12/75  Loss=2.0087\n",
      "[Fine-tune] Epoch 13/75  Loss=1.9783\n",
      "[Fine-tune] Epoch 14/75  Loss=1.9618\n",
      "[Fine-tune] Epoch 15/75  Loss=1.9561\n",
      "[Fine-tune] Epoch 16/75  Loss=1.9499\n",
      "[Fine-tune] Epoch 17/75  Loss=1.9161\n",
      "[Fine-tune] Epoch 18/75  Loss=1.9026\n",
      "[Fine-tune] Epoch 19/75  Loss=1.8854\n",
      "[Fine-tune] Epoch 20/75  Loss=1.8819\n",
      "[Fine-tune] Epoch 21/75  Loss=1.8698\n",
      "[Fine-tune] Epoch 22/75  Loss=1.8682\n",
      "[Fine-tune] Epoch 23/75  Loss=1.8469\n",
      "[Fine-tune] Epoch 24/75  Loss=1.8464\n",
      "[Fine-tune] Epoch 25/75  Loss=1.8375\n",
      "[Fine-tune] Epoch 26/75  Loss=1.8155\n",
      "[Fine-tune] Epoch 27/75  Loss=1.8171\n",
      "[Fine-tune] Epoch 28/75  Loss=1.8159\n",
      "[Fine-tune] Epoch 29/75  Loss=1.8031\n",
      "[Fine-tune] Epoch 30/75  Loss=1.7944\n",
      "[Fine-tune] Epoch 31/75  Loss=1.7831\n",
      "[Fine-tune] Epoch 32/75  Loss=1.7857\n",
      "[Fine-tune] Epoch 33/75  Loss=1.7723\n",
      "[Fine-tune] Epoch 34/75  Loss=1.7672\n",
      "[Fine-tune] Epoch 35/75  Loss=1.7507\n",
      "[Fine-tune] Epoch 36/75  Loss=1.7568\n",
      "[Fine-tune] Epoch 37/75  Loss=1.7601\n",
      "[Fine-tune] Epoch 38/75  Loss=1.7458\n",
      "[Fine-tune] Epoch 39/75  Loss=1.7493\n",
      "[Fine-tune] Epoch 40/75  Loss=1.7471\n",
      "[Fine-tune] Epoch 41/75  Loss=1.7316\n",
      "[Fine-tune] Epoch 42/75  Loss=1.7483\n",
      "[Fine-tune] Epoch 43/75  Loss=1.7376\n",
      "[Fine-tune] Epoch 44/75  Loss=1.7139\n",
      "[Fine-tune] Epoch 45/75  Loss=1.7326\n",
      "[Fine-tune] Epoch 46/75  Loss=1.7277\n",
      "[Fine-tune] Epoch 47/75  Loss=1.7273\n",
      "[Fine-tune] Epoch 48/75  Loss=1.7137\n",
      "[Fine-tune] Epoch 49/75  Loss=1.7212\n",
      "[Fine-tune] Epoch 50/75  Loss=1.7034\n",
      "[Fine-tune] Epoch 51/75  Loss=1.7103\n",
      "[Fine-tune] Epoch 52/75  Loss=1.7223\n",
      "[Fine-tune] Epoch 53/75  Loss=1.7042\n",
      "[Fine-tune] Epoch 54/75  Loss=1.7049\n",
      "[Fine-tune] Epoch 55/75  Loss=1.7024\n",
      "[Fine-tune] Epoch 56/75  Loss=1.7098\n",
      "[Fine-tune] Epoch 57/75  Loss=1.7043\n",
      "[Fine-tune] Epoch 58/75  Loss=1.6858\n",
      "[Fine-tune] Epoch 59/75  Loss=1.7037\n",
      "[Fine-tune] Epoch 60/75  Loss=1.6937\n",
      "[Fine-tune] Epoch 61/75  Loss=1.6908\n",
      "[Fine-tune] Epoch 62/75  Loss=1.6869\n",
      "[Fine-tune] Epoch 63/75  Loss=1.6998\n",
      "[Fine-tune] Epoch 64/75  Loss=1.6858\n",
      "[Fine-tune] Epoch 65/75  Loss=1.6946\n",
      "[Fine-tune] Epoch 66/75  Loss=1.6903\n",
      "[Fine-tune] Epoch 67/75  Loss=1.6912\n",
      "[Fine-tune] Epoch 68/75  Loss=1.6897\n",
      "[Fine-tune] Epoch 69/75  Loss=1.6839\n",
      "[Fine-tune] Epoch 70/75  Loss=1.6874\n",
      "[Fine-tune] Epoch 71/75  Loss=1.6852\n",
      "[Fine-tune] Epoch 72/75  Loss=1.6911\n",
      "[Fine-tune] Epoch 73/75  Loss=1.6850\n",
      "[Fine-tune] Epoch 74/75  Loss=1.6712\n",
      "[Fine-tune] Epoch 75/75  Loss=1.6858\n",
      "[Pretrain] Epoch 1/150  Loss=3.2575  Acc=0.0402\n",
      "[Pretrain] Epoch 2/150  Loss=3.1147  Acc=0.0688\n",
      "[Pretrain] Epoch 3/150  Loss=3.0499  Acc=0.0848\n",
      "[Pretrain] Epoch 4/150  Loss=3.0170  Acc=0.0929\n",
      "[Pretrain] Epoch 5/150  Loss=2.9237  Acc=0.1245\n",
      "[Pretrain] Epoch 6/150  Loss=2.7642  Acc=0.1478\n",
      "[Pretrain] Epoch 7/150  Loss=2.4515  Acc=0.2175\n",
      "[Pretrain] Epoch 8/150  Loss=2.3132  Acc=0.2575\n",
      "[Pretrain] Epoch 9/150  Loss=2.1913  Acc=0.2967\n",
      "[Pretrain] Epoch 10/150  Loss=2.1183  Acc=0.3125\n",
      "[Pretrain] Epoch 11/150  Loss=2.0642  Acc=0.3314\n",
      "[Pretrain] Epoch 12/150  Loss=2.0127  Acc=0.3502\n",
      "[Pretrain] Epoch 13/150  Loss=1.9882  Acc=0.3549\n",
      "[Pretrain] Epoch 14/150  Loss=1.9528  Acc=0.3728\n",
      "[Pretrain] Epoch 15/150  Loss=1.9133  Acc=0.3829\n",
      "[Pretrain] Epoch 16/150  Loss=1.8812  Acc=0.3926\n",
      "[Pretrain] Epoch 17/150  Loss=1.8461  Acc=0.4059\n",
      "[Pretrain] Epoch 18/150  Loss=1.8276  Acc=0.4100\n",
      "[Pretrain] Epoch 19/150  Loss=1.8181  Acc=0.4142\n",
      "[Pretrain] Epoch 20/150  Loss=1.7745  Acc=0.4251\n",
      "[Pretrain] Epoch 21/150  Loss=1.7702  Acc=0.4237\n",
      "[Pretrain] Epoch 22/150  Loss=1.7574  Acc=0.4294\n",
      "[Pretrain] Epoch 23/150  Loss=1.7083  Acc=0.4432\n",
      "[Pretrain] Epoch 24/150  Loss=1.6957  Acc=0.4533\n",
      "[Pretrain] Epoch 25/150  Loss=1.6890  Acc=0.4538\n",
      "[Pretrain] Epoch 26/150  Loss=1.6633  Acc=0.4644\n",
      "[Pretrain] Epoch 27/150  Loss=1.6560  Acc=0.4635\n",
      "[Pretrain] Epoch 28/150  Loss=1.6425  Acc=0.4738\n",
      "[Pretrain] Epoch 29/150  Loss=1.6281  Acc=0.4713\n",
      "[Pretrain] Epoch 30/150  Loss=1.5901  Acc=0.4808\n",
      "[Pretrain] Epoch 31/150  Loss=1.5853  Acc=0.4858\n",
      "[Pretrain] Epoch 32/150  Loss=1.5458  Acc=0.4962\n",
      "[Pretrain] Epoch 33/150  Loss=1.5660  Acc=0.4934\n",
      "[Pretrain] Epoch 34/150  Loss=1.5501  Acc=0.5000\n",
      "[Pretrain] Epoch 35/150  Loss=1.5346  Acc=0.4982\n",
      "[Pretrain] Epoch 36/150  Loss=1.5348  Acc=0.5045\n",
      "[Pretrain] Epoch 37/150  Loss=1.4982  Acc=0.5149\n",
      "[Pretrain] Epoch 38/150  Loss=1.5114  Acc=0.5101\n",
      "[Pretrain] Epoch 39/150  Loss=1.4900  Acc=0.5162\n",
      "[Pretrain] Epoch 40/150  Loss=1.4772  Acc=0.5210\n",
      "[Pretrain] Epoch 41/150  Loss=1.4640  Acc=0.5228\n",
      "[Pretrain] Epoch 42/150  Loss=1.4591  Acc=0.5314\n",
      "[Pretrain] Epoch 43/150  Loss=1.4463  Acc=0.5300\n",
      "[Pretrain] Epoch 44/150  Loss=1.4460  Acc=0.5295\n",
      "[Pretrain] Epoch 45/150  Loss=1.4312  Acc=0.5277\n",
      "[Pretrain] Epoch 46/150  Loss=1.4190  Acc=0.5397\n",
      "[Pretrain] Epoch 47/150  Loss=1.4271  Acc=0.5296\n",
      "[Pretrain] Epoch 48/150  Loss=1.4031  Acc=0.5348\n",
      "[Pretrain] Epoch 49/150  Loss=1.3997  Acc=0.5524\n",
      "[Pretrain] Epoch 50/150  Loss=1.3828  Acc=0.5517\n",
      "[Pretrain] Epoch 51/150  Loss=1.3867  Acc=0.5524\n",
      "[Pretrain] Epoch 52/150  Loss=1.4035  Acc=0.5489\n",
      "[Pretrain] Epoch 53/150  Loss=1.3732  Acc=0.5476\n",
      "[Pretrain] Epoch 54/150  Loss=1.3806  Acc=0.5481\n",
      "[Pretrain] Epoch 55/150  Loss=1.3660  Acc=0.5638\n",
      "[Pretrain] Epoch 56/150  Loss=1.3614  Acc=0.5571\n",
      "[Pretrain] Epoch 57/150  Loss=1.3559  Acc=0.5587\n",
      "[Pretrain] Epoch 58/150  Loss=1.3536  Acc=0.5557\n",
      "[Pretrain] Epoch 59/150  Loss=1.3461  Acc=0.5647\n",
      "[Pretrain] Epoch 60/150  Loss=1.3389  Acc=0.5636\n",
      "[Pretrain] Epoch 61/150  Loss=1.3477  Acc=0.5652\n",
      "[Pretrain] Epoch 62/150  Loss=1.3410  Acc=0.5659\n",
      "[Pretrain] Epoch 63/150  Loss=1.3274  Acc=0.5645\n",
      "[Pretrain] Epoch 64/150  Loss=1.3223  Acc=0.5650\n",
      "[Pretrain] Epoch 65/150  Loss=1.3365  Acc=0.5704\n",
      "[Pretrain] Epoch 66/150  Loss=1.3214  Acc=0.5704\n",
      "[Pretrain] Epoch 67/150  Loss=1.3318  Acc=0.5709\n",
      "[Pretrain] Epoch 68/150  Loss=1.3346  Acc=0.5652\n",
      "[Pretrain] Epoch 69/150  Loss=1.3261  Acc=0.5650\n",
      "[Pretrain] Epoch 70/150  Loss=1.3211  Acc=0.5733\n",
      "[Pretrain] Epoch 71/150  Loss=1.3118  Acc=0.5722\n",
      "[Pretrain] Epoch 72/150  Loss=1.3245  Acc=0.5682\n",
      "[Pretrain] Epoch 73/150  Loss=1.3255  Acc=0.5654\n",
      "[Pretrain] Epoch 74/150  Loss=1.3201  Acc=0.5718\n",
      "[Pretrain] Epoch 75/150  Loss=1.3101  Acc=0.5724\n",
      "[Pretrain] Epoch 76/150  Loss=1.3113  Acc=0.5709\n",
      "[Pretrain] Epoch 77/150  Loss=1.3028  Acc=0.5697\n",
      "[Pretrain] Epoch 78/150  Loss=1.3075  Acc=0.5731\n",
      "[Pretrain] Epoch 79/150  Loss=1.3001  Acc=0.5830\n",
      "[Pretrain] Epoch 80/150  Loss=1.3004  Acc=0.5747\n",
      "[Pretrain] Epoch 81/150  Loss=1.2958  Acc=0.5738\n",
      "[Pretrain] Epoch 82/150  Loss=1.2914  Acc=0.5729\n",
      "[Pretrain] Epoch 83/150  Loss=1.3008  Acc=0.5727\n",
      "[Pretrain] Epoch 84/150  Loss=1.2849  Acc=0.5849\n",
      "[Pretrain] Epoch 85/150  Loss=1.2902  Acc=0.5819\n",
      "[Pretrain] Epoch 86/150  Loss=1.3040  Acc=0.5753\n",
      "[Pretrain] Epoch 87/150  Loss=1.2706  Acc=0.5866\n",
      "[Pretrain] Epoch 88/150  Loss=1.3000  Acc=0.5745\n",
      "[Pretrain] Epoch 89/150  Loss=1.2847  Acc=0.5871\n",
      "[Pretrain] Epoch 90/150  Loss=1.2731  Acc=0.5896\n",
      "[Pretrain] Epoch 91/150  Loss=1.2847  Acc=0.5837\n",
      "[Pretrain] Epoch 92/150  Loss=1.2988  Acc=0.5785\n",
      "[Pretrain] Epoch 93/150  Loss=1.2906  Acc=0.5837\n",
      "[Pretrain] Epoch 94/150  Loss=1.2897  Acc=0.5808\n",
      "[Pretrain] Epoch 95/150  Loss=1.2910  Acc=0.5740\n",
      "[Pretrain] Epoch 96/150  Loss=1.2770  Acc=0.5855\n",
      "[Pretrain] Epoch 97/150  Loss=1.2936  Acc=0.5812\n",
      "[Pretrain] Epoch 98/150  Loss=1.2713  Acc=0.5844\n",
      "[Pretrain] Epoch 99/150  Loss=1.2853  Acc=0.5770\n",
      "[Pretrain] Epoch 100/150  Loss=1.2634  Acc=0.5862\n",
      "[Pretrain] Epoch 101/150  Loss=1.2679  Acc=0.5880\n",
      "[Pretrain] Epoch 102/150  Loss=1.2928  Acc=0.5760\n",
      "[Pretrain] Epoch 103/150  Loss=1.2755  Acc=0.5911\n",
      "[Pretrain] Epoch 104/150  Loss=1.2797  Acc=0.5812\n",
      "[Pretrain] Epoch 105/150  Loss=1.2855  Acc=0.5765\n",
      "[Pretrain] Epoch 106/150  Loss=1.2836  Acc=0.5819\n",
      "[Pretrain] Epoch 107/150  Loss=1.2796  Acc=0.5806\n",
      "[Pretrain] Epoch 108/150  Loss=1.2659  Acc=0.5848\n",
      "[Pretrain] Epoch 109/150  Loss=1.2931  Acc=0.5844\n",
      "[Pretrain] Epoch 110/150  Loss=1.2768  Acc=0.5884\n",
      "[Pretrain] Epoch 111/150  Loss=1.2602  Acc=0.5918\n",
      "[Pretrain] Epoch 112/150  Loss=1.2720  Acc=0.5923\n",
      "[Pretrain] Epoch 113/150  Loss=1.2597  Acc=0.5941\n",
      "[Pretrain] Epoch 114/150  Loss=1.2820  Acc=0.5774\n",
      "[Pretrain] Epoch 115/150  Loss=1.2848  Acc=0.5794\n",
      "[Pretrain] Epoch 116/150  Loss=1.2781  Acc=0.5839\n",
      "[Pretrain] Epoch 117/150  Loss=1.2812  Acc=0.5844\n",
      "[Pretrain] Epoch 118/150  Loss=1.2858  Acc=0.5841\n",
      "[Pretrain] Epoch 119/150  Loss=1.2776  Acc=0.5810\n",
      "[Pretrain] Epoch 120/150  Loss=1.2703  Acc=0.5884\n",
      "[Pretrain] Epoch 121/150  Loss=1.2828  Acc=0.5833\n",
      "[Pretrain] Epoch 122/150  Loss=1.2762  Acc=0.5842\n",
      "[Pretrain] Epoch 123/150  Loss=1.2751  Acc=0.5794\n",
      "[Pretrain] Epoch 124/150  Loss=1.2769  Acc=0.5765\n",
      "[Pretrain] Epoch 125/150  Loss=1.2606  Acc=0.5884\n",
      "[Pretrain] Epoch 126/150  Loss=1.2755  Acc=0.5869\n",
      "[Pretrain] Epoch 127/150  Loss=1.2817  Acc=0.5788\n",
      "[Pretrain] Epoch 128/150  Loss=1.2673  Acc=0.5864\n",
      "[Pretrain] Epoch 129/150  Loss=1.2719  Acc=0.5805\n",
      "[Pretrain] Epoch 130/150  Loss=1.2878  Acc=0.5785\n",
      "[Pretrain] Epoch 131/150  Loss=1.2734  Acc=0.5833\n",
      "[Pretrain] Epoch 132/150  Loss=1.2815  Acc=0.5819\n",
      "[Pretrain] Epoch 133/150  Loss=1.2756  Acc=0.5810\n",
      "[Pretrain] Epoch 134/150  Loss=1.2687  Acc=0.5860\n",
      "[Pretrain] Epoch 135/150  Loss=1.2758  Acc=0.5876\n",
      "[Pretrain] Epoch 136/150  Loss=1.2760  Acc=0.5815\n",
      "[Pretrain] Epoch 137/150  Loss=1.2623  Acc=0.5887\n",
      "[Pretrain] Epoch 138/150  Loss=1.2625  Acc=0.5884\n",
      "[Pretrain] Epoch 139/150  Loss=1.2829  Acc=0.5828\n",
      "[Pretrain] Epoch 140/150  Loss=1.2727  Acc=0.5761\n",
      "[Pretrain] Epoch 141/150  Loss=1.2740  Acc=0.5824\n",
      "[Pretrain] Epoch 142/150  Loss=1.2751  Acc=0.5796\n",
      "[Pretrain] Epoch 143/150  Loss=1.2718  Acc=0.5819\n",
      "[Pretrain] Epoch 144/150  Loss=1.2751  Acc=0.5880\n",
      "[Pretrain] Epoch 145/150  Loss=1.2737  Acc=0.5849\n",
      "[Pretrain] Epoch 146/150  Loss=1.2774  Acc=0.5830\n",
      "[Pretrain] Epoch 147/150  Loss=1.2666  Acc=0.5821\n",
      "[Pretrain] Epoch 148/150  Loss=1.2774  Acc=0.5871\n",
      "[Pretrain] Epoch 149/150  Loss=1.2778  Acc=0.5848\n",
      "[Pretrain] Epoch 150/150  Loss=1.2827  Acc=0.5839\n",
      "[Fine-tune] Epoch 1/75  Loss=2.7152\n",
      "[Fine-tune] Epoch 2/75  Loss=2.2313\n",
      "[Fine-tune] Epoch 3/75  Loss=2.0838\n",
      "[Fine-tune] Epoch 4/75  Loss=1.9641\n",
      "[Fine-tune] Epoch 5/75  Loss=1.9000\n",
      "[Fine-tune] Epoch 6/75  Loss=1.8040\n",
      "[Fine-tune] Epoch 7/75  Loss=1.7791\n",
      "[Fine-tune] Epoch 8/75  Loss=1.7393\n",
      "[Fine-tune] Epoch 9/75  Loss=1.6908\n",
      "[Fine-tune] Epoch 10/75  Loss=1.6439\n",
      "[Fine-tune] Epoch 11/75  Loss=1.6181\n",
      "[Fine-tune] Epoch 12/75  Loss=1.5695\n",
      "[Fine-tune] Epoch 13/75  Loss=1.5410\n",
      "[Fine-tune] Epoch 14/75  Loss=1.5024\n",
      "[Fine-tune] Epoch 15/75  Loss=1.4676\n",
      "[Fine-tune] Epoch 16/75  Loss=1.4468\n",
      "[Fine-tune] Epoch 17/75  Loss=1.4213\n",
      "[Fine-tune] Epoch 18/75  Loss=1.4099\n",
      "[Fine-tune] Epoch 19/75  Loss=1.3798\n",
      "[Fine-tune] Epoch 20/75  Loss=1.3563\n",
      "[Fine-tune] Epoch 21/75  Loss=1.3301\n",
      "[Fine-tune] Epoch 22/75  Loss=1.2904\n",
      "[Fine-tune] Epoch 23/75  Loss=1.2923\n",
      "[Fine-tune] Epoch 24/75  Loss=1.2683\n",
      "[Fine-tune] Epoch 25/75  Loss=1.2462\n",
      "[Fine-tune] Epoch 26/75  Loss=1.2232\n",
      "[Fine-tune] Epoch 27/75  Loss=1.2167\n",
      "[Fine-tune] Epoch 28/75  Loss=1.2064\n",
      "[Fine-tune] Epoch 29/75  Loss=1.1846\n",
      "[Fine-tune] Epoch 30/75  Loss=1.1617\n",
      "[Fine-tune] Epoch 31/75  Loss=1.1518\n",
      "[Fine-tune] Epoch 32/75  Loss=1.1324\n",
      "[Fine-tune] Epoch 33/75  Loss=1.1315\n",
      "[Fine-tune] Epoch 34/75  Loss=1.1094\n",
      "[Fine-tune] Epoch 35/75  Loss=1.1028\n",
      "[Fine-tune] Epoch 36/75  Loss=1.1025\n",
      "[Fine-tune] Epoch 37/75  Loss=1.0848\n",
      "[Fine-tune] Epoch 38/75  Loss=1.0780\n",
      "[Fine-tune] Epoch 39/75  Loss=1.0755\n",
      "[Fine-tune] Epoch 40/75  Loss=1.0685\n",
      "[Fine-tune] Epoch 41/75  Loss=1.0582\n",
      "[Fine-tune] Epoch 42/75  Loss=1.0470\n",
      "[Fine-tune] Epoch 43/75  Loss=1.0432\n",
      "[Fine-tune] Epoch 44/75  Loss=1.0427\n",
      "[Fine-tune] Epoch 45/75  Loss=1.0321\n",
      "[Fine-tune] Epoch 46/75  Loss=1.0174\n",
      "[Fine-tune] Epoch 47/75  Loss=1.0220\n",
      "[Fine-tune] Epoch 48/75  Loss=1.0062\n",
      "[Fine-tune] Epoch 49/75  Loss=1.0038\n",
      "[Fine-tune] Epoch 50/75  Loss=0.9970\n",
      "[Fine-tune] Epoch 51/75  Loss=1.0026\n",
      "[Fine-tune] Epoch 52/75  Loss=0.9919\n",
      "[Fine-tune] Epoch 53/75  Loss=0.9915\n",
      "[Fine-tune] Epoch 54/75  Loss=0.9703\n",
      "[Fine-tune] Epoch 55/75  Loss=0.9731\n",
      "[Fine-tune] Epoch 56/75  Loss=0.9745\n",
      "[Fine-tune] Epoch 57/75  Loss=0.9657\n",
      "[Fine-tune] Epoch 58/75  Loss=0.9572\n",
      "[Fine-tune] Epoch 59/75  Loss=0.9724\n",
      "[Fine-tune] Epoch 60/75  Loss=0.9683\n",
      "[Fine-tune] Epoch 61/75  Loss=0.9486\n",
      "[Fine-tune] Epoch 62/75  Loss=0.9555\n",
      "[Fine-tune] Epoch 63/75  Loss=0.9556\n",
      "[Fine-tune] Epoch 64/75  Loss=0.9502\n",
      "[Fine-tune] Epoch 65/75  Loss=0.9694\n",
      "[Fine-tune] Epoch 66/75  Loss=0.9427\n",
      "[Fine-tune] Epoch 67/75  Loss=0.9399\n",
      "[Fine-tune] Epoch 68/75  Loss=0.9478\n",
      "[Fine-tune] Epoch 69/75  Loss=0.9401\n",
      "[Fine-tune] Epoch 70/75  Loss=0.9365\n",
      "[Fine-tune] Epoch 71/75  Loss=0.9520\n",
      "[Fine-tune] Epoch 72/75  Loss=0.9506\n",
      "[Fine-tune] Epoch 73/75  Loss=0.9497\n",
      "[Fine-tune] Epoch 74/75  Loss=0.9405\n",
      "[Fine-tune] Epoch 75/75  Loss=0.9364\n",
      "[Pretrain] Epoch 1/150  Loss=3.6335  Acc=0.0449\n",
      "[Pretrain] Epoch 2/150  Loss=3.1374  Acc=0.0647\n",
      "[Pretrain] Epoch 3/150  Loss=3.0511  Acc=0.0862\n",
      "[Pretrain] Epoch 4/150  Loss=2.9578  Acc=0.1119\n",
      "[Pretrain] Epoch 5/150  Loss=2.8204  Acc=0.1399\n",
      "[Pretrain] Epoch 6/150  Loss=2.6022  Acc=0.1695\n",
      "[Pretrain] Epoch 7/150  Loss=2.4819  Acc=0.2028\n",
      "[Pretrain] Epoch 8/150  Loss=2.3641  Acc=0.2344\n",
      "[Pretrain] Epoch 9/150  Loss=2.3125  Acc=0.2484\n",
      "[Pretrain] Epoch 10/150  Loss=2.2513  Acc=0.2710\n",
      "[Pretrain] Epoch 11/150  Loss=2.1900  Acc=0.2816\n",
      "[Pretrain] Epoch 12/150  Loss=2.1376  Acc=0.2987\n",
      "[Pretrain] Epoch 13/150  Loss=2.1308  Acc=0.3156\n",
      "[Pretrain] Epoch 14/150  Loss=2.0985  Acc=0.3163\n",
      "[Pretrain] Epoch 15/150  Loss=2.0591  Acc=0.3267\n",
      "[Pretrain] Epoch 16/150  Loss=2.0228  Acc=0.3376\n",
      "[Pretrain] Epoch 17/150  Loss=1.9622  Acc=0.3664\n",
      "[Pretrain] Epoch 18/150  Loss=1.9540  Acc=0.3526\n",
      "[Pretrain] Epoch 19/150  Loss=1.9151  Acc=0.3721\n",
      "[Pretrain] Epoch 20/150  Loss=1.8909  Acc=0.3818\n",
      "[Pretrain] Epoch 21/150  Loss=1.8828  Acc=0.3885\n",
      "[Pretrain] Epoch 22/150  Loss=1.8410  Acc=0.3983\n",
      "[Pretrain] Epoch 23/150  Loss=1.8122  Acc=0.3983\n",
      "[Pretrain] Epoch 24/150  Loss=1.8033  Acc=0.4107\n",
      "[Pretrain] Epoch 25/150  Loss=1.7823  Acc=0.4170\n",
      "[Pretrain] Epoch 26/150  Loss=1.7550  Acc=0.4337\n",
      "[Pretrain] Epoch 27/150  Loss=1.7233  Acc=0.4427\n",
      "[Pretrain] Epoch 28/150  Loss=1.7150  Acc=0.4395\n",
      "[Pretrain] Epoch 29/150  Loss=1.6890  Acc=0.4510\n",
      "[Pretrain] Epoch 30/150  Loss=1.6936  Acc=0.4508\n",
      "[Pretrain] Epoch 31/150  Loss=1.6522  Acc=0.4580\n",
      "[Pretrain] Epoch 32/150  Loss=1.6197  Acc=0.4637\n",
      "[Pretrain] Epoch 33/150  Loss=1.6060  Acc=0.4765\n",
      "[Pretrain] Epoch 34/150  Loss=1.5806  Acc=0.4786\n",
      "[Pretrain] Epoch 35/150  Loss=1.5655  Acc=0.4898\n",
      "[Pretrain] Epoch 36/150  Loss=1.5373  Acc=0.4937\n",
      "[Pretrain] Epoch 37/150  Loss=1.5387  Acc=0.4957\n",
      "[Pretrain] Epoch 38/150  Loss=1.5139  Acc=0.5065\n",
      "[Pretrain] Epoch 39/150  Loss=1.4931  Acc=0.5160\n",
      "[Pretrain] Epoch 40/150  Loss=1.4887  Acc=0.5108\n",
      "[Pretrain] Epoch 41/150  Loss=1.4917  Acc=0.5077\n",
      "[Pretrain] Epoch 42/150  Loss=1.4528  Acc=0.5178\n",
      "[Pretrain] Epoch 43/150  Loss=1.4364  Acc=0.5278\n",
      "[Pretrain] Epoch 44/150  Loss=1.4226  Acc=0.5305\n",
      "[Pretrain] Epoch 45/150  Loss=1.4056  Acc=0.5417\n",
      "[Pretrain] Epoch 46/150  Loss=1.4132  Acc=0.5347\n",
      "[Pretrain] Epoch 47/150  Loss=1.3741  Acc=0.5454\n",
      "[Pretrain] Epoch 48/150  Loss=1.3743  Acc=0.5535\n",
      "[Pretrain] Epoch 49/150  Loss=1.3722  Acc=0.5562\n",
      "[Pretrain] Epoch 50/150  Loss=1.3413  Acc=0.5568\n",
      "[Pretrain] Epoch 51/150  Loss=1.3333  Acc=0.5616\n",
      "[Pretrain] Epoch 52/150  Loss=1.3336  Acc=0.5557\n",
      "[Pretrain] Epoch 53/150  Loss=1.3189  Acc=0.5656\n",
      "[Pretrain] Epoch 54/150  Loss=1.3011  Acc=0.5688\n",
      "[Pretrain] Epoch 55/150  Loss=1.3014  Acc=0.5738\n",
      "[Pretrain] Epoch 56/150  Loss=1.2869  Acc=0.5756\n",
      "[Pretrain] Epoch 57/150  Loss=1.2815  Acc=0.5815\n",
      "[Pretrain] Epoch 58/150  Loss=1.2704  Acc=0.5866\n",
      "[Pretrain] Epoch 59/150  Loss=1.2690  Acc=0.5866\n",
      "[Pretrain] Epoch 60/150  Loss=1.2619  Acc=0.5792\n",
      "[Pretrain] Epoch 61/150  Loss=1.2562  Acc=0.5918\n",
      "[Pretrain] Epoch 62/150  Loss=1.2516  Acc=0.5841\n",
      "[Pretrain] Epoch 63/150  Loss=1.2468  Acc=0.5891\n",
      "[Pretrain] Epoch 64/150  Loss=1.2419  Acc=0.5925\n",
      "[Pretrain] Epoch 65/150  Loss=1.2156  Acc=0.6024\n",
      "[Pretrain] Epoch 66/150  Loss=1.2191  Acc=0.5955\n",
      "[Pretrain] Epoch 67/150  Loss=1.2274  Acc=0.5981\n",
      "[Pretrain] Epoch 68/150  Loss=1.2136  Acc=0.5973\n",
      "[Pretrain] Epoch 69/150  Loss=1.2047  Acc=0.6058\n",
      "[Pretrain] Epoch 70/150  Loss=1.2131  Acc=0.6009\n",
      "[Pretrain] Epoch 71/150  Loss=1.2024  Acc=0.6074\n",
      "[Pretrain] Epoch 72/150  Loss=1.2175  Acc=0.5975\n",
      "[Pretrain] Epoch 73/150  Loss=1.1948  Acc=0.6051\n",
      "[Pretrain] Epoch 74/150  Loss=1.1785  Acc=0.6114\n",
      "[Pretrain] Epoch 75/150  Loss=1.1979  Acc=0.6060\n",
      "[Pretrain] Epoch 76/150  Loss=1.1721  Acc=0.6166\n",
      "[Pretrain] Epoch 77/150  Loss=1.1720  Acc=0.6063\n",
      "[Pretrain] Epoch 78/150  Loss=1.1770  Acc=0.6160\n",
      "[Pretrain] Epoch 79/150  Loss=1.1629  Acc=0.6114\n",
      "[Pretrain] Epoch 80/150  Loss=1.1876  Acc=0.6088\n",
      "[Pretrain] Epoch 81/150  Loss=1.1816  Acc=0.6083\n",
      "[Pretrain] Epoch 82/150  Loss=1.1775  Acc=0.6122\n",
      "[Pretrain] Epoch 83/150  Loss=1.1804  Acc=0.6034\n",
      "[Pretrain] Epoch 84/150  Loss=1.1532  Acc=0.6259\n",
      "[Pretrain] Epoch 85/150  Loss=1.1661  Acc=0.6106\n",
      "[Pretrain] Epoch 86/150  Loss=1.1519  Acc=0.6236\n",
      "[Pretrain] Epoch 87/150  Loss=1.1565  Acc=0.6219\n",
      "[Pretrain] Epoch 88/150  Loss=1.1611  Acc=0.6175\n",
      "[Pretrain] Epoch 89/150  Loss=1.1580  Acc=0.6160\n",
      "[Pretrain] Epoch 90/150  Loss=1.1453  Acc=0.6246\n",
      "[Pretrain] Epoch 91/150  Loss=1.1584  Acc=0.6184\n",
      "[Pretrain] Epoch 92/150  Loss=1.1597  Acc=0.6202\n",
      "[Pretrain] Epoch 93/150  Loss=1.1311  Acc=0.6273\n",
      "[Pretrain] Epoch 94/150  Loss=1.1582  Acc=0.6171\n",
      "[Pretrain] Epoch 95/150  Loss=1.1469  Acc=0.6239\n",
      "[Pretrain] Epoch 96/150  Loss=1.1454  Acc=0.6239\n",
      "[Pretrain] Epoch 97/150  Loss=1.1541  Acc=0.6200\n",
      "[Pretrain] Epoch 98/150  Loss=1.1467  Acc=0.6173\n",
      "[Pretrain] Epoch 99/150  Loss=1.1497  Acc=0.6167\n",
      "[Pretrain] Epoch 100/150  Loss=1.1397  Acc=0.6304\n",
      "[Pretrain] Epoch 101/150  Loss=1.1353  Acc=0.6313\n",
      "[Pretrain] Epoch 102/150  Loss=1.1414  Acc=0.6264\n",
      "[Pretrain] Epoch 103/150  Loss=1.1469  Acc=0.6209\n",
      "[Pretrain] Epoch 104/150  Loss=1.1397  Acc=0.6200\n",
      "[Pretrain] Epoch 105/150  Loss=1.1325  Acc=0.6316\n",
      "[Pretrain] Epoch 106/150  Loss=1.1493  Acc=0.6255\n",
      "[Pretrain] Epoch 107/150  Loss=1.1507  Acc=0.6232\n",
      "[Pretrain] Epoch 108/150  Loss=1.1291  Acc=0.6230\n",
      "[Pretrain] Epoch 109/150  Loss=1.1463  Acc=0.6219\n",
      "[Pretrain] Epoch 110/150  Loss=1.1264  Acc=0.6304\n",
      "[Pretrain] Epoch 111/150  Loss=1.1430  Acc=0.6221\n",
      "[Pretrain] Epoch 112/150  Loss=1.1294  Acc=0.6282\n",
      "[Pretrain] Epoch 113/150  Loss=1.1258  Acc=0.6232\n",
      "[Pretrain] Epoch 114/150  Loss=1.1370  Acc=0.6241\n",
      "[Pretrain] Epoch 115/150  Loss=1.1331  Acc=0.6212\n",
      "[Pretrain] Epoch 116/150  Loss=1.1446  Acc=0.6234\n",
      "[Pretrain] Epoch 117/150  Loss=1.1374  Acc=0.6246\n",
      "[Pretrain] Epoch 118/150  Loss=1.1393  Acc=0.6246\n",
      "[Pretrain] Epoch 119/150  Loss=1.1418  Acc=0.6191\n",
      "[Pretrain] Epoch 120/150  Loss=1.1269  Acc=0.6338\n",
      "[Pretrain] Epoch 121/150  Loss=1.1393  Acc=0.6216\n",
      "[Pretrain] Epoch 122/150  Loss=1.1451  Acc=0.6291\n",
      "[Pretrain] Epoch 123/150  Loss=1.1309  Acc=0.6272\n",
      "[Pretrain] Epoch 124/150  Loss=1.1350  Acc=0.6241\n",
      "[Pretrain] Epoch 125/150  Loss=1.1254  Acc=0.6327\n",
      "[Pretrain] Epoch 126/150  Loss=1.1211  Acc=0.6372\n",
      "[Pretrain] Epoch 127/150  Loss=1.1319  Acc=0.6286\n",
      "[Pretrain] Epoch 128/150  Loss=1.1290  Acc=0.6282\n",
      "[Pretrain] Epoch 129/150  Loss=1.1499  Acc=0.6167\n",
      "[Pretrain] Epoch 130/150  Loss=1.1319  Acc=0.6243\n",
      "[Pretrain] Epoch 131/150  Loss=1.1414  Acc=0.6288\n",
      "[Pretrain] Epoch 132/150  Loss=1.1252  Acc=0.6237\n",
      "[Pretrain] Epoch 133/150  Loss=1.1282  Acc=0.6250\n",
      "[Pretrain] Epoch 134/150  Loss=1.1198  Acc=0.6309\n",
      "[Pretrain] Epoch 135/150  Loss=1.1363  Acc=0.6277\n",
      "[Pretrain] Epoch 136/150  Loss=1.1334  Acc=0.6212\n",
      "[Pretrain] Epoch 137/150  Loss=1.1385  Acc=0.6263\n",
      "[Pretrain] Epoch 138/150  Loss=1.1343  Acc=0.6298\n",
      "[Pretrain] Epoch 139/150  Loss=1.1364  Acc=0.6272\n",
      "[Pretrain] Epoch 140/150  Loss=1.1307  Acc=0.6264\n",
      "[Pretrain] Epoch 141/150  Loss=1.1174  Acc=0.6313\n",
      "[Pretrain] Epoch 142/150  Loss=1.1261  Acc=0.6291\n",
      "[Pretrain] Epoch 143/150  Loss=1.1222  Acc=0.6325\n",
      "[Pretrain] Epoch 144/150  Loss=1.1385  Acc=0.6202\n",
      "[Pretrain] Epoch 145/150  Loss=1.1186  Acc=0.6322\n",
      "[Pretrain] Epoch 146/150  Loss=1.1174  Acc=0.6252\n",
      "[Pretrain] Epoch 147/150  Loss=1.1377  Acc=0.6203\n",
      "[Pretrain] Epoch 148/150  Loss=1.1264  Acc=0.6342\n",
      "[Pretrain] Epoch 149/150  Loss=1.1347  Acc=0.6254\n",
      "[Pretrain] Epoch 150/150  Loss=1.1335  Acc=0.6241\n",
      "[Fine-tune] Epoch 1/75  Loss=3.1998\n",
      "[Fine-tune] Epoch 2/75  Loss=2.7254\n",
      "[Fine-tune] Epoch 3/75  Loss=2.4793\n",
      "[Fine-tune] Epoch 4/75  Loss=2.3747\n",
      "[Fine-tune] Epoch 5/75  Loss=2.2824\n",
      "[Fine-tune] Epoch 6/75  Loss=2.2079\n",
      "[Fine-tune] Epoch 7/75  Loss=2.1645\n",
      "[Fine-tune] Epoch 8/75  Loss=2.1051\n",
      "[Fine-tune] Epoch 9/75  Loss=2.0852\n",
      "[Fine-tune] Epoch 10/75  Loss=2.0606\n",
      "[Fine-tune] Epoch 11/75  Loss=2.0362\n",
      "[Fine-tune] Epoch 12/75  Loss=2.0127\n",
      "[Fine-tune] Epoch 13/75  Loss=1.9972\n",
      "[Fine-tune] Epoch 14/75  Loss=1.9818\n",
      "[Fine-tune] Epoch 15/75  Loss=1.9602\n",
      "[Fine-tune] Epoch 16/75  Loss=1.9356\n",
      "[Fine-tune] Epoch 17/75  Loss=1.9379\n",
      "[Fine-tune] Epoch 18/75  Loss=1.9165\n",
      "[Fine-tune] Epoch 19/75  Loss=1.9042\n",
      "[Fine-tune] Epoch 20/75  Loss=1.8911\n",
      "[Fine-tune] Epoch 21/75  Loss=1.8811\n",
      "[Fine-tune] Epoch 22/75  Loss=1.8601\n",
      "[Fine-tune] Epoch 23/75  Loss=1.8697\n",
      "[Fine-tune] Epoch 24/75  Loss=1.8591\n",
      "[Fine-tune] Epoch 25/75  Loss=1.8498\n",
      "[Fine-tune] Epoch 26/75  Loss=1.8459\n",
      "[Fine-tune] Epoch 27/75  Loss=1.8219\n",
      "[Fine-tune] Epoch 28/75  Loss=1.8222\n",
      "[Fine-tune] Epoch 29/75  Loss=1.8198\n",
      "[Fine-tune] Epoch 30/75  Loss=1.8055\n",
      "[Fine-tune] Epoch 31/75  Loss=1.8104\n",
      "[Fine-tune] Epoch 32/75  Loss=1.8096\n",
      "[Fine-tune] Epoch 33/75  Loss=1.7832\n",
      "[Fine-tune] Epoch 34/75  Loss=1.8061\n",
      "[Fine-tune] Epoch 35/75  Loss=1.7972\n",
      "[Fine-tune] Epoch 36/75  Loss=1.7877\n",
      "[Fine-tune] Epoch 37/75  Loss=1.7874\n",
      "[Fine-tune] Epoch 38/75  Loss=1.7764\n",
      "[Fine-tune] Epoch 39/75  Loss=1.7639\n",
      "[Fine-tune] Epoch 40/75  Loss=1.7650\n",
      "[Fine-tune] Epoch 41/75  Loss=1.7620\n",
      "[Fine-tune] Epoch 42/75  Loss=1.7618\n",
      "[Fine-tune] Epoch 43/75  Loss=1.7667\n",
      "[Fine-tune] Epoch 44/75  Loss=1.7572\n",
      "[Fine-tune] Epoch 45/75  Loss=1.7506\n",
      "[Fine-tune] Epoch 46/75  Loss=1.7624\n",
      "[Fine-tune] Epoch 47/75  Loss=1.7425\n",
      "[Fine-tune] Epoch 48/75  Loss=1.7413\n",
      "[Fine-tune] Epoch 49/75  Loss=1.7434\n",
      "[Fine-tune] Epoch 50/75  Loss=1.7408\n",
      "[Fine-tune] Epoch 51/75  Loss=1.7366\n",
      "[Fine-tune] Epoch 52/75  Loss=1.7496\n",
      "[Fine-tune] Epoch 53/75  Loss=1.7312\n",
      "[Fine-tune] Epoch 54/75  Loss=1.7352\n",
      "[Fine-tune] Epoch 55/75  Loss=1.7261\n",
      "[Fine-tune] Epoch 56/75  Loss=1.7279\n",
      "[Fine-tune] Epoch 57/75  Loss=1.7407\n",
      "[Fine-tune] Epoch 58/75  Loss=1.7328\n",
      "[Fine-tune] Epoch 59/75  Loss=1.7281\n",
      "[Fine-tune] Epoch 60/75  Loss=1.7215\n",
      "[Fine-tune] Epoch 61/75  Loss=1.7298\n",
      "[Fine-tune] Epoch 62/75  Loss=1.7165\n",
      "[Fine-tune] Epoch 63/75  Loss=1.7266\n",
      "[Fine-tune] Epoch 64/75  Loss=1.7237\n",
      "[Fine-tune] Epoch 65/75  Loss=1.7225\n",
      "[Fine-tune] Epoch 66/75  Loss=1.7197\n",
      "[Fine-tune] Epoch 67/75  Loss=1.7203\n",
      "[Fine-tune] Epoch 68/75  Loss=1.7266\n",
      "[Fine-tune] Epoch 69/75  Loss=1.7221\n",
      "[Fine-tune] Epoch 70/75  Loss=1.7179\n",
      "[Fine-tune] Epoch 71/75  Loss=1.7115\n",
      "[Fine-tune] Epoch 72/75  Loss=1.7123\n",
      "[Fine-tune] Epoch 73/75  Loss=1.7130\n",
      "[Fine-tune] Epoch 74/75  Loss=1.7220\n",
      "[Fine-tune] Epoch 75/75  Loss=1.7135\n",
      "[Pretrain] Epoch 1/50  Loss=3.2483  Acc=0.0404\n",
      "[Pretrain] Epoch 2/50  Loss=3.1218  Acc=0.0711\n",
      "[Pretrain] Epoch 3/50  Loss=3.0522  Acc=0.0896\n",
      "[Pretrain] Epoch 4/50  Loss=2.9953  Acc=0.0968\n",
      "[Pretrain] Epoch 5/50  Loss=2.8894  Acc=0.1243\n",
      "[Pretrain] Epoch 6/50  Loss=2.6485  Acc=0.1800\n",
      "[Pretrain] Epoch 7/50  Loss=2.4450  Acc=0.2241\n",
      "[Pretrain] Epoch 8/50  Loss=2.2927  Acc=0.2640\n",
      "[Pretrain] Epoch 9/50  Loss=2.1880  Acc=0.2892\n",
      "[Pretrain] Epoch 10/50  Loss=2.1057  Acc=0.3168\n",
      "[Pretrain] Epoch 11/50  Loss=2.0691  Acc=0.3328\n",
      "[Pretrain] Epoch 12/50  Loss=2.0112  Acc=0.3441\n",
      "[Pretrain] Epoch 13/50  Loss=1.9734  Acc=0.3615\n",
      "[Pretrain] Epoch 14/50  Loss=1.9450  Acc=0.3723\n",
      "[Pretrain] Epoch 15/50  Loss=1.9118  Acc=0.3890\n",
      "[Pretrain] Epoch 16/50  Loss=1.8877  Acc=0.3870\n",
      "[Pretrain] Epoch 17/50  Loss=1.8591  Acc=0.4028\n",
      "[Pretrain] Epoch 18/50  Loss=1.8294  Acc=0.4122\n",
      "[Pretrain] Epoch 19/50  Loss=1.8263  Acc=0.4115\n",
      "[Pretrain] Epoch 20/50  Loss=1.7843  Acc=0.4231\n",
      "[Pretrain] Epoch 21/50  Loss=1.7791  Acc=0.4262\n",
      "[Pretrain] Epoch 22/50  Loss=1.7698  Acc=0.4335\n",
      "[Pretrain] Epoch 23/50  Loss=1.7332  Acc=0.4382\n",
      "[Pretrain] Epoch 24/50  Loss=1.7076  Acc=0.4485\n",
      "[Pretrain] Epoch 25/50  Loss=1.6915  Acc=0.4465\n",
      "[Pretrain] Epoch 26/50  Loss=1.6758  Acc=0.4623\n",
      "[Pretrain] Epoch 27/50  Loss=1.6787  Acc=0.4564\n",
      "[Pretrain] Epoch 28/50  Loss=1.6518  Acc=0.4675\n",
      "[Pretrain] Epoch 29/50  Loss=1.6315  Acc=0.4713\n",
      "[Pretrain] Epoch 30/50  Loss=1.6154  Acc=0.4776\n",
      "[Pretrain] Epoch 31/50  Loss=1.5991  Acc=0.4820\n",
      "[Pretrain] Epoch 32/50  Loss=1.5988  Acc=0.4846\n",
      "[Pretrain] Epoch 33/50  Loss=1.5770  Acc=0.4941\n",
      "[Pretrain] Epoch 34/50  Loss=1.5588  Acc=0.4923\n",
      "[Pretrain] Epoch 35/50  Loss=1.5476  Acc=0.4941\n",
      "[Pretrain] Epoch 36/50  Loss=1.5438  Acc=0.4982\n",
      "[Pretrain] Epoch 37/50  Loss=1.5442  Acc=0.4966\n",
      "[Pretrain] Epoch 38/50  Loss=1.5235  Acc=0.4952\n",
      "[Pretrain] Epoch 39/50  Loss=1.4911  Acc=0.5083\n",
      "[Pretrain] Epoch 40/50  Loss=1.5057  Acc=0.5113\n",
      "[Pretrain] Epoch 41/50  Loss=1.5064  Acc=0.5084\n",
      "[Pretrain] Epoch 42/50  Loss=1.4690  Acc=0.5273\n",
      "[Pretrain] Epoch 43/50  Loss=1.4767  Acc=0.5180\n",
      "[Pretrain] Epoch 44/50  Loss=1.4736  Acc=0.5250\n",
      "[Pretrain] Epoch 45/50  Loss=1.4518  Acc=0.5325\n",
      "[Pretrain] Epoch 46/50  Loss=1.4551  Acc=0.5205\n",
      "[Pretrain] Epoch 47/50  Loss=1.4456  Acc=0.5348\n",
      "[Pretrain] Epoch 48/50  Loss=1.4429  Acc=0.5293\n",
      "[Pretrain] Epoch 49/50  Loss=1.4193  Acc=0.5363\n",
      "[Pretrain] Epoch 50/50  Loss=1.4300  Acc=0.5354\n",
      "[Fine-tune] Epoch 1/75  Loss=3.3095\n",
      "[Fine-tune] Epoch 2/75  Loss=3.2023\n",
      "[Fine-tune] Epoch 3/75  Loss=3.0924\n",
      "[Fine-tune] Epoch 4/75  Loss=3.0295\n",
      "[Fine-tune] Epoch 5/75  Loss=2.8650\n",
      "[Fine-tune] Epoch 6/75  Loss=2.7607\n",
      "[Fine-tune] Epoch 7/75  Loss=2.7202\n",
      "[Fine-tune] Epoch 8/75  Loss=2.6752\n",
      "[Fine-tune] Epoch 9/75  Loss=2.6159\n",
      "[Fine-tune] Epoch 10/75  Loss=2.5437\n",
      "[Fine-tune] Epoch 11/75  Loss=2.4845\n",
      "[Fine-tune] Epoch 12/75  Loss=2.4442\n",
      "[Fine-tune] Epoch 13/75  Loss=2.4099\n",
      "[Fine-tune] Epoch 14/75  Loss=2.3796\n",
      "[Fine-tune] Epoch 15/75  Loss=2.3196\n",
      "[Fine-tune] Epoch 16/75  Loss=2.2858\n",
      "[Fine-tune] Epoch 17/75  Loss=2.2719\n",
      "[Fine-tune] Epoch 18/75  Loss=2.2360\n",
      "[Fine-tune] Epoch 19/75  Loss=2.2058\n",
      "[Fine-tune] Epoch 20/75  Loss=2.1803\n",
      "[Fine-tune] Epoch 21/75  Loss=2.1561\n",
      "[Fine-tune] Epoch 22/75  Loss=2.1414\n",
      "[Fine-tune] Epoch 23/75  Loss=2.1001\n",
      "[Fine-tune] Epoch 24/75  Loss=2.0912\n",
      "[Fine-tune] Epoch 25/75  Loss=2.0653\n",
      "[Fine-tune] Epoch 26/75  Loss=2.0351\n",
      "[Fine-tune] Epoch 27/75  Loss=2.0252\n",
      "[Fine-tune] Epoch 28/75  Loss=1.9896\n",
      "[Fine-tune] Epoch 29/75  Loss=1.9845\n",
      "[Fine-tune] Epoch 30/75  Loss=1.9791\n",
      "[Fine-tune] Epoch 31/75  Loss=1.9421\n",
      "[Fine-tune] Epoch 32/75  Loss=1.9400\n",
      "[Fine-tune] Epoch 33/75  Loss=1.9285\n",
      "[Fine-tune] Epoch 34/75  Loss=1.9078\n",
      "[Fine-tune] Epoch 35/75  Loss=1.9048\n",
      "[Fine-tune] Epoch 36/75  Loss=1.8897\n",
      "[Fine-tune] Epoch 37/75  Loss=1.8864\n",
      "[Fine-tune] Epoch 38/75  Loss=1.8585\n",
      "[Fine-tune] Epoch 39/75  Loss=1.8525\n",
      "[Fine-tune] Epoch 40/75  Loss=1.8561\n",
      "[Fine-tune] Epoch 41/75  Loss=1.8413\n",
      "[Fine-tune] Epoch 42/75  Loss=1.8315\n",
      "[Fine-tune] Epoch 43/75  Loss=1.8239\n",
      "[Fine-tune] Epoch 44/75  Loss=1.8173\n",
      "[Fine-tune] Epoch 45/75  Loss=1.8033\n",
      "[Fine-tune] Epoch 46/75  Loss=1.7950\n",
      "[Fine-tune] Epoch 47/75  Loss=1.7983\n",
      "[Fine-tune] Epoch 48/75  Loss=1.7764\n",
      "[Fine-tune] Epoch 49/75  Loss=1.7821\n",
      "[Fine-tune] Epoch 50/75  Loss=1.7630\n",
      "[Fine-tune] Epoch 51/75  Loss=1.7564\n",
      "[Fine-tune] Epoch 52/75  Loss=1.7532\n",
      "[Fine-tune] Epoch 53/75  Loss=1.7526\n",
      "[Fine-tune] Epoch 54/75  Loss=1.7371\n",
      "[Fine-tune] Epoch 55/75  Loss=1.7233\n",
      "[Fine-tune] Epoch 56/75  Loss=1.7402\n",
      "[Fine-tune] Epoch 57/75  Loss=1.7201\n",
      "[Fine-tune] Epoch 58/75  Loss=1.7188\n",
      "[Fine-tune] Epoch 59/75  Loss=1.7241\n",
      "[Fine-tune] Epoch 60/75  Loss=1.7066\n",
      "[Fine-tune] Epoch 61/75  Loss=1.7068\n",
      "[Fine-tune] Epoch 62/75  Loss=1.7043\n",
      "[Fine-tune] Epoch 63/75  Loss=1.7077\n",
      "[Fine-tune] Epoch 64/75  Loss=1.7010\n",
      "[Fine-tune] Epoch 65/75  Loss=1.6946\n",
      "[Fine-tune] Epoch 66/75  Loss=1.7027\n",
      "[Fine-tune] Epoch 67/75  Loss=1.7014\n",
      "[Fine-tune] Epoch 68/75  Loss=1.6801\n",
      "[Fine-tune] Epoch 69/75  Loss=1.6721\n",
      "[Fine-tune] Epoch 70/75  Loss=1.6806\n",
      "[Fine-tune] Epoch 71/75  Loss=1.6909\n",
      "[Fine-tune] Epoch 72/75  Loss=1.6818\n",
      "[Fine-tune] Epoch 73/75  Loss=1.6745\n",
      "[Fine-tune] Epoch 74/75  Loss=1.6597\n",
      "[Fine-tune] Epoch 75/75  Loss=1.6635\n",
      "[Pretrain] Epoch 1/50  Loss=3.7364  Acc=0.0417\n",
      "[Pretrain] Epoch 2/50  Loss=3.0952  Acc=0.0846\n",
      "[Pretrain] Epoch 3/50  Loss=2.7286  Acc=0.1448\n",
      "[Pretrain] Epoch 4/50  Loss=2.5653  Acc=0.1850\n",
      "[Pretrain] Epoch 5/50  Loss=2.4132  Acc=0.2277\n",
      "[Pretrain] Epoch 6/50  Loss=2.3737  Acc=0.2489\n",
      "[Pretrain] Epoch 7/50  Loss=2.2985  Acc=0.2672\n",
      "[Pretrain] Epoch 8/50  Loss=2.1963  Acc=0.2989\n",
      "[Pretrain] Epoch 9/50  Loss=2.1560  Acc=0.3046\n",
      "[Pretrain] Epoch 10/50  Loss=2.1363  Acc=0.3211\n",
      "[Pretrain] Epoch 11/50  Loss=2.0929  Acc=0.3235\n",
      "[Pretrain] Epoch 12/50  Loss=2.0514  Acc=0.3420\n",
      "[Pretrain] Epoch 13/50  Loss=2.0450  Acc=0.3396\n",
      "[Pretrain] Epoch 14/50  Loss=2.0052  Acc=0.3416\n",
      "[Pretrain] Epoch 15/50  Loss=1.9574  Acc=0.3666\n",
      "[Pretrain] Epoch 16/50  Loss=1.9515  Acc=0.3687\n",
      "[Pretrain] Epoch 17/50  Loss=1.9190  Acc=0.3849\n",
      "[Pretrain] Epoch 18/50  Loss=1.8869  Acc=0.3886\n",
      "[Pretrain] Epoch 19/50  Loss=1.8751  Acc=0.3913\n",
      "[Pretrain] Epoch 20/50  Loss=1.8315  Acc=0.4048\n",
      "[Pretrain] Epoch 21/50  Loss=1.8444  Acc=0.4037\n",
      "[Pretrain] Epoch 22/50  Loss=1.8126  Acc=0.4142\n",
      "[Pretrain] Epoch 23/50  Loss=1.7760  Acc=0.4186\n",
      "[Pretrain] Epoch 24/50  Loss=1.7547  Acc=0.4186\n",
      "[Pretrain] Epoch 25/50  Loss=1.7624  Acc=0.4269\n",
      "[Pretrain] Epoch 26/50  Loss=1.7283  Acc=0.4294\n",
      "[Pretrain] Epoch 27/50  Loss=1.7015  Acc=0.4490\n",
      "[Pretrain] Epoch 28/50  Loss=1.6874  Acc=0.4522\n",
      "[Pretrain] Epoch 29/50  Loss=1.6813  Acc=0.4468\n",
      "[Pretrain] Epoch 30/50  Loss=1.6434  Acc=0.4560\n",
      "[Pretrain] Epoch 31/50  Loss=1.6123  Acc=0.4756\n",
      "[Pretrain] Epoch 32/50  Loss=1.6117  Acc=0.4670\n",
      "[Pretrain] Epoch 33/50  Loss=1.5951  Acc=0.4788\n",
      "[Pretrain] Epoch 34/50  Loss=1.5531  Acc=0.4890\n",
      "[Pretrain] Epoch 35/50  Loss=1.5630  Acc=0.4864\n",
      "[Pretrain] Epoch 36/50  Loss=1.5254  Acc=0.5002\n",
      "[Pretrain] Epoch 37/50  Loss=1.5115  Acc=0.4984\n",
      "[Pretrain] Epoch 38/50  Loss=1.5112  Acc=0.5050\n",
      "[Pretrain] Epoch 39/50  Loss=1.4768  Acc=0.5110\n",
      "[Pretrain] Epoch 40/50  Loss=1.4711  Acc=0.5174\n",
      "[Pretrain] Epoch 41/50  Loss=1.4520  Acc=0.5257\n",
      "[Pretrain] Epoch 42/50  Loss=1.4405  Acc=0.5302\n",
      "[Pretrain] Epoch 43/50  Loss=1.4174  Acc=0.5304\n",
      "[Pretrain] Epoch 44/50  Loss=1.4362  Acc=0.5298\n",
      "[Pretrain] Epoch 45/50  Loss=1.4127  Acc=0.5284\n",
      "[Pretrain] Epoch 46/50  Loss=1.3758  Acc=0.5463\n",
      "[Pretrain] Epoch 47/50  Loss=1.3793  Acc=0.5440\n",
      "[Pretrain] Epoch 48/50  Loss=1.3538  Acc=0.5564\n",
      "[Pretrain] Epoch 49/50  Loss=1.3611  Acc=0.5591\n",
      "[Pretrain] Epoch 50/50  Loss=1.3469  Acc=0.5603\n",
      "[Fine-tune] Epoch 1/75  Loss=3.2470\n",
      "[Fine-tune] Epoch 2/75  Loss=2.8573\n",
      "[Fine-tune] Epoch 3/75  Loss=2.6725\n",
      "[Fine-tune] Epoch 4/75  Loss=2.6001\n",
      "[Fine-tune] Epoch 5/75  Loss=2.5343\n",
      "[Fine-tune] Epoch 6/75  Loss=2.4890\n",
      "[Fine-tune] Epoch 7/75  Loss=2.4215\n",
      "[Fine-tune] Epoch 8/75  Loss=2.3831\n",
      "[Fine-tune] Epoch 9/75  Loss=2.3567\n",
      "[Fine-tune] Epoch 10/75  Loss=2.2909\n",
      "[Fine-tune] Epoch 11/75  Loss=2.2367\n",
      "[Fine-tune] Epoch 12/75  Loss=2.2035\n",
      "[Fine-tune] Epoch 13/75  Loss=2.1527\n",
      "[Fine-tune] Epoch 14/75  Loss=2.1166\n",
      "[Fine-tune] Epoch 15/75  Loss=2.1008\n",
      "[Fine-tune] Epoch 16/75  Loss=2.0528\n",
      "[Fine-tune] Epoch 17/75  Loss=2.0538\n",
      "[Fine-tune] Epoch 18/75  Loss=2.0385\n",
      "[Fine-tune] Epoch 19/75  Loss=2.0208\n",
      "[Fine-tune] Epoch 20/75  Loss=1.9774\n",
      "[Fine-tune] Epoch 21/75  Loss=1.9637\n",
      "[Fine-tune] Epoch 22/75  Loss=1.9354\n",
      "[Fine-tune] Epoch 23/75  Loss=1.8980\n",
      "[Fine-tune] Epoch 24/75  Loss=1.8987\n",
      "[Fine-tune] Epoch 25/75  Loss=1.8519\n",
      "[Fine-tune] Epoch 26/75  Loss=1.8536\n",
      "[Fine-tune] Epoch 27/75  Loss=1.8306\n",
      "[Fine-tune] Epoch 28/75  Loss=1.8192\n",
      "[Fine-tune] Epoch 29/75  Loss=1.7964\n",
      "[Fine-tune] Epoch 30/75  Loss=1.7749\n",
      "[Fine-tune] Epoch 31/75  Loss=1.7611\n",
      "[Fine-tune] Epoch 32/75  Loss=1.7623\n",
      "[Fine-tune] Epoch 33/75  Loss=1.7484\n",
      "[Fine-tune] Epoch 34/75  Loss=1.7380\n",
      "[Fine-tune] Epoch 35/75  Loss=1.7032\n",
      "[Fine-tune] Epoch 36/75  Loss=1.7138\n",
      "[Fine-tune] Epoch 37/75  Loss=1.6743\n",
      "[Fine-tune] Epoch 38/75  Loss=1.6652\n",
      "[Fine-tune] Epoch 39/75  Loss=1.6643\n",
      "[Fine-tune] Epoch 40/75  Loss=1.6830\n",
      "[Fine-tune] Epoch 41/75  Loss=1.6507\n",
      "[Fine-tune] Epoch 42/75  Loss=1.6382\n",
      "[Fine-tune] Epoch 43/75  Loss=1.6463\n",
      "[Fine-tune] Epoch 44/75  Loss=1.6306\n",
      "[Fine-tune] Epoch 45/75  Loss=1.6024\n",
      "[Fine-tune] Epoch 46/75  Loss=1.6024\n",
      "[Fine-tune] Epoch 47/75  Loss=1.5977\n",
      "[Fine-tune] Epoch 48/75  Loss=1.5965\n",
      "[Fine-tune] Epoch 49/75  Loss=1.5873\n",
      "[Fine-tune] Epoch 50/75  Loss=1.5760\n",
      "[Fine-tune] Epoch 51/75  Loss=1.5757\n",
      "[Fine-tune] Epoch 52/75  Loss=1.5657\n",
      "[Fine-tune] Epoch 53/75  Loss=1.5640\n",
      "[Fine-tune] Epoch 54/75  Loss=1.5538\n",
      "[Fine-tune] Epoch 55/75  Loss=1.5544\n",
      "[Fine-tune] Epoch 56/75  Loss=1.5453\n",
      "[Fine-tune] Epoch 57/75  Loss=1.5546\n",
      "[Fine-tune] Epoch 58/75  Loss=1.5393\n",
      "[Fine-tune] Epoch 59/75  Loss=1.5386\n",
      "[Fine-tune] Epoch 60/75  Loss=1.5256\n",
      "[Fine-tune] Epoch 61/75  Loss=1.5189\n",
      "[Fine-tune] Epoch 62/75  Loss=1.5196\n",
      "[Fine-tune] Epoch 63/75  Loss=1.5251\n",
      "[Fine-tune] Epoch 64/75  Loss=1.5302\n",
      "[Fine-tune] Epoch 65/75  Loss=1.5158\n",
      "[Fine-tune] Epoch 66/75  Loss=1.4979\n",
      "[Fine-tune] Epoch 67/75  Loss=1.4950\n",
      "[Fine-tune] Epoch 68/75  Loss=1.5003\n",
      "[Fine-tune] Epoch 69/75  Loss=1.5106\n",
      "[Fine-tune] Epoch 70/75  Loss=1.5018\n",
      "[Fine-tune] Epoch 71/75  Loss=1.4975\n",
      "[Fine-tune] Epoch 72/75  Loss=1.5002\n",
      "[Fine-tune] Epoch 73/75  Loss=1.4952\n",
      "[Fine-tune] Epoch 74/75  Loss=1.4901\n",
      "[Fine-tune] Epoch 75/75  Loss=1.4799\n",
      "[Pretrain] Epoch 1/75  Loss=3.2558  Acc=0.0417\n",
      "[Pretrain] Epoch 2/75  Loss=3.0988  Acc=0.0758\n",
      "[Pretrain] Epoch 3/75  Loss=2.9094  Acc=0.1040\n",
      "[Pretrain] Epoch 4/75  Loss=2.6468  Acc=0.1667\n",
      "[Pretrain] Epoch 5/75  Loss=2.5158  Acc=0.2026\n",
      "[Pretrain] Epoch 6/75  Loss=2.3559  Acc=0.2452\n",
      "[Pretrain] Epoch 7/75  Loss=2.2444  Acc=0.2724\n",
      "[Pretrain] Epoch 8/75  Loss=2.1668  Acc=0.2942\n",
      "[Pretrain] Epoch 9/75  Loss=2.0869  Acc=0.3222\n",
      "[Pretrain] Epoch 10/75  Loss=2.0559  Acc=0.3328\n",
      "[Pretrain] Epoch 11/75  Loss=2.0435  Acc=0.3323\n",
      "[Pretrain] Epoch 12/75  Loss=2.0065  Acc=0.3488\n",
      "[Pretrain] Epoch 13/75  Loss=1.9681  Acc=0.3676\n",
      "[Pretrain] Epoch 14/75  Loss=1.9312  Acc=0.3660\n",
      "[Pretrain] Epoch 15/75  Loss=1.9172  Acc=0.3743\n",
      "[Pretrain] Epoch 16/75  Loss=1.9159  Acc=0.3816\n",
      "[Pretrain] Epoch 17/75  Loss=1.8785  Acc=0.3860\n",
      "[Pretrain] Epoch 18/75  Loss=1.8581  Acc=0.3978\n",
      "[Pretrain] Epoch 19/75  Loss=1.8362  Acc=0.4025\n",
      "[Pretrain] Epoch 20/75  Loss=1.7800  Acc=0.4219\n",
      "[Pretrain] Epoch 21/75  Loss=1.7664  Acc=0.4289\n",
      "[Pretrain] Epoch 22/75  Loss=1.7713  Acc=0.4233\n",
      "[Pretrain] Epoch 23/75  Loss=1.7420  Acc=0.4397\n",
      "[Pretrain] Epoch 24/75  Loss=1.7235  Acc=0.4443\n",
      "[Pretrain] Epoch 25/75  Loss=1.6897  Acc=0.4520\n",
      "[Pretrain] Epoch 26/75  Loss=1.7052  Acc=0.4481\n",
      "[Pretrain] Epoch 27/75  Loss=1.6691  Acc=0.4648\n",
      "[Pretrain] Epoch 28/75  Loss=1.6564  Acc=0.4731\n",
      "[Pretrain] Epoch 29/75  Loss=1.6377  Acc=0.4752\n",
      "[Pretrain] Epoch 30/75  Loss=1.6120  Acc=0.4808\n",
      "[Pretrain] Epoch 31/75  Loss=1.5932  Acc=0.4811\n",
      "[Pretrain] Epoch 32/75  Loss=1.5844  Acc=0.4926\n",
      "[Pretrain] Epoch 33/75  Loss=1.5748  Acc=0.4865\n",
      "[Pretrain] Epoch 34/75  Loss=1.5631  Acc=0.4975\n",
      "[Pretrain] Epoch 35/75  Loss=1.5631  Acc=0.4925\n",
      "[Pretrain] Epoch 36/75  Loss=1.5433  Acc=0.4973\n",
      "[Pretrain] Epoch 37/75  Loss=1.5091  Acc=0.5144\n",
      "[Pretrain] Epoch 38/75  Loss=1.5255  Acc=0.5061\n",
      "[Pretrain] Epoch 39/75  Loss=1.4827  Acc=0.5172\n",
      "[Pretrain] Epoch 40/75  Loss=1.4947  Acc=0.5212\n",
      "[Pretrain] Epoch 41/75  Loss=1.4911  Acc=0.5174\n",
      "[Pretrain] Epoch 42/75  Loss=1.4675  Acc=0.5226\n",
      "[Pretrain] Epoch 43/75  Loss=1.4627  Acc=0.5251\n",
      "[Pretrain] Epoch 44/75  Loss=1.4605  Acc=0.5298\n",
      "[Pretrain] Epoch 45/75  Loss=1.4492  Acc=0.5286\n",
      "[Pretrain] Epoch 46/75  Loss=1.4461  Acc=0.5330\n",
      "[Pretrain] Epoch 47/75  Loss=1.4380  Acc=0.5304\n",
      "[Pretrain] Epoch 48/75  Loss=1.4250  Acc=0.5284\n",
      "[Pretrain] Epoch 49/75  Loss=1.4051  Acc=0.5465\n",
      "[Pretrain] Epoch 50/75  Loss=1.4003  Acc=0.5413\n",
      "[Pretrain] Epoch 51/75  Loss=1.4133  Acc=0.5440\n",
      "[Pretrain] Epoch 52/75  Loss=1.3916  Acc=0.5512\n",
      "[Pretrain] Epoch 53/75  Loss=1.4022  Acc=0.5480\n",
      "[Pretrain] Epoch 54/75  Loss=1.3818  Acc=0.5517\n",
      "[Pretrain] Epoch 55/75  Loss=1.3882  Acc=0.5524\n",
      "[Pretrain] Epoch 56/75  Loss=1.3734  Acc=0.5548\n",
      "[Pretrain] Epoch 57/75  Loss=1.3784  Acc=0.5508\n",
      "[Pretrain] Epoch 58/75  Loss=1.3759  Acc=0.5512\n",
      "[Pretrain] Epoch 59/75  Loss=1.3650  Acc=0.5585\n",
      "[Pretrain] Epoch 60/75  Loss=1.3679  Acc=0.5598\n",
      "[Pretrain] Epoch 61/75  Loss=1.3420  Acc=0.5603\n",
      "[Pretrain] Epoch 62/75  Loss=1.3331  Acc=0.5629\n",
      "[Pretrain] Epoch 63/75  Loss=1.3462  Acc=0.5593\n",
      "[Pretrain] Epoch 64/75  Loss=1.3570  Acc=0.5550\n",
      "[Pretrain] Epoch 65/75  Loss=1.3339  Acc=0.5577\n",
      "[Pretrain] Epoch 66/75  Loss=1.3375  Acc=0.5620\n",
      "[Pretrain] Epoch 67/75  Loss=1.3486  Acc=0.5587\n",
      "[Pretrain] Epoch 68/75  Loss=1.3207  Acc=0.5733\n",
      "[Pretrain] Epoch 69/75  Loss=1.3350  Acc=0.5647\n",
      "[Pretrain] Epoch 70/75  Loss=1.3241  Acc=0.5657\n",
      "[Pretrain] Epoch 71/75  Loss=1.3407  Acc=0.5641\n",
      "[Pretrain] Epoch 72/75  Loss=1.3169  Acc=0.5753\n",
      "[Pretrain] Epoch 73/75  Loss=1.3278  Acc=0.5744\n",
      "[Pretrain] Epoch 74/75  Loss=1.3217  Acc=0.5700\n",
      "[Pretrain] Epoch 75/75  Loss=1.3106  Acc=0.5702\n",
      "[Fine-tune] Epoch 1/75  Loss=3.2939\n",
      "[Fine-tune] Epoch 2/75  Loss=3.1571\n",
      "[Fine-tune] Epoch 3/75  Loss=3.0829\n",
      "[Fine-tune] Epoch 4/75  Loss=3.0638\n",
      "[Fine-tune] Epoch 5/75  Loss=3.0496\n",
      "[Fine-tune] Epoch 6/75  Loss=2.9671\n",
      "[Fine-tune] Epoch 7/75  Loss=2.8005\n",
      "[Fine-tune] Epoch 8/75  Loss=2.6622\n",
      "[Fine-tune] Epoch 9/75  Loss=2.5628\n",
      "[Fine-tune] Epoch 10/75  Loss=2.5370\n",
      "[Fine-tune] Epoch 11/75  Loss=2.5026\n",
      "[Fine-tune] Epoch 12/75  Loss=2.4666\n",
      "[Fine-tune] Epoch 13/75  Loss=2.4381\n",
      "[Fine-tune] Epoch 14/75  Loss=2.3918\n",
      "[Fine-tune] Epoch 15/75  Loss=2.3468\n",
      "[Fine-tune] Epoch 16/75  Loss=2.3209\n",
      "[Fine-tune] Epoch 17/75  Loss=2.2821\n",
      "[Fine-tune] Epoch 18/75  Loss=2.2479\n",
      "[Fine-tune] Epoch 19/75  Loss=2.2093\n",
      "[Fine-tune] Epoch 20/75  Loss=2.1792\n",
      "[Fine-tune] Epoch 21/75  Loss=2.1475\n",
      "[Fine-tune] Epoch 22/75  Loss=2.1256\n",
      "[Fine-tune] Epoch 23/75  Loss=2.1041\n",
      "[Fine-tune] Epoch 24/75  Loss=2.0743\n",
      "[Fine-tune] Epoch 25/75  Loss=2.0631\n",
      "[Fine-tune] Epoch 26/75  Loss=2.0578\n",
      "[Fine-tune] Epoch 27/75  Loss=2.0384\n",
      "[Fine-tune] Epoch 28/75  Loss=2.0162\n",
      "[Fine-tune] Epoch 29/75  Loss=2.0096\n",
      "[Fine-tune] Epoch 30/75  Loss=1.9719\n",
      "[Fine-tune] Epoch 31/75  Loss=1.9597\n",
      "[Fine-tune] Epoch 32/75  Loss=1.9426\n",
      "[Fine-tune] Epoch 33/75  Loss=1.9310\n",
      "[Fine-tune] Epoch 34/75  Loss=1.9231\n",
      "[Fine-tune] Epoch 35/75  Loss=1.9195\n",
      "[Fine-tune] Epoch 36/75  Loss=1.9068\n",
      "[Fine-tune] Epoch 37/75  Loss=1.8834\n",
      "[Fine-tune] Epoch 38/75  Loss=1.8862\n",
      "[Fine-tune] Epoch 39/75  Loss=1.8736\n",
      "[Fine-tune] Epoch 40/75  Loss=1.8555\n",
      "[Fine-tune] Epoch 41/75  Loss=1.8522\n",
      "[Fine-tune] Epoch 42/75  Loss=1.8412\n",
      "[Fine-tune] Epoch 43/75  Loss=1.8307\n",
      "[Fine-tune] Epoch 44/75  Loss=1.8333\n",
      "[Fine-tune] Epoch 45/75  Loss=1.8063\n",
      "[Fine-tune] Epoch 46/75  Loss=1.8118\n",
      "[Fine-tune] Epoch 47/75  Loss=1.8133\n",
      "[Fine-tune] Epoch 48/75  Loss=1.7730\n",
      "[Fine-tune] Epoch 49/75  Loss=1.7786\n",
      "[Fine-tune] Epoch 50/75  Loss=1.7671\n",
      "[Fine-tune] Epoch 51/75  Loss=1.7562\n",
      "[Fine-tune] Epoch 52/75  Loss=1.7662\n",
      "[Fine-tune] Epoch 53/75  Loss=1.7560\n",
      "[Fine-tune] Epoch 54/75  Loss=1.7421\n",
      "[Fine-tune] Epoch 55/75  Loss=1.7497\n",
      "[Fine-tune] Epoch 56/75  Loss=1.7339\n",
      "[Fine-tune] Epoch 57/75  Loss=1.7163\n",
      "[Fine-tune] Epoch 58/75  Loss=1.7085\n",
      "[Fine-tune] Epoch 59/75  Loss=1.6948\n",
      "[Fine-tune] Epoch 60/75  Loss=1.7080\n",
      "[Fine-tune] Epoch 61/75  Loss=1.7108\n",
      "[Fine-tune] Epoch 62/75  Loss=1.6902\n",
      "[Fine-tune] Epoch 63/75  Loss=1.7015\n",
      "[Fine-tune] Epoch 64/75  Loss=1.6865\n",
      "[Fine-tune] Epoch 65/75  Loss=1.6942\n",
      "[Fine-tune] Epoch 66/75  Loss=1.6678\n",
      "[Fine-tune] Epoch 67/75  Loss=1.6898\n",
      "[Fine-tune] Epoch 68/75  Loss=1.6733\n",
      "[Fine-tune] Epoch 69/75  Loss=1.6741\n",
      "[Fine-tune] Epoch 70/75  Loss=1.6767\n",
      "[Fine-tune] Epoch 71/75  Loss=1.6688\n",
      "[Fine-tune] Epoch 72/75  Loss=1.6697\n",
      "[Fine-tune] Epoch 73/75  Loss=1.6565\n",
      "[Fine-tune] Epoch 74/75  Loss=1.6554\n",
      "[Fine-tune] Epoch 75/75  Loss=1.6574\n",
      "[Pretrain] Epoch 1/75  Loss=3.6482  Acc=0.0361\n",
      "[Pretrain] Epoch 2/75  Loss=3.1290  Acc=0.0675\n",
      "[Pretrain] Epoch 3/75  Loss=3.0471  Acc=0.0880\n",
      "[Pretrain] Epoch 4/75  Loss=2.8572  Acc=0.1166\n",
      "[Pretrain] Epoch 5/75  Loss=2.6248  Acc=0.1733\n",
      "[Pretrain] Epoch 6/75  Loss=2.5203  Acc=0.2040\n",
      "[Pretrain] Epoch 7/75  Loss=2.4211  Acc=0.2319\n",
      "[Pretrain] Epoch 8/75  Loss=2.3343  Acc=0.2570\n",
      "[Pretrain] Epoch 9/75  Loss=2.2563  Acc=0.2775\n",
      "[Pretrain] Epoch 10/75  Loss=2.2467  Acc=0.2786\n",
      "[Pretrain] Epoch 11/75  Loss=2.1561  Acc=0.3023\n",
      "[Pretrain] Epoch 12/75  Loss=2.1221  Acc=0.3111\n",
      "[Pretrain] Epoch 13/75  Loss=2.0978  Acc=0.3235\n",
      "[Pretrain] Epoch 14/75  Loss=2.0476  Acc=0.3382\n",
      "[Pretrain] Epoch 15/75  Loss=2.0127  Acc=0.3520\n",
      "[Pretrain] Epoch 16/75  Loss=1.9953  Acc=0.3495\n",
      "[Pretrain] Epoch 17/75  Loss=1.9751  Acc=0.3621\n",
      "[Pretrain] Epoch 18/75  Loss=1.9585  Acc=0.3689\n",
      "[Pretrain] Epoch 19/75  Loss=1.9206  Acc=0.3793\n",
      "[Pretrain] Epoch 20/75  Loss=1.9009  Acc=0.3759\n",
      "[Pretrain] Epoch 21/75  Loss=1.8876  Acc=0.3908\n",
      "[Pretrain] Epoch 22/75  Loss=1.8569  Acc=0.3948\n",
      "[Pretrain] Epoch 23/75  Loss=1.8325  Acc=0.4021\n",
      "[Pretrain] Epoch 24/75  Loss=1.8188  Acc=0.4163\n",
      "[Pretrain] Epoch 25/75  Loss=1.8107  Acc=0.4073\n",
      "[Pretrain] Epoch 26/75  Loss=1.7721  Acc=0.4212\n",
      "[Pretrain] Epoch 27/75  Loss=1.7547  Acc=0.4271\n",
      "[Pretrain] Epoch 28/75  Loss=1.7379  Acc=0.4319\n",
      "[Pretrain] Epoch 29/75  Loss=1.7014  Acc=0.4441\n",
      "[Pretrain] Epoch 30/75  Loss=1.6899  Acc=0.4510\n",
      "[Pretrain] Epoch 31/75  Loss=1.6772  Acc=0.4551\n",
      "[Pretrain] Epoch 32/75  Loss=1.6493  Acc=0.4625\n",
      "[Pretrain] Epoch 33/75  Loss=1.6372  Acc=0.4619\n",
      "[Pretrain] Epoch 34/75  Loss=1.6300  Acc=0.4695\n",
      "[Pretrain] Epoch 35/75  Loss=1.5960  Acc=0.4810\n",
      "[Pretrain] Epoch 36/75  Loss=1.5780  Acc=0.4864\n",
      "[Pretrain] Epoch 37/75  Loss=1.5890  Acc=0.4858\n",
      "[Pretrain] Epoch 38/75  Loss=1.5512  Acc=0.4982\n",
      "[Pretrain] Epoch 39/75  Loss=1.5427  Acc=0.4941\n",
      "[Pretrain] Epoch 40/75  Loss=1.5178  Acc=0.4984\n",
      "[Pretrain] Epoch 41/75  Loss=1.5052  Acc=0.5061\n",
      "[Pretrain] Epoch 42/75  Loss=1.4923  Acc=0.5111\n",
      "[Pretrain] Epoch 43/75  Loss=1.4714  Acc=0.5224\n",
      "[Pretrain] Epoch 44/75  Loss=1.4738  Acc=0.5216\n",
      "[Pretrain] Epoch 45/75  Loss=1.4499  Acc=0.5269\n",
      "[Pretrain] Epoch 46/75  Loss=1.4443  Acc=0.5257\n",
      "[Pretrain] Epoch 47/75  Loss=1.4328  Acc=0.5345\n",
      "[Pretrain] Epoch 48/75  Loss=1.4032  Acc=0.5384\n",
      "[Pretrain] Epoch 49/75  Loss=1.4031  Acc=0.5375\n",
      "[Pretrain] Epoch 50/75  Loss=1.3996  Acc=0.5411\n",
      "[Pretrain] Epoch 51/75  Loss=1.3733  Acc=0.5451\n",
      "[Pretrain] Epoch 52/75  Loss=1.3625  Acc=0.5535\n",
      "[Pretrain] Epoch 53/75  Loss=1.3576  Acc=0.5514\n",
      "[Pretrain] Epoch 54/75  Loss=1.3441  Acc=0.5648\n",
      "[Pretrain] Epoch 55/75  Loss=1.3414  Acc=0.5560\n",
      "[Pretrain] Epoch 56/75  Loss=1.3300  Acc=0.5578\n",
      "[Pretrain] Epoch 57/75  Loss=1.3408  Acc=0.5587\n",
      "[Pretrain] Epoch 58/75  Loss=1.3176  Acc=0.5684\n",
      "[Pretrain] Epoch 59/75  Loss=1.3256  Acc=0.5636\n",
      "[Pretrain] Epoch 60/75  Loss=1.2979  Acc=0.5753\n",
      "[Pretrain] Epoch 61/75  Loss=1.2962  Acc=0.5731\n",
      "[Pretrain] Epoch 62/75  Loss=1.3052  Acc=0.5695\n",
      "[Pretrain] Epoch 63/75  Loss=1.2948  Acc=0.5783\n",
      "[Pretrain] Epoch 64/75  Loss=1.3057  Acc=0.5717\n",
      "[Pretrain] Epoch 65/75  Loss=1.2714  Acc=0.5837\n",
      "[Pretrain] Epoch 66/75  Loss=1.2769  Acc=0.5814\n",
      "[Pretrain] Epoch 67/75  Loss=1.2702  Acc=0.5867\n",
      "[Pretrain] Epoch 68/75  Loss=1.2518  Acc=0.5932\n",
      "[Pretrain] Epoch 69/75  Loss=1.2497  Acc=0.5869\n",
      "[Pretrain] Epoch 70/75  Loss=1.2576  Acc=0.5873\n",
      "[Pretrain] Epoch 71/75  Loss=1.2344  Acc=0.5930\n",
      "[Pretrain] Epoch 72/75  Loss=1.2412  Acc=0.5930\n",
      "[Pretrain] Epoch 73/75  Loss=1.2280  Acc=0.6011\n",
      "[Pretrain] Epoch 74/75  Loss=1.2378  Acc=0.5839\n",
      "[Pretrain] Epoch 75/75  Loss=1.2313  Acc=0.5954\n",
      "[Fine-tune] Epoch 1/75  Loss=3.2898\n",
      "[Fine-tune] Epoch 2/75  Loss=3.0990\n",
      "[Fine-tune] Epoch 3/75  Loss=3.0462\n",
      "[Fine-tune] Epoch 4/75  Loss=2.9981\n",
      "[Fine-tune] Epoch 5/75  Loss=2.8260\n",
      "[Fine-tune] Epoch 6/75  Loss=2.6252\n",
      "[Fine-tune] Epoch 7/75  Loss=2.4788\n",
      "[Fine-tune] Epoch 8/75  Loss=2.4075\n",
      "[Fine-tune] Epoch 9/75  Loss=2.3340\n",
      "[Fine-tune] Epoch 10/75  Loss=2.2609\n",
      "[Fine-tune] Epoch 11/75  Loss=2.1950\n",
      "[Fine-tune] Epoch 12/75  Loss=2.1801\n",
      "[Fine-tune] Epoch 13/75  Loss=2.1379\n",
      "[Fine-tune] Epoch 14/75  Loss=2.1168\n",
      "[Fine-tune] Epoch 15/75  Loss=2.0910\n",
      "[Fine-tune] Epoch 16/75  Loss=2.0488\n",
      "[Fine-tune] Epoch 17/75  Loss=2.0104\n",
      "[Fine-tune] Epoch 18/75  Loss=2.0032\n",
      "[Fine-tune] Epoch 19/75  Loss=1.9980\n",
      "[Fine-tune] Epoch 20/75  Loss=1.9466\n",
      "[Fine-tune] Epoch 21/75  Loss=1.9315\n",
      "[Fine-tune] Epoch 22/75  Loss=1.9087\n",
      "[Fine-tune] Epoch 23/75  Loss=1.8872\n",
      "[Fine-tune] Epoch 24/75  Loss=1.8777\n",
      "[Fine-tune] Epoch 25/75  Loss=1.8525\n",
      "[Fine-tune] Epoch 26/75  Loss=1.8263\n",
      "[Fine-tune] Epoch 27/75  Loss=1.8217\n",
      "[Fine-tune] Epoch 28/75  Loss=1.8041\n",
      "[Fine-tune] Epoch 29/75  Loss=1.7895\n",
      "[Fine-tune] Epoch 30/75  Loss=1.7692\n",
      "[Fine-tune] Epoch 31/75  Loss=1.7471\n",
      "[Fine-tune] Epoch 32/75  Loss=1.7312\n",
      "[Fine-tune] Epoch 33/75  Loss=1.7164\n",
      "[Fine-tune] Epoch 34/75  Loss=1.7160\n",
      "[Fine-tune] Epoch 35/75  Loss=1.7102\n",
      "[Fine-tune] Epoch 36/75  Loss=1.6857\n",
      "[Fine-tune] Epoch 37/75  Loss=1.6720\n",
      "[Fine-tune] Epoch 38/75  Loss=1.6640\n",
      "[Fine-tune] Epoch 39/75  Loss=1.6589\n",
      "[Fine-tune] Epoch 40/75  Loss=1.6541\n",
      "[Fine-tune] Epoch 41/75  Loss=1.6330\n",
      "[Fine-tune] Epoch 42/75  Loss=1.6338\n",
      "[Fine-tune] Epoch 43/75  Loss=1.6234\n",
      "[Fine-tune] Epoch 44/75  Loss=1.6114\n",
      "[Fine-tune] Epoch 45/75  Loss=1.6032\n",
      "[Fine-tune] Epoch 46/75  Loss=1.5943\n",
      "[Fine-tune] Epoch 47/75  Loss=1.5824\n",
      "[Fine-tune] Epoch 48/75  Loss=1.5668\n",
      "[Fine-tune] Epoch 49/75  Loss=1.5602\n",
      "[Fine-tune] Epoch 50/75  Loss=1.5687\n",
      "[Fine-tune] Epoch 51/75  Loss=1.5420\n",
      "[Fine-tune] Epoch 52/75  Loss=1.5451\n",
      "[Fine-tune] Epoch 53/75  Loss=1.5452\n",
      "[Fine-tune] Epoch 54/75  Loss=1.5415\n",
      "[Fine-tune] Epoch 55/75  Loss=1.5386\n",
      "[Fine-tune] Epoch 56/75  Loss=1.5394\n",
      "[Fine-tune] Epoch 57/75  Loss=1.5231\n",
      "[Fine-tune] Epoch 58/75  Loss=1.5261\n",
      "[Fine-tune] Epoch 59/75  Loss=1.5165\n",
      "[Fine-tune] Epoch 60/75  Loss=1.5085\n",
      "[Fine-tune] Epoch 61/75  Loss=1.5090\n",
      "[Fine-tune] Epoch 62/75  Loss=1.5035\n",
      "[Fine-tune] Epoch 63/75  Loss=1.5058\n",
      "[Fine-tune] Epoch 64/75  Loss=1.4980\n",
      "[Fine-tune] Epoch 65/75  Loss=1.4987\n",
      "[Fine-tune] Epoch 66/75  Loss=1.4934\n",
      "[Fine-tune] Epoch 67/75  Loss=1.4729\n",
      "[Fine-tune] Epoch 68/75  Loss=1.4805\n",
      "[Fine-tune] Epoch 69/75  Loss=1.4902\n",
      "[Fine-tune] Epoch 70/75  Loss=1.4878\n",
      "[Fine-tune] Epoch 71/75  Loss=1.4879\n",
      "[Fine-tune] Epoch 72/75  Loss=1.4766\n",
      "[Fine-tune] Epoch 73/75  Loss=1.4860\n",
      "[Fine-tune] Epoch 74/75  Loss=1.4596\n",
      "[Fine-tune] Epoch 75/75  Loss=1.4573\n",
      "[Pretrain] Epoch 1/100  Loss=3.2660  Acc=0.0426\n",
      "[Pretrain] Epoch 2/100  Loss=3.1489  Acc=0.0614\n",
      "[Pretrain] Epoch 3/100  Loss=3.0487  Acc=0.0779\n",
      "[Pretrain] Epoch 4/100  Loss=2.9869  Acc=0.1009\n",
      "[Pretrain] Epoch 5/100  Loss=2.8373  Acc=0.1464\n",
      "[Pretrain] Epoch 6/100  Loss=2.5396  Acc=0.2035\n",
      "[Pretrain] Epoch 7/100  Loss=2.3600  Acc=0.2541\n",
      "[Pretrain] Epoch 8/100  Loss=2.2625  Acc=0.2795\n",
      "[Pretrain] Epoch 9/100  Loss=2.1718  Acc=0.3073\n",
      "[Pretrain] Epoch 10/100  Loss=2.1308  Acc=0.3254\n",
      "[Pretrain] Epoch 11/100  Loss=2.0528  Acc=0.3452\n",
      "[Pretrain] Epoch 12/100  Loss=2.0420  Acc=0.3439\n",
      "[Pretrain] Epoch 13/100  Loss=1.9768  Acc=0.3685\n",
      "[Pretrain] Epoch 14/100  Loss=1.9470  Acc=0.3669\n",
      "[Pretrain] Epoch 15/100  Loss=1.9356  Acc=0.3764\n",
      "[Pretrain] Epoch 16/100  Loss=1.8963  Acc=0.3865\n",
      "[Pretrain] Epoch 17/100  Loss=1.8884  Acc=0.3888\n",
      "[Pretrain] Epoch 18/100  Loss=1.8366  Acc=0.4062\n",
      "[Pretrain] Epoch 19/100  Loss=1.8257  Acc=0.4062\n",
      "[Pretrain] Epoch 20/100  Loss=1.8255  Acc=0.4118\n",
      "[Pretrain] Epoch 21/100  Loss=1.7877  Acc=0.4221\n",
      "[Pretrain] Epoch 22/100  Loss=1.7602  Acc=0.4282\n",
      "[Pretrain] Epoch 23/100  Loss=1.7631  Acc=0.4283\n",
      "[Pretrain] Epoch 24/100  Loss=1.7237  Acc=0.4371\n",
      "[Pretrain] Epoch 25/100  Loss=1.6961  Acc=0.4476\n",
      "[Pretrain] Epoch 26/100  Loss=1.6794  Acc=0.4596\n",
      "[Pretrain] Epoch 27/100  Loss=1.6752  Acc=0.4546\n",
      "[Pretrain] Epoch 28/100  Loss=1.6609  Acc=0.4668\n",
      "[Pretrain] Epoch 29/100  Loss=1.6498  Acc=0.4686\n",
      "[Pretrain] Epoch 30/100  Loss=1.6233  Acc=0.4700\n",
      "[Pretrain] Epoch 31/100  Loss=1.5994  Acc=0.4867\n",
      "[Pretrain] Epoch 32/100  Loss=1.6062  Acc=0.4736\n",
      "[Pretrain] Epoch 33/100  Loss=1.5998  Acc=0.4788\n",
      "[Pretrain] Epoch 34/100  Loss=1.5802  Acc=0.4876\n",
      "[Pretrain] Epoch 35/100  Loss=1.5606  Acc=0.4912\n",
      "[Pretrain] Epoch 36/100  Loss=1.5611  Acc=0.4937\n",
      "[Pretrain] Epoch 37/100  Loss=1.5273  Acc=0.5018\n",
      "[Pretrain] Epoch 38/100  Loss=1.5330  Acc=0.4984\n",
      "[Pretrain] Epoch 39/100  Loss=1.5253  Acc=0.5149\n",
      "[Pretrain] Epoch 40/100  Loss=1.5082  Acc=0.5079\n",
      "[Pretrain] Epoch 41/100  Loss=1.4912  Acc=0.5180\n",
      "[Pretrain] Epoch 42/100  Loss=1.4968  Acc=0.5093\n",
      "[Pretrain] Epoch 43/100  Loss=1.4932  Acc=0.5119\n",
      "[Pretrain] Epoch 44/100  Loss=1.4933  Acc=0.5079\n",
      "[Pretrain] Epoch 45/100  Loss=1.4704  Acc=0.5287\n",
      "[Pretrain] Epoch 46/100  Loss=1.4586  Acc=0.5244\n",
      "[Pretrain] Epoch 47/100  Loss=1.4477  Acc=0.5278\n",
      "[Pretrain] Epoch 48/100  Loss=1.4440  Acc=0.5309\n",
      "[Pretrain] Epoch 49/100  Loss=1.4467  Acc=0.5348\n",
      "[Pretrain] Epoch 50/100  Loss=1.4359  Acc=0.5284\n",
      "[Pretrain] Epoch 51/100  Loss=1.4323  Acc=0.5365\n",
      "[Pretrain] Epoch 52/100  Loss=1.4219  Acc=0.5377\n",
      "[Pretrain] Epoch 53/100  Loss=1.4129  Acc=0.5456\n",
      "[Pretrain] Epoch 54/100  Loss=1.4092  Acc=0.5406\n",
      "[Pretrain] Epoch 55/100  Loss=1.4036  Acc=0.5411\n",
      "[Pretrain] Epoch 56/100  Loss=1.4044  Acc=0.5438\n",
      "[Pretrain] Epoch 57/100  Loss=1.4161  Acc=0.5363\n",
      "[Pretrain] Epoch 58/100  Loss=1.4031  Acc=0.5418\n",
      "[Pretrain] Epoch 59/100  Loss=1.3807  Acc=0.5510\n",
      "[Pretrain] Epoch 60/100  Loss=1.3968  Acc=0.5435\n",
      "[Pretrain] Epoch 61/100  Loss=1.3875  Acc=0.5431\n",
      "[Pretrain] Epoch 62/100  Loss=1.3987  Acc=0.5420\n",
      "[Pretrain] Epoch 63/100  Loss=1.3732  Acc=0.5559\n",
      "[Pretrain] Epoch 64/100  Loss=1.3802  Acc=0.5483\n",
      "[Pretrain] Epoch 65/100  Loss=1.3740  Acc=0.5472\n",
      "[Pretrain] Epoch 66/100  Loss=1.3491  Acc=0.5627\n",
      "[Pretrain] Epoch 67/100  Loss=1.3616  Acc=0.5524\n",
      "[Pretrain] Epoch 68/100  Loss=1.3631  Acc=0.5582\n",
      "[Pretrain] Epoch 69/100  Loss=1.3490  Acc=0.5580\n",
      "[Pretrain] Epoch 70/100  Loss=1.3657  Acc=0.5530\n",
      "[Pretrain] Epoch 71/100  Loss=1.3720  Acc=0.5467\n",
      "[Pretrain] Epoch 72/100  Loss=1.3534  Acc=0.5587\n",
      "[Pretrain] Epoch 73/100  Loss=1.3404  Acc=0.5672\n",
      "[Pretrain] Epoch 74/100  Loss=1.3489  Acc=0.5625\n",
      "[Pretrain] Epoch 75/100  Loss=1.3483  Acc=0.5616\n",
      "[Pretrain] Epoch 76/100  Loss=1.3442  Acc=0.5598\n",
      "[Pretrain] Epoch 77/100  Loss=1.3343  Acc=0.5656\n",
      "[Pretrain] Epoch 78/100  Loss=1.3445  Acc=0.5564\n",
      "[Pretrain] Epoch 79/100  Loss=1.3438  Acc=0.5690\n",
      "[Pretrain] Epoch 80/100  Loss=1.3359  Acc=0.5675\n",
      "[Pretrain] Epoch 81/100  Loss=1.3427  Acc=0.5600\n",
      "[Pretrain] Epoch 82/100  Loss=1.3423  Acc=0.5670\n",
      "[Pretrain] Epoch 83/100  Loss=1.3349  Acc=0.5675\n",
      "[Pretrain] Epoch 84/100  Loss=1.3441  Acc=0.5600\n",
      "[Pretrain] Epoch 85/100  Loss=1.3237  Acc=0.5686\n",
      "[Pretrain] Epoch 86/100  Loss=1.3226  Acc=0.5663\n",
      "[Pretrain] Epoch 87/100  Loss=1.3236  Acc=0.5720\n",
      "[Pretrain] Epoch 88/100  Loss=1.3271  Acc=0.5627\n",
      "[Pretrain] Epoch 89/100  Loss=1.3300  Acc=0.5673\n",
      "[Pretrain] Epoch 90/100  Loss=1.3223  Acc=0.5661\n",
      "[Pretrain] Epoch 91/100  Loss=1.3195  Acc=0.5717\n",
      "[Pretrain] Epoch 92/100  Loss=1.3294  Acc=0.5639\n",
      "[Pretrain] Epoch 93/100  Loss=1.3324  Acc=0.5648\n",
      "[Pretrain] Epoch 94/100  Loss=1.3242  Acc=0.5652\n",
      "[Pretrain] Epoch 95/100  Loss=1.3260  Acc=0.5661\n",
      "[Pretrain] Epoch 96/100  Loss=1.3350  Acc=0.5607\n",
      "[Pretrain] Epoch 97/100  Loss=1.3172  Acc=0.5745\n",
      "[Pretrain] Epoch 98/100  Loss=1.3333  Acc=0.5702\n",
      "[Pretrain] Epoch 99/100  Loss=1.3222  Acc=0.5722\n",
      "[Pretrain] Epoch 100/100  Loss=1.3234  Acc=0.5632\n",
      "[Fine-tune] Epoch 1/75  Loss=3.3112\n",
      "[Fine-tune] Epoch 2/75  Loss=3.1480\n",
      "[Fine-tune] Epoch 3/75  Loss=3.0818\n",
      "[Fine-tune] Epoch 4/75  Loss=3.0375\n",
      "[Fine-tune] Epoch 5/75  Loss=2.9225\n",
      "[Fine-tune] Epoch 6/75  Loss=2.7898\n",
      "[Fine-tune] Epoch 7/75  Loss=2.7629\n",
      "[Fine-tune] Epoch 8/75  Loss=2.6897\n",
      "[Fine-tune] Epoch 9/75  Loss=2.5957\n",
      "[Fine-tune] Epoch 10/75  Loss=2.5096\n",
      "[Fine-tune] Epoch 11/75  Loss=2.4750\n",
      "[Fine-tune] Epoch 12/75  Loss=2.4173\n",
      "[Fine-tune] Epoch 13/75  Loss=2.3914\n",
      "[Fine-tune] Epoch 14/75  Loss=2.3473\n",
      "[Fine-tune] Epoch 15/75  Loss=2.3072\n",
      "[Fine-tune] Epoch 16/75  Loss=2.2899\n",
      "[Fine-tune] Epoch 17/75  Loss=2.2375\n",
      "[Fine-tune] Epoch 18/75  Loss=2.2127\n",
      "[Fine-tune] Epoch 19/75  Loss=2.1843\n",
      "[Fine-tune] Epoch 20/75  Loss=2.1429\n",
      "[Fine-tune] Epoch 21/75  Loss=2.1189\n",
      "[Fine-tune] Epoch 22/75  Loss=2.0743\n",
      "[Fine-tune] Epoch 23/75  Loss=2.0806\n",
      "[Fine-tune] Epoch 24/75  Loss=2.0454\n",
      "[Fine-tune] Epoch 25/75  Loss=2.0054\n",
      "[Fine-tune] Epoch 26/75  Loss=1.9841\n",
      "[Fine-tune] Epoch 27/75  Loss=1.9917\n",
      "[Fine-tune] Epoch 28/75  Loss=1.9403\n",
      "[Fine-tune] Epoch 29/75  Loss=1.9468\n",
      "[Fine-tune] Epoch 30/75  Loss=1.9026\n",
      "[Fine-tune] Epoch 31/75  Loss=1.9022\n",
      "[Fine-tune] Epoch 32/75  Loss=1.8864\n",
      "[Fine-tune] Epoch 33/75  Loss=1.8836\n",
      "[Fine-tune] Epoch 34/75  Loss=1.8515\n",
      "[Fine-tune] Epoch 35/75  Loss=1.8380\n",
      "[Fine-tune] Epoch 36/75  Loss=1.8357\n",
      "[Fine-tune] Epoch 37/75  Loss=1.8094\n",
      "[Fine-tune] Epoch 38/75  Loss=1.7936\n",
      "[Fine-tune] Epoch 39/75  Loss=1.7882\n",
      "[Fine-tune] Epoch 40/75  Loss=1.7692\n",
      "[Fine-tune] Epoch 41/75  Loss=1.7672\n",
      "[Fine-tune] Epoch 42/75  Loss=1.7602\n",
      "[Fine-tune] Epoch 43/75  Loss=1.7555\n",
      "[Fine-tune] Epoch 44/75  Loss=1.7226\n",
      "[Fine-tune] Epoch 45/75  Loss=1.7255\n",
      "[Fine-tune] Epoch 46/75  Loss=1.7124\n",
      "[Fine-tune] Epoch 47/75  Loss=1.6973\n",
      "[Fine-tune] Epoch 48/75  Loss=1.6828\n",
      "[Fine-tune] Epoch 49/75  Loss=1.6727\n",
      "[Fine-tune] Epoch 50/75  Loss=1.6785\n",
      "[Fine-tune] Epoch 51/75  Loss=1.6820\n",
      "[Fine-tune] Epoch 52/75  Loss=1.6713\n",
      "[Fine-tune] Epoch 53/75  Loss=1.6651\n",
      "[Fine-tune] Epoch 54/75  Loss=1.6612\n",
      "[Fine-tune] Epoch 55/75  Loss=1.6562\n",
      "[Fine-tune] Epoch 56/75  Loss=1.6426\n",
      "[Fine-tune] Epoch 57/75  Loss=1.6020\n",
      "[Fine-tune] Epoch 58/75  Loss=1.6258\n",
      "[Fine-tune] Epoch 59/75  Loss=1.6163\n",
      "[Fine-tune] Epoch 60/75  Loss=1.6011\n",
      "[Fine-tune] Epoch 61/75  Loss=1.5954\n",
      "[Fine-tune] Epoch 62/75  Loss=1.6085\n",
      "[Fine-tune] Epoch 63/75  Loss=1.6023\n",
      "[Fine-tune] Epoch 64/75  Loss=1.5913\n",
      "[Fine-tune] Epoch 65/75  Loss=1.5958\n",
      "[Fine-tune] Epoch 66/75  Loss=1.5753\n",
      "[Fine-tune] Epoch 67/75  Loss=1.5715\n",
      "[Fine-tune] Epoch 68/75  Loss=1.5728\n",
      "[Fine-tune] Epoch 69/75  Loss=1.5647\n",
      "[Fine-tune] Epoch 70/75  Loss=1.5772\n",
      "[Fine-tune] Epoch 71/75  Loss=1.5724\n",
      "[Fine-tune] Epoch 72/75  Loss=1.5597\n",
      "[Fine-tune] Epoch 73/75  Loss=1.5588\n",
      "[Fine-tune] Epoch 74/75  Loss=1.5572\n",
      "[Fine-tune] Epoch 75/75  Loss=1.5512\n",
      "[Pretrain] Epoch 1/100  Loss=3.6905  Acc=0.0422\n",
      "[Pretrain] Epoch 2/100  Loss=3.2224  Acc=0.0435\n",
      "[Pretrain] Epoch 3/100  Loss=2.9972  Acc=0.0986\n",
      "[Pretrain] Epoch 4/100  Loss=2.6299  Acc=0.1699\n",
      "[Pretrain] Epoch 5/100  Loss=2.5016  Acc=0.2046\n",
      "[Pretrain] Epoch 6/100  Loss=2.3933  Acc=0.2364\n",
      "[Pretrain] Epoch 7/100  Loss=2.3501  Acc=0.2561\n",
      "[Pretrain] Epoch 8/100  Loss=2.2612  Acc=0.2766\n",
      "[Pretrain] Epoch 9/100  Loss=2.2361  Acc=0.2879\n",
      "[Pretrain] Epoch 10/100  Loss=2.1911  Acc=0.2906\n",
      "[Pretrain] Epoch 11/100  Loss=2.1340  Acc=0.3084\n",
      "[Pretrain] Epoch 12/100  Loss=2.0967  Acc=0.3163\n",
      "[Pretrain] Epoch 13/100  Loss=2.0665  Acc=0.3274\n",
      "[Pretrain] Epoch 14/100  Loss=2.0517  Acc=0.3301\n",
      "[Pretrain] Epoch 15/100  Loss=2.0444  Acc=0.3330\n",
      "[Pretrain] Epoch 16/100  Loss=1.9982  Acc=0.3531\n",
      "[Pretrain] Epoch 17/100  Loss=1.9705  Acc=0.3606\n",
      "[Pretrain] Epoch 18/100  Loss=1.9639  Acc=0.3608\n",
      "[Pretrain] Epoch 19/100  Loss=1.9270  Acc=0.3698\n",
      "[Pretrain] Epoch 20/100  Loss=1.8947  Acc=0.3849\n",
      "[Pretrain] Epoch 21/100  Loss=1.8708  Acc=0.3948\n",
      "[Pretrain] Epoch 22/100  Loss=1.8448  Acc=0.3951\n",
      "[Pretrain] Epoch 23/100  Loss=1.8261  Acc=0.4041\n",
      "[Pretrain] Epoch 24/100  Loss=1.8003  Acc=0.4120\n",
      "[Pretrain] Epoch 25/100  Loss=1.7867  Acc=0.4172\n",
      "[Pretrain] Epoch 26/100  Loss=1.7661  Acc=0.4237\n",
      "[Pretrain] Epoch 27/100  Loss=1.7378  Acc=0.4346\n",
      "[Pretrain] Epoch 28/100  Loss=1.7128  Acc=0.4319\n",
      "[Pretrain] Epoch 29/100  Loss=1.6848  Acc=0.4495\n",
      "[Pretrain] Epoch 30/100  Loss=1.6730  Acc=0.4564\n",
      "[Pretrain] Epoch 31/100  Loss=1.6545  Acc=0.4526\n",
      "[Pretrain] Epoch 32/100  Loss=1.6333  Acc=0.4668\n",
      "[Pretrain] Epoch 33/100  Loss=1.6022  Acc=0.4752\n",
      "[Pretrain] Epoch 34/100  Loss=1.5947  Acc=0.4772\n",
      "[Pretrain] Epoch 35/100  Loss=1.5745  Acc=0.4802\n",
      "[Pretrain] Epoch 36/100  Loss=1.5608  Acc=0.4844\n",
      "[Pretrain] Epoch 37/100  Loss=1.5427  Acc=0.4864\n",
      "[Pretrain] Epoch 38/100  Loss=1.5206  Acc=0.4966\n",
      "[Pretrain] Epoch 39/100  Loss=1.5091  Acc=0.4986\n",
      "[Pretrain] Epoch 40/100  Loss=1.4877  Acc=0.5115\n",
      "[Pretrain] Epoch 41/100  Loss=1.4613  Acc=0.5196\n",
      "[Pretrain] Epoch 42/100  Loss=1.4569  Acc=0.5199\n",
      "[Pretrain] Epoch 43/100  Loss=1.4490  Acc=0.5232\n",
      "[Pretrain] Epoch 44/100  Loss=1.4156  Acc=0.5260\n",
      "[Pretrain] Epoch 45/100  Loss=1.4054  Acc=0.5408\n",
      "[Pretrain] Epoch 46/100  Loss=1.4225  Acc=0.5363\n",
      "[Pretrain] Epoch 47/100  Loss=1.3873  Acc=0.5433\n",
      "[Pretrain] Epoch 48/100  Loss=1.3749  Acc=0.5472\n",
      "[Pretrain] Epoch 49/100  Loss=1.3509  Acc=0.5539\n",
      "[Pretrain] Epoch 50/100  Loss=1.3456  Acc=0.5607\n",
      "[Pretrain] Epoch 51/100  Loss=1.3599  Acc=0.5524\n",
      "[Pretrain] Epoch 52/100  Loss=1.3361  Acc=0.5594\n",
      "[Pretrain] Epoch 53/100  Loss=1.3250  Acc=0.5652\n",
      "[Pretrain] Epoch 54/100  Loss=1.3341  Acc=0.5643\n",
      "[Pretrain] Epoch 55/100  Loss=1.3086  Acc=0.5656\n",
      "[Pretrain] Epoch 56/100  Loss=1.2990  Acc=0.5744\n",
      "[Pretrain] Epoch 57/100  Loss=1.2959  Acc=0.5709\n",
      "[Pretrain] Epoch 58/100  Loss=1.2843  Acc=0.5733\n",
      "[Pretrain] Epoch 59/100  Loss=1.2764  Acc=0.5785\n",
      "[Pretrain] Epoch 60/100  Loss=1.2804  Acc=0.5731\n",
      "[Pretrain] Epoch 61/100  Loss=1.2726  Acc=0.5817\n",
      "[Pretrain] Epoch 62/100  Loss=1.2671  Acc=0.5787\n",
      "[Pretrain] Epoch 63/100  Loss=1.2580  Acc=0.5824\n",
      "[Pretrain] Epoch 64/100  Loss=1.2407  Acc=0.5885\n",
      "[Pretrain] Epoch 65/100  Loss=1.2382  Acc=0.5946\n",
      "[Pretrain] Epoch 66/100  Loss=1.2359  Acc=0.5864\n",
      "[Pretrain] Epoch 67/100  Loss=1.2332  Acc=0.6006\n",
      "[Pretrain] Epoch 68/100  Loss=1.2169  Acc=0.5943\n",
      "[Pretrain] Epoch 69/100  Loss=1.2080  Acc=0.5988\n",
      "[Pretrain] Epoch 70/100  Loss=1.2163  Acc=0.6015\n",
      "[Pretrain] Epoch 71/100  Loss=1.2242  Acc=0.6011\n",
      "[Pretrain] Epoch 72/100  Loss=1.2255  Acc=0.6006\n",
      "[Pretrain] Epoch 73/100  Loss=1.1928  Acc=0.6081\n",
      "[Pretrain] Epoch 74/100  Loss=1.2095  Acc=0.5968\n",
      "[Pretrain] Epoch 75/100  Loss=1.1929  Acc=0.6054\n",
      "[Pretrain] Epoch 76/100  Loss=1.2032  Acc=0.6069\n",
      "[Pretrain] Epoch 77/100  Loss=1.1853  Acc=0.6051\n",
      "[Pretrain] Epoch 78/100  Loss=1.1817  Acc=0.6088\n",
      "[Pretrain] Epoch 79/100  Loss=1.1753  Acc=0.6114\n",
      "[Pretrain] Epoch 80/100  Loss=1.1860  Acc=0.6119\n",
      "[Pretrain] Epoch 81/100  Loss=1.1940  Acc=0.6101\n",
      "[Pretrain] Epoch 82/100  Loss=1.1738  Acc=0.6130\n",
      "[Pretrain] Epoch 83/100  Loss=1.1878  Acc=0.6135\n",
      "[Pretrain] Epoch 84/100  Loss=1.1641  Acc=0.6176\n",
      "[Pretrain] Epoch 85/100  Loss=1.1746  Acc=0.6122\n",
      "[Pretrain] Epoch 86/100  Loss=1.1686  Acc=0.6198\n",
      "[Pretrain] Epoch 87/100  Loss=1.1649  Acc=0.6097\n",
      "[Pretrain] Epoch 88/100  Loss=1.1664  Acc=0.6117\n",
      "[Pretrain] Epoch 89/100  Loss=1.1706  Acc=0.6101\n",
      "[Pretrain] Epoch 90/100  Loss=1.1709  Acc=0.6133\n",
      "[Pretrain] Epoch 91/100  Loss=1.1612  Acc=0.6193\n",
      "[Pretrain] Epoch 92/100  Loss=1.1781  Acc=0.6137\n",
      "[Pretrain] Epoch 93/100  Loss=1.1515  Acc=0.6196\n",
      "[Pretrain] Epoch 94/100  Loss=1.1658  Acc=0.6196\n",
      "[Pretrain] Epoch 95/100  Loss=1.1593  Acc=0.6248\n",
      "[Pretrain] Epoch 96/100  Loss=1.1547  Acc=0.6209\n",
      "[Pretrain] Epoch 97/100  Loss=1.1599  Acc=0.6085\n",
      "[Pretrain] Epoch 98/100  Loss=1.1446  Acc=0.6198\n",
      "[Pretrain] Epoch 99/100  Loss=1.1381  Acc=0.6210\n",
      "[Pretrain] Epoch 100/100  Loss=1.1565  Acc=0.6207\n",
      "[Fine-tune] Epoch 1/75  Loss=3.1816\n",
      "[Fine-tune] Epoch 2/75  Loss=2.7563\n",
      "[Fine-tune] Epoch 3/75  Loss=2.5959\n",
      "[Fine-tune] Epoch 4/75  Loss=2.5244\n",
      "[Fine-tune] Epoch 5/75  Loss=2.4053\n",
      "[Fine-tune] Epoch 6/75  Loss=2.3290\n",
      "[Fine-tune] Epoch 7/75  Loss=2.2653\n",
      "[Fine-tune] Epoch 8/75  Loss=2.2350\n",
      "[Fine-tune] Epoch 9/75  Loss=2.1830\n",
      "[Fine-tune] Epoch 10/75  Loss=2.1425\n",
      "[Fine-tune] Epoch 11/75  Loss=2.1049\n",
      "[Fine-tune] Epoch 12/75  Loss=2.0773\n",
      "[Fine-tune] Epoch 13/75  Loss=2.0396\n",
      "[Fine-tune] Epoch 14/75  Loss=2.0189\n",
      "[Fine-tune] Epoch 15/75  Loss=2.0028\n",
      "[Fine-tune] Epoch 16/75  Loss=1.9633\n",
      "[Fine-tune] Epoch 17/75  Loss=1.9600\n",
      "[Fine-tune] Epoch 18/75  Loss=1.9267\n",
      "[Fine-tune] Epoch 19/75  Loss=1.9059\n",
      "[Fine-tune] Epoch 20/75  Loss=1.8776\n",
      "[Fine-tune] Epoch 21/75  Loss=1.8647\n",
      "[Fine-tune] Epoch 22/75  Loss=1.8372\n",
      "[Fine-tune] Epoch 23/75  Loss=1.8212\n",
      "[Fine-tune] Epoch 24/75  Loss=1.7824\n",
      "[Fine-tune] Epoch 25/75  Loss=1.7801\n",
      "[Fine-tune] Epoch 26/75  Loss=1.7516\n",
      "[Fine-tune] Epoch 27/75  Loss=1.7458\n",
      "[Fine-tune] Epoch 28/75  Loss=1.7417\n",
      "[Fine-tune] Epoch 29/75  Loss=1.7184\n",
      "[Fine-tune] Epoch 30/75  Loss=1.6988\n",
      "[Fine-tune] Epoch 31/75  Loss=1.6804\n",
      "[Fine-tune] Epoch 32/75  Loss=1.6811\n",
      "[Fine-tune] Epoch 33/75  Loss=1.6636\n",
      "[Fine-tune] Epoch 34/75  Loss=1.6458\n",
      "[Fine-tune] Epoch 35/75  Loss=1.6245\n",
      "[Fine-tune] Epoch 36/75  Loss=1.6114\n",
      "[Fine-tune] Epoch 37/75  Loss=1.6119\n",
      "[Fine-tune] Epoch 38/75  Loss=1.5902\n",
      "[Fine-tune] Epoch 39/75  Loss=1.5902\n",
      "[Fine-tune] Epoch 40/75  Loss=1.5822\n",
      "[Fine-tune] Epoch 41/75  Loss=1.5784\n",
      "[Fine-tune] Epoch 42/75  Loss=1.5546\n",
      "[Fine-tune] Epoch 43/75  Loss=1.5513\n",
      "[Fine-tune] Epoch 44/75  Loss=1.5436\n",
      "[Fine-tune] Epoch 45/75  Loss=1.5373\n",
      "[Fine-tune] Epoch 46/75  Loss=1.5187\n",
      "[Fine-tune] Epoch 47/75  Loss=1.5249\n",
      "[Fine-tune] Epoch 48/75  Loss=1.4948\n",
      "[Fine-tune] Epoch 49/75  Loss=1.5186\n",
      "[Fine-tune] Epoch 50/75  Loss=1.4935\n",
      "[Fine-tune] Epoch 51/75  Loss=1.4855\n",
      "[Fine-tune] Epoch 52/75  Loss=1.4771\n",
      "[Fine-tune] Epoch 53/75  Loss=1.4677\n",
      "[Fine-tune] Epoch 54/75  Loss=1.4797\n",
      "[Fine-tune] Epoch 55/75  Loss=1.4719\n",
      "[Fine-tune] Epoch 56/75  Loss=1.4712\n",
      "[Fine-tune] Epoch 57/75  Loss=1.4545\n",
      "[Fine-tune] Epoch 58/75  Loss=1.4626\n",
      "[Fine-tune] Epoch 59/75  Loss=1.4519\n",
      "[Fine-tune] Epoch 60/75  Loss=1.4517\n",
      "[Fine-tune] Epoch 61/75  Loss=1.4529\n",
      "[Fine-tune] Epoch 62/75  Loss=1.4328\n",
      "[Fine-tune] Epoch 63/75  Loss=1.4376\n",
      "[Fine-tune] Epoch 64/75  Loss=1.4308\n",
      "[Fine-tune] Epoch 65/75  Loss=1.4269\n",
      "[Fine-tune] Epoch 66/75  Loss=1.4200\n",
      "[Fine-tune] Epoch 67/75  Loss=1.4334\n",
      "[Fine-tune] Epoch 68/75  Loss=1.4243\n",
      "[Fine-tune] Epoch 69/75  Loss=1.4160\n",
      "[Fine-tune] Epoch 70/75  Loss=1.4183\n",
      "[Fine-tune] Epoch 71/75  Loss=1.4088\n",
      "[Fine-tune] Epoch 72/75  Loss=1.3916\n",
      "[Fine-tune] Epoch 73/75  Loss=1.4108\n",
      "[Fine-tune] Epoch 74/75  Loss=1.4184\n",
      "[Fine-tune] Epoch 75/75  Loss=1.4057\n",
      "[Pretrain] Epoch 1/150  Loss=3.2384  Acc=0.0487\n",
      "[Pretrain] Epoch 2/150  Loss=3.0838  Acc=0.0803\n",
      "[Pretrain] Epoch 3/150  Loss=3.0038  Acc=0.0810\n",
      "[Pretrain] Epoch 4/150  Loss=2.7304  Acc=0.1386\n",
      "[Pretrain] Epoch 5/150  Loss=2.5163  Acc=0.1898\n",
      "[Pretrain] Epoch 6/150  Loss=2.3782  Acc=0.2331\n",
      "[Pretrain] Epoch 7/150  Loss=2.2692  Acc=0.2620\n",
      "[Pretrain] Epoch 8/150  Loss=2.1936  Acc=0.2863\n",
      "[Pretrain] Epoch 9/150  Loss=2.1182  Acc=0.3193\n",
      "[Pretrain] Epoch 10/150  Loss=2.0693  Acc=0.3274\n",
      "[Pretrain] Epoch 11/150  Loss=2.0519  Acc=0.3339\n",
      "[Pretrain] Epoch 12/150  Loss=1.9826  Acc=0.3543\n",
      "[Pretrain] Epoch 13/150  Loss=1.9637  Acc=0.3614\n",
      "[Pretrain] Epoch 14/150  Loss=1.9267  Acc=0.3723\n",
      "[Pretrain] Epoch 15/150  Loss=1.9024  Acc=0.3940\n",
      "[Pretrain] Epoch 16/150  Loss=1.8983  Acc=0.3935\n",
      "[Pretrain] Epoch 17/150  Loss=1.8367  Acc=0.4039\n",
      "[Pretrain] Epoch 18/150  Loss=1.8275  Acc=0.4084\n",
      "[Pretrain] Epoch 19/150  Loss=1.8118  Acc=0.4093\n",
      "[Pretrain] Epoch 20/150  Loss=1.7789  Acc=0.4256\n",
      "[Pretrain] Epoch 21/150  Loss=1.7429  Acc=0.4310\n",
      "[Pretrain] Epoch 22/150  Loss=1.7371  Acc=0.4379\n",
      "[Pretrain] Epoch 23/150  Loss=1.7086  Acc=0.4485\n",
      "[Pretrain] Epoch 24/150  Loss=1.6943  Acc=0.4470\n",
      "[Pretrain] Epoch 25/150  Loss=1.6680  Acc=0.4614\n",
      "[Pretrain] Epoch 26/150  Loss=1.6677  Acc=0.4628\n",
      "[Pretrain] Epoch 27/150  Loss=1.6483  Acc=0.4671\n",
      "[Pretrain] Epoch 28/150  Loss=1.6369  Acc=0.4743\n",
      "[Pretrain] Epoch 29/150  Loss=1.6241  Acc=0.4713\n",
      "[Pretrain] Epoch 30/150  Loss=1.5959  Acc=0.4851\n",
      "[Pretrain] Epoch 31/150  Loss=1.5764  Acc=0.4856\n",
      "[Pretrain] Epoch 32/150  Loss=1.5658  Acc=0.4928\n",
      "[Pretrain] Epoch 33/150  Loss=1.5527  Acc=0.4987\n",
      "[Pretrain] Epoch 34/150  Loss=1.5253  Acc=0.5066\n",
      "[Pretrain] Epoch 35/150  Loss=1.5165  Acc=0.5111\n",
      "[Pretrain] Epoch 36/150  Loss=1.5145  Acc=0.5032\n",
      "[Pretrain] Epoch 37/150  Loss=1.5178  Acc=0.5154\n",
      "[Pretrain] Epoch 38/150  Loss=1.4954  Acc=0.5178\n",
      "[Pretrain] Epoch 39/150  Loss=1.4960  Acc=0.5097\n",
      "[Pretrain] Epoch 40/150  Loss=1.4587  Acc=0.5216\n",
      "[Pretrain] Epoch 41/150  Loss=1.4481  Acc=0.5327\n",
      "[Pretrain] Epoch 42/150  Loss=1.4478  Acc=0.5257\n",
      "[Pretrain] Epoch 43/150  Loss=1.4458  Acc=0.5295\n",
      "[Pretrain] Epoch 44/150  Loss=1.4429  Acc=0.5300\n",
      "[Pretrain] Epoch 45/150  Loss=1.4206  Acc=0.5374\n",
      "[Pretrain] Epoch 46/150  Loss=1.4068  Acc=0.5433\n",
      "[Pretrain] Epoch 47/150  Loss=1.4066  Acc=0.5413\n",
      "[Pretrain] Epoch 48/150  Loss=1.3908  Acc=0.5442\n",
      "[Pretrain] Epoch 49/150  Loss=1.3981  Acc=0.5381\n",
      "[Pretrain] Epoch 50/150  Loss=1.3840  Acc=0.5539\n",
      "[Pretrain] Epoch 51/150  Loss=1.3971  Acc=0.5422\n",
      "[Pretrain] Epoch 52/150  Loss=1.3854  Acc=0.5501\n",
      "[Pretrain] Epoch 53/150  Loss=1.3633  Acc=0.5593\n",
      "[Pretrain] Epoch 54/150  Loss=1.3775  Acc=0.5506\n",
      "[Pretrain] Epoch 55/150  Loss=1.3663  Acc=0.5503\n",
      "[Pretrain] Epoch 56/150  Loss=1.3541  Acc=0.5609\n",
      "[Pretrain] Epoch 57/150  Loss=1.3573  Acc=0.5600\n",
      "[Pretrain] Epoch 58/150  Loss=1.3588  Acc=0.5503\n",
      "[Pretrain] Epoch 59/150  Loss=1.3443  Acc=0.5582\n",
      "[Pretrain] Epoch 60/150  Loss=1.3516  Acc=0.5636\n",
      "[Pretrain] Epoch 61/150  Loss=1.3425  Acc=0.5564\n",
      "[Pretrain] Epoch 62/150  Loss=1.3318  Acc=0.5675\n",
      "[Pretrain] Epoch 63/150  Loss=1.3372  Acc=0.5634\n",
      "[Pretrain] Epoch 64/150  Loss=1.3198  Acc=0.5736\n",
      "[Pretrain] Epoch 65/150  Loss=1.3149  Acc=0.5665\n",
      "[Pretrain] Epoch 66/150  Loss=1.3191  Acc=0.5735\n",
      "[Pretrain] Epoch 67/150  Loss=1.3174  Acc=0.5684\n",
      "[Pretrain] Epoch 68/150  Loss=1.3393  Acc=0.5663\n",
      "[Pretrain] Epoch 69/150  Loss=1.3054  Acc=0.5699\n",
      "[Pretrain] Epoch 70/150  Loss=1.3143  Acc=0.5708\n",
      "[Pretrain] Epoch 71/150  Loss=1.3165  Acc=0.5691\n",
      "[Pretrain] Epoch 72/150  Loss=1.3003  Acc=0.5749\n",
      "[Pretrain] Epoch 73/150  Loss=1.3094  Acc=0.5722\n",
      "[Pretrain] Epoch 74/150  Loss=1.3024  Acc=0.5799\n",
      "[Pretrain] Epoch 75/150  Loss=1.3042  Acc=0.5761\n",
      "[Pretrain] Epoch 76/150  Loss=1.3062  Acc=0.5753\n",
      "[Pretrain] Epoch 77/150  Loss=1.2909  Acc=0.5767\n",
      "[Pretrain] Epoch 78/150  Loss=1.2895  Acc=0.5797\n",
      "[Pretrain] Epoch 79/150  Loss=1.3110  Acc=0.5659\n",
      "[Pretrain] Epoch 80/150  Loss=1.2826  Acc=0.5778\n",
      "[Pretrain] Epoch 81/150  Loss=1.2965  Acc=0.5787\n",
      "[Pretrain] Epoch 82/150  Loss=1.2773  Acc=0.5779\n",
      "[Pretrain] Epoch 83/150  Loss=1.3088  Acc=0.5742\n",
      "[Pretrain] Epoch 84/150  Loss=1.2859  Acc=0.5753\n",
      "[Pretrain] Epoch 85/150  Loss=1.2874  Acc=0.5808\n",
      "[Pretrain] Epoch 86/150  Loss=1.2892  Acc=0.5848\n",
      "[Pretrain] Epoch 87/150  Loss=1.2825  Acc=0.5817\n",
      "[Pretrain] Epoch 88/150  Loss=1.2818  Acc=0.5806\n",
      "[Pretrain] Epoch 89/150  Loss=1.2922  Acc=0.5814\n",
      "[Pretrain] Epoch 90/150  Loss=1.2843  Acc=0.5808\n",
      "[Pretrain] Epoch 91/150  Loss=1.2866  Acc=0.5814\n",
      "[Pretrain] Epoch 92/150  Loss=1.2753  Acc=0.5783\n",
      "[Pretrain] Epoch 93/150  Loss=1.3027  Acc=0.5720\n",
      "[Pretrain] Epoch 94/150  Loss=1.2781  Acc=0.5858\n",
      "[Pretrain] Epoch 95/150  Loss=1.2852  Acc=0.5778\n",
      "[Pretrain] Epoch 96/150  Loss=1.2820  Acc=0.5842\n",
      "[Pretrain] Epoch 97/150  Loss=1.2655  Acc=0.5858\n",
      "[Pretrain] Epoch 98/150  Loss=1.2802  Acc=0.5797\n",
      "[Pretrain] Epoch 99/150  Loss=1.2870  Acc=0.5756\n",
      "[Pretrain] Epoch 100/150  Loss=1.2920  Acc=0.5819\n",
      "[Pretrain] Epoch 101/150  Loss=1.2711  Acc=0.5844\n",
      "[Pretrain] Epoch 102/150  Loss=1.2741  Acc=0.5866\n",
      "[Pretrain] Epoch 103/150  Loss=1.2659  Acc=0.5841\n",
      "[Pretrain] Epoch 104/150  Loss=1.2721  Acc=0.5841\n",
      "[Pretrain] Epoch 105/150  Loss=1.2629  Acc=0.5884\n",
      "[Pretrain] Epoch 106/150  Loss=1.2657  Acc=0.5864\n",
      "[Pretrain] Epoch 107/150  Loss=1.2710  Acc=0.5882\n",
      "[Pretrain] Epoch 108/150  Loss=1.2756  Acc=0.5761\n",
      "[Pretrain] Epoch 109/150  Loss=1.2850  Acc=0.5744\n",
      "[Pretrain] Epoch 110/150  Loss=1.2676  Acc=0.5884\n",
      "[Pretrain] Epoch 111/150  Loss=1.2664  Acc=0.5727\n",
      "[Pretrain] Epoch 112/150  Loss=1.2676  Acc=0.5849\n",
      "[Pretrain] Epoch 113/150  Loss=1.2669  Acc=0.5912\n",
      "[Pretrain] Epoch 114/150  Loss=1.2686  Acc=0.5857\n",
      "[Pretrain] Epoch 115/150  Loss=1.2834  Acc=0.5812\n",
      "[Pretrain] Epoch 116/150  Loss=1.2901  Acc=0.5774\n",
      "[Pretrain] Epoch 117/150  Loss=1.2714  Acc=0.5835\n",
      "[Pretrain] Epoch 118/150  Loss=1.2674  Acc=0.5871\n",
      "[Pretrain] Epoch 119/150  Loss=1.2477  Acc=0.5878\n",
      "[Pretrain] Epoch 120/150  Loss=1.2853  Acc=0.5776\n",
      "[Pretrain] Epoch 121/150  Loss=1.2679  Acc=0.5875\n",
      "[Pretrain] Epoch 122/150  Loss=1.2625  Acc=0.5862\n",
      "[Pretrain] Epoch 123/150  Loss=1.2618  Acc=0.5866\n",
      "[Pretrain] Epoch 124/150  Loss=1.2721  Acc=0.5805\n",
      "[Pretrain] Epoch 125/150  Loss=1.2833  Acc=0.5754\n",
      "[Pretrain] Epoch 126/150  Loss=1.2741  Acc=0.5796\n",
      "[Pretrain] Epoch 127/150  Loss=1.2605  Acc=0.5900\n",
      "[Pretrain] Epoch 128/150  Loss=1.2853  Acc=0.5849\n",
      "[Pretrain] Epoch 129/150  Loss=1.2727  Acc=0.5860\n",
      "[Pretrain] Epoch 130/150  Loss=1.2795  Acc=0.5765\n",
      "[Pretrain] Epoch 131/150  Loss=1.2568  Acc=0.5907\n",
      "[Pretrain] Epoch 132/150  Loss=1.2663  Acc=0.5849\n",
      "[Pretrain] Epoch 133/150  Loss=1.2838  Acc=0.5769\n",
      "[Pretrain] Epoch 134/150  Loss=1.2672  Acc=0.5846\n",
      "[Pretrain] Epoch 135/150  Loss=1.2632  Acc=0.5873\n",
      "[Pretrain] Epoch 136/150  Loss=1.2651  Acc=0.5900\n",
      "[Pretrain] Epoch 137/150  Loss=1.2725  Acc=0.5876\n",
      "[Pretrain] Epoch 138/150  Loss=1.2579  Acc=0.5896\n",
      "[Pretrain] Epoch 139/150  Loss=1.2711  Acc=0.5848\n",
      "[Pretrain] Epoch 140/150  Loss=1.2704  Acc=0.5815\n",
      "[Pretrain] Epoch 141/150  Loss=1.2635  Acc=0.5814\n",
      "[Pretrain] Epoch 142/150  Loss=1.2750  Acc=0.5880\n",
      "[Pretrain] Epoch 143/150  Loss=1.2617  Acc=0.5849\n",
      "[Pretrain] Epoch 144/150  Loss=1.2624  Acc=0.5902\n",
      "[Pretrain] Epoch 145/150  Loss=1.2806  Acc=0.5873\n",
      "[Pretrain] Epoch 146/150  Loss=1.2790  Acc=0.5851\n",
      "[Pretrain] Epoch 147/150  Loss=1.2744  Acc=0.5848\n",
      "[Pretrain] Epoch 148/150  Loss=1.2693  Acc=0.5894\n",
      "[Pretrain] Epoch 149/150  Loss=1.2848  Acc=0.5776\n",
      "[Pretrain] Epoch 150/150  Loss=1.2706  Acc=0.5833\n",
      "[Fine-tune] Epoch 1/75  Loss=3.3069\n",
      "[Fine-tune] Epoch 2/75  Loss=3.2203\n",
      "[Fine-tune] Epoch 3/75  Loss=3.1194\n",
      "[Fine-tune] Epoch 4/75  Loss=3.0583\n",
      "[Fine-tune] Epoch 5/75  Loss=2.9888\n",
      "[Fine-tune] Epoch 6/75  Loss=2.8698\n",
      "[Fine-tune] Epoch 7/75  Loss=2.8053\n",
      "[Fine-tune] Epoch 8/75  Loss=2.7637\n",
      "[Fine-tune] Epoch 9/75  Loss=2.7339\n",
      "[Fine-tune] Epoch 10/75  Loss=2.6961\n",
      "[Fine-tune] Epoch 11/75  Loss=2.6271\n",
      "[Fine-tune] Epoch 12/75  Loss=2.5301\n",
      "[Fine-tune] Epoch 13/75  Loss=2.4818\n",
      "[Fine-tune] Epoch 14/75  Loss=2.4237\n",
      "[Fine-tune] Epoch 15/75  Loss=2.3578\n",
      "[Fine-tune] Epoch 16/75  Loss=2.3185\n",
      "[Fine-tune] Epoch 17/75  Loss=2.2609\n",
      "[Fine-tune] Epoch 18/75  Loss=2.2439\n",
      "[Fine-tune] Epoch 19/75  Loss=2.1946\n",
      "[Fine-tune] Epoch 20/75  Loss=2.1600\n",
      "[Fine-tune] Epoch 21/75  Loss=2.1454\n",
      "[Fine-tune] Epoch 22/75  Loss=2.1134\n",
      "[Fine-tune] Epoch 23/75  Loss=2.0797\n",
      "[Fine-tune] Epoch 24/75  Loss=2.0703\n",
      "[Fine-tune] Epoch 25/75  Loss=2.0337\n",
      "[Fine-tune] Epoch 26/75  Loss=2.0250\n",
      "[Fine-tune] Epoch 27/75  Loss=2.0072\n",
      "[Fine-tune] Epoch 28/75  Loss=1.9777\n",
      "[Fine-tune] Epoch 29/75  Loss=1.9689\n",
      "[Fine-tune] Epoch 30/75  Loss=1.9443\n",
      "[Fine-tune] Epoch 31/75  Loss=1.9325\n",
      "[Fine-tune] Epoch 32/75  Loss=1.9170\n",
      "[Fine-tune] Epoch 33/75  Loss=1.9046\n",
      "[Fine-tune] Epoch 34/75  Loss=1.8687\n",
      "[Fine-tune] Epoch 35/75  Loss=1.8558\n",
      "[Fine-tune] Epoch 36/75  Loss=1.8497\n",
      "[Fine-tune] Epoch 37/75  Loss=1.8423\n",
      "[Fine-tune] Epoch 38/75  Loss=1.8087\n",
      "[Fine-tune] Epoch 39/75  Loss=1.8132\n",
      "[Fine-tune] Epoch 40/75  Loss=1.7963\n",
      "[Fine-tune] Epoch 41/75  Loss=1.7797\n",
      "[Fine-tune] Epoch 42/75  Loss=1.7842\n",
      "[Fine-tune] Epoch 43/75  Loss=1.7596\n",
      "[Fine-tune] Epoch 44/75  Loss=1.7416\n",
      "[Fine-tune] Epoch 45/75  Loss=1.7291\n",
      "[Fine-tune] Epoch 46/75  Loss=1.7440\n",
      "[Fine-tune] Epoch 47/75  Loss=1.7294\n",
      "[Fine-tune] Epoch 48/75  Loss=1.7292\n",
      "[Fine-tune] Epoch 49/75  Loss=1.7097\n",
      "[Fine-tune] Epoch 50/75  Loss=1.7045\n",
      "[Fine-tune] Epoch 51/75  Loss=1.6900\n",
      "[Fine-tune] Epoch 52/75  Loss=1.6856\n",
      "[Fine-tune] Epoch 53/75  Loss=1.6954\n",
      "[Fine-tune] Epoch 54/75  Loss=1.6747\n",
      "[Fine-tune] Epoch 55/75  Loss=1.6609\n",
      "[Fine-tune] Epoch 56/75  Loss=1.6563\n",
      "[Fine-tune] Epoch 57/75  Loss=1.6512\n",
      "[Fine-tune] Epoch 58/75  Loss=1.6526\n",
      "[Fine-tune] Epoch 59/75  Loss=1.6401\n",
      "[Fine-tune] Epoch 60/75  Loss=1.6390\n",
      "[Fine-tune] Epoch 61/75  Loss=1.6349\n",
      "[Fine-tune] Epoch 62/75  Loss=1.6231\n",
      "[Fine-tune] Epoch 63/75  Loss=1.6334\n",
      "[Fine-tune] Epoch 64/75  Loss=1.6232\n",
      "[Fine-tune] Epoch 65/75  Loss=1.6078\n",
      "[Fine-tune] Epoch 66/75  Loss=1.6218\n",
      "[Fine-tune] Epoch 67/75  Loss=1.6037\n",
      "[Fine-tune] Epoch 68/75  Loss=1.6014\n",
      "[Fine-tune] Epoch 69/75  Loss=1.5885\n",
      "[Fine-tune] Epoch 70/75  Loss=1.5930\n",
      "[Fine-tune] Epoch 71/75  Loss=1.5883\n",
      "[Fine-tune] Epoch 72/75  Loss=1.5965\n",
      "[Fine-tune] Epoch 73/75  Loss=1.5849\n",
      "[Fine-tune] Epoch 74/75  Loss=1.5918\n",
      "[Fine-tune] Epoch 75/75  Loss=1.5864\n",
      "[Pretrain] Epoch 1/150  Loss=3.5391  Acc=0.0436\n",
      "[Pretrain] Epoch 2/150  Loss=3.2198  Acc=0.0431\n",
      "[Pretrain] Epoch 3/150  Loss=3.1108  Acc=0.0747\n",
      "[Pretrain] Epoch 4/150  Loss=3.0432  Acc=0.0848\n",
      "[Pretrain] Epoch 5/150  Loss=2.9971  Acc=0.1009\n",
      "[Pretrain] Epoch 6/150  Loss=2.8359  Acc=0.1422\n",
      "[Pretrain] Epoch 7/150  Loss=2.6286  Acc=0.1683\n",
      "[Pretrain] Epoch 8/150  Loss=2.4823  Acc=0.2107\n",
      "[Pretrain] Epoch 9/150  Loss=2.3554  Acc=0.2430\n",
      "[Pretrain] Epoch 10/150  Loss=2.2930  Acc=0.2597\n",
      "[Pretrain] Epoch 11/150  Loss=2.2066  Acc=0.2820\n",
      "[Pretrain] Epoch 12/150  Loss=2.1648  Acc=0.2997\n",
      "[Pretrain] Epoch 13/150  Loss=2.1118  Acc=0.3150\n",
      "[Pretrain] Epoch 14/150  Loss=2.0709  Acc=0.3290\n",
      "[Pretrain] Epoch 15/150  Loss=2.0542  Acc=0.3204\n",
      "[Pretrain] Epoch 16/150  Loss=2.0093  Acc=0.3411\n",
      "[Pretrain] Epoch 17/150  Loss=1.9721  Acc=0.3563\n",
      "[Pretrain] Epoch 18/150  Loss=1.9487  Acc=0.3752\n",
      "[Pretrain] Epoch 19/150  Loss=1.9034  Acc=0.3736\n",
      "[Pretrain] Epoch 20/150  Loss=1.8955  Acc=0.3858\n",
      "[Pretrain] Epoch 21/150  Loss=1.8730  Acc=0.3924\n",
      "[Pretrain] Epoch 22/150  Loss=1.8674  Acc=0.3876\n",
      "[Pretrain] Epoch 23/150  Loss=1.8363  Acc=0.4066\n",
      "[Pretrain] Epoch 24/150  Loss=1.8023  Acc=0.4168\n",
      "[Pretrain] Epoch 25/150  Loss=1.7837  Acc=0.4163\n",
      "[Pretrain] Epoch 26/150  Loss=1.7581  Acc=0.4237\n",
      "[Pretrain] Epoch 27/150  Loss=1.7365  Acc=0.4337\n",
      "[Pretrain] Epoch 28/150  Loss=1.7149  Acc=0.4398\n",
      "[Pretrain] Epoch 29/150  Loss=1.6779  Acc=0.4565\n",
      "[Pretrain] Epoch 30/150  Loss=1.6894  Acc=0.4461\n",
      "[Pretrain] Epoch 31/150  Loss=1.6512  Acc=0.4549\n",
      "[Pretrain] Epoch 32/150  Loss=1.6336  Acc=0.4657\n",
      "[Pretrain] Epoch 33/150  Loss=1.6069  Acc=0.4820\n",
      "[Pretrain] Epoch 34/150  Loss=1.5952  Acc=0.4797\n",
      "[Pretrain] Epoch 35/150  Loss=1.5746  Acc=0.4869\n",
      "[Pretrain] Epoch 36/150  Loss=1.5626  Acc=0.4837\n",
      "[Pretrain] Epoch 37/150  Loss=1.5507  Acc=0.4932\n",
      "[Pretrain] Epoch 38/150  Loss=1.5311  Acc=0.4969\n",
      "[Pretrain] Epoch 39/150  Loss=1.5207  Acc=0.5011\n",
      "[Pretrain] Epoch 40/150  Loss=1.4917  Acc=0.5059\n",
      "[Pretrain] Epoch 41/150  Loss=1.4782  Acc=0.5180\n",
      "[Pretrain] Epoch 42/150  Loss=1.4693  Acc=0.5154\n",
      "[Pretrain] Epoch 43/150  Loss=1.4509  Acc=0.5246\n",
      "[Pretrain] Epoch 44/150  Loss=1.4484  Acc=0.5246\n",
      "[Pretrain] Epoch 45/150  Loss=1.4405  Acc=0.5370\n",
      "[Pretrain] Epoch 46/150  Loss=1.4029  Acc=0.5374\n",
      "[Pretrain] Epoch 47/150  Loss=1.4030  Acc=0.5388\n",
      "[Pretrain] Epoch 48/150  Loss=1.3873  Acc=0.5454\n",
      "[Pretrain] Epoch 49/150  Loss=1.3606  Acc=0.5532\n",
      "[Pretrain] Epoch 50/150  Loss=1.3634  Acc=0.5483\n",
      "[Pretrain] Epoch 51/150  Loss=1.3634  Acc=0.5541\n",
      "[Pretrain] Epoch 52/150  Loss=1.3404  Acc=0.5616\n",
      "[Pretrain] Epoch 53/150  Loss=1.3239  Acc=0.5686\n",
      "[Pretrain] Epoch 54/150  Loss=1.3232  Acc=0.5632\n",
      "[Pretrain] Epoch 55/150  Loss=1.3015  Acc=0.5665\n",
      "[Pretrain] Epoch 56/150  Loss=1.2927  Acc=0.5738\n",
      "[Pretrain] Epoch 57/150  Loss=1.2922  Acc=0.5790\n",
      "[Pretrain] Epoch 58/150  Loss=1.2725  Acc=0.5772\n",
      "[Pretrain] Epoch 59/150  Loss=1.2845  Acc=0.5772\n",
      "[Pretrain] Epoch 60/150  Loss=1.2518  Acc=0.5878\n",
      "[Pretrain] Epoch 61/150  Loss=1.2855  Acc=0.5708\n",
      "[Pretrain] Epoch 62/150  Loss=1.2417  Acc=0.5999\n",
      "[Pretrain] Epoch 63/150  Loss=1.2496  Acc=0.5828\n",
      "[Pretrain] Epoch 64/150  Loss=1.2347  Acc=0.5946\n",
      "[Pretrain] Epoch 65/150  Loss=1.2273  Acc=0.5943\n",
      "[Pretrain] Epoch 66/150  Loss=1.2339  Acc=0.5921\n",
      "[Pretrain] Epoch 67/150  Loss=1.2124  Acc=0.6096\n",
      "[Pretrain] Epoch 68/150  Loss=1.2291  Acc=0.5912\n",
      "[Pretrain] Epoch 69/150  Loss=1.2267  Acc=0.5964\n",
      "[Pretrain] Epoch 70/150  Loss=1.2055  Acc=0.6026\n",
      "[Pretrain] Epoch 71/150  Loss=1.2138  Acc=0.5995\n",
      "[Pretrain] Epoch 72/150  Loss=1.2151  Acc=0.5968\n",
      "[Pretrain] Epoch 73/150  Loss=1.1980  Acc=0.6076\n",
      "[Pretrain] Epoch 74/150  Loss=1.1925  Acc=0.6094\n",
      "[Pretrain] Epoch 75/150  Loss=1.1919  Acc=0.6020\n",
      "[Pretrain] Epoch 76/150  Loss=1.2030  Acc=0.6038\n",
      "[Pretrain] Epoch 77/150  Loss=1.1885  Acc=0.6088\n",
      "[Pretrain] Epoch 78/150  Loss=1.1900  Acc=0.6078\n",
      "[Pretrain] Epoch 79/150  Loss=1.1757  Acc=0.6122\n",
      "[Pretrain] Epoch 80/150  Loss=1.1775  Acc=0.6130\n",
      "[Pretrain] Epoch 81/150  Loss=1.1806  Acc=0.6110\n",
      "[Pretrain] Epoch 82/150  Loss=1.1728  Acc=0.6180\n",
      "[Pretrain] Epoch 83/150  Loss=1.1598  Acc=0.6151\n",
      "[Pretrain] Epoch 84/150  Loss=1.1618  Acc=0.6167\n",
      "[Pretrain] Epoch 85/150  Loss=1.1668  Acc=0.6105\n",
      "[Pretrain] Epoch 86/150  Loss=1.1783  Acc=0.6133\n",
      "[Pretrain] Epoch 87/150  Loss=1.1787  Acc=0.6083\n",
      "[Pretrain] Epoch 88/150  Loss=1.1669  Acc=0.6144\n",
      "[Pretrain] Epoch 89/150  Loss=1.1510  Acc=0.6243\n",
      "[Pretrain] Epoch 90/150  Loss=1.1406  Acc=0.6236\n",
      "[Pretrain] Epoch 91/150  Loss=1.1644  Acc=0.6155\n",
      "[Pretrain] Epoch 92/150  Loss=1.1675  Acc=0.6112\n",
      "[Pretrain] Epoch 93/150  Loss=1.1567  Acc=0.6171\n",
      "[Pretrain] Epoch 94/150  Loss=1.1411  Acc=0.6320\n",
      "[Pretrain] Epoch 95/150  Loss=1.1566  Acc=0.6209\n",
      "[Pretrain] Epoch 96/150  Loss=1.1557  Acc=0.6255\n",
      "[Pretrain] Epoch 97/150  Loss=1.1417  Acc=0.6207\n",
      "[Pretrain] Epoch 98/150  Loss=1.1515  Acc=0.6209\n",
      "[Pretrain] Epoch 99/150  Loss=1.1486  Acc=0.6223\n",
      "[Pretrain] Epoch 100/150  Loss=1.1460  Acc=0.6178\n",
      "[Pretrain] Epoch 101/150  Loss=1.1500  Acc=0.6198\n",
      "[Pretrain] Epoch 102/150  Loss=1.1520  Acc=0.6246\n",
      "[Pretrain] Epoch 103/150  Loss=1.1570  Acc=0.6155\n",
      "[Pretrain] Epoch 104/150  Loss=1.1542  Acc=0.6162\n",
      "[Pretrain] Epoch 105/150  Loss=1.1493  Acc=0.6196\n",
      "[Pretrain] Epoch 106/150  Loss=1.1581  Acc=0.6167\n",
      "[Pretrain] Epoch 107/150  Loss=1.1443  Acc=0.6273\n",
      "[Pretrain] Epoch 108/150  Loss=1.1408  Acc=0.6245\n",
      "[Pretrain] Epoch 109/150  Loss=1.1442  Acc=0.6234\n",
      "[Pretrain] Epoch 110/150  Loss=1.1343  Acc=0.6306\n",
      "[Pretrain] Epoch 111/150  Loss=1.1322  Acc=0.6255\n",
      "[Pretrain] Epoch 112/150  Loss=1.1488  Acc=0.6193\n",
      "[Pretrain] Epoch 113/150  Loss=1.1543  Acc=0.6302\n",
      "[Pretrain] Epoch 114/150  Loss=1.1431  Acc=0.6210\n",
      "[Pretrain] Epoch 115/150  Loss=1.1478  Acc=0.6324\n",
      "[Pretrain] Epoch 116/150  Loss=1.1437  Acc=0.6277\n",
      "[Pretrain] Epoch 117/150  Loss=1.1343  Acc=0.6187\n",
      "[Pretrain] Epoch 118/150  Loss=1.1340  Acc=0.6196\n",
      "[Pretrain] Epoch 119/150  Loss=1.1439  Acc=0.6250\n",
      "[Pretrain] Epoch 120/150  Loss=1.1316  Acc=0.6272\n",
      "[Pretrain] Epoch 121/150  Loss=1.1233  Acc=0.6298\n",
      "[Pretrain] Epoch 122/150  Loss=1.1340  Acc=0.6246\n",
      "[Pretrain] Epoch 123/150  Loss=1.1239  Acc=0.6316\n",
      "[Pretrain] Epoch 124/150  Loss=1.1413  Acc=0.6255\n",
      "[Pretrain] Epoch 125/150  Loss=1.1295  Acc=0.6243\n",
      "[Pretrain] Epoch 126/150  Loss=1.1344  Acc=0.6277\n",
      "[Pretrain] Epoch 127/150  Loss=1.1249  Acc=0.6254\n",
      "[Pretrain] Epoch 128/150  Loss=1.1439  Acc=0.6234\n",
      "[Pretrain] Epoch 129/150  Loss=1.1273  Acc=0.6281\n",
      "[Pretrain] Epoch 130/150  Loss=1.1317  Acc=0.6279\n",
      "[Pretrain] Epoch 131/150  Loss=1.1364  Acc=0.6248\n",
      "[Pretrain] Epoch 132/150  Loss=1.1292  Acc=0.6245\n",
      "[Pretrain] Epoch 133/150  Loss=1.1313  Acc=0.6316\n",
      "[Pretrain] Epoch 134/150  Loss=1.1278  Acc=0.6248\n",
      "[Pretrain] Epoch 135/150  Loss=1.1178  Acc=0.6297\n",
      "[Pretrain] Epoch 136/150  Loss=1.1287  Acc=0.6290\n",
      "[Pretrain] Epoch 137/150  Loss=1.1289  Acc=0.6318\n",
      "[Pretrain] Epoch 138/150  Loss=1.1287  Acc=0.6290\n",
      "[Pretrain] Epoch 139/150  Loss=1.1239  Acc=0.6205\n",
      "[Pretrain] Epoch 140/150  Loss=1.1327  Acc=0.6259\n",
      "[Pretrain] Epoch 141/150  Loss=1.1359  Acc=0.6234\n",
      "[Pretrain] Epoch 142/150  Loss=1.1234  Acc=0.6257\n",
      "[Pretrain] Epoch 143/150  Loss=1.1417  Acc=0.6264\n",
      "[Pretrain] Epoch 144/150  Loss=1.1202  Acc=0.6307\n",
      "[Pretrain] Epoch 145/150  Loss=1.1386  Acc=0.6309\n",
      "[Pretrain] Epoch 146/150  Loss=1.1301  Acc=0.6298\n",
      "[Pretrain] Epoch 147/150  Loss=1.1299  Acc=0.6298\n",
      "[Pretrain] Epoch 148/150  Loss=1.1295  Acc=0.6254\n",
      "[Pretrain] Epoch 149/150  Loss=1.1248  Acc=0.6255\n",
      "[Pretrain] Epoch 150/150  Loss=1.1317  Acc=0.6272\n",
      "[Fine-tune] Epoch 1/75  Loss=3.2643\n",
      "[Fine-tune] Epoch 2/75  Loss=3.0708\n",
      "[Fine-tune] Epoch 3/75  Loss=2.9815\n",
      "[Fine-tune] Epoch 4/75  Loss=2.7403\n",
      "[Fine-tune] Epoch 5/75  Loss=2.5837\n",
      "[Fine-tune] Epoch 6/75  Loss=2.4885\n",
      "[Fine-tune] Epoch 7/75  Loss=2.3843\n",
      "[Fine-tune] Epoch 8/75  Loss=2.3655\n",
      "[Fine-tune] Epoch 9/75  Loss=2.2933\n",
      "[Fine-tune] Epoch 10/75  Loss=2.2731\n",
      "[Fine-tune] Epoch 11/75  Loss=2.2261\n",
      "[Fine-tune] Epoch 12/75  Loss=2.2014\n",
      "[Fine-tune] Epoch 13/75  Loss=2.1551\n",
      "[Fine-tune] Epoch 14/75  Loss=2.1247\n",
      "[Fine-tune] Epoch 15/75  Loss=2.0945\n",
      "[Fine-tune] Epoch 16/75  Loss=2.0565\n",
      "[Fine-tune] Epoch 17/75  Loss=2.0385\n",
      "[Fine-tune] Epoch 18/75  Loss=1.9967\n",
      "[Fine-tune] Epoch 19/75  Loss=1.9977\n",
      "[Fine-tune] Epoch 20/75  Loss=1.9540\n",
      "[Fine-tune] Epoch 21/75  Loss=1.9435\n",
      "[Fine-tune] Epoch 22/75  Loss=1.9393\n",
      "[Fine-tune] Epoch 23/75  Loss=1.8983\n",
      "[Fine-tune] Epoch 24/75  Loss=1.8723\n",
      "[Fine-tune] Epoch 25/75  Loss=1.8676\n",
      "[Fine-tune] Epoch 26/75  Loss=1.8610\n",
      "[Fine-tune] Epoch 27/75  Loss=1.8234\n",
      "[Fine-tune] Epoch 28/75  Loss=1.8301\n",
      "[Fine-tune] Epoch 29/75  Loss=1.8115\n",
      "[Fine-tune] Epoch 30/75  Loss=1.8168\n",
      "[Fine-tune] Epoch 31/75  Loss=1.7899\n",
      "[Fine-tune] Epoch 32/75  Loss=1.7720\n",
      "[Fine-tune] Epoch 33/75  Loss=1.7713\n",
      "[Fine-tune] Epoch 34/75  Loss=1.7453\n",
      "[Fine-tune] Epoch 35/75  Loss=1.7533\n",
      "[Fine-tune] Epoch 36/75  Loss=1.7218\n",
      "[Fine-tune] Epoch 37/75  Loss=1.7244\n",
      "[Fine-tune] Epoch 38/75  Loss=1.7214\n",
      "[Fine-tune] Epoch 39/75  Loss=1.7117\n",
      "[Fine-tune] Epoch 40/75  Loss=1.7121\n",
      "[Fine-tune] Epoch 41/75  Loss=1.6987\n",
      "[Fine-tune] Epoch 42/75  Loss=1.6824\n",
      "[Fine-tune] Epoch 43/75  Loss=1.6832\n",
      "[Fine-tune] Epoch 44/75  Loss=1.6732\n",
      "[Fine-tune] Epoch 45/75  Loss=1.6543\n",
      "[Fine-tune] Epoch 46/75  Loss=1.6589\n",
      "[Fine-tune] Epoch 47/75  Loss=1.6558\n",
      "[Fine-tune] Epoch 48/75  Loss=1.6351\n",
      "[Fine-tune] Epoch 49/75  Loss=1.6523\n",
      "[Fine-tune] Epoch 50/75  Loss=1.6179\n",
      "[Fine-tune] Epoch 51/75  Loss=1.6232\n",
      "[Fine-tune] Epoch 52/75  Loss=1.6261\n",
      "[Fine-tune] Epoch 53/75  Loss=1.6160\n",
      "[Fine-tune] Epoch 54/75  Loss=1.6126\n",
      "[Fine-tune] Epoch 55/75  Loss=1.6193\n",
      "[Fine-tune] Epoch 56/75  Loss=1.6005\n",
      "[Fine-tune] Epoch 57/75  Loss=1.6043\n",
      "[Fine-tune] Epoch 58/75  Loss=1.5985\n",
      "[Fine-tune] Epoch 59/75  Loss=1.5892\n",
      "[Fine-tune] Epoch 60/75  Loss=1.5909\n",
      "[Fine-tune] Epoch 61/75  Loss=1.5773\n",
      "[Fine-tune] Epoch 62/75  Loss=1.5813\n",
      "[Fine-tune] Epoch 63/75  Loss=1.5893\n",
      "[Fine-tune] Epoch 64/75  Loss=1.5743\n",
      "[Fine-tune] Epoch 65/75  Loss=1.5868\n",
      "[Fine-tune] Epoch 66/75  Loss=1.5744\n",
      "[Fine-tune] Epoch 67/75  Loss=1.5672\n",
      "[Fine-tune] Epoch 68/75  Loss=1.5671\n",
      "[Fine-tune] Epoch 69/75  Loss=1.5682\n",
      "[Fine-tune] Epoch 70/75  Loss=1.5688\n",
      "[Fine-tune] Epoch 71/75  Loss=1.5647\n",
      "[Fine-tune] Epoch 72/75  Loss=1.5500\n",
      "[Fine-tune] Epoch 73/75  Loss=1.5615\n",
      "[Fine-tune] Epoch 74/75  Loss=1.5575\n",
      "[Fine-tune] Epoch 75/75  Loss=1.5525\n",
      "[Pretrain] Epoch 1/50  Loss=3.2604  Acc=0.0424\n",
      "[Pretrain] Epoch 2/50  Loss=3.2129  Acc=0.0427\n",
      "[Pretrain] Epoch 3/50  Loss=3.0495  Acc=0.0742\n",
      "[Pretrain] Epoch 4/50  Loss=2.7277  Acc=0.1336\n",
      "[Pretrain] Epoch 5/50  Loss=2.5626  Acc=0.1733\n",
      "[Pretrain] Epoch 6/50  Loss=2.4551  Acc=0.2141\n",
      "[Pretrain] Epoch 7/50  Loss=2.3412  Acc=0.2428\n",
      "[Pretrain] Epoch 8/50  Loss=2.2762  Acc=0.2604\n",
      "[Pretrain] Epoch 9/50  Loss=2.2388  Acc=0.2728\n",
      "[Pretrain] Epoch 10/50  Loss=2.1702  Acc=0.2953\n",
      "[Pretrain] Epoch 11/50  Loss=2.0807  Acc=0.3172\n",
      "[Pretrain] Epoch 12/50  Loss=2.0680  Acc=0.3235\n",
      "[Pretrain] Epoch 13/50  Loss=2.0279  Acc=0.3371\n",
      "[Pretrain] Epoch 14/50  Loss=1.9946  Acc=0.3513\n",
      "[Pretrain] Epoch 15/50  Loss=1.9787  Acc=0.3633\n",
      "[Pretrain] Epoch 16/50  Loss=1.9301  Acc=0.3773\n",
      "[Pretrain] Epoch 17/50  Loss=1.8816  Acc=0.3888\n",
      "[Pretrain] Epoch 18/50  Loss=1.8605  Acc=0.3978\n",
      "[Pretrain] Epoch 19/50  Loss=1.8717  Acc=0.3935\n",
      "[Pretrain] Epoch 20/50  Loss=1.8387  Acc=0.4062\n",
      "[Pretrain] Epoch 21/50  Loss=1.8130  Acc=0.4156\n",
      "[Pretrain] Epoch 22/50  Loss=1.7988  Acc=0.4210\n",
      "[Pretrain] Epoch 23/50  Loss=1.7693  Acc=0.4262\n",
      "[Pretrain] Epoch 24/50  Loss=1.7558  Acc=0.4321\n",
      "[Pretrain] Epoch 25/50  Loss=1.7314  Acc=0.4452\n",
      "[Pretrain] Epoch 26/50  Loss=1.7199  Acc=0.4431\n",
      "[Pretrain] Epoch 27/50  Loss=1.6940  Acc=0.4499\n",
      "[Pretrain] Epoch 28/50  Loss=1.6756  Acc=0.4587\n",
      "[Pretrain] Epoch 29/50  Loss=1.6735  Acc=0.4576\n",
      "[Pretrain] Epoch 30/50  Loss=1.6670  Acc=0.4578\n",
      "[Pretrain] Epoch 31/50  Loss=1.6459  Acc=0.4759\n",
      "[Pretrain] Epoch 32/50  Loss=1.6283  Acc=0.4720\n",
      "[Pretrain] Epoch 33/50  Loss=1.6211  Acc=0.4777\n",
      "[Pretrain] Epoch 34/50  Loss=1.6029  Acc=0.4844\n",
      "[Pretrain] Epoch 35/50  Loss=1.5962  Acc=0.4846\n",
      "[Pretrain] Epoch 36/50  Loss=1.5930  Acc=0.4781\n",
      "[Pretrain] Epoch 37/50  Loss=1.5572  Acc=0.4953\n",
      "[Pretrain] Epoch 38/50  Loss=1.5551  Acc=0.5000\n",
      "[Pretrain] Epoch 39/50  Loss=1.5413  Acc=0.4964\n",
      "[Pretrain] Epoch 40/50  Loss=1.5288  Acc=0.5065\n",
      "[Pretrain] Epoch 41/50  Loss=1.5241  Acc=0.5048\n",
      "[Pretrain] Epoch 42/50  Loss=1.5108  Acc=0.5106\n",
      "[Pretrain] Epoch 43/50  Loss=1.5115  Acc=0.5147\n",
      "[Pretrain] Epoch 44/50  Loss=1.5009  Acc=0.5115\n",
      "[Pretrain] Epoch 45/50  Loss=1.4997  Acc=0.5201\n",
      "[Pretrain] Epoch 46/50  Loss=1.4724  Acc=0.5235\n",
      "[Pretrain] Epoch 47/50  Loss=1.4885  Acc=0.5205\n",
      "[Pretrain] Epoch 48/50  Loss=1.4717  Acc=0.5156\n",
      "[Pretrain] Epoch 49/50  Loss=1.4688  Acc=0.5232\n",
      "[Pretrain] Epoch 50/50  Loss=1.4417  Acc=0.5327\n",
      "[Fine-tune] Epoch 1/75  Loss=3.2781\n",
      "[Fine-tune] Epoch 2/75  Loss=3.1684\n",
      "[Fine-tune] Epoch 3/75  Loss=3.0263\n",
      "[Fine-tune] Epoch 4/75  Loss=2.6940\n",
      "[Fine-tune] Epoch 5/75  Loss=2.5347\n",
      "[Fine-tune] Epoch 6/75  Loss=2.4628\n",
      "[Fine-tune] Epoch 7/75  Loss=2.3706\n",
      "[Fine-tune] Epoch 8/75  Loss=2.3475\n",
      "[Fine-tune] Epoch 9/75  Loss=2.3002\n",
      "[Fine-tune] Epoch 10/75  Loss=2.2521\n",
      "[Fine-tune] Epoch 11/75  Loss=2.2161\n",
      "[Fine-tune] Epoch 12/75  Loss=2.1881\n",
      "[Fine-tune] Epoch 13/75  Loss=2.1500\n",
      "[Fine-tune] Epoch 14/75  Loss=2.1228\n",
      "[Fine-tune] Epoch 15/75  Loss=2.1072\n",
      "[Fine-tune] Epoch 16/75  Loss=2.0657\n",
      "[Fine-tune] Epoch 17/75  Loss=2.0502\n",
      "[Fine-tune] Epoch 18/75  Loss=2.0240\n",
      "[Fine-tune] Epoch 19/75  Loss=1.9919\n",
      "[Fine-tune] Epoch 20/75  Loss=1.9695\n",
      "[Fine-tune] Epoch 21/75  Loss=1.9409\n",
      "[Fine-tune] Epoch 22/75  Loss=1.9262\n",
      "[Fine-tune] Epoch 23/75  Loss=1.9126\n",
      "[Fine-tune] Epoch 24/75  Loss=1.8713\n",
      "[Fine-tune] Epoch 25/75  Loss=1.8723\n",
      "[Fine-tune] Epoch 26/75  Loss=1.8449\n",
      "[Fine-tune] Epoch 27/75  Loss=1.8352\n",
      "[Fine-tune] Epoch 28/75  Loss=1.7962\n",
      "[Fine-tune] Epoch 29/75  Loss=1.7889\n",
      "[Fine-tune] Epoch 30/75  Loss=1.7753\n",
      "[Fine-tune] Epoch 31/75  Loss=1.7544\n",
      "[Fine-tune] Epoch 32/75  Loss=1.7431\n",
      "[Fine-tune] Epoch 33/75  Loss=1.7245\n",
      "[Fine-tune] Epoch 34/75  Loss=1.7290\n",
      "[Fine-tune] Epoch 35/75  Loss=1.7166\n",
      "[Fine-tune] Epoch 36/75  Loss=1.6772\n",
      "[Fine-tune] Epoch 37/75  Loss=1.6935\n",
      "[Fine-tune] Epoch 38/75  Loss=1.6578\n",
      "[Fine-tune] Epoch 39/75  Loss=1.6496\n",
      "[Fine-tune] Epoch 40/75  Loss=1.6544\n",
      "[Fine-tune] Epoch 41/75  Loss=1.6262\n",
      "[Fine-tune] Epoch 42/75  Loss=1.6095\n",
      "[Fine-tune] Epoch 43/75  Loss=1.6143\n",
      "[Fine-tune] Epoch 44/75  Loss=1.6014\n",
      "[Fine-tune] Epoch 45/75  Loss=1.5906\n",
      "[Fine-tune] Epoch 46/75  Loss=1.5834\n",
      "[Fine-tune] Epoch 47/75  Loss=1.5766\n",
      "[Fine-tune] Epoch 48/75  Loss=1.5638\n",
      "[Fine-tune] Epoch 49/75  Loss=1.5580\n",
      "[Fine-tune] Epoch 50/75  Loss=1.5590\n",
      "[Fine-tune] Epoch 51/75  Loss=1.5608\n",
      "[Fine-tune] Epoch 52/75  Loss=1.5414\n",
      "[Fine-tune] Epoch 53/75  Loss=1.5346\n",
      "[Fine-tune] Epoch 54/75  Loss=1.5299\n",
      "[Fine-tune] Epoch 55/75  Loss=1.5209\n",
      "[Fine-tune] Epoch 56/75  Loss=1.5210\n",
      "[Fine-tune] Epoch 57/75  Loss=1.5198\n",
      "[Fine-tune] Epoch 58/75  Loss=1.5184\n",
      "[Fine-tune] Epoch 59/75  Loss=1.5169\n",
      "[Fine-tune] Epoch 60/75  Loss=1.5039\n",
      "[Fine-tune] Epoch 61/75  Loss=1.4885\n",
      "[Fine-tune] Epoch 62/75  Loss=1.4852\n",
      "[Fine-tune] Epoch 63/75  Loss=1.4867\n",
      "[Fine-tune] Epoch 64/75  Loss=1.4768\n",
      "[Fine-tune] Epoch 65/75  Loss=1.4857\n",
      "[Fine-tune] Epoch 66/75  Loss=1.4742\n",
      "[Fine-tune] Epoch 67/75  Loss=1.4701\n",
      "[Fine-tune] Epoch 68/75  Loss=1.4766\n",
      "[Fine-tune] Epoch 69/75  Loss=1.4578\n",
      "[Fine-tune] Epoch 70/75  Loss=1.4693\n",
      "[Fine-tune] Epoch 71/75  Loss=1.4594\n",
      "[Fine-tune] Epoch 72/75  Loss=1.4581\n",
      "[Fine-tune] Epoch 73/75  Loss=1.4616\n",
      "[Fine-tune] Epoch 74/75  Loss=1.4613\n",
      "[Fine-tune] Epoch 75/75  Loss=1.4426\n",
      "[Pretrain] Epoch 1/50  Loss=3.6423  Acc=0.0383\n",
      "[Pretrain] Epoch 2/50  Loss=3.1252  Acc=0.0697\n",
      "[Pretrain] Epoch 3/50  Loss=2.9939  Acc=0.0878\n",
      "[Pretrain] Epoch 4/50  Loss=2.7278  Acc=0.1433\n",
      "[Pretrain] Epoch 5/50  Loss=2.6166  Acc=0.1690\n",
      "[Pretrain] Epoch 6/50  Loss=2.4650  Acc=0.2189\n",
      "[Pretrain] Epoch 7/50  Loss=2.3384  Acc=0.2473\n",
      "[Pretrain] Epoch 8/50  Loss=2.2975  Acc=0.2645\n",
      "[Pretrain] Epoch 9/50  Loss=2.2102  Acc=0.2827\n",
      "[Pretrain] Epoch 10/50  Loss=2.1688  Acc=0.3012\n",
      "[Pretrain] Epoch 11/50  Loss=2.1249  Acc=0.3111\n",
      "[Pretrain] Epoch 12/50  Loss=2.1070  Acc=0.3172\n",
      "[Pretrain] Epoch 13/50  Loss=2.0667  Acc=0.3226\n",
      "[Pretrain] Epoch 14/50  Loss=2.0447  Acc=0.3366\n",
      "[Pretrain] Epoch 15/50  Loss=2.0041  Acc=0.3425\n",
      "[Pretrain] Epoch 16/50  Loss=1.9614  Acc=0.3624\n",
      "[Pretrain] Epoch 17/50  Loss=1.9612  Acc=0.3649\n",
      "[Pretrain] Epoch 18/50  Loss=1.9048  Acc=0.3745\n",
      "[Pretrain] Epoch 19/50  Loss=1.9138  Acc=0.3750\n",
      "[Pretrain] Epoch 20/50  Loss=1.8702  Acc=0.3933\n",
      "[Pretrain] Epoch 21/50  Loss=1.8296  Acc=0.4010\n",
      "[Pretrain] Epoch 22/50  Loss=1.8241  Acc=0.4059\n",
      "[Pretrain] Epoch 23/50  Loss=1.8062  Acc=0.4104\n",
      "[Pretrain] Epoch 24/50  Loss=1.8058  Acc=0.4208\n",
      "[Pretrain] Epoch 25/50  Loss=1.7516  Acc=0.4273\n",
      "[Pretrain] Epoch 26/50  Loss=1.7226  Acc=0.4375\n",
      "[Pretrain] Epoch 27/50  Loss=1.7187  Acc=0.4402\n",
      "[Pretrain] Epoch 28/50  Loss=1.6703  Acc=0.4614\n",
      "[Pretrain] Epoch 29/50  Loss=1.6588  Acc=0.4630\n",
      "[Pretrain] Epoch 30/50  Loss=1.6358  Acc=0.4698\n",
      "[Pretrain] Epoch 31/50  Loss=1.6201  Acc=0.4673\n",
      "[Pretrain] Epoch 32/50  Loss=1.5885  Acc=0.4842\n",
      "[Pretrain] Epoch 33/50  Loss=1.5539  Acc=0.4939\n",
      "[Pretrain] Epoch 34/50  Loss=1.5545  Acc=0.5009\n",
      "[Pretrain] Epoch 35/50  Loss=1.5174  Acc=0.5119\n",
      "[Pretrain] Epoch 36/50  Loss=1.5008  Acc=0.5138\n",
      "[Pretrain] Epoch 37/50  Loss=1.5002  Acc=0.5090\n",
      "[Pretrain] Epoch 38/50  Loss=1.4594  Acc=0.5214\n",
      "[Pretrain] Epoch 39/50  Loss=1.4646  Acc=0.5253\n",
      "[Pretrain] Epoch 40/50  Loss=1.4320  Acc=0.5307\n",
      "[Pretrain] Epoch 41/50  Loss=1.4177  Acc=0.5444\n",
      "[Pretrain] Epoch 42/50  Loss=1.3872  Acc=0.5447\n",
      "[Pretrain] Epoch 43/50  Loss=1.3788  Acc=0.5458\n",
      "[Pretrain] Epoch 44/50  Loss=1.3668  Acc=0.5487\n",
      "[Pretrain] Epoch 45/50  Loss=1.3648  Acc=0.5524\n",
      "[Pretrain] Epoch 46/50  Loss=1.3431  Acc=0.5571\n",
      "[Pretrain] Epoch 47/50  Loss=1.3324  Acc=0.5673\n",
      "[Pretrain] Epoch 48/50  Loss=1.2968  Acc=0.5819\n",
      "[Pretrain] Epoch 49/50  Loss=1.3005  Acc=0.5753\n",
      "[Pretrain] Epoch 50/50  Loss=1.2888  Acc=0.5819\n",
      "[Fine-tune] Epoch 1/75  Loss=2.9114\n",
      "[Fine-tune] Epoch 2/75  Loss=2.4230\n",
      "[Fine-tune] Epoch 3/75  Loss=2.2656\n",
      "[Fine-tune] Epoch 4/75  Loss=2.1942\n",
      "[Fine-tune] Epoch 5/75  Loss=2.1130\n",
      "[Fine-tune] Epoch 6/75  Loss=2.0481\n",
      "[Fine-tune] Epoch 7/75  Loss=2.0260\n",
      "[Fine-tune] Epoch 8/75  Loss=1.9745\n",
      "[Fine-tune] Epoch 9/75  Loss=1.9184\n",
      "[Fine-tune] Epoch 10/75  Loss=1.9240\n",
      "[Fine-tune] Epoch 11/75  Loss=1.8616\n",
      "[Fine-tune] Epoch 12/75  Loss=1.8139\n",
      "[Fine-tune] Epoch 13/75  Loss=1.7993\n",
      "[Fine-tune] Epoch 14/75  Loss=1.7434\n",
      "[Fine-tune] Epoch 15/75  Loss=1.7195\n",
      "[Fine-tune] Epoch 16/75  Loss=1.6813\n",
      "[Fine-tune] Epoch 17/75  Loss=1.6608\n",
      "[Fine-tune] Epoch 18/75  Loss=1.6113\n",
      "[Fine-tune] Epoch 19/75  Loss=1.5821\n",
      "[Fine-tune] Epoch 20/75  Loss=1.5658\n",
      "[Fine-tune] Epoch 21/75  Loss=1.5304\n",
      "[Fine-tune] Epoch 22/75  Loss=1.5160\n",
      "[Fine-tune] Epoch 23/75  Loss=1.4815\n",
      "[Fine-tune] Epoch 24/75  Loss=1.4732\n",
      "[Fine-tune] Epoch 25/75  Loss=1.4338\n",
      "[Fine-tune] Epoch 26/75  Loss=1.4100\n",
      "[Fine-tune] Epoch 27/75  Loss=1.4068\n",
      "[Fine-tune] Epoch 28/75  Loss=1.3747\n",
      "[Fine-tune] Epoch 29/75  Loss=1.3605\n",
      "[Fine-tune] Epoch 30/75  Loss=1.3355\n",
      "[Fine-tune] Epoch 31/75  Loss=1.3414\n",
      "[Fine-tune] Epoch 32/75  Loss=1.3188\n",
      "[Fine-tune] Epoch 33/75  Loss=1.2857\n",
      "[Fine-tune] Epoch 34/75  Loss=1.2767\n",
      "[Fine-tune] Epoch 35/75  Loss=1.2652\n",
      "[Fine-tune] Epoch 36/75  Loss=1.2551\n",
      "[Fine-tune] Epoch 37/75  Loss=1.2601\n",
      "[Fine-tune] Epoch 38/75  Loss=1.2401\n",
      "[Fine-tune] Epoch 39/75  Loss=1.2330\n",
      "[Fine-tune] Epoch 40/75  Loss=1.2221\n",
      "[Fine-tune] Epoch 41/75  Loss=1.1970\n",
      "[Fine-tune] Epoch 42/75  Loss=1.2055\n",
      "[Fine-tune] Epoch 43/75  Loss=1.2055\n",
      "[Fine-tune] Epoch 44/75  Loss=1.1904\n",
      "[Fine-tune] Epoch 45/75  Loss=1.1808\n",
      "[Fine-tune] Epoch 46/75  Loss=1.1669\n",
      "[Fine-tune] Epoch 47/75  Loss=1.1518\n",
      "[Fine-tune] Epoch 48/75  Loss=1.1440\n",
      "[Fine-tune] Epoch 49/75  Loss=1.1583\n",
      "[Fine-tune] Epoch 50/75  Loss=1.1347\n",
      "[Fine-tune] Epoch 51/75  Loss=1.1445\n",
      "[Fine-tune] Epoch 52/75  Loss=1.1417\n",
      "[Fine-tune] Epoch 53/75  Loss=1.1389\n",
      "[Fine-tune] Epoch 54/75  Loss=1.1231\n",
      "[Fine-tune] Epoch 55/75  Loss=1.1115\n",
      "[Fine-tune] Epoch 56/75  Loss=1.1042\n",
      "[Fine-tune] Epoch 57/75  Loss=1.1101\n",
      "[Fine-tune] Epoch 58/75  Loss=1.1022\n",
      "[Fine-tune] Epoch 59/75  Loss=1.1129\n",
      "[Fine-tune] Epoch 60/75  Loss=1.0995\n",
      "[Fine-tune] Epoch 61/75  Loss=1.0825\n",
      "[Fine-tune] Epoch 62/75  Loss=1.1034\n",
      "[Fine-tune] Epoch 63/75  Loss=1.1000\n",
      "[Fine-tune] Epoch 64/75  Loss=1.0858\n",
      "[Fine-tune] Epoch 65/75  Loss=1.0835\n",
      "[Fine-tune] Epoch 66/75  Loss=1.0732\n",
      "[Fine-tune] Epoch 67/75  Loss=1.0699\n",
      "[Fine-tune] Epoch 68/75  Loss=1.0907\n",
      "[Fine-tune] Epoch 69/75  Loss=1.0868\n",
      "[Fine-tune] Epoch 70/75  Loss=1.0576\n",
      "[Fine-tune] Epoch 71/75  Loss=1.0613\n",
      "[Fine-tune] Epoch 72/75  Loss=1.0703\n",
      "[Fine-tune] Epoch 73/75  Loss=1.0574\n",
      "[Fine-tune] Epoch 74/75  Loss=1.0681\n",
      "[Fine-tune] Epoch 75/75  Loss=1.0737\n",
      "[Pretrain] Epoch 1/75  Loss=3.2426  Acc=0.0444\n",
      "[Pretrain] Epoch 2/75  Loss=3.1602  Acc=0.0550\n",
      "[Pretrain] Epoch 3/75  Loss=3.0264  Acc=0.0921\n",
      "[Pretrain] Epoch 4/75  Loss=2.7275  Acc=0.1442\n",
      "[Pretrain] Epoch 5/75  Loss=2.5232  Acc=0.1976\n",
      "[Pretrain] Epoch 6/75  Loss=2.4004  Acc=0.2302\n",
      "[Pretrain] Epoch 7/75  Loss=2.2664  Acc=0.2678\n",
      "[Pretrain] Epoch 8/75  Loss=2.1910  Acc=0.2940\n",
      "[Pretrain] Epoch 9/75  Loss=2.1434  Acc=0.3084\n",
      "[Pretrain] Epoch 10/75  Loss=2.1134  Acc=0.3059\n",
      "[Pretrain] Epoch 11/75  Loss=2.0843  Acc=0.3227\n",
      "[Pretrain] Epoch 12/75  Loss=2.0230  Acc=0.3463\n",
      "[Pretrain] Epoch 13/75  Loss=1.9811  Acc=0.3596\n",
      "[Pretrain] Epoch 14/75  Loss=1.9756  Acc=0.3622\n",
      "[Pretrain] Epoch 15/75  Loss=1.9106  Acc=0.3816\n",
      "[Pretrain] Epoch 16/75  Loss=1.8902  Acc=0.3897\n",
      "[Pretrain] Epoch 17/75  Loss=1.8638  Acc=0.3908\n",
      "[Pretrain] Epoch 18/75  Loss=1.8421  Acc=0.3982\n",
      "[Pretrain] Epoch 19/75  Loss=1.8006  Acc=0.4149\n",
      "[Pretrain] Epoch 20/75  Loss=1.7781  Acc=0.4215\n",
      "[Pretrain] Epoch 21/75  Loss=1.7838  Acc=0.4226\n",
      "[Pretrain] Epoch 22/75  Loss=1.7643  Acc=0.4249\n",
      "[Pretrain] Epoch 23/75  Loss=1.7297  Acc=0.4411\n",
      "[Pretrain] Epoch 24/75  Loss=1.7209  Acc=0.4459\n",
      "[Pretrain] Epoch 25/75  Loss=1.7065  Acc=0.4520\n",
      "[Pretrain] Epoch 26/75  Loss=1.6817  Acc=0.4603\n",
      "[Pretrain] Epoch 27/75  Loss=1.6789  Acc=0.4585\n",
      "[Pretrain] Epoch 28/75  Loss=1.6527  Acc=0.4759\n",
      "[Pretrain] Epoch 29/75  Loss=1.6404  Acc=0.4675\n",
      "[Pretrain] Epoch 30/75  Loss=1.6223  Acc=0.4779\n",
      "[Pretrain] Epoch 31/75  Loss=1.6166  Acc=0.4754\n",
      "[Pretrain] Epoch 32/75  Loss=1.5847  Acc=0.4828\n",
      "[Pretrain] Epoch 33/75  Loss=1.5813  Acc=0.4885\n",
      "[Pretrain] Epoch 34/75  Loss=1.5823  Acc=0.4865\n",
      "[Pretrain] Epoch 35/75  Loss=1.5465  Acc=0.4955\n",
      "[Pretrain] Epoch 36/75  Loss=1.5506  Acc=0.4962\n",
      "[Pretrain] Epoch 37/75  Loss=1.5519  Acc=0.4977\n",
      "[Pretrain] Epoch 38/75  Loss=1.5206  Acc=0.5050\n",
      "[Pretrain] Epoch 39/75  Loss=1.4939  Acc=0.5151\n",
      "[Pretrain] Epoch 40/75  Loss=1.4971  Acc=0.5178\n",
      "[Pretrain] Epoch 41/75  Loss=1.4916  Acc=0.5172\n",
      "[Pretrain] Epoch 42/75  Loss=1.4749  Acc=0.5207\n",
      "[Pretrain] Epoch 43/75  Loss=1.4599  Acc=0.5268\n",
      "[Pretrain] Epoch 44/75  Loss=1.4498  Acc=0.5361\n",
      "[Pretrain] Epoch 45/75  Loss=1.4417  Acc=0.5325\n",
      "[Pretrain] Epoch 46/75  Loss=1.4439  Acc=0.5251\n",
      "[Pretrain] Epoch 47/75  Loss=1.4323  Acc=0.5379\n",
      "[Pretrain] Epoch 48/75  Loss=1.4336  Acc=0.5356\n",
      "[Pretrain] Epoch 49/75  Loss=1.4120  Acc=0.5390\n",
      "[Pretrain] Epoch 50/75  Loss=1.4028  Acc=0.5487\n",
      "[Pretrain] Epoch 51/75  Loss=1.3993  Acc=0.5463\n",
      "[Pretrain] Epoch 52/75  Loss=1.4042  Acc=0.5510\n",
      "[Pretrain] Epoch 53/75  Loss=1.3747  Acc=0.5490\n",
      "[Pretrain] Epoch 54/75  Loss=1.3963  Acc=0.5487\n",
      "[Pretrain] Epoch 55/75  Loss=1.3870  Acc=0.5512\n",
      "[Pretrain] Epoch 56/75  Loss=1.3749  Acc=0.5555\n",
      "[Pretrain] Epoch 57/75  Loss=1.3638  Acc=0.5515\n",
      "[Pretrain] Epoch 58/75  Loss=1.3562  Acc=0.5524\n",
      "[Pretrain] Epoch 59/75  Loss=1.3563  Acc=0.5505\n",
      "[Pretrain] Epoch 60/75  Loss=1.3502  Acc=0.5621\n",
      "[Pretrain] Epoch 61/75  Loss=1.3552  Acc=0.5582\n",
      "[Pretrain] Epoch 62/75  Loss=1.3594  Acc=0.5533\n",
      "[Pretrain] Epoch 63/75  Loss=1.3407  Acc=0.5665\n",
      "[Pretrain] Epoch 64/75  Loss=1.3376  Acc=0.5666\n",
      "[Pretrain] Epoch 65/75  Loss=1.3397  Acc=0.5659\n",
      "[Pretrain] Epoch 66/75  Loss=1.3356  Acc=0.5673\n",
      "[Pretrain] Epoch 67/75  Loss=1.3391  Acc=0.5609\n",
      "[Pretrain] Epoch 68/75  Loss=1.3305  Acc=0.5661\n",
      "[Pretrain] Epoch 69/75  Loss=1.3419  Acc=0.5672\n",
      "[Pretrain] Epoch 70/75  Loss=1.3202  Acc=0.5720\n",
      "[Pretrain] Epoch 71/75  Loss=1.3212  Acc=0.5672\n",
      "[Pretrain] Epoch 72/75  Loss=1.3119  Acc=0.5731\n",
      "[Pretrain] Epoch 73/75  Loss=1.3112  Acc=0.5740\n",
      "[Pretrain] Epoch 74/75  Loss=1.3302  Acc=0.5693\n",
      "[Pretrain] Epoch 75/75  Loss=1.3088  Acc=0.5744\n",
      "[Fine-tune] Epoch 1/75  Loss=3.2562\n",
      "[Fine-tune] Epoch 2/75  Loss=3.1720\n",
      "[Fine-tune] Epoch 3/75  Loss=3.0854\n",
      "[Fine-tune] Epoch 4/75  Loss=3.0616\n",
      "[Fine-tune] Epoch 5/75  Loss=3.0175\n",
      "[Fine-tune] Epoch 6/75  Loss=2.8486\n",
      "[Fine-tune] Epoch 7/75  Loss=2.6846\n",
      "[Fine-tune] Epoch 8/75  Loss=2.5944\n",
      "[Fine-tune] Epoch 9/75  Loss=2.5236\n",
      "[Fine-tune] Epoch 10/75  Loss=2.4479\n",
      "[Fine-tune] Epoch 11/75  Loss=2.3716\n",
      "[Fine-tune] Epoch 12/75  Loss=2.3135\n",
      "[Fine-tune] Epoch 13/75  Loss=2.2661\n",
      "[Fine-tune] Epoch 14/75  Loss=2.2223\n",
      "[Fine-tune] Epoch 15/75  Loss=2.1689\n",
      "[Fine-tune] Epoch 16/75  Loss=2.1269\n",
      "[Fine-tune] Epoch 17/75  Loss=2.0950\n",
      "[Fine-tune] Epoch 18/75  Loss=2.0702\n",
      "[Fine-tune] Epoch 19/75  Loss=2.0317\n",
      "[Fine-tune] Epoch 20/75  Loss=2.0060\n",
      "[Fine-tune] Epoch 21/75  Loss=1.9849\n",
      "[Fine-tune] Epoch 22/75  Loss=1.9508\n",
      "[Fine-tune] Epoch 23/75  Loss=1.9544\n",
      "[Fine-tune] Epoch 24/75  Loss=1.9332\n",
      "[Fine-tune] Epoch 25/75  Loss=1.8896\n",
      "[Fine-tune] Epoch 26/75  Loss=1.8877\n",
      "[Fine-tune] Epoch 27/75  Loss=1.8725\n",
      "[Fine-tune] Epoch 28/75  Loss=1.8563\n",
      "[Fine-tune] Epoch 29/75  Loss=1.8215\n",
      "[Fine-tune] Epoch 30/75  Loss=1.8099\n",
      "[Fine-tune] Epoch 31/75  Loss=1.8047\n",
      "[Fine-tune] Epoch 32/75  Loss=1.7893\n",
      "[Fine-tune] Epoch 33/75  Loss=1.7859\n",
      "[Fine-tune] Epoch 34/75  Loss=1.7584\n",
      "[Fine-tune] Epoch 35/75  Loss=1.7462\n",
      "[Fine-tune] Epoch 36/75  Loss=1.7351\n",
      "[Fine-tune] Epoch 37/75  Loss=1.7205\n",
      "[Fine-tune] Epoch 38/75  Loss=1.7063\n",
      "[Fine-tune] Epoch 39/75  Loss=1.6929\n",
      "[Fine-tune] Epoch 40/75  Loss=1.6819\n",
      "[Fine-tune] Epoch 41/75  Loss=1.6660\n",
      "[Fine-tune] Epoch 42/75  Loss=1.6638\n",
      "[Fine-tune] Epoch 43/75  Loss=1.6461\n",
      "[Fine-tune] Epoch 44/75  Loss=1.6325\n",
      "[Fine-tune] Epoch 45/75  Loss=1.6324\n",
      "[Fine-tune] Epoch 46/75  Loss=1.6367\n",
      "[Fine-tune] Epoch 47/75  Loss=1.6196\n",
      "[Fine-tune] Epoch 48/75  Loss=1.5991\n",
      "[Fine-tune] Epoch 49/75  Loss=1.6119\n",
      "[Fine-tune] Epoch 50/75  Loss=1.5837\n",
      "[Fine-tune] Epoch 51/75  Loss=1.5832\n",
      "[Fine-tune] Epoch 52/75  Loss=1.5797\n",
      "[Fine-tune] Epoch 53/75  Loss=1.5849\n",
      "[Fine-tune] Epoch 54/75  Loss=1.5658\n",
      "[Fine-tune] Epoch 55/75  Loss=1.5602\n",
      "[Fine-tune] Epoch 56/75  Loss=1.5376\n",
      "[Fine-tune] Epoch 57/75  Loss=1.5463\n",
      "[Fine-tune] Epoch 58/75  Loss=1.5420\n",
      "[Fine-tune] Epoch 59/75  Loss=1.5458\n",
      "[Fine-tune] Epoch 60/75  Loss=1.5341\n",
      "[Fine-tune] Epoch 61/75  Loss=1.5352\n",
      "[Fine-tune] Epoch 62/75  Loss=1.5223\n",
      "[Fine-tune] Epoch 63/75  Loss=1.5208\n",
      "[Fine-tune] Epoch 64/75  Loss=1.5039\n",
      "[Fine-tune] Epoch 65/75  Loss=1.5102\n",
      "[Fine-tune] Epoch 66/75  Loss=1.5030\n",
      "[Fine-tune] Epoch 67/75  Loss=1.5251\n",
      "[Fine-tune] Epoch 68/75  Loss=1.5041\n",
      "[Fine-tune] Epoch 69/75  Loss=1.5001\n",
      "[Fine-tune] Epoch 70/75  Loss=1.4944\n",
      "[Fine-tune] Epoch 71/75  Loss=1.4901\n",
      "[Fine-tune] Epoch 72/75  Loss=1.5038\n",
      "[Fine-tune] Epoch 73/75  Loss=1.5044\n",
      "[Fine-tune] Epoch 74/75  Loss=1.5043\n",
      "[Fine-tune] Epoch 75/75  Loss=1.4923\n",
      "[Pretrain] Epoch 1/75  Loss=3.6350  Acc=0.0440\n",
      "[Pretrain] Epoch 2/75  Loss=3.1392  Acc=0.0700\n",
      "[Pretrain] Epoch 3/75  Loss=3.0558  Acc=0.0849\n",
      "[Pretrain] Epoch 4/75  Loss=3.0114  Acc=0.0900\n",
      "[Pretrain] Epoch 5/75  Loss=2.9127  Acc=0.0902\n",
      "[Pretrain] Epoch 6/75  Loss=2.7336  Acc=0.1413\n",
      "[Pretrain] Epoch 7/75  Loss=2.5329  Acc=0.1904\n",
      "[Pretrain] Epoch 8/75  Loss=2.4498  Acc=0.2168\n",
      "[Pretrain] Epoch 9/75  Loss=2.3621  Acc=0.2367\n",
      "[Pretrain] Epoch 10/75  Loss=2.3148  Acc=0.2540\n",
      "[Pretrain] Epoch 11/75  Loss=2.2642  Acc=0.2694\n",
      "[Pretrain] Epoch 12/75  Loss=2.2142  Acc=0.2857\n",
      "[Pretrain] Epoch 13/75  Loss=2.1924  Acc=0.2935\n",
      "[Pretrain] Epoch 14/75  Loss=2.1352  Acc=0.3030\n",
      "[Pretrain] Epoch 15/75  Loss=2.0832  Acc=0.3226\n",
      "[Pretrain] Epoch 16/75  Loss=2.0572  Acc=0.3360\n",
      "[Pretrain] Epoch 17/75  Loss=2.0316  Acc=0.3429\n",
      "[Pretrain] Epoch 18/75  Loss=1.9860  Acc=0.3522\n",
      "[Pretrain] Epoch 19/75  Loss=1.9665  Acc=0.3551\n",
      "[Pretrain] Epoch 20/75  Loss=1.9351  Acc=0.3694\n",
      "[Pretrain] Epoch 21/75  Loss=1.9445  Acc=0.3651\n",
      "[Pretrain] Epoch 22/75  Loss=1.9124  Acc=0.3666\n",
      "[Pretrain] Epoch 23/75  Loss=1.8907  Acc=0.3842\n",
      "[Pretrain] Epoch 24/75  Loss=1.8603  Acc=0.3930\n",
      "[Pretrain] Epoch 25/75  Loss=1.8614  Acc=0.3876\n",
      "[Pretrain] Epoch 26/75  Loss=1.8335  Acc=0.3992\n",
      "[Pretrain] Epoch 27/75  Loss=1.8004  Acc=0.4082\n",
      "[Pretrain] Epoch 28/75  Loss=1.8098  Acc=0.4048\n",
      "[Pretrain] Epoch 29/75  Loss=1.7687  Acc=0.4176\n",
      "[Pretrain] Epoch 30/75  Loss=1.7457  Acc=0.4289\n",
      "[Pretrain] Epoch 31/75  Loss=1.7405  Acc=0.4230\n",
      "[Pretrain] Epoch 32/75  Loss=1.7073  Acc=0.4328\n",
      "[Pretrain] Epoch 33/75  Loss=1.6956  Acc=0.4510\n",
      "[Pretrain] Epoch 34/75  Loss=1.6875  Acc=0.4501\n",
      "[Pretrain] Epoch 35/75  Loss=1.6696  Acc=0.4504\n",
      "[Pretrain] Epoch 36/75  Loss=1.6670  Acc=0.4524\n",
      "[Pretrain] Epoch 37/75  Loss=1.6368  Acc=0.4544\n",
      "[Pretrain] Epoch 38/75  Loss=1.6383  Acc=0.4569\n",
      "[Pretrain] Epoch 39/75  Loss=1.6221  Acc=0.4652\n",
      "[Pretrain] Epoch 40/75  Loss=1.6153  Acc=0.4664\n",
      "[Pretrain] Epoch 41/75  Loss=1.5995  Acc=0.4729\n",
      "[Pretrain] Epoch 42/75  Loss=1.5855  Acc=0.4795\n",
      "[Pretrain] Epoch 43/75  Loss=1.5712  Acc=0.4790\n",
      "[Pretrain] Epoch 44/75  Loss=1.5590  Acc=0.4781\n",
      "[Pretrain] Epoch 45/75  Loss=1.5457  Acc=0.4914\n",
      "[Pretrain] Epoch 46/75  Loss=1.5221  Acc=0.4953\n",
      "[Pretrain] Epoch 47/75  Loss=1.5337  Acc=0.4966\n",
      "[Pretrain] Epoch 48/75  Loss=1.5112  Acc=0.5007\n",
      "[Pretrain] Epoch 49/75  Loss=1.5194  Acc=0.4986\n",
      "[Pretrain] Epoch 50/75  Loss=1.5004  Acc=0.4957\n",
      "[Pretrain] Epoch 51/75  Loss=1.4833  Acc=0.5086\n",
      "[Pretrain] Epoch 52/75  Loss=1.4966  Acc=0.5086\n",
      "[Pretrain] Epoch 53/75  Loss=1.4706  Acc=0.5171\n",
      "[Pretrain] Epoch 54/75  Loss=1.4689  Acc=0.5104\n",
      "[Pretrain] Epoch 55/75  Loss=1.4662  Acc=0.5233\n",
      "[Pretrain] Epoch 56/75  Loss=1.4586  Acc=0.5151\n",
      "[Pretrain] Epoch 57/75  Loss=1.4367  Acc=0.5271\n",
      "[Pretrain] Epoch 58/75  Loss=1.4317  Acc=0.5226\n",
      "[Pretrain] Epoch 59/75  Loss=1.4206  Acc=0.5305\n",
      "[Pretrain] Epoch 60/75  Loss=1.4262  Acc=0.5280\n",
      "[Pretrain] Epoch 61/75  Loss=1.4028  Acc=0.5408\n",
      "[Pretrain] Epoch 62/75  Loss=1.4161  Acc=0.5316\n",
      "[Pretrain] Epoch 63/75  Loss=1.4026  Acc=0.5374\n",
      "[Pretrain] Epoch 64/75  Loss=1.3995  Acc=0.5332\n",
      "[Pretrain] Epoch 65/75  Loss=1.3916  Acc=0.5365\n",
      "[Pretrain] Epoch 66/75  Loss=1.3843  Acc=0.5409\n",
      "[Pretrain] Epoch 67/75  Loss=1.3786  Acc=0.5427\n",
      "[Pretrain] Epoch 68/75  Loss=1.3801  Acc=0.5510\n",
      "[Pretrain] Epoch 69/75  Loss=1.3778  Acc=0.5476\n",
      "[Pretrain] Epoch 70/75  Loss=1.3656  Acc=0.5530\n",
      "[Pretrain] Epoch 71/75  Loss=1.3641  Acc=0.5462\n",
      "[Pretrain] Epoch 72/75  Loss=1.3528  Acc=0.5487\n",
      "[Pretrain] Epoch 73/75  Loss=1.3635  Acc=0.5462\n",
      "[Pretrain] Epoch 74/75  Loss=1.3675  Acc=0.5566\n",
      "[Pretrain] Epoch 75/75  Loss=1.3443  Acc=0.5555\n",
      "[Fine-tune] Epoch 1/75  Loss=2.9620\n",
      "[Fine-tune] Epoch 2/75  Loss=2.5289\n",
      "[Fine-tune] Epoch 3/75  Loss=2.3469\n",
      "[Fine-tune] Epoch 4/75  Loss=2.2759\n",
      "[Fine-tune] Epoch 5/75  Loss=2.2010\n",
      "[Fine-tune] Epoch 6/75  Loss=2.1493\n",
      "[Fine-tune] Epoch 7/75  Loss=2.0834\n",
      "[Fine-tune] Epoch 8/75  Loss=2.0298\n",
      "[Fine-tune] Epoch 9/75  Loss=1.9945\n",
      "[Fine-tune] Epoch 10/75  Loss=1.9610\n",
      "[Fine-tune] Epoch 11/75  Loss=1.9192\n",
      "[Fine-tune] Epoch 12/75  Loss=1.9066\n",
      "[Fine-tune] Epoch 13/75  Loss=1.8692\n",
      "[Fine-tune] Epoch 14/75  Loss=1.8337\n",
      "[Fine-tune] Epoch 15/75  Loss=1.7974\n",
      "[Fine-tune] Epoch 16/75  Loss=1.7933\n",
      "[Fine-tune] Epoch 17/75  Loss=1.7321\n",
      "[Fine-tune] Epoch 18/75  Loss=1.7303\n",
      "[Fine-tune] Epoch 19/75  Loss=1.6882\n",
      "[Fine-tune] Epoch 20/75  Loss=1.6827\n",
      "[Fine-tune] Epoch 21/75  Loss=1.6483\n",
      "[Fine-tune] Epoch 22/75  Loss=1.6208\n",
      "[Fine-tune] Epoch 23/75  Loss=1.6027\n",
      "[Fine-tune] Epoch 24/75  Loss=1.5814\n",
      "[Fine-tune] Epoch 25/75  Loss=1.5535\n",
      "[Fine-tune] Epoch 26/75  Loss=1.5483\n",
      "[Fine-tune] Epoch 27/75  Loss=1.5122\n",
      "[Fine-tune] Epoch 28/75  Loss=1.5040\n",
      "[Fine-tune] Epoch 29/75  Loss=1.4949\n",
      "[Fine-tune] Epoch 30/75  Loss=1.4726\n",
      "[Fine-tune] Epoch 31/75  Loss=1.4506\n",
      "[Fine-tune] Epoch 32/75  Loss=1.4389\n",
      "[Fine-tune] Epoch 33/75  Loss=1.4334\n",
      "[Fine-tune] Epoch 34/75  Loss=1.4069\n",
      "[Fine-tune] Epoch 35/75  Loss=1.3984\n",
      "[Fine-tune] Epoch 36/75  Loss=1.3891\n",
      "[Fine-tune] Epoch 37/75  Loss=1.3651\n",
      "[Fine-tune] Epoch 38/75  Loss=1.3604\n",
      "[Fine-tune] Epoch 39/75  Loss=1.3521\n",
      "[Fine-tune] Epoch 40/75  Loss=1.3500\n",
      "[Fine-tune] Epoch 41/75  Loss=1.3511\n",
      "[Fine-tune] Epoch 42/75  Loss=1.3129\n",
      "[Fine-tune] Epoch 43/75  Loss=1.3155\n",
      "[Fine-tune] Epoch 44/75  Loss=1.3057\n",
      "[Fine-tune] Epoch 45/75  Loss=1.3013\n",
      "[Fine-tune] Epoch 46/75  Loss=1.2860\n",
      "[Fine-tune] Epoch 47/75  Loss=1.2877\n",
      "[Fine-tune] Epoch 48/75  Loss=1.2845\n",
      "[Fine-tune] Epoch 49/75  Loss=1.2741\n",
      "[Fine-tune] Epoch 50/75  Loss=1.2700\n",
      "[Fine-tune] Epoch 51/75  Loss=1.2645\n",
      "[Fine-tune] Epoch 52/75  Loss=1.2500\n",
      "[Fine-tune] Epoch 53/75  Loss=1.2393\n",
      "[Fine-tune] Epoch 54/75  Loss=1.2408\n",
      "[Fine-tune] Epoch 55/75  Loss=1.2372\n",
      "[Fine-tune] Epoch 56/75  Loss=1.2340\n",
      "[Fine-tune] Epoch 57/75  Loss=1.2385\n",
      "[Fine-tune] Epoch 58/75  Loss=1.2346\n",
      "[Fine-tune] Epoch 59/75  Loss=1.2145\n",
      "[Fine-tune] Epoch 60/75  Loss=1.2119\n",
      "[Fine-tune] Epoch 61/75  Loss=1.2218\n",
      "[Fine-tune] Epoch 62/75  Loss=1.2118\n",
      "[Fine-tune] Epoch 63/75  Loss=1.2035\n",
      "[Fine-tune] Epoch 64/75  Loss=1.1975\n",
      "[Fine-tune] Epoch 65/75  Loss=1.2049\n",
      "[Fine-tune] Epoch 66/75  Loss=1.2000\n",
      "[Fine-tune] Epoch 67/75  Loss=1.1877\n",
      "[Fine-tune] Epoch 68/75  Loss=1.1951\n",
      "[Fine-tune] Epoch 69/75  Loss=1.2011\n",
      "[Fine-tune] Epoch 70/75  Loss=1.1956\n",
      "[Fine-tune] Epoch 71/75  Loss=1.1907\n",
      "[Fine-tune] Epoch 72/75  Loss=1.1888\n",
      "[Fine-tune] Epoch 73/75  Loss=1.1820\n",
      "[Fine-tune] Epoch 74/75  Loss=1.1747\n",
      "[Fine-tune] Epoch 75/75  Loss=1.1815\n",
      "[Pretrain] Epoch 1/100  Loss=3.2286  Acc=0.0435\n",
      "[Pretrain] Epoch 2/100  Loss=2.9410  Acc=0.0909\n",
      "[Pretrain] Epoch 3/100  Loss=2.6264  Acc=0.1543\n",
      "[Pretrain] Epoch 4/100  Loss=2.5052  Acc=0.1950\n",
      "[Pretrain] Epoch 5/100  Loss=2.3838  Acc=0.2355\n",
      "[Pretrain] Epoch 6/100  Loss=2.2701  Acc=0.2672\n",
      "[Pretrain] Epoch 7/100  Loss=2.2009  Acc=0.2893\n",
      "[Pretrain] Epoch 8/100  Loss=2.1346  Acc=0.3053\n",
      "[Pretrain] Epoch 9/100  Loss=2.0892  Acc=0.3193\n",
      "[Pretrain] Epoch 10/100  Loss=2.0313  Acc=0.3330\n",
      "[Pretrain] Epoch 11/100  Loss=2.0018  Acc=0.3482\n",
      "[Pretrain] Epoch 12/100  Loss=1.9862  Acc=0.3468\n",
      "[Pretrain] Epoch 13/100  Loss=1.9600  Acc=0.3712\n",
      "[Pretrain] Epoch 14/100  Loss=1.9171  Acc=0.3779\n",
      "[Pretrain] Epoch 15/100  Loss=1.8908  Acc=0.3860\n",
      "[Pretrain] Epoch 16/100  Loss=1.8608  Acc=0.3876\n",
      "[Pretrain] Epoch 17/100  Loss=1.8447  Acc=0.4107\n",
      "[Pretrain] Epoch 18/100  Loss=1.8161  Acc=0.4151\n",
      "[Pretrain] Epoch 19/100  Loss=1.7970  Acc=0.4186\n",
      "[Pretrain] Epoch 20/100  Loss=1.7805  Acc=0.4206\n",
      "[Pretrain] Epoch 21/100  Loss=1.7492  Acc=0.4273\n",
      "[Pretrain] Epoch 22/100  Loss=1.7325  Acc=0.4337\n",
      "[Pretrain] Epoch 23/100  Loss=1.7108  Acc=0.4420\n",
      "[Pretrain] Epoch 24/100  Loss=1.6963  Acc=0.4468\n",
      "[Pretrain] Epoch 25/100  Loss=1.6627  Acc=0.4617\n",
      "[Pretrain] Epoch 26/100  Loss=1.6428  Acc=0.4668\n",
      "[Pretrain] Epoch 27/100  Loss=1.6424  Acc=0.4750\n",
      "[Pretrain] Epoch 28/100  Loss=1.6422  Acc=0.4713\n",
      "[Pretrain] Epoch 29/100  Loss=1.6058  Acc=0.4745\n",
      "[Pretrain] Epoch 30/100  Loss=1.6032  Acc=0.4813\n",
      "[Pretrain] Epoch 31/100  Loss=1.5672  Acc=0.4912\n",
      "[Pretrain] Epoch 32/100  Loss=1.5548  Acc=0.5000\n",
      "[Pretrain] Epoch 33/100  Loss=1.5433  Acc=0.5016\n",
      "[Pretrain] Epoch 34/100  Loss=1.5110  Acc=0.5048\n",
      "[Pretrain] Epoch 35/100  Loss=1.5032  Acc=0.5093\n",
      "[Pretrain] Epoch 36/100  Loss=1.4857  Acc=0.5117\n",
      "[Pretrain] Epoch 37/100  Loss=1.4630  Acc=0.5278\n",
      "[Pretrain] Epoch 38/100  Loss=1.4631  Acc=0.5278\n",
      "[Pretrain] Epoch 39/100  Loss=1.4520  Acc=0.5320\n",
      "[Pretrain] Epoch 40/100  Loss=1.4555  Acc=0.5233\n",
      "[Pretrain] Epoch 41/100  Loss=1.4220  Acc=0.5339\n",
      "[Pretrain] Epoch 42/100  Loss=1.4180  Acc=0.5395\n",
      "[Pretrain] Epoch 43/100  Loss=1.4054  Acc=0.5411\n",
      "[Pretrain] Epoch 44/100  Loss=1.4132  Acc=0.5359\n",
      "[Pretrain] Epoch 45/100  Loss=1.4009  Acc=0.5447\n",
      "[Pretrain] Epoch 46/100  Loss=1.3927  Acc=0.5533\n",
      "[Pretrain] Epoch 47/100  Loss=1.3670  Acc=0.5569\n",
      "[Pretrain] Epoch 48/100  Loss=1.3689  Acc=0.5496\n",
      "[Pretrain] Epoch 49/100  Loss=1.3678  Acc=0.5577\n",
      "[Pretrain] Epoch 50/100  Loss=1.3426  Acc=0.5661\n",
      "[Pretrain] Epoch 51/100  Loss=1.3571  Acc=0.5544\n",
      "[Pretrain] Epoch 52/100  Loss=1.3538  Acc=0.5569\n",
      "[Pretrain] Epoch 53/100  Loss=1.3445  Acc=0.5575\n",
      "[Pretrain] Epoch 54/100  Loss=1.3261  Acc=0.5711\n",
      "[Pretrain] Epoch 55/100  Loss=1.3316  Acc=0.5681\n",
      "[Pretrain] Epoch 56/100  Loss=1.3216  Acc=0.5677\n",
      "[Pretrain] Epoch 57/100  Loss=1.3177  Acc=0.5702\n",
      "[Pretrain] Epoch 58/100  Loss=1.3105  Acc=0.5657\n",
      "[Pretrain] Epoch 59/100  Loss=1.3109  Acc=0.5708\n",
      "[Pretrain] Epoch 60/100  Loss=1.2947  Acc=0.5760\n",
      "[Pretrain] Epoch 61/100  Loss=1.3029  Acc=0.5772\n",
      "[Pretrain] Epoch 62/100  Loss=1.3018  Acc=0.5677\n",
      "[Pretrain] Epoch 63/100  Loss=1.2952  Acc=0.5797\n",
      "[Pretrain] Epoch 64/100  Loss=1.2884  Acc=0.5761\n",
      "[Pretrain] Epoch 65/100  Loss=1.2997  Acc=0.5729\n",
      "[Pretrain] Epoch 66/100  Loss=1.2827  Acc=0.5846\n",
      "[Pretrain] Epoch 67/100  Loss=1.2882  Acc=0.5844\n",
      "[Pretrain] Epoch 68/100  Loss=1.2768  Acc=0.5814\n",
      "[Pretrain] Epoch 69/100  Loss=1.2763  Acc=0.5835\n",
      "[Pretrain] Epoch 70/100  Loss=1.2635  Acc=0.5900\n",
      "[Pretrain] Epoch 71/100  Loss=1.2648  Acc=0.5848\n",
      "[Pretrain] Epoch 72/100  Loss=1.2631  Acc=0.5839\n",
      "[Pretrain] Epoch 73/100  Loss=1.2841  Acc=0.5903\n",
      "[Pretrain] Epoch 74/100  Loss=1.2801  Acc=0.5787\n",
      "[Pretrain] Epoch 75/100  Loss=1.2617  Acc=0.5891\n",
      "[Pretrain] Epoch 76/100  Loss=1.2631  Acc=0.5873\n",
      "[Pretrain] Epoch 77/100  Loss=1.2757  Acc=0.5790\n",
      "[Pretrain] Epoch 78/100  Loss=1.2438  Acc=0.5939\n",
      "[Pretrain] Epoch 79/100  Loss=1.2518  Acc=0.5907\n",
      "[Pretrain] Epoch 80/100  Loss=1.2730  Acc=0.5801\n",
      "[Pretrain] Epoch 81/100  Loss=1.2749  Acc=0.5824\n",
      "[Pretrain] Epoch 82/100  Loss=1.2648  Acc=0.5876\n",
      "[Pretrain] Epoch 83/100  Loss=1.2506  Acc=0.5929\n",
      "[Pretrain] Epoch 84/100  Loss=1.2527  Acc=0.5867\n",
      "[Pretrain] Epoch 85/100  Loss=1.2428  Acc=0.5990\n",
      "[Pretrain] Epoch 86/100  Loss=1.2435  Acc=0.5930\n",
      "[Pretrain] Epoch 87/100  Loss=1.2536  Acc=0.5876\n",
      "[Pretrain] Epoch 88/100  Loss=1.2565  Acc=0.5932\n",
      "[Pretrain] Epoch 89/100  Loss=1.2674  Acc=0.5880\n",
      "[Pretrain] Epoch 90/100  Loss=1.2447  Acc=0.5950\n",
      "[Pretrain] Epoch 91/100  Loss=1.2452  Acc=0.5982\n",
      "[Pretrain] Epoch 92/100  Loss=1.2410  Acc=0.5930\n",
      "[Pretrain] Epoch 93/100  Loss=1.2356  Acc=0.5957\n",
      "[Pretrain] Epoch 94/100  Loss=1.2531  Acc=0.5894\n",
      "[Pretrain] Epoch 95/100  Loss=1.2488  Acc=0.5929\n",
      "[Pretrain] Epoch 96/100  Loss=1.2400  Acc=0.5959\n",
      "[Pretrain] Epoch 97/100  Loss=1.2355  Acc=0.5963\n",
      "[Pretrain] Epoch 98/100  Loss=1.2441  Acc=0.5921\n",
      "[Pretrain] Epoch 99/100  Loss=1.2372  Acc=0.6013\n",
      "[Pretrain] Epoch 100/100  Loss=1.2406  Acc=0.5959\n",
      "[Fine-tune] Epoch 1/75  Loss=3.2680\n",
      "[Fine-tune] Epoch 2/75  Loss=3.1660\n",
      "[Fine-tune] Epoch 3/75  Loss=3.0856\n",
      "[Fine-tune] Epoch 4/75  Loss=3.0365\n",
      "[Fine-tune] Epoch 5/75  Loss=2.9718\n",
      "[Fine-tune] Epoch 6/75  Loss=2.7953\n",
      "[Fine-tune] Epoch 7/75  Loss=2.6206\n",
      "[Fine-tune] Epoch 8/75  Loss=2.4858\n",
      "[Fine-tune] Epoch 9/75  Loss=2.3890\n",
      "[Fine-tune] Epoch 10/75  Loss=2.3306\n",
      "[Fine-tune] Epoch 11/75  Loss=2.2646\n",
      "[Fine-tune] Epoch 12/75  Loss=2.2201\n",
      "[Fine-tune] Epoch 13/75  Loss=2.1831\n",
      "[Fine-tune] Epoch 14/75  Loss=2.1776\n",
      "[Fine-tune] Epoch 15/75  Loss=2.1243\n",
      "[Fine-tune] Epoch 16/75  Loss=2.1081\n",
      "[Fine-tune] Epoch 17/75  Loss=2.0723\n",
      "[Fine-tune] Epoch 18/75  Loss=2.0436\n",
      "[Fine-tune] Epoch 19/75  Loss=2.0459\n",
      "[Fine-tune] Epoch 20/75  Loss=1.9909\n",
      "[Fine-tune] Epoch 21/75  Loss=1.9793\n",
      "[Fine-tune] Epoch 22/75  Loss=1.9561\n",
      "[Fine-tune] Epoch 23/75  Loss=1.9335\n",
      "[Fine-tune] Epoch 24/75  Loss=1.9206\n",
      "[Fine-tune] Epoch 25/75  Loss=1.8753\n",
      "[Fine-tune] Epoch 26/75  Loss=1.8809\n",
      "[Fine-tune] Epoch 27/75  Loss=1.8628\n",
      "[Fine-tune] Epoch 28/75  Loss=1.8605\n",
      "[Fine-tune] Epoch 29/75  Loss=1.8384\n",
      "[Fine-tune] Epoch 30/75  Loss=1.8302\n",
      "[Fine-tune] Epoch 31/75  Loss=1.8069\n",
      "[Fine-tune] Epoch 32/75  Loss=1.8028\n",
      "[Fine-tune] Epoch 33/75  Loss=1.7925\n",
      "[Fine-tune] Epoch 34/75  Loss=1.7742\n",
      "[Fine-tune] Epoch 35/75  Loss=1.7719\n",
      "[Fine-tune] Epoch 36/75  Loss=1.7366\n",
      "[Fine-tune] Epoch 37/75  Loss=1.7410\n",
      "[Fine-tune] Epoch 38/75  Loss=1.7364\n",
      "[Fine-tune] Epoch 39/75  Loss=1.7098\n",
      "[Fine-tune] Epoch 40/75  Loss=1.7051\n",
      "[Fine-tune] Epoch 41/75  Loss=1.7012\n",
      "[Fine-tune] Epoch 42/75  Loss=1.6880\n",
      "[Fine-tune] Epoch 43/75  Loss=1.6723\n",
      "[Fine-tune] Epoch 44/75  Loss=1.6666\n",
      "[Fine-tune] Epoch 45/75  Loss=1.6425\n",
      "[Fine-tune] Epoch 46/75  Loss=1.6410\n",
      "[Fine-tune] Epoch 47/75  Loss=1.6375\n",
      "[Fine-tune] Epoch 48/75  Loss=1.6285\n",
      "[Fine-tune] Epoch 49/75  Loss=1.6223\n",
      "[Fine-tune] Epoch 50/75  Loss=1.6080\n",
      "[Fine-tune] Epoch 51/75  Loss=1.6106\n",
      "[Fine-tune] Epoch 52/75  Loss=1.6022\n",
      "[Fine-tune] Epoch 53/75  Loss=1.5798\n",
      "[Fine-tune] Epoch 54/75  Loss=1.5967\n",
      "[Fine-tune] Epoch 55/75  Loss=1.5772\n",
      "[Fine-tune] Epoch 56/75  Loss=1.5782\n",
      "[Fine-tune] Epoch 57/75  Loss=1.5868\n",
      "[Fine-tune] Epoch 58/75  Loss=1.5656\n",
      "[Fine-tune] Epoch 59/75  Loss=1.5548\n",
      "[Fine-tune] Epoch 60/75  Loss=1.5446\n",
      "[Fine-tune] Epoch 61/75  Loss=1.5649\n",
      "[Fine-tune] Epoch 62/75  Loss=1.5359\n",
      "[Fine-tune] Epoch 63/75  Loss=1.5401\n",
      "[Fine-tune] Epoch 64/75  Loss=1.5193\n",
      "[Fine-tune] Epoch 65/75  Loss=1.5455\n",
      "[Fine-tune] Epoch 66/75  Loss=1.5328\n",
      "[Fine-tune] Epoch 67/75  Loss=1.5289\n",
      "[Fine-tune] Epoch 68/75  Loss=1.5275\n",
      "[Fine-tune] Epoch 69/75  Loss=1.5239\n",
      "[Fine-tune] Epoch 70/75  Loss=1.5371\n",
      "[Fine-tune] Epoch 71/75  Loss=1.5269\n",
      "[Fine-tune] Epoch 72/75  Loss=1.5221\n",
      "[Fine-tune] Epoch 73/75  Loss=1.5246\n",
      "[Fine-tune] Epoch 74/75  Loss=1.5099\n",
      "[Fine-tune] Epoch 75/75  Loss=1.5165\n",
      "[Pretrain] Epoch 1/100  Loss=3.7701  Acc=0.0390\n",
      "[Pretrain] Epoch 2/100  Loss=3.1688  Acc=0.0650\n",
      "[Pretrain] Epoch 3/100  Loss=3.0726  Acc=0.0799\n",
      "[Pretrain] Epoch 4/100  Loss=3.0243  Acc=0.0903\n",
      "[Pretrain] Epoch 5/100  Loss=2.8718  Acc=0.1282\n",
      "[Pretrain] Epoch 6/100  Loss=2.6676  Acc=0.1633\n",
      "[Pretrain] Epoch 7/100  Loss=2.4672  Acc=0.2083\n",
      "[Pretrain] Epoch 8/100  Loss=2.3469  Acc=0.2347\n",
      "[Pretrain] Epoch 9/100  Loss=2.2819  Acc=0.2631\n",
      "[Pretrain] Epoch 10/100  Loss=2.2541  Acc=0.2721\n",
      "[Pretrain] Epoch 11/100  Loss=2.1982  Acc=0.2879\n",
      "[Pretrain] Epoch 12/100  Loss=2.1907  Acc=0.2942\n",
      "[Pretrain] Epoch 13/100  Loss=2.1341  Acc=0.2989\n",
      "[Pretrain] Epoch 14/100  Loss=2.0910  Acc=0.3085\n",
      "[Pretrain] Epoch 15/100  Loss=2.0748  Acc=0.3157\n",
      "[Pretrain] Epoch 16/100  Loss=2.0365  Acc=0.3267\n",
      "[Pretrain] Epoch 17/100  Loss=2.0195  Acc=0.3373\n",
      "[Pretrain] Epoch 18/100  Loss=1.9964  Acc=0.3536\n",
      "[Pretrain] Epoch 19/100  Loss=1.9791  Acc=0.3475\n",
      "[Pretrain] Epoch 20/100  Loss=1.9310  Acc=0.3694\n",
      "[Pretrain] Epoch 21/100  Loss=1.8926  Acc=0.3860\n",
      "[Pretrain] Epoch 22/100  Loss=1.8643  Acc=0.3895\n",
      "[Pretrain] Epoch 23/100  Loss=1.8419  Acc=0.3987\n",
      "[Pretrain] Epoch 24/100  Loss=1.8184  Acc=0.4088\n",
      "[Pretrain] Epoch 25/100  Loss=1.7879  Acc=0.4204\n",
      "[Pretrain] Epoch 26/100  Loss=1.7460  Acc=0.4273\n",
      "[Pretrain] Epoch 27/100  Loss=1.7108  Acc=0.4461\n",
      "[Pretrain] Epoch 28/100  Loss=1.6913  Acc=0.4517\n",
      "[Pretrain] Epoch 29/100  Loss=1.6709  Acc=0.4560\n",
      "[Pretrain] Epoch 30/100  Loss=1.6445  Acc=0.4551\n",
      "[Pretrain] Epoch 31/100  Loss=1.6467  Acc=0.4688\n",
      "[Pretrain] Epoch 32/100  Loss=1.6135  Acc=0.4765\n",
      "[Pretrain] Epoch 33/100  Loss=1.5806  Acc=0.4860\n",
      "[Pretrain] Epoch 34/100  Loss=1.5788  Acc=0.4864\n",
      "[Pretrain] Epoch 35/100  Loss=1.5429  Acc=0.4978\n",
      "[Pretrain] Epoch 36/100  Loss=1.5217  Acc=0.5018\n",
      "[Pretrain] Epoch 37/100  Loss=1.4998  Acc=0.5077\n",
      "[Pretrain] Epoch 38/100  Loss=1.4856  Acc=0.5102\n",
      "[Pretrain] Epoch 39/100  Loss=1.4735  Acc=0.5235\n",
      "[Pretrain] Epoch 40/100  Loss=1.4566  Acc=0.5273\n",
      "[Pretrain] Epoch 41/100  Loss=1.4332  Acc=0.5381\n",
      "[Pretrain] Epoch 42/100  Loss=1.4055  Acc=0.5474\n",
      "[Pretrain] Epoch 43/100  Loss=1.4042  Acc=0.5420\n",
      "[Pretrain] Epoch 44/100  Loss=1.3880  Acc=0.5451\n",
      "[Pretrain] Epoch 45/100  Loss=1.3561  Acc=0.5575\n",
      "[Pretrain] Epoch 46/100  Loss=1.3415  Acc=0.5607\n",
      "[Pretrain] Epoch 47/100  Loss=1.3507  Acc=0.5598\n",
      "[Pretrain] Epoch 48/100  Loss=1.3309  Acc=0.5616\n",
      "[Pretrain] Epoch 49/100  Loss=1.3030  Acc=0.5691\n",
      "[Pretrain] Epoch 50/100  Loss=1.3195  Acc=0.5661\n",
      "[Pretrain] Epoch 51/100  Loss=1.3018  Acc=0.5736\n",
      "[Pretrain] Epoch 52/100  Loss=1.2883  Acc=0.5722\n",
      "[Pretrain] Epoch 53/100  Loss=1.2861  Acc=0.5828\n",
      "[Pretrain] Epoch 54/100  Loss=1.2581  Acc=0.5891\n",
      "[Pretrain] Epoch 55/100  Loss=1.2762  Acc=0.5844\n",
      "[Pretrain] Epoch 56/100  Loss=1.2576  Acc=0.5806\n",
      "[Pretrain] Epoch 57/100  Loss=1.2260  Acc=0.6018\n",
      "[Pretrain] Epoch 58/100  Loss=1.2329  Acc=0.5982\n",
      "[Pretrain] Epoch 59/100  Loss=1.2203  Acc=0.5975\n",
      "[Pretrain] Epoch 60/100  Loss=1.2237  Acc=0.6040\n",
      "[Pretrain] Epoch 61/100  Loss=1.2063  Acc=0.6031\n",
      "[Pretrain] Epoch 62/100  Loss=1.1992  Acc=0.6124\n",
      "[Pretrain] Epoch 63/100  Loss=1.1959  Acc=0.6106\n",
      "[Pretrain] Epoch 64/100  Loss=1.1664  Acc=0.6175\n",
      "[Pretrain] Epoch 65/100  Loss=1.1739  Acc=0.6122\n",
      "[Pretrain] Epoch 66/100  Loss=1.1665  Acc=0.6162\n",
      "[Pretrain] Epoch 67/100  Loss=1.1548  Acc=0.6225\n",
      "[Pretrain] Epoch 68/100  Loss=1.1672  Acc=0.6169\n",
      "[Pretrain] Epoch 69/100  Loss=1.1550  Acc=0.6250\n",
      "[Pretrain] Epoch 70/100  Loss=1.1480  Acc=0.6232\n",
      "[Pretrain] Epoch 71/100  Loss=1.1636  Acc=0.6216\n",
      "[Pretrain] Epoch 72/100  Loss=1.1618  Acc=0.6210\n",
      "[Pretrain] Epoch 73/100  Loss=1.1403  Acc=0.6245\n",
      "[Pretrain] Epoch 74/100  Loss=1.1545  Acc=0.6191\n",
      "[Pretrain] Epoch 75/100  Loss=1.1473  Acc=0.6250\n",
      "[Pretrain] Epoch 76/100  Loss=1.1304  Acc=0.6311\n",
      "[Pretrain] Epoch 77/100  Loss=1.1344  Acc=0.6291\n",
      "[Pretrain] Epoch 78/100  Loss=1.1365  Acc=0.6311\n",
      "[Pretrain] Epoch 79/100  Loss=1.1343  Acc=0.6257\n",
      "[Pretrain] Epoch 80/100  Loss=1.1168  Acc=0.6316\n",
      "[Pretrain] Epoch 81/100  Loss=1.1260  Acc=0.6300\n",
      "[Pretrain] Epoch 82/100  Loss=1.1238  Acc=0.6395\n",
      "[Pretrain] Epoch 83/100  Loss=1.1267  Acc=0.6288\n",
      "[Pretrain] Epoch 84/100  Loss=1.1131  Acc=0.6336\n",
      "[Pretrain] Epoch 85/100  Loss=1.1151  Acc=0.6315\n",
      "[Pretrain] Epoch 86/100  Loss=1.1107  Acc=0.6381\n",
      "[Pretrain] Epoch 87/100  Loss=1.1136  Acc=0.6352\n",
      "[Pretrain] Epoch 88/100  Loss=1.1086  Acc=0.6374\n",
      "[Pretrain] Epoch 89/100  Loss=1.0947  Acc=0.6376\n",
      "[Pretrain] Epoch 90/100  Loss=1.1000  Acc=0.6361\n",
      "[Pretrain] Epoch 91/100  Loss=1.0937  Acc=0.6428\n",
      "[Pretrain] Epoch 92/100  Loss=1.0827  Acc=0.6433\n",
      "[Pretrain] Epoch 93/100  Loss=1.0960  Acc=0.6403\n",
      "[Pretrain] Epoch 94/100  Loss=1.0923  Acc=0.6442\n",
      "[Pretrain] Epoch 95/100  Loss=1.1070  Acc=0.6343\n",
      "[Pretrain] Epoch 96/100  Loss=1.0983  Acc=0.6467\n",
      "[Pretrain] Epoch 97/100  Loss=1.0909  Acc=0.6356\n",
      "[Pretrain] Epoch 98/100  Loss=1.1084  Acc=0.6458\n",
      "[Pretrain] Epoch 99/100  Loss=1.0976  Acc=0.6331\n",
      "[Pretrain] Epoch 100/100  Loss=1.0968  Acc=0.6381\n",
      "[Fine-tune] Epoch 1/75  Loss=3.1453\n",
      "[Fine-tune] Epoch 2/75  Loss=2.5565\n",
      "[Fine-tune] Epoch 3/75  Loss=2.3234\n",
      "[Fine-tune] Epoch 4/75  Loss=2.2357\n",
      "[Fine-tune] Epoch 5/75  Loss=2.1247\n",
      "[Fine-tune] Epoch 6/75  Loss=2.0840\n",
      "[Fine-tune] Epoch 7/75  Loss=2.0254\n",
      "[Fine-tune] Epoch 8/75  Loss=1.9778\n",
      "[Fine-tune] Epoch 9/75  Loss=1.9562\n",
      "[Fine-tune] Epoch 10/75  Loss=1.9178\n",
      "[Fine-tune] Epoch 11/75  Loss=1.8716\n",
      "[Fine-tune] Epoch 12/75  Loss=1.8259\n",
      "[Fine-tune] Epoch 13/75  Loss=1.8188\n",
      "[Fine-tune] Epoch 14/75  Loss=1.7774\n",
      "[Fine-tune] Epoch 15/75  Loss=1.7403\n",
      "[Fine-tune] Epoch 16/75  Loss=1.7056\n",
      "[Fine-tune] Epoch 17/75  Loss=1.6951\n",
      "[Fine-tune] Epoch 18/75  Loss=1.6671\n",
      "[Fine-tune] Epoch 19/75  Loss=1.6413\n",
      "[Fine-tune] Epoch 20/75  Loss=1.6164\n",
      "[Fine-tune] Epoch 21/75  Loss=1.5786\n",
      "[Fine-tune] Epoch 22/75  Loss=1.5496\n",
      "[Fine-tune] Epoch 23/75  Loss=1.5223\n",
      "[Fine-tune] Epoch 24/75  Loss=1.5307\n",
      "[Fine-tune] Epoch 25/75  Loss=1.4997\n",
      "[Fine-tune] Epoch 26/75  Loss=1.4761\n",
      "[Fine-tune] Epoch 27/75  Loss=1.4526\n",
      "[Fine-tune] Epoch 28/75  Loss=1.4392\n",
      "[Fine-tune] Epoch 29/75  Loss=1.4303\n",
      "[Fine-tune] Epoch 30/75  Loss=1.4005\n",
      "[Fine-tune] Epoch 31/75  Loss=1.3823\n",
      "[Fine-tune] Epoch 32/75  Loss=1.3875\n",
      "[Fine-tune] Epoch 33/75  Loss=1.3664\n",
      "[Fine-tune] Epoch 34/75  Loss=1.3448\n",
      "[Fine-tune] Epoch 35/75  Loss=1.3161\n",
      "[Fine-tune] Epoch 36/75  Loss=1.3331\n",
      "[Fine-tune] Epoch 37/75  Loss=1.3079\n",
      "[Fine-tune] Epoch 38/75  Loss=1.2940\n",
      "[Fine-tune] Epoch 39/75  Loss=1.2665\n",
      "[Fine-tune] Epoch 40/75  Loss=1.2538\n",
      "[Fine-tune] Epoch 41/75  Loss=1.2865\n",
      "[Fine-tune] Epoch 42/75  Loss=1.2507\n",
      "[Fine-tune] Epoch 43/75  Loss=1.2403\n",
      "[Fine-tune] Epoch 44/75  Loss=1.2274\n",
      "[Fine-tune] Epoch 45/75  Loss=1.2228\n",
      "[Fine-tune] Epoch 46/75  Loss=1.2056\n",
      "[Fine-tune] Epoch 47/75  Loss=1.2230\n",
      "[Fine-tune] Epoch 48/75  Loss=1.1968\n",
      "[Fine-tune] Epoch 49/75  Loss=1.1979\n",
      "[Fine-tune] Epoch 50/75  Loss=1.1939\n",
      "[Fine-tune] Epoch 51/75  Loss=1.1920\n",
      "[Fine-tune] Epoch 52/75  Loss=1.1723\n",
      "[Fine-tune] Epoch 53/75  Loss=1.1784\n",
      "[Fine-tune] Epoch 54/75  Loss=1.1616\n",
      "[Fine-tune] Epoch 55/75  Loss=1.1589\n",
      "[Fine-tune] Epoch 56/75  Loss=1.1566\n",
      "[Fine-tune] Epoch 57/75  Loss=1.1440\n",
      "[Fine-tune] Epoch 58/75  Loss=1.1497\n",
      "[Fine-tune] Epoch 59/75  Loss=1.1570\n",
      "[Fine-tune] Epoch 60/75  Loss=1.1523\n",
      "[Fine-tune] Epoch 61/75  Loss=1.1380\n",
      "[Fine-tune] Epoch 62/75  Loss=1.1386\n",
      "[Fine-tune] Epoch 63/75  Loss=1.1396\n",
      "[Fine-tune] Epoch 64/75  Loss=1.1312\n",
      "[Fine-tune] Epoch 65/75  Loss=1.1284\n",
      "[Fine-tune] Epoch 66/75  Loss=1.1121\n",
      "[Fine-tune] Epoch 67/75  Loss=1.1274\n",
      "[Fine-tune] Epoch 68/75  Loss=1.1182\n",
      "[Fine-tune] Epoch 69/75  Loss=1.1270\n",
      "[Fine-tune] Epoch 70/75  Loss=1.1128\n",
      "[Fine-tune] Epoch 71/75  Loss=1.1186\n",
      "[Fine-tune] Epoch 72/75  Loss=1.1149\n",
      "[Fine-tune] Epoch 73/75  Loss=1.1046\n",
      "[Fine-tune] Epoch 74/75  Loss=1.0983\n",
      "[Fine-tune] Epoch 75/75  Loss=1.0974\n",
      "[Pretrain] Epoch 1/150  Loss=3.2271  Acc=0.0472\n",
      "[Pretrain] Epoch 2/150  Loss=3.0355  Acc=0.0880\n",
      "[Pretrain] Epoch 3/150  Loss=2.7447  Acc=0.1421\n",
      "[Pretrain] Epoch 4/150  Loss=2.5471  Acc=0.1873\n",
      "[Pretrain] Epoch 5/150  Loss=2.4064  Acc=0.2288\n",
      "[Pretrain] Epoch 6/150  Loss=2.2719  Acc=0.2662\n",
      "[Pretrain] Epoch 7/150  Loss=2.1812  Acc=0.3014\n",
      "[Pretrain] Epoch 8/150  Loss=2.1457  Acc=0.3073\n",
      "[Pretrain] Epoch 9/150  Loss=2.0747  Acc=0.3265\n",
      "[Pretrain] Epoch 10/150  Loss=2.0409  Acc=0.3358\n",
      "[Pretrain] Epoch 11/150  Loss=1.9809  Acc=0.3574\n",
      "[Pretrain] Epoch 12/150  Loss=1.9417  Acc=0.3728\n",
      "[Pretrain] Epoch 13/150  Loss=1.9238  Acc=0.3687\n",
      "[Pretrain] Epoch 14/150  Loss=1.8985  Acc=0.3845\n",
      "[Pretrain] Epoch 15/150  Loss=1.8862  Acc=0.3919\n",
      "[Pretrain] Epoch 16/150  Loss=1.8390  Acc=0.4018\n",
      "[Pretrain] Epoch 17/150  Loss=1.8360  Acc=0.4082\n",
      "[Pretrain] Epoch 18/150  Loss=1.8146  Acc=0.4097\n",
      "[Pretrain] Epoch 19/150  Loss=1.7699  Acc=0.4204\n",
      "[Pretrain] Epoch 20/150  Loss=1.7820  Acc=0.4246\n",
      "[Pretrain] Epoch 21/150  Loss=1.7443  Acc=0.4386\n",
      "[Pretrain] Epoch 22/150  Loss=1.7184  Acc=0.4517\n",
      "[Pretrain] Epoch 23/150  Loss=1.7107  Acc=0.4416\n",
      "[Pretrain] Epoch 24/150  Loss=1.6781  Acc=0.4549\n",
      "[Pretrain] Epoch 25/150  Loss=1.6777  Acc=0.4573\n",
      "[Pretrain] Epoch 26/150  Loss=1.6561  Acc=0.4616\n",
      "[Pretrain] Epoch 27/150  Loss=1.6416  Acc=0.4673\n",
      "[Pretrain] Epoch 28/150  Loss=1.6418  Acc=0.4723\n",
      "[Pretrain] Epoch 29/150  Loss=1.6015  Acc=0.4799\n",
      "[Pretrain] Epoch 30/150  Loss=1.5904  Acc=0.4810\n",
      "[Pretrain] Epoch 31/150  Loss=1.5758  Acc=0.4869\n",
      "[Pretrain] Epoch 32/150  Loss=1.5497  Acc=0.4950\n",
      "[Pretrain] Epoch 33/150  Loss=1.5413  Acc=0.5081\n",
      "[Pretrain] Epoch 34/150  Loss=1.5296  Acc=0.4978\n",
      "[Pretrain] Epoch 35/150  Loss=1.5246  Acc=0.5056\n",
      "[Pretrain] Epoch 36/150  Loss=1.4999  Acc=0.5095\n",
      "[Pretrain] Epoch 37/150  Loss=1.4850  Acc=0.5180\n",
      "[Pretrain] Epoch 38/150  Loss=1.4677  Acc=0.5214\n",
      "[Pretrain] Epoch 39/150  Loss=1.4686  Acc=0.5214\n",
      "[Pretrain] Epoch 40/150  Loss=1.4628  Acc=0.5289\n",
      "[Pretrain] Epoch 41/150  Loss=1.4368  Acc=0.5311\n",
      "[Pretrain] Epoch 42/150  Loss=1.4273  Acc=0.5312\n",
      "[Pretrain] Epoch 43/150  Loss=1.4224  Acc=0.5395\n",
      "[Pretrain] Epoch 44/150  Loss=1.4099  Acc=0.5436\n",
      "[Pretrain] Epoch 45/150  Loss=1.4074  Acc=0.5399\n",
      "[Pretrain] Epoch 46/150  Loss=1.3969  Acc=0.5489\n",
      "[Pretrain] Epoch 47/150  Loss=1.3967  Acc=0.5456\n",
      "[Pretrain] Epoch 48/150  Loss=1.3918  Acc=0.5465\n",
      "[Pretrain] Epoch 49/150  Loss=1.3806  Acc=0.5544\n",
      "[Pretrain] Epoch 50/150  Loss=1.3638  Acc=0.5620\n",
      "[Pretrain] Epoch 51/150  Loss=1.3739  Acc=0.5589\n",
      "[Pretrain] Epoch 52/150  Loss=1.3678  Acc=0.5512\n",
      "[Pretrain] Epoch 53/150  Loss=1.3713  Acc=0.5602\n",
      "[Pretrain] Epoch 54/150  Loss=1.3473  Acc=0.5645\n",
      "[Pretrain] Epoch 55/150  Loss=1.3491  Acc=0.5605\n",
      "[Pretrain] Epoch 56/150  Loss=1.3349  Acc=0.5720\n",
      "[Pretrain] Epoch 57/150  Loss=1.3348  Acc=0.5681\n",
      "[Pretrain] Epoch 58/150  Loss=1.3230  Acc=0.5699\n",
      "[Pretrain] Epoch 59/150  Loss=1.3230  Acc=0.5706\n",
      "[Pretrain] Epoch 60/150  Loss=1.3307  Acc=0.5718\n",
      "[Pretrain] Epoch 61/150  Loss=1.3079  Acc=0.5704\n",
      "[Pretrain] Epoch 62/150  Loss=1.3164  Acc=0.5747\n",
      "[Pretrain] Epoch 63/150  Loss=1.2978  Acc=0.5702\n",
      "[Pretrain] Epoch 64/150  Loss=1.3061  Acc=0.5794\n",
      "[Pretrain] Epoch 65/150  Loss=1.3059  Acc=0.5761\n",
      "[Pretrain] Epoch 66/150  Loss=1.2903  Acc=0.5792\n",
      "[Pretrain] Epoch 67/150  Loss=1.3117  Acc=0.5722\n",
      "[Pretrain] Epoch 68/150  Loss=1.2896  Acc=0.5767\n",
      "[Pretrain] Epoch 69/150  Loss=1.2965  Acc=0.5803\n",
      "[Pretrain] Epoch 70/150  Loss=1.2906  Acc=0.5810\n",
      "[Pretrain] Epoch 71/150  Loss=1.2851  Acc=0.5824\n",
      "[Pretrain] Epoch 72/150  Loss=1.2782  Acc=0.5857\n",
      "[Pretrain] Epoch 73/150  Loss=1.2911  Acc=0.5839\n",
      "[Pretrain] Epoch 74/150  Loss=1.2778  Acc=0.5857\n",
      "[Pretrain] Epoch 75/150  Loss=1.2823  Acc=0.5826\n",
      "[Pretrain] Epoch 76/150  Loss=1.2766  Acc=0.5848\n",
      "[Pretrain] Epoch 77/150  Loss=1.2668  Acc=0.5896\n",
      "[Pretrain] Epoch 78/150  Loss=1.2816  Acc=0.5815\n",
      "[Pretrain] Epoch 79/150  Loss=1.2534  Acc=0.5909\n",
      "[Pretrain] Epoch 80/150  Loss=1.2800  Acc=0.5907\n",
      "[Pretrain] Epoch 81/150  Loss=1.2767  Acc=0.5858\n",
      "[Pretrain] Epoch 82/150  Loss=1.2647  Acc=0.5858\n",
      "[Pretrain] Epoch 83/150  Loss=1.2689  Acc=0.5864\n",
      "[Pretrain] Epoch 84/150  Loss=1.2596  Acc=0.5823\n",
      "[Pretrain] Epoch 85/150  Loss=1.2641  Acc=0.5885\n",
      "[Pretrain] Epoch 86/150  Loss=1.2857  Acc=0.5821\n",
      "[Pretrain] Epoch 87/150  Loss=1.2658  Acc=0.5896\n",
      "[Pretrain] Epoch 88/150  Loss=1.2503  Acc=0.5921\n",
      "[Pretrain] Epoch 89/150  Loss=1.2575  Acc=0.5918\n",
      "[Pretrain] Epoch 90/150  Loss=1.2461  Acc=0.5921\n",
      "[Pretrain] Epoch 91/150  Loss=1.2543  Acc=0.5968\n",
      "[Pretrain] Epoch 92/150  Loss=1.2532  Acc=0.5912\n",
      "[Pretrain] Epoch 93/150  Loss=1.2497  Acc=0.5905\n",
      "[Pretrain] Epoch 94/150  Loss=1.2541  Acc=0.5921\n",
      "[Pretrain] Epoch 95/150  Loss=1.2643  Acc=0.5914\n",
      "[Pretrain] Epoch 96/150  Loss=1.2647  Acc=0.5959\n",
      "[Pretrain] Epoch 97/150  Loss=1.2530  Acc=0.5898\n",
      "[Pretrain] Epoch 98/150  Loss=1.2496  Acc=0.5952\n",
      "[Pretrain] Epoch 99/150  Loss=1.2584  Acc=0.5905\n",
      "[Pretrain] Epoch 100/150  Loss=1.2613  Acc=0.5920\n",
      "[Pretrain] Epoch 101/150  Loss=1.2576  Acc=0.5911\n",
      "[Pretrain] Epoch 102/150  Loss=1.2553  Acc=0.5918\n",
      "[Pretrain] Epoch 103/150  Loss=1.2561  Acc=0.5894\n",
      "[Pretrain] Epoch 104/150  Loss=1.2430  Acc=0.5939\n",
      "[Pretrain] Epoch 105/150  Loss=1.2582  Acc=0.5936\n",
      "[Pretrain] Epoch 106/150  Loss=1.2429  Acc=0.5993\n",
      "[Pretrain] Epoch 107/150  Loss=1.2565  Acc=0.5909\n",
      "[Pretrain] Epoch 108/150  Loss=1.2508  Acc=0.5902\n",
      "[Pretrain] Epoch 109/150  Loss=1.2300  Acc=0.5981\n",
      "[Pretrain] Epoch 110/150  Loss=1.2464  Acc=0.5952\n",
      "[Pretrain] Epoch 111/150  Loss=1.2520  Acc=0.5921\n",
      "[Pretrain] Epoch 112/150  Loss=1.2484  Acc=0.5943\n",
      "[Pretrain] Epoch 113/150  Loss=1.2466  Acc=0.5955\n",
      "[Pretrain] Epoch 114/150  Loss=1.2426  Acc=0.5997\n",
      "[Pretrain] Epoch 115/150  Loss=1.2419  Acc=0.6017\n",
      "[Pretrain] Epoch 116/150  Loss=1.2481  Acc=0.5943\n",
      "[Pretrain] Epoch 117/150  Loss=1.2469  Acc=0.5945\n",
      "[Pretrain] Epoch 118/150  Loss=1.2527  Acc=0.5876\n",
      "[Pretrain] Epoch 119/150  Loss=1.2378  Acc=0.5982\n",
      "[Pretrain] Epoch 120/150  Loss=1.2344  Acc=0.6026\n",
      "[Pretrain] Epoch 121/150  Loss=1.2639  Acc=0.5945\n",
      "[Pretrain] Epoch 122/150  Loss=1.2535  Acc=0.5903\n",
      "[Pretrain] Epoch 123/150  Loss=1.2400  Acc=0.5945\n",
      "[Pretrain] Epoch 124/150  Loss=1.2521  Acc=0.5921\n",
      "[Pretrain] Epoch 125/150  Loss=1.2428  Acc=0.5982\n",
      "[Pretrain] Epoch 126/150  Loss=1.2501  Acc=0.5938\n",
      "[Pretrain] Epoch 127/150  Loss=1.2606  Acc=0.5894\n",
      "[Pretrain] Epoch 128/150  Loss=1.2561  Acc=0.6009\n",
      "[Pretrain] Epoch 129/150  Loss=1.2422  Acc=0.5973\n",
      "[Pretrain] Epoch 130/150  Loss=1.2405  Acc=0.6006\n",
      "[Pretrain] Epoch 131/150  Loss=1.2300  Acc=0.5981\n",
      "[Pretrain] Epoch 132/150  Loss=1.2380  Acc=0.5963\n",
      "[Pretrain] Epoch 133/150  Loss=1.2489  Acc=0.5941\n",
      "[Pretrain] Epoch 134/150  Loss=1.2442  Acc=0.5950\n",
      "[Pretrain] Epoch 135/150  Loss=1.2550  Acc=0.5939\n",
      "[Pretrain] Epoch 136/150  Loss=1.2391  Acc=0.5995\n",
      "[Pretrain] Epoch 137/150  Loss=1.2515  Acc=0.5982\n",
      "[Pretrain] Epoch 138/150  Loss=1.2491  Acc=0.5873\n",
      "[Pretrain] Epoch 139/150  Loss=1.2499  Acc=0.5952\n",
      "[Pretrain] Epoch 140/150  Loss=1.2531  Acc=0.5945\n",
      "[Pretrain] Epoch 141/150  Loss=1.2340  Acc=0.6054\n",
      "[Pretrain] Epoch 142/150  Loss=1.2499  Acc=0.5950\n",
      "[Pretrain] Epoch 143/150  Loss=1.2388  Acc=0.5988\n",
      "[Pretrain] Epoch 144/150  Loss=1.2510  Acc=0.5934\n",
      "[Pretrain] Epoch 145/150  Loss=1.2494  Acc=0.5929\n",
      "[Pretrain] Epoch 146/150  Loss=1.2545  Acc=0.5986\n",
      "[Pretrain] Epoch 147/150  Loss=1.2574  Acc=0.5950\n",
      "[Pretrain] Epoch 148/150  Loss=1.2401  Acc=0.6009\n",
      "[Pretrain] Epoch 149/150  Loss=1.2514  Acc=0.5929\n",
      "[Pretrain] Epoch 150/150  Loss=1.2453  Acc=0.5975\n",
      "[Fine-tune] Epoch 1/75  Loss=3.2512\n",
      "[Fine-tune] Epoch 2/75  Loss=3.1202\n",
      "[Fine-tune] Epoch 3/75  Loss=3.0474\n",
      "[Fine-tune] Epoch 4/75  Loss=2.8459\n",
      "[Fine-tune] Epoch 5/75  Loss=2.5704\n",
      "[Fine-tune] Epoch 6/75  Loss=2.4668\n",
      "[Fine-tune] Epoch 7/75  Loss=2.4290\n",
      "[Fine-tune] Epoch 8/75  Loss=2.3550\n",
      "[Fine-tune] Epoch 9/75  Loss=2.3025\n",
      "[Fine-tune] Epoch 10/75  Loss=2.2455\n",
      "[Fine-tune] Epoch 11/75  Loss=2.2194\n",
      "[Fine-tune] Epoch 12/75  Loss=2.1452\n",
      "[Fine-tune] Epoch 13/75  Loss=2.1235\n",
      "[Fine-tune] Epoch 14/75  Loss=2.0739\n",
      "[Fine-tune] Epoch 15/75  Loss=2.0366\n",
      "[Fine-tune] Epoch 16/75  Loss=2.0261\n",
      "[Fine-tune] Epoch 17/75  Loss=1.9751\n",
      "[Fine-tune] Epoch 18/75  Loss=1.9549\n",
      "[Fine-tune] Epoch 19/75  Loss=1.9403\n",
      "[Fine-tune] Epoch 20/75  Loss=1.9142\n",
      "[Fine-tune] Epoch 21/75  Loss=1.8744\n",
      "[Fine-tune] Epoch 22/75  Loss=1.8519\n",
      "[Fine-tune] Epoch 23/75  Loss=1.8628\n",
      "[Fine-tune] Epoch 24/75  Loss=1.8182\n",
      "[Fine-tune] Epoch 25/75  Loss=1.7971\n",
      "[Fine-tune] Epoch 26/75  Loss=1.7724\n",
      "[Fine-tune] Epoch 27/75  Loss=1.7568\n",
      "[Fine-tune] Epoch 28/75  Loss=1.7335\n",
      "[Fine-tune] Epoch 29/75  Loss=1.7097\n",
      "[Fine-tune] Epoch 30/75  Loss=1.7023\n",
      "[Fine-tune] Epoch 31/75  Loss=1.6976\n",
      "[Fine-tune] Epoch 32/75  Loss=1.6648\n",
      "[Fine-tune] Epoch 33/75  Loss=1.6657\n",
      "[Fine-tune] Epoch 34/75  Loss=1.6594\n",
      "[Fine-tune] Epoch 35/75  Loss=1.6232\n",
      "[Fine-tune] Epoch 36/75  Loss=1.6186\n",
      "[Fine-tune] Epoch 37/75  Loss=1.5965\n",
      "[Fine-tune] Epoch 38/75  Loss=1.5849\n",
      "[Fine-tune] Epoch 39/75  Loss=1.5671\n",
      "[Fine-tune] Epoch 40/75  Loss=1.5505\n",
      "[Fine-tune] Epoch 41/75  Loss=1.5552\n",
      "[Fine-tune] Epoch 42/75  Loss=1.5440\n",
      "[Fine-tune] Epoch 43/75  Loss=1.5197\n",
      "[Fine-tune] Epoch 44/75  Loss=1.5056\n",
      "[Fine-tune] Epoch 45/75  Loss=1.4960\n",
      "[Fine-tune] Epoch 46/75  Loss=1.4929\n",
      "[Fine-tune] Epoch 47/75  Loss=1.4755\n",
      "[Fine-tune] Epoch 48/75  Loss=1.4779\n",
      "[Fine-tune] Epoch 49/75  Loss=1.4812\n",
      "[Fine-tune] Epoch 50/75  Loss=1.4663\n",
      "[Fine-tune] Epoch 51/75  Loss=1.4635\n",
      "[Fine-tune] Epoch 52/75  Loss=1.4524\n",
      "[Fine-tune] Epoch 53/75  Loss=1.4530\n",
      "[Fine-tune] Epoch 54/75  Loss=1.4511\n",
      "[Fine-tune] Epoch 55/75  Loss=1.4215\n",
      "[Fine-tune] Epoch 56/75  Loss=1.4230\n",
      "[Fine-tune] Epoch 57/75  Loss=1.4112\n",
      "[Fine-tune] Epoch 58/75  Loss=1.4355\n",
      "[Fine-tune] Epoch 59/75  Loss=1.4204\n",
      "[Fine-tune] Epoch 60/75  Loss=1.4046\n",
      "[Fine-tune] Epoch 61/75  Loss=1.3993\n",
      "[Fine-tune] Epoch 62/75  Loss=1.4064\n",
      "[Fine-tune] Epoch 63/75  Loss=1.4005\n",
      "[Fine-tune] Epoch 64/75  Loss=1.4028\n",
      "[Fine-tune] Epoch 65/75  Loss=1.3999\n",
      "[Fine-tune] Epoch 66/75  Loss=1.3894\n",
      "[Fine-tune] Epoch 67/75  Loss=1.3954\n",
      "[Fine-tune] Epoch 68/75  Loss=1.3940\n",
      "[Fine-tune] Epoch 69/75  Loss=1.3792\n",
      "[Fine-tune] Epoch 70/75  Loss=1.3807\n",
      "[Fine-tune] Epoch 71/75  Loss=1.3658\n",
      "[Fine-tune] Epoch 72/75  Loss=1.3785\n",
      "[Fine-tune] Epoch 73/75  Loss=1.3717\n",
      "[Fine-tune] Epoch 74/75  Loss=1.3821\n",
      "[Fine-tune] Epoch 75/75  Loss=1.3648\n",
      "[Pretrain] Epoch 1/150  Loss=3.6996  Acc=0.0370\n",
      "[Pretrain] Epoch 2/150  Loss=3.1691  Acc=0.0580\n",
      "[Pretrain] Epoch 3/150  Loss=3.0124  Acc=0.0821\n",
      "[Pretrain] Epoch 4/150  Loss=2.8465  Acc=0.1124\n",
      "[Pretrain] Epoch 5/150  Loss=2.6782  Acc=0.1557\n",
      "[Pretrain] Epoch 6/150  Loss=2.5454  Acc=0.1970\n",
      "[Pretrain] Epoch 7/150  Loss=2.4297  Acc=0.2263\n",
      "[Pretrain] Epoch 8/150  Loss=2.3680  Acc=0.2385\n",
      "[Pretrain] Epoch 9/150  Loss=2.3012  Acc=0.2615\n",
      "[Pretrain] Epoch 10/150  Loss=2.2975  Acc=0.2563\n",
      "[Pretrain] Epoch 11/150  Loss=2.2824  Acc=0.2557\n",
      "[Pretrain] Epoch 12/150  Loss=2.2297  Acc=0.2807\n",
      "[Pretrain] Epoch 13/150  Loss=2.1842  Acc=0.2972\n",
      "[Pretrain] Epoch 14/150  Loss=2.1474  Acc=0.3026\n",
      "[Pretrain] Epoch 15/150  Loss=2.1337  Acc=0.3159\n",
      "[Pretrain] Epoch 16/150  Loss=2.0978  Acc=0.3231\n",
      "[Pretrain] Epoch 17/150  Loss=2.0470  Acc=0.3342\n",
      "[Pretrain] Epoch 18/150  Loss=2.0185  Acc=0.3391\n",
      "[Pretrain] Epoch 19/150  Loss=2.0025  Acc=0.3529\n",
      "[Pretrain] Epoch 20/150  Loss=1.9826  Acc=0.3551\n",
      "[Pretrain] Epoch 21/150  Loss=1.9343  Acc=0.3732\n",
      "[Pretrain] Epoch 22/150  Loss=1.9153  Acc=0.3745\n",
      "[Pretrain] Epoch 23/150  Loss=1.8811  Acc=0.3838\n",
      "[Pretrain] Epoch 24/150  Loss=1.8626  Acc=0.3942\n",
      "[Pretrain] Epoch 25/150  Loss=1.8524  Acc=0.4016\n",
      "[Pretrain] Epoch 26/150  Loss=1.8249  Acc=0.4122\n",
      "[Pretrain] Epoch 27/150  Loss=1.7977  Acc=0.4113\n",
      "[Pretrain] Epoch 28/150  Loss=1.7792  Acc=0.4244\n",
      "[Pretrain] Epoch 29/150  Loss=1.7492  Acc=0.4289\n",
      "[Pretrain] Epoch 30/150  Loss=1.7192  Acc=0.4361\n",
      "[Pretrain] Epoch 31/150  Loss=1.7384  Acc=0.4276\n",
      "[Pretrain] Epoch 32/150  Loss=1.6907  Acc=0.4463\n",
      "[Pretrain] Epoch 33/150  Loss=1.6786  Acc=0.4495\n",
      "[Pretrain] Epoch 34/150  Loss=1.6318  Acc=0.4610\n",
      "[Pretrain] Epoch 35/150  Loss=1.6199  Acc=0.4749\n",
      "[Pretrain] Epoch 36/150  Loss=1.6054  Acc=0.4677\n",
      "[Pretrain] Epoch 37/150  Loss=1.5947  Acc=0.4793\n",
      "[Pretrain] Epoch 38/150  Loss=1.5639  Acc=0.4934\n",
      "[Pretrain] Epoch 39/150  Loss=1.5556  Acc=0.4840\n",
      "[Pretrain] Epoch 40/150  Loss=1.5399  Acc=0.4921\n",
      "[Pretrain] Epoch 41/150  Loss=1.5145  Acc=0.4975\n",
      "[Pretrain] Epoch 42/150  Loss=1.5043  Acc=0.5022\n",
      "[Pretrain] Epoch 43/150  Loss=1.4875  Acc=0.5095\n",
      "[Pretrain] Epoch 44/150  Loss=1.4794  Acc=0.5144\n",
      "[Pretrain] Epoch 45/150  Loss=1.4750  Acc=0.5223\n",
      "[Pretrain] Epoch 46/150  Loss=1.4514  Acc=0.5248\n",
      "[Pretrain] Epoch 47/150  Loss=1.4411  Acc=0.5253\n",
      "[Pretrain] Epoch 48/150  Loss=1.4256  Acc=0.5287\n",
      "[Pretrain] Epoch 49/150  Loss=1.4287  Acc=0.5361\n",
      "[Pretrain] Epoch 50/150  Loss=1.4122  Acc=0.5347\n",
      "[Pretrain] Epoch 51/150  Loss=1.4050  Acc=0.5397\n",
      "[Pretrain] Epoch 52/150  Loss=1.3939  Acc=0.5365\n",
      "[Pretrain] Epoch 53/150  Loss=1.3631  Acc=0.5559\n",
      "[Pretrain] Epoch 54/150  Loss=1.3719  Acc=0.5519\n",
      "[Pretrain] Epoch 55/150  Loss=1.3626  Acc=0.5541\n",
      "[Pretrain] Epoch 56/150  Loss=1.3520  Acc=0.5559\n",
      "[Pretrain] Epoch 57/150  Loss=1.3484  Acc=0.5562\n",
      "[Pretrain] Epoch 58/150  Loss=1.3329  Acc=0.5643\n",
      "[Pretrain] Epoch 59/150  Loss=1.3252  Acc=0.5629\n",
      "[Pretrain] Epoch 60/150  Loss=1.3170  Acc=0.5684\n",
      "[Pretrain] Epoch 61/150  Loss=1.3159  Acc=0.5704\n",
      "[Pretrain] Epoch 62/150  Loss=1.3039  Acc=0.5702\n",
      "[Pretrain] Epoch 63/150  Loss=1.3081  Acc=0.5657\n",
      "[Pretrain] Epoch 64/150  Loss=1.3050  Acc=0.5735\n",
      "[Pretrain] Epoch 65/150  Loss=1.2754  Acc=0.5858\n",
      "[Pretrain] Epoch 66/150  Loss=1.2870  Acc=0.5758\n",
      "[Pretrain] Epoch 67/150  Loss=1.2736  Acc=0.5833\n",
      "[Pretrain] Epoch 68/150  Loss=1.2689  Acc=0.5803\n",
      "[Pretrain] Epoch 69/150  Loss=1.2750  Acc=0.5812\n",
      "[Pretrain] Epoch 70/150  Loss=1.2488  Acc=0.5842\n",
      "[Pretrain] Epoch 71/150  Loss=1.2633  Acc=0.5862\n",
      "[Pretrain] Epoch 72/150  Loss=1.2406  Acc=0.5869\n",
      "[Pretrain] Epoch 73/150  Loss=1.2596  Acc=0.5871\n",
      "[Pretrain] Epoch 74/150  Loss=1.2483  Acc=0.5938\n",
      "[Pretrain] Epoch 75/150  Loss=1.2415  Acc=0.5991\n",
      "[Pretrain] Epoch 76/150  Loss=1.2538  Acc=0.5817\n",
      "[Pretrain] Epoch 77/150  Loss=1.2292  Acc=0.5966\n",
      "[Pretrain] Epoch 78/150  Loss=1.2420  Acc=0.5975\n",
      "[Pretrain] Epoch 79/150  Loss=1.2454  Acc=0.5936\n",
      "[Pretrain] Epoch 80/150  Loss=1.2223  Acc=0.5993\n",
      "[Pretrain] Epoch 81/150  Loss=1.2255  Acc=0.5988\n",
      "[Pretrain] Epoch 82/150  Loss=1.2206  Acc=0.5984\n",
      "[Pretrain] Epoch 83/150  Loss=1.2235  Acc=0.6009\n",
      "[Pretrain] Epoch 84/150  Loss=1.2154  Acc=0.5997\n",
      "[Pretrain] Epoch 85/150  Loss=1.2231  Acc=0.6022\n",
      "[Pretrain] Epoch 86/150  Loss=1.2163  Acc=0.6009\n",
      "[Pretrain] Epoch 87/150  Loss=1.2098  Acc=0.5988\n",
      "[Pretrain] Epoch 88/150  Loss=1.2211  Acc=0.6038\n",
      "[Pretrain] Epoch 89/150  Loss=1.2155  Acc=0.6011\n",
      "[Pretrain] Epoch 90/150  Loss=1.2075  Acc=0.5982\n",
      "[Pretrain] Epoch 91/150  Loss=1.2062  Acc=0.6069\n",
      "[Pretrain] Epoch 92/150  Loss=1.2006  Acc=0.6099\n",
      "[Pretrain] Epoch 93/150  Loss=1.2002  Acc=0.6105\n",
      "[Pretrain] Epoch 94/150  Loss=1.1839  Acc=0.6090\n",
      "[Pretrain] Epoch 95/150  Loss=1.1883  Acc=0.6079\n",
      "[Pretrain] Epoch 96/150  Loss=1.2107  Acc=0.6029\n",
      "[Pretrain] Epoch 97/150  Loss=1.2044  Acc=0.6004\n",
      "[Pretrain] Epoch 98/150  Loss=1.1900  Acc=0.6121\n",
      "[Pretrain] Epoch 99/150  Loss=1.1841  Acc=0.6115\n",
      "[Pretrain] Epoch 100/150  Loss=1.1854  Acc=0.6117\n",
      "[Pretrain] Epoch 101/150  Loss=1.1832  Acc=0.6126\n",
      "[Pretrain] Epoch 102/150  Loss=1.1999  Acc=0.6067\n",
      "[Pretrain] Epoch 103/150  Loss=1.1942  Acc=0.6051\n",
      "[Pretrain] Epoch 104/150  Loss=1.2024  Acc=0.6092\n",
      "[Pretrain] Epoch 105/150  Loss=1.1800  Acc=0.6096\n",
      "[Pretrain] Epoch 106/150  Loss=1.1830  Acc=0.6137\n",
      "[Pretrain] Epoch 107/150  Loss=1.1905  Acc=0.6078\n",
      "[Pretrain] Epoch 108/150  Loss=1.1727  Acc=0.6139\n",
      "[Pretrain] Epoch 109/150  Loss=1.2051  Acc=0.6054\n",
      "[Pretrain] Epoch 110/150  Loss=1.1966  Acc=0.6079\n",
      "[Pretrain] Epoch 111/150  Loss=1.2052  Acc=0.6024\n",
      "[Pretrain] Epoch 112/150  Loss=1.1883  Acc=0.6094\n",
      "[Pretrain] Epoch 113/150  Loss=1.1862  Acc=0.6135\n",
      "[Pretrain] Epoch 114/150  Loss=1.1878  Acc=0.6099\n",
      "[Pretrain] Epoch 115/150  Loss=1.1727  Acc=0.6139\n",
      "[Pretrain] Epoch 116/150  Loss=1.1753  Acc=0.6202\n",
      "[Pretrain] Epoch 117/150  Loss=1.1769  Acc=0.6148\n",
      "[Pretrain] Epoch 118/150  Loss=1.1946  Acc=0.6074\n",
      "[Pretrain] Epoch 119/150  Loss=1.1879  Acc=0.6097\n",
      "[Pretrain] Epoch 120/150  Loss=1.1850  Acc=0.6076\n",
      "[Pretrain] Epoch 121/150  Loss=1.1795  Acc=0.6130\n",
      "[Pretrain] Epoch 122/150  Loss=1.1673  Acc=0.6178\n",
      "[Pretrain] Epoch 123/150  Loss=1.1798  Acc=0.6121\n",
      "[Pretrain] Epoch 124/150  Loss=1.1758  Acc=0.6142\n",
      "[Pretrain] Epoch 125/150  Loss=1.1911  Acc=0.6090\n",
      "[Pretrain] Epoch 126/150  Loss=1.1830  Acc=0.6114\n",
      "[Pretrain] Epoch 127/150  Loss=1.1838  Acc=0.6144\n",
      "[Pretrain] Epoch 128/150  Loss=1.1888  Acc=0.6096\n",
      "[Pretrain] Epoch 129/150  Loss=1.1803  Acc=0.6101\n",
      "[Pretrain] Epoch 130/150  Loss=1.1803  Acc=0.6151\n",
      "[Pretrain] Epoch 131/150  Loss=1.1820  Acc=0.6140\n",
      "[Pretrain] Epoch 132/150  Loss=1.1783  Acc=0.6087\n",
      "[Pretrain] Epoch 133/150  Loss=1.1807  Acc=0.6110\n",
      "[Pretrain] Epoch 134/150  Loss=1.1815  Acc=0.6169\n",
      "[Pretrain] Epoch 135/150  Loss=1.1763  Acc=0.6101\n",
      "[Pretrain] Epoch 136/150  Loss=1.1880  Acc=0.6103\n",
      "[Pretrain] Epoch 137/150  Loss=1.1892  Acc=0.6112\n",
      "[Pretrain] Epoch 138/150  Loss=1.1809  Acc=0.6137\n",
      "[Pretrain] Epoch 139/150  Loss=1.1759  Acc=0.6122\n",
      "[Pretrain] Epoch 140/150  Loss=1.1727  Acc=0.6160\n",
      "[Pretrain] Epoch 141/150  Loss=1.1741  Acc=0.6200\n",
      "[Pretrain] Epoch 142/150  Loss=1.1902  Acc=0.6105\n",
      "[Pretrain] Epoch 143/150  Loss=1.1831  Acc=0.6133\n",
      "[Pretrain] Epoch 144/150  Loss=1.1774  Acc=0.6117\n",
      "[Pretrain] Epoch 145/150  Loss=1.1764  Acc=0.6112\n",
      "[Pretrain] Epoch 146/150  Loss=1.1855  Acc=0.6135\n",
      "[Pretrain] Epoch 147/150  Loss=1.1786  Acc=0.6158\n",
      "[Pretrain] Epoch 148/150  Loss=1.1708  Acc=0.6198\n",
      "[Pretrain] Epoch 149/150  Loss=1.1859  Acc=0.6099\n",
      "[Pretrain] Epoch 150/150  Loss=1.1843  Acc=0.6167\n",
      "[Fine-tune] Epoch 1/75  Loss=3.2219\n",
      "[Fine-tune] Epoch 2/75  Loss=2.8954\n",
      "[Fine-tune] Epoch 3/75  Loss=2.5125\n",
      "[Fine-tune] Epoch 4/75  Loss=2.3032\n",
      "[Fine-tune] Epoch 5/75  Loss=2.2071\n",
      "[Fine-tune] Epoch 6/75  Loss=2.1484\n",
      "[Fine-tune] Epoch 7/75  Loss=2.0583\n",
      "[Fine-tune] Epoch 8/75  Loss=2.0018\n",
      "[Fine-tune] Epoch 9/75  Loss=1.9829\n",
      "[Fine-tune] Epoch 10/75  Loss=1.9538\n",
      "[Fine-tune] Epoch 11/75  Loss=1.9037\n",
      "[Fine-tune] Epoch 12/75  Loss=1.8876\n",
      "[Fine-tune] Epoch 13/75  Loss=1.8601\n",
      "[Fine-tune] Epoch 14/75  Loss=1.8151\n",
      "[Fine-tune] Epoch 15/75  Loss=1.8112\n",
      "[Fine-tune] Epoch 16/75  Loss=1.7520\n",
      "[Fine-tune] Epoch 17/75  Loss=1.7373\n",
      "[Fine-tune] Epoch 18/75  Loss=1.7156\n",
      "[Fine-tune] Epoch 19/75  Loss=1.6872\n",
      "[Fine-tune] Epoch 20/75  Loss=1.6710\n",
      "[Fine-tune] Epoch 21/75  Loss=1.6523\n",
      "[Fine-tune] Epoch 22/75  Loss=1.6258\n",
      "[Fine-tune] Epoch 23/75  Loss=1.6064\n",
      "[Fine-tune] Epoch 24/75  Loss=1.5739\n",
      "[Fine-tune] Epoch 25/75  Loss=1.5674\n",
      "[Fine-tune] Epoch 26/75  Loss=1.5398\n",
      "[Fine-tune] Epoch 27/75  Loss=1.5219\n",
      "[Fine-tune] Epoch 28/75  Loss=1.4987\n",
      "[Fine-tune] Epoch 29/75  Loss=1.4852\n",
      "[Fine-tune] Epoch 30/75  Loss=1.4636\n",
      "[Fine-tune] Epoch 31/75  Loss=1.4480\n",
      "[Fine-tune] Epoch 32/75  Loss=1.4383\n",
      "[Fine-tune] Epoch 33/75  Loss=1.4328\n",
      "[Fine-tune] Epoch 34/75  Loss=1.4144\n",
      "[Fine-tune] Epoch 35/75  Loss=1.3950\n",
      "[Fine-tune] Epoch 36/75  Loss=1.3980\n",
      "[Fine-tune] Epoch 37/75  Loss=1.3836\n",
      "[Fine-tune] Epoch 38/75  Loss=1.3665\n",
      "[Fine-tune] Epoch 39/75  Loss=1.3606\n",
      "[Fine-tune] Epoch 40/75  Loss=1.3556\n",
      "[Fine-tune] Epoch 41/75  Loss=1.3331\n",
      "[Fine-tune] Epoch 42/75  Loss=1.3567\n",
      "[Fine-tune] Epoch 43/75  Loss=1.3155\n",
      "[Fine-tune] Epoch 44/75  Loss=1.3224\n",
      "[Fine-tune] Epoch 45/75  Loss=1.3123\n",
      "[Fine-tune] Epoch 46/75  Loss=1.3147\n",
      "[Fine-tune] Epoch 47/75  Loss=1.3015\n",
      "[Fine-tune] Epoch 48/75  Loss=1.2934\n",
      "[Fine-tune] Epoch 49/75  Loss=1.2936\n",
      "[Fine-tune] Epoch 50/75  Loss=1.2779\n",
      "[Fine-tune] Epoch 51/75  Loss=1.2688\n",
      "[Fine-tune] Epoch 52/75  Loss=1.2737\n",
      "[Fine-tune] Epoch 53/75  Loss=1.2697\n",
      "[Fine-tune] Epoch 54/75  Loss=1.2510\n",
      "[Fine-tune] Epoch 55/75  Loss=1.2522\n",
      "[Fine-tune] Epoch 56/75  Loss=1.2548\n",
      "[Fine-tune] Epoch 57/75  Loss=1.2438\n",
      "[Fine-tune] Epoch 58/75  Loss=1.2491\n",
      "[Fine-tune] Epoch 59/75  Loss=1.2433\n",
      "[Fine-tune] Epoch 60/75  Loss=1.2488\n",
      "[Fine-tune] Epoch 61/75  Loss=1.2266\n",
      "[Fine-tune] Epoch 62/75  Loss=1.2288\n",
      "[Fine-tune] Epoch 63/75  Loss=1.2344\n",
      "[Fine-tune] Epoch 64/75  Loss=1.2315\n",
      "[Fine-tune] Epoch 65/75  Loss=1.2147\n",
      "[Fine-tune] Epoch 66/75  Loss=1.2185\n",
      "[Fine-tune] Epoch 67/75  Loss=1.2201\n",
      "[Fine-tune] Epoch 68/75  Loss=1.2203\n",
      "[Fine-tune] Epoch 69/75  Loss=1.2147\n",
      "[Fine-tune] Epoch 70/75  Loss=1.2095\n",
      "[Fine-tune] Epoch 71/75  Loss=1.2090\n",
      "[Fine-tune] Epoch 72/75  Loss=1.2078\n",
      "[Fine-tune] Epoch 73/75  Loss=1.2124\n",
      "[Fine-tune] Epoch 74/75  Loss=1.2013\n",
      "[Fine-tune] Epoch 75/75  Loss=1.2063\n",
      "[Pretrain] Epoch 1/50  Loss=3.2557  Acc=0.0383\n",
      "[Pretrain] Epoch 2/50  Loss=3.1091  Acc=0.0709\n",
      "[Pretrain] Epoch 3/50  Loss=2.9330  Acc=0.1063\n",
      "[Pretrain] Epoch 4/50  Loss=2.6152  Acc=0.1703\n",
      "[Pretrain] Epoch 5/50  Loss=2.4623  Acc=0.2114\n",
      "[Pretrain] Epoch 6/50  Loss=2.3524  Acc=0.2383\n",
      "[Pretrain] Epoch 7/50  Loss=2.2891  Acc=0.2613\n",
      "[Pretrain] Epoch 8/50  Loss=2.2461  Acc=0.2773\n",
      "[Pretrain] Epoch 9/50  Loss=2.1843  Acc=0.2888\n",
      "[Pretrain] Epoch 10/50  Loss=2.1153  Acc=0.3118\n",
      "[Pretrain] Epoch 11/50  Loss=2.0863  Acc=0.3321\n",
      "[Pretrain] Epoch 12/50  Loss=2.0196  Acc=0.3484\n",
      "[Pretrain] Epoch 13/50  Loss=1.9680  Acc=0.3596\n",
      "[Pretrain] Epoch 14/50  Loss=1.9333  Acc=0.3755\n",
      "[Pretrain] Epoch 15/50  Loss=1.9180  Acc=0.3770\n",
      "[Pretrain] Epoch 16/50  Loss=1.8717  Acc=0.3958\n",
      "[Pretrain] Epoch 17/50  Loss=1.8384  Acc=0.4154\n",
      "[Pretrain] Epoch 18/50  Loss=1.8254  Acc=0.4077\n",
      "[Pretrain] Epoch 19/50  Loss=1.7753  Acc=0.4195\n",
      "[Pretrain] Epoch 20/50  Loss=1.7926  Acc=0.4255\n",
      "[Pretrain] Epoch 21/50  Loss=1.7565  Acc=0.4309\n",
      "[Pretrain] Epoch 22/50  Loss=1.7477  Acc=0.4402\n",
      "[Pretrain] Epoch 23/50  Loss=1.7050  Acc=0.4485\n",
      "[Pretrain] Epoch 24/50  Loss=1.6839  Acc=0.4610\n",
      "[Pretrain] Epoch 25/50  Loss=1.6793  Acc=0.4546\n",
      "[Pretrain] Epoch 26/50  Loss=1.6571  Acc=0.4564\n",
      "[Pretrain] Epoch 27/50  Loss=1.6416  Acc=0.4723\n",
      "[Pretrain] Epoch 28/50  Loss=1.6358  Acc=0.4722\n",
      "[Pretrain] Epoch 29/50  Loss=1.6023  Acc=0.4793\n",
      "[Pretrain] Epoch 30/50  Loss=1.5909  Acc=0.4853\n",
      "[Pretrain] Epoch 31/50  Loss=1.5676  Acc=0.4925\n",
      "[Pretrain] Epoch 32/50  Loss=1.5596  Acc=0.4926\n",
      "[Pretrain] Epoch 33/50  Loss=1.5442  Acc=0.4982\n",
      "[Pretrain] Epoch 34/50  Loss=1.5165  Acc=0.5061\n",
      "[Pretrain] Epoch 35/50  Loss=1.5103  Acc=0.5120\n",
      "[Pretrain] Epoch 36/50  Loss=1.5055  Acc=0.5111\n",
      "[Pretrain] Epoch 37/50  Loss=1.4801  Acc=0.5160\n",
      "[Pretrain] Epoch 38/50  Loss=1.4938  Acc=0.5126\n",
      "[Pretrain] Epoch 39/50  Loss=1.4774  Acc=0.5217\n",
      "[Pretrain] Epoch 40/50  Loss=1.4463  Acc=0.5282\n",
      "[Pretrain] Epoch 41/50  Loss=1.4485  Acc=0.5329\n",
      "[Pretrain] Epoch 42/50  Loss=1.4445  Acc=0.5242\n",
      "[Pretrain] Epoch 43/50  Loss=1.4279  Acc=0.5345\n",
      "[Pretrain] Epoch 44/50  Loss=1.4232  Acc=0.5377\n",
      "[Pretrain] Epoch 45/50  Loss=1.4282  Acc=0.5417\n",
      "[Pretrain] Epoch 46/50  Loss=1.4227  Acc=0.5411\n",
      "[Pretrain] Epoch 47/50  Loss=1.3912  Acc=0.5460\n",
      "[Pretrain] Epoch 48/50  Loss=1.3757  Acc=0.5458\n",
      "[Pretrain] Epoch 49/50  Loss=1.3957  Acc=0.5445\n",
      "[Pretrain] Epoch 50/50  Loss=1.3736  Acc=0.5497\n",
      "[Fine-tune] Epoch 1/100  Loss=2.6877\n",
      "[Fine-tune] Epoch 2/100  Loss=2.2082\n",
      "[Fine-tune] Epoch 3/100  Loss=2.0492\n",
      "[Fine-tune] Epoch 4/100  Loss=1.9461\n",
      "[Fine-tune] Epoch 5/100  Loss=1.8687\n",
      "[Fine-tune] Epoch 6/100  Loss=1.8245\n",
      "[Fine-tune] Epoch 7/100  Loss=1.7746\n",
      "[Fine-tune] Epoch 8/100  Loss=1.7182\n",
      "[Fine-tune] Epoch 9/100  Loss=1.7025\n",
      "[Fine-tune] Epoch 10/100  Loss=1.6508\n",
      "[Fine-tune] Epoch 11/100  Loss=1.6250\n",
      "[Fine-tune] Epoch 12/100  Loss=1.5939\n",
      "[Fine-tune] Epoch 13/100  Loss=1.5519\n",
      "[Fine-tune] Epoch 14/100  Loss=1.5098\n",
      "[Fine-tune] Epoch 15/100  Loss=1.4912\n",
      "[Fine-tune] Epoch 16/100  Loss=1.4594\n",
      "[Fine-tune] Epoch 17/100  Loss=1.4229\n",
      "[Fine-tune] Epoch 18/100  Loss=1.4278\n",
      "[Fine-tune] Epoch 19/100  Loss=1.3973\n",
      "[Fine-tune] Epoch 20/100  Loss=1.3589\n",
      "[Fine-tune] Epoch 21/100  Loss=1.3413\n",
      "[Fine-tune] Epoch 22/100  Loss=1.3196\n",
      "[Fine-tune] Epoch 23/100  Loss=1.2990\n",
      "[Fine-tune] Epoch 24/100  Loss=1.2989\n",
      "[Fine-tune] Epoch 25/100  Loss=1.2723\n",
      "[Fine-tune] Epoch 26/100  Loss=1.2476\n",
      "[Fine-tune] Epoch 27/100  Loss=1.2428\n",
      "[Fine-tune] Epoch 28/100  Loss=1.2285\n",
      "[Fine-tune] Epoch 29/100  Loss=1.2106\n",
      "[Fine-tune] Epoch 30/100  Loss=1.1852\n",
      "[Fine-tune] Epoch 31/100  Loss=1.1779\n",
      "[Fine-tune] Epoch 32/100  Loss=1.1581\n",
      "[Fine-tune] Epoch 33/100  Loss=1.1459\n",
      "[Fine-tune] Epoch 34/100  Loss=1.1337\n",
      "[Fine-tune] Epoch 35/100  Loss=1.1281\n",
      "[Fine-tune] Epoch 36/100  Loss=1.1160\n",
      "[Fine-tune] Epoch 37/100  Loss=1.1110\n",
      "[Fine-tune] Epoch 38/100  Loss=1.0834\n",
      "[Fine-tune] Epoch 39/100  Loss=1.0864\n",
      "[Fine-tune] Epoch 40/100  Loss=1.0831\n",
      "[Fine-tune] Epoch 41/100  Loss=1.0794\n",
      "[Fine-tune] Epoch 42/100  Loss=1.0658\n",
      "[Fine-tune] Epoch 43/100  Loss=1.0594\n",
      "[Fine-tune] Epoch 44/100  Loss=1.0373\n",
      "[Fine-tune] Epoch 45/100  Loss=1.0520\n",
      "[Fine-tune] Epoch 46/100  Loss=1.0410\n",
      "[Fine-tune] Epoch 47/100  Loss=1.0289\n",
      "[Fine-tune] Epoch 48/100  Loss=1.0282\n",
      "[Fine-tune] Epoch 49/100  Loss=1.0126\n",
      "[Fine-tune] Epoch 50/100  Loss=1.0189\n",
      "[Fine-tune] Epoch 51/100  Loss=1.0117\n",
      "[Fine-tune] Epoch 52/100  Loss=1.0069\n",
      "[Fine-tune] Epoch 53/100  Loss=1.0042\n",
      "[Fine-tune] Epoch 54/100  Loss=1.0025\n",
      "[Fine-tune] Epoch 55/100  Loss=0.9898\n",
      "[Fine-tune] Epoch 56/100  Loss=0.9968\n",
      "[Fine-tune] Epoch 57/100  Loss=0.9754\n",
      "[Fine-tune] Epoch 58/100  Loss=0.9847\n",
      "[Fine-tune] Epoch 59/100  Loss=0.9757\n",
      "[Fine-tune] Epoch 60/100  Loss=0.9815\n",
      "[Fine-tune] Epoch 61/100  Loss=0.9835\n",
      "[Fine-tune] Epoch 62/100  Loss=0.9790\n",
      "[Fine-tune] Epoch 63/100  Loss=0.9595\n",
      "[Fine-tune] Epoch 64/100  Loss=0.9554\n",
      "[Fine-tune] Epoch 65/100  Loss=0.9600\n",
      "[Fine-tune] Epoch 66/100  Loss=0.9618\n",
      "[Fine-tune] Epoch 67/100  Loss=0.9631\n",
      "[Fine-tune] Epoch 68/100  Loss=0.9545\n",
      "[Fine-tune] Epoch 69/100  Loss=0.9533\n",
      "[Fine-tune] Epoch 70/100  Loss=0.9494\n",
      "[Fine-tune] Epoch 71/100  Loss=0.9510\n",
      "[Fine-tune] Epoch 72/100  Loss=0.9609\n",
      "[Fine-tune] Epoch 73/100  Loss=0.9580\n",
      "[Fine-tune] Epoch 74/100  Loss=0.9555\n",
      "[Fine-tune] Epoch 75/100  Loss=0.9476\n",
      "[Fine-tune] Epoch 76/100  Loss=0.9355\n",
      "[Fine-tune] Epoch 77/100  Loss=0.9480\n",
      "[Fine-tune] Epoch 78/100  Loss=0.9352\n",
      "[Fine-tune] Epoch 79/100  Loss=0.9499\n",
      "[Fine-tune] Epoch 80/100  Loss=0.9351\n",
      "[Fine-tune] Epoch 81/100  Loss=0.9278\n",
      "[Fine-tune] Epoch 82/100  Loss=0.9438\n",
      "[Fine-tune] Epoch 83/100  Loss=0.9463\n",
      "[Fine-tune] Epoch 84/100  Loss=0.9414\n",
      "[Fine-tune] Epoch 85/100  Loss=0.9398\n",
      "[Fine-tune] Epoch 86/100  Loss=0.9414\n",
      "[Fine-tune] Epoch 87/100  Loss=0.9398\n",
      "[Fine-tune] Epoch 88/100  Loss=0.9330\n",
      "[Fine-tune] Epoch 89/100  Loss=0.9410\n",
      "[Fine-tune] Epoch 90/100  Loss=0.9419\n",
      "[Fine-tune] Epoch 91/100  Loss=0.9346\n",
      "[Fine-tune] Epoch 92/100  Loss=0.9405\n",
      "[Fine-tune] Epoch 93/100  Loss=0.9413\n",
      "[Fine-tune] Epoch 94/100  Loss=0.9458\n",
      "[Fine-tune] Epoch 95/100  Loss=0.9270\n",
      "[Fine-tune] Epoch 96/100  Loss=0.9348\n",
      "[Fine-tune] Epoch 97/100  Loss=0.9249\n",
      "[Fine-tune] Epoch 98/100  Loss=0.9351\n",
      "[Fine-tune] Epoch 99/100  Loss=0.9335\n",
      "[Fine-tune] Epoch 100/100  Loss=0.9331\n",
      "[Pretrain] Epoch 1/50  Loss=3.7250  Acc=0.0431\n",
      "[Pretrain] Epoch 2/50  Loss=3.0701  Acc=0.0921\n",
      "[Pretrain] Epoch 3/50  Loss=2.7233  Acc=0.1606\n",
      "[Pretrain] Epoch 4/50  Loss=2.5333  Acc=0.1968\n",
      "[Pretrain] Epoch 5/50  Loss=2.4310  Acc=0.2196\n",
      "[Pretrain] Epoch 6/50  Loss=2.3945  Acc=0.2254\n",
      "[Pretrain] Epoch 7/50  Loss=2.3781  Acc=0.2435\n",
      "[Pretrain] Epoch 8/50  Loss=2.3243  Acc=0.2543\n",
      "[Pretrain] Epoch 9/50  Loss=2.2612  Acc=0.2676\n",
      "[Pretrain] Epoch 10/50  Loss=2.2261  Acc=0.2848\n",
      "[Pretrain] Epoch 11/50  Loss=2.1944  Acc=0.2917\n",
      "[Pretrain] Epoch 12/50  Loss=2.1362  Acc=0.3127\n",
      "[Pretrain] Epoch 13/50  Loss=2.1109  Acc=0.3152\n",
      "[Pretrain] Epoch 14/50  Loss=2.0508  Acc=0.3290\n",
      "[Pretrain] Epoch 15/50  Loss=2.0350  Acc=0.3335\n",
      "[Pretrain] Epoch 16/50  Loss=2.0139  Acc=0.3488\n",
      "[Pretrain] Epoch 17/50  Loss=1.9739  Acc=0.3590\n",
      "[Pretrain] Epoch 18/50  Loss=1.9648  Acc=0.3506\n",
      "[Pretrain] Epoch 19/50  Loss=1.9225  Acc=0.3700\n",
      "[Pretrain] Epoch 20/50  Loss=1.9131  Acc=0.3737\n",
      "[Pretrain] Epoch 21/50  Loss=1.8670  Acc=0.3903\n",
      "[Pretrain] Epoch 22/50  Loss=1.8602  Acc=0.3931\n",
      "[Pretrain] Epoch 23/50  Loss=1.8411  Acc=0.4014\n",
      "[Pretrain] Epoch 24/50  Loss=1.7895  Acc=0.4131\n",
      "[Pretrain] Epoch 25/50  Loss=1.7613  Acc=0.4262\n",
      "[Pretrain] Epoch 26/50  Loss=1.7601  Acc=0.4289\n",
      "[Pretrain] Epoch 27/50  Loss=1.7096  Acc=0.4371\n",
      "[Pretrain] Epoch 28/50  Loss=1.6928  Acc=0.4485\n",
      "[Pretrain] Epoch 29/50  Loss=1.6612  Acc=0.4533\n",
      "[Pretrain] Epoch 30/50  Loss=1.6649  Acc=0.4582\n",
      "[Pretrain] Epoch 31/50  Loss=1.6371  Acc=0.4662\n",
      "[Pretrain] Epoch 32/50  Loss=1.6039  Acc=0.4722\n",
      "[Pretrain] Epoch 33/50  Loss=1.6065  Acc=0.4745\n",
      "[Pretrain] Epoch 34/50  Loss=1.5597  Acc=0.4921\n",
      "[Pretrain] Epoch 35/50  Loss=1.5497  Acc=0.4885\n",
      "[Pretrain] Epoch 36/50  Loss=1.5307  Acc=0.5066\n",
      "[Pretrain] Epoch 37/50  Loss=1.4938  Acc=0.5102\n",
      "[Pretrain] Epoch 38/50  Loss=1.4894  Acc=0.5090\n",
      "[Pretrain] Epoch 39/50  Loss=1.4736  Acc=0.5154\n",
      "[Pretrain] Epoch 40/50  Loss=1.4565  Acc=0.5259\n",
      "[Pretrain] Epoch 41/50  Loss=1.4100  Acc=0.5345\n",
      "[Pretrain] Epoch 42/50  Loss=1.4311  Acc=0.5286\n",
      "[Pretrain] Epoch 43/50  Loss=1.4067  Acc=0.5377\n",
      "[Pretrain] Epoch 44/50  Loss=1.3650  Acc=0.5533\n",
      "[Pretrain] Epoch 45/50  Loss=1.3761  Acc=0.5406\n",
      "[Pretrain] Epoch 46/50  Loss=1.3604  Acc=0.5533\n",
      "[Pretrain] Epoch 47/50  Loss=1.3644  Acc=0.5521\n",
      "[Pretrain] Epoch 48/50  Loss=1.3440  Acc=0.5530\n",
      "[Pretrain] Epoch 49/50  Loss=1.3420  Acc=0.5555\n",
      "[Pretrain] Epoch 50/50  Loss=1.3053  Acc=0.5690\n",
      "[Fine-tune] Epoch 1/100  Loss=3.1000\n",
      "[Fine-tune] Epoch 2/100  Loss=2.6283\n",
      "[Fine-tune] Epoch 3/100  Loss=2.4384\n",
      "[Fine-tune] Epoch 4/100  Loss=2.3071\n",
      "[Fine-tune] Epoch 5/100  Loss=2.2194\n",
      "[Fine-tune] Epoch 6/100  Loss=2.1458\n",
      "[Fine-tune] Epoch 7/100  Loss=2.1117\n",
      "[Fine-tune] Epoch 8/100  Loss=2.0641\n",
      "[Fine-tune] Epoch 9/100  Loss=2.0223\n",
      "[Fine-tune] Epoch 10/100  Loss=1.9889\n",
      "[Fine-tune] Epoch 11/100  Loss=1.9712\n",
      "[Fine-tune] Epoch 12/100  Loss=1.9479\n",
      "[Fine-tune] Epoch 13/100  Loss=1.9278\n",
      "[Fine-tune] Epoch 14/100  Loss=1.9248\n",
      "[Fine-tune] Epoch 15/100  Loss=1.8980\n",
      "[Fine-tune] Epoch 16/100  Loss=1.8787\n",
      "[Fine-tune] Epoch 17/100  Loss=1.8622\n",
      "[Fine-tune] Epoch 18/100  Loss=1.8521\n",
      "[Fine-tune] Epoch 19/100  Loss=1.8435\n",
      "[Fine-tune] Epoch 20/100  Loss=1.8201\n",
      "[Fine-tune] Epoch 21/100  Loss=1.8214\n",
      "[Fine-tune] Epoch 22/100  Loss=1.8119\n",
      "[Fine-tune] Epoch 23/100  Loss=1.7968\n",
      "[Fine-tune] Epoch 24/100  Loss=1.7779\n",
      "[Fine-tune] Epoch 25/100  Loss=1.7805\n",
      "[Fine-tune] Epoch 26/100  Loss=1.7656\n",
      "[Fine-tune] Epoch 27/100  Loss=1.7640\n",
      "[Fine-tune] Epoch 28/100  Loss=1.7447\n",
      "[Fine-tune] Epoch 29/100  Loss=1.7458\n",
      "[Fine-tune] Epoch 30/100  Loss=1.7341\n",
      "[Fine-tune] Epoch 31/100  Loss=1.7352\n",
      "[Fine-tune] Epoch 32/100  Loss=1.7213\n",
      "[Fine-tune] Epoch 33/100  Loss=1.7175\n",
      "[Fine-tune] Epoch 34/100  Loss=1.7216\n",
      "[Fine-tune] Epoch 35/100  Loss=1.7086\n",
      "[Fine-tune] Epoch 36/100  Loss=1.7102\n",
      "[Fine-tune] Epoch 37/100  Loss=1.7078\n",
      "[Fine-tune] Epoch 38/100  Loss=1.7007\n",
      "[Fine-tune] Epoch 39/100  Loss=1.6805\n",
      "[Fine-tune] Epoch 40/100  Loss=1.6858\n",
      "[Fine-tune] Epoch 41/100  Loss=1.6760\n",
      "[Fine-tune] Epoch 42/100  Loss=1.6767\n",
      "[Fine-tune] Epoch 43/100  Loss=1.6827\n",
      "[Fine-tune] Epoch 44/100  Loss=1.6633\n",
      "[Fine-tune] Epoch 45/100  Loss=1.6785\n",
      "[Fine-tune] Epoch 46/100  Loss=1.6722\n",
      "[Fine-tune] Epoch 47/100  Loss=1.6760\n",
      "[Fine-tune] Epoch 48/100  Loss=1.6593\n",
      "[Fine-tune] Epoch 49/100  Loss=1.6658\n",
      "[Fine-tune] Epoch 50/100  Loss=1.6518\n",
      "[Fine-tune] Epoch 51/100  Loss=1.6645\n",
      "[Fine-tune] Epoch 52/100  Loss=1.6549\n",
      "[Fine-tune] Epoch 53/100  Loss=1.6565\n",
      "[Fine-tune] Epoch 54/100  Loss=1.6484\n",
      "[Fine-tune] Epoch 55/100  Loss=1.6471\n",
      "[Fine-tune] Epoch 56/100  Loss=1.6411\n",
      "[Fine-tune] Epoch 57/100  Loss=1.6462\n",
      "[Fine-tune] Epoch 58/100  Loss=1.6432\n",
      "[Fine-tune] Epoch 59/100  Loss=1.6421\n",
      "[Fine-tune] Epoch 60/100  Loss=1.6316\n",
      "[Fine-tune] Epoch 61/100  Loss=1.6478\n",
      "[Fine-tune] Epoch 62/100  Loss=1.6326\n",
      "[Fine-tune] Epoch 63/100  Loss=1.6358\n",
      "[Fine-tune] Epoch 64/100  Loss=1.6449\n",
      "[Fine-tune] Epoch 65/100  Loss=1.6320\n",
      "[Fine-tune] Epoch 66/100  Loss=1.6287\n",
      "[Fine-tune] Epoch 67/100  Loss=1.6302\n",
      "[Fine-tune] Epoch 68/100  Loss=1.6396\n",
      "[Fine-tune] Epoch 69/100  Loss=1.6304\n",
      "[Fine-tune] Epoch 70/100  Loss=1.6348\n",
      "[Fine-tune] Epoch 71/100  Loss=1.6359\n",
      "[Fine-tune] Epoch 72/100  Loss=1.6251\n",
      "[Fine-tune] Epoch 73/100  Loss=1.6328\n",
      "[Fine-tune] Epoch 74/100  Loss=1.6140\n",
      "[Fine-tune] Epoch 75/100  Loss=1.6366\n",
      "[Fine-tune] Epoch 76/100  Loss=1.6195\n",
      "[Fine-tune] Epoch 77/100  Loss=1.6292\n",
      "[Fine-tune] Epoch 78/100  Loss=1.6330\n",
      "[Fine-tune] Epoch 79/100  Loss=1.6134\n",
      "[Fine-tune] Epoch 80/100  Loss=1.6254\n",
      "[Fine-tune] Epoch 81/100  Loss=1.6228\n",
      "[Fine-tune] Epoch 82/100  Loss=1.6262\n",
      "[Fine-tune] Epoch 83/100  Loss=1.6199\n",
      "[Fine-tune] Epoch 84/100  Loss=1.6200\n",
      "[Fine-tune] Epoch 85/100  Loss=1.6243\n",
      "[Fine-tune] Epoch 86/100  Loss=1.6337\n",
      "[Fine-tune] Epoch 87/100  Loss=1.6153\n",
      "[Fine-tune] Epoch 88/100  Loss=1.6238\n",
      "[Fine-tune] Epoch 89/100  Loss=1.6288\n",
      "[Fine-tune] Epoch 90/100  Loss=1.6237\n",
      "[Fine-tune] Epoch 91/100  Loss=1.6180\n",
      "[Fine-tune] Epoch 92/100  Loss=1.6315\n",
      "[Fine-tune] Epoch 93/100  Loss=1.6358\n",
      "[Fine-tune] Epoch 94/100  Loss=1.6274\n",
      "[Fine-tune] Epoch 95/100  Loss=1.6119\n",
      "[Fine-tune] Epoch 96/100  Loss=1.6362\n",
      "[Fine-tune] Epoch 97/100  Loss=1.6168\n",
      "[Fine-tune] Epoch 98/100  Loss=1.6201\n",
      "[Fine-tune] Epoch 99/100  Loss=1.6104\n",
      "[Fine-tune] Epoch 100/100  Loss=1.6246\n",
      "[Pretrain] Epoch 1/75  Loss=3.2421  Acc=0.0392\n",
      "[Pretrain] Epoch 2/75  Loss=2.9751  Acc=0.0833\n",
      "[Pretrain] Epoch 3/75  Loss=2.6768  Acc=0.1487\n",
      "[Pretrain] Epoch 4/75  Loss=2.5146  Acc=0.1898\n",
      "[Pretrain] Epoch 5/75  Loss=2.3886  Acc=0.2324\n",
      "[Pretrain] Epoch 6/75  Loss=2.2742  Acc=0.2611\n",
      "[Pretrain] Epoch 7/75  Loss=2.1936  Acc=0.2924\n",
      "[Pretrain] Epoch 8/75  Loss=2.1906  Acc=0.2848\n",
      "[Pretrain] Epoch 9/75  Loss=2.0997  Acc=0.3261\n",
      "[Pretrain] Epoch 10/75  Loss=2.0620  Acc=0.3323\n",
      "[Pretrain] Epoch 11/75  Loss=2.0221  Acc=0.3414\n",
      "[Pretrain] Epoch 12/75  Loss=1.9667  Acc=0.3603\n",
      "[Pretrain] Epoch 13/75  Loss=1.9318  Acc=0.3707\n",
      "[Pretrain] Epoch 14/75  Loss=1.9033  Acc=0.3879\n",
      "[Pretrain] Epoch 15/75  Loss=1.8673  Acc=0.3953\n",
      "[Pretrain] Epoch 16/75  Loss=1.8458  Acc=0.4075\n",
      "[Pretrain] Epoch 17/75  Loss=1.8290  Acc=0.4102\n",
      "[Pretrain] Epoch 18/75  Loss=1.7913  Acc=0.4256\n",
      "[Pretrain] Epoch 19/75  Loss=1.7823  Acc=0.4291\n",
      "[Pretrain] Epoch 20/75  Loss=1.7707  Acc=0.4255\n",
      "[Pretrain] Epoch 21/75  Loss=1.7304  Acc=0.4449\n",
      "[Pretrain] Epoch 22/75  Loss=1.7224  Acc=0.4476\n",
      "[Pretrain] Epoch 23/75  Loss=1.6939  Acc=0.4522\n",
      "[Pretrain] Epoch 24/75  Loss=1.6881  Acc=0.4511\n",
      "[Pretrain] Epoch 25/75  Loss=1.6602  Acc=0.4528\n",
      "[Pretrain] Epoch 26/75  Loss=1.6330  Acc=0.4691\n",
      "[Pretrain] Epoch 27/75  Loss=1.6237  Acc=0.4754\n",
      "[Pretrain] Epoch 28/75  Loss=1.6104  Acc=0.4732\n",
      "[Pretrain] Epoch 29/75  Loss=1.5834  Acc=0.4793\n",
      "[Pretrain] Epoch 30/75  Loss=1.5757  Acc=0.4824\n",
      "[Pretrain] Epoch 31/75  Loss=1.5612  Acc=0.4898\n",
      "[Pretrain] Epoch 32/75  Loss=1.5481  Acc=0.5011\n",
      "[Pretrain] Epoch 33/75  Loss=1.5173  Acc=0.5086\n",
      "[Pretrain] Epoch 34/75  Loss=1.5101  Acc=0.5061\n",
      "[Pretrain] Epoch 35/75  Loss=1.4957  Acc=0.5165\n",
      "[Pretrain] Epoch 36/75  Loss=1.4839  Acc=0.5239\n",
      "[Pretrain] Epoch 37/75  Loss=1.4713  Acc=0.5233\n",
      "[Pretrain] Epoch 38/75  Loss=1.4688  Acc=0.5248\n",
      "[Pretrain] Epoch 39/75  Loss=1.4591  Acc=0.5248\n",
      "[Pretrain] Epoch 40/75  Loss=1.4344  Acc=0.5289\n",
      "[Pretrain] Epoch 41/75  Loss=1.4321  Acc=0.5295\n",
      "[Pretrain] Epoch 42/75  Loss=1.4187  Acc=0.5476\n",
      "[Pretrain] Epoch 43/75  Loss=1.4065  Acc=0.5406\n",
      "[Pretrain] Epoch 44/75  Loss=1.3918  Acc=0.5418\n",
      "[Pretrain] Epoch 45/75  Loss=1.3831  Acc=0.5524\n",
      "[Pretrain] Epoch 46/75  Loss=1.3849  Acc=0.5494\n",
      "[Pretrain] Epoch 47/75  Loss=1.3632  Acc=0.5528\n",
      "[Pretrain] Epoch 48/75  Loss=1.3854  Acc=0.5505\n",
      "[Pretrain] Epoch 49/75  Loss=1.3761  Acc=0.5501\n",
      "[Pretrain] Epoch 50/75  Loss=1.3588  Acc=0.5560\n",
      "[Pretrain] Epoch 51/75  Loss=1.3355  Acc=0.5713\n",
      "[Pretrain] Epoch 52/75  Loss=1.3442  Acc=0.5629\n",
      "[Pretrain] Epoch 53/75  Loss=1.3479  Acc=0.5593\n",
      "[Pretrain] Epoch 54/75  Loss=1.3158  Acc=0.5675\n",
      "[Pretrain] Epoch 55/75  Loss=1.3141  Acc=0.5717\n",
      "[Pretrain] Epoch 56/75  Loss=1.3189  Acc=0.5778\n",
      "[Pretrain] Epoch 57/75  Loss=1.3120  Acc=0.5677\n",
      "[Pretrain] Epoch 58/75  Loss=1.3084  Acc=0.5681\n",
      "[Pretrain] Epoch 59/75  Loss=1.3108  Acc=0.5720\n",
      "[Pretrain] Epoch 60/75  Loss=1.2859  Acc=0.5796\n",
      "[Pretrain] Epoch 61/75  Loss=1.2961  Acc=0.5790\n",
      "[Pretrain] Epoch 62/75  Loss=1.2963  Acc=0.5711\n",
      "[Pretrain] Epoch 63/75  Loss=1.2780  Acc=0.5826\n",
      "[Pretrain] Epoch 64/75  Loss=1.2786  Acc=0.5889\n",
      "[Pretrain] Epoch 65/75  Loss=1.2698  Acc=0.5893\n",
      "[Pretrain] Epoch 66/75  Loss=1.2736  Acc=0.5907\n",
      "[Pretrain] Epoch 67/75  Loss=1.2677  Acc=0.5887\n",
      "[Pretrain] Epoch 68/75  Loss=1.2896  Acc=0.5817\n",
      "[Pretrain] Epoch 69/75  Loss=1.2643  Acc=0.5909\n",
      "[Pretrain] Epoch 70/75  Loss=1.2586  Acc=0.5891\n",
      "[Pretrain] Epoch 71/75  Loss=1.2458  Acc=0.5979\n",
      "[Pretrain] Epoch 72/75  Loss=1.2559  Acc=0.5927\n",
      "[Pretrain] Epoch 73/75  Loss=1.2445  Acc=0.5929\n",
      "[Pretrain] Epoch 74/75  Loss=1.2378  Acc=0.5991\n",
      "[Pretrain] Epoch 75/75  Loss=1.2521  Acc=0.5912\n",
      "[Fine-tune] Epoch 1/100  Loss=2.6259\n",
      "[Fine-tune] Epoch 2/100  Loss=2.2267\n",
      "[Fine-tune] Epoch 3/100  Loss=2.0710\n",
      "[Fine-tune] Epoch 4/100  Loss=1.9654\n",
      "[Fine-tune] Epoch 5/100  Loss=1.9004\n",
      "[Fine-tune] Epoch 6/100  Loss=1.8410\n",
      "[Fine-tune] Epoch 7/100  Loss=1.7606\n",
      "[Fine-tune] Epoch 8/100  Loss=1.7483\n",
      "[Fine-tune] Epoch 9/100  Loss=1.6767\n",
      "[Fine-tune] Epoch 10/100  Loss=1.6527\n",
      "[Fine-tune] Epoch 11/100  Loss=1.6269\n",
      "[Fine-tune] Epoch 12/100  Loss=1.5603\n",
      "[Fine-tune] Epoch 13/100  Loss=1.5224\n",
      "[Fine-tune] Epoch 14/100  Loss=1.4916\n",
      "[Fine-tune] Epoch 15/100  Loss=1.4692\n",
      "[Fine-tune] Epoch 16/100  Loss=1.4446\n",
      "[Fine-tune] Epoch 17/100  Loss=1.3962\n",
      "[Fine-tune] Epoch 18/100  Loss=1.3695\n",
      "[Fine-tune] Epoch 19/100  Loss=1.3454\n",
      "[Fine-tune] Epoch 20/100  Loss=1.3166\n",
      "[Fine-tune] Epoch 21/100  Loss=1.2931\n",
      "[Fine-tune] Epoch 22/100  Loss=1.2711\n",
      "[Fine-tune] Epoch 23/100  Loss=1.2516\n",
      "[Fine-tune] Epoch 24/100  Loss=1.2262\n",
      "[Fine-tune] Epoch 25/100  Loss=1.2056\n",
      "[Fine-tune] Epoch 26/100  Loss=1.1703\n",
      "[Fine-tune] Epoch 27/100  Loss=1.1898\n",
      "[Fine-tune] Epoch 28/100  Loss=1.1560\n",
      "[Fine-tune] Epoch 29/100  Loss=1.1309\n",
      "[Fine-tune] Epoch 30/100  Loss=1.1311\n",
      "[Fine-tune] Epoch 31/100  Loss=1.1111\n",
      "[Fine-tune] Epoch 32/100  Loss=1.1028\n",
      "[Fine-tune] Epoch 33/100  Loss=1.0673\n",
      "[Fine-tune] Epoch 34/100  Loss=1.0592\n",
      "[Fine-tune] Epoch 35/100  Loss=1.0645\n",
      "[Fine-tune] Epoch 36/100  Loss=1.0524\n",
      "[Fine-tune] Epoch 37/100  Loss=1.0353\n",
      "[Fine-tune] Epoch 38/100  Loss=1.0260\n",
      "[Fine-tune] Epoch 39/100  Loss=1.0297\n",
      "[Fine-tune] Epoch 40/100  Loss=1.0015\n",
      "[Fine-tune] Epoch 41/100  Loss=1.0027\n",
      "[Fine-tune] Epoch 42/100  Loss=0.9936\n",
      "[Fine-tune] Epoch 43/100  Loss=1.0085\n",
      "[Fine-tune] Epoch 44/100  Loss=0.9860\n",
      "[Fine-tune] Epoch 45/100  Loss=0.9829\n",
      "[Fine-tune] Epoch 46/100  Loss=0.9850\n",
      "[Fine-tune] Epoch 47/100  Loss=0.9704\n",
      "[Fine-tune] Epoch 48/100  Loss=0.9724\n",
      "[Fine-tune] Epoch 49/100  Loss=0.9542\n",
      "[Fine-tune] Epoch 50/100  Loss=0.9450\n",
      "[Fine-tune] Epoch 51/100  Loss=0.9418\n",
      "[Fine-tune] Epoch 52/100  Loss=0.9344\n",
      "[Fine-tune] Epoch 53/100  Loss=0.9322\n",
      "[Fine-tune] Epoch 54/100  Loss=0.9308\n",
      "[Fine-tune] Epoch 55/100  Loss=0.9242\n",
      "[Fine-tune] Epoch 56/100  Loss=0.9158\n",
      "[Fine-tune] Epoch 57/100  Loss=0.9136\n",
      "[Fine-tune] Epoch 58/100  Loss=0.9204\n",
      "[Fine-tune] Epoch 59/100  Loss=0.9087\n",
      "[Fine-tune] Epoch 60/100  Loss=0.9082\n",
      "[Fine-tune] Epoch 61/100  Loss=0.9067\n",
      "[Fine-tune] Epoch 62/100  Loss=0.9002\n",
      "[Fine-tune] Epoch 63/100  Loss=0.8992\n",
      "[Fine-tune] Epoch 64/100  Loss=0.8924\n",
      "[Fine-tune] Epoch 65/100  Loss=0.8966\n",
      "[Fine-tune] Epoch 66/100  Loss=0.8844\n",
      "[Fine-tune] Epoch 67/100  Loss=0.8835\n",
      "[Fine-tune] Epoch 68/100  Loss=0.8933\n",
      "[Fine-tune] Epoch 69/100  Loss=0.9045\n",
      "[Fine-tune] Epoch 70/100  Loss=0.8926\n",
      "[Fine-tune] Epoch 71/100  Loss=0.8758\n",
      "[Fine-tune] Epoch 72/100  Loss=0.8848\n",
      "[Fine-tune] Epoch 73/100  Loss=0.8723\n",
      "[Fine-tune] Epoch 74/100  Loss=0.8692\n",
      "[Fine-tune] Epoch 75/100  Loss=0.8723\n",
      "[Fine-tune] Epoch 76/100  Loss=0.8740\n",
      "[Fine-tune] Epoch 77/100  Loss=0.8701\n",
      "[Fine-tune] Epoch 78/100  Loss=0.8774\n",
      "[Fine-tune] Epoch 79/100  Loss=0.8776\n",
      "[Fine-tune] Epoch 80/100  Loss=0.8794\n",
      "[Fine-tune] Epoch 81/100  Loss=0.8708\n",
      "[Fine-tune] Epoch 82/100  Loss=0.8653\n",
      "[Fine-tune] Epoch 83/100  Loss=0.8674\n",
      "[Fine-tune] Epoch 84/100  Loss=0.8653\n",
      "[Fine-tune] Epoch 85/100  Loss=0.8746\n",
      "[Fine-tune] Epoch 86/100  Loss=0.8669\n",
      "[Fine-tune] Epoch 87/100  Loss=0.8807\n",
      "[Fine-tune] Epoch 88/100  Loss=0.8479\n",
      "[Fine-tune] Epoch 89/100  Loss=0.8739\n",
      "[Fine-tune] Epoch 90/100  Loss=0.8709\n",
      "[Fine-tune] Epoch 91/100  Loss=0.8664\n",
      "[Fine-tune] Epoch 92/100  Loss=0.8547\n",
      "[Fine-tune] Epoch 93/100  Loss=0.8517\n",
      "[Fine-tune] Epoch 94/100  Loss=0.8652\n",
      "[Fine-tune] Epoch 95/100  Loss=0.8693\n",
      "[Fine-tune] Epoch 96/100  Loss=0.8651\n",
      "[Fine-tune] Epoch 97/100  Loss=0.8663\n",
      "[Fine-tune] Epoch 98/100  Loss=0.8526\n",
      "[Fine-tune] Epoch 99/100  Loss=0.8635\n",
      "[Fine-tune] Epoch 100/100  Loss=0.8580\n",
      "[Pretrain] Epoch 1/75  Loss=3.6753  Acc=0.0390\n",
      "[Pretrain] Epoch 2/75  Loss=3.1985  Acc=0.0401\n",
      "[Pretrain] Epoch 3/75  Loss=2.9310  Acc=0.0900\n",
      "[Pretrain] Epoch 4/75  Loss=2.6886  Acc=0.1473\n",
      "[Pretrain] Epoch 5/75  Loss=2.5610  Acc=0.1801\n",
      "[Pretrain] Epoch 6/75  Loss=2.4870  Acc=0.2013\n",
      "[Pretrain] Epoch 7/75  Loss=2.4030  Acc=0.2320\n",
      "[Pretrain] Epoch 8/75  Loss=2.3467  Acc=0.2522\n",
      "[Pretrain] Epoch 9/75  Loss=2.2546  Acc=0.2759\n",
      "[Pretrain] Epoch 10/75  Loss=2.2155  Acc=0.2836\n",
      "[Pretrain] Epoch 11/75  Loss=2.1440  Acc=0.3111\n",
      "[Pretrain] Epoch 12/75  Loss=2.1029  Acc=0.3235\n",
      "[Pretrain] Epoch 13/75  Loss=2.0779  Acc=0.3258\n",
      "[Pretrain] Epoch 14/75  Loss=2.0338  Acc=0.3351\n",
      "[Pretrain] Epoch 15/75  Loss=2.0260  Acc=0.3427\n",
      "[Pretrain] Epoch 16/75  Loss=1.9826  Acc=0.3540\n",
      "[Pretrain] Epoch 17/75  Loss=1.9655  Acc=0.3558\n",
      "[Pretrain] Epoch 18/75  Loss=1.9281  Acc=0.3797\n",
      "[Pretrain] Epoch 19/75  Loss=1.9101  Acc=0.3793\n",
      "[Pretrain] Epoch 20/75  Loss=1.8791  Acc=0.3833\n",
      "[Pretrain] Epoch 21/75  Loss=1.8399  Acc=0.4009\n",
      "[Pretrain] Epoch 22/75  Loss=1.8545  Acc=0.4012\n",
      "[Pretrain] Epoch 23/75  Loss=1.8128  Acc=0.4143\n",
      "[Pretrain] Epoch 24/75  Loss=1.7836  Acc=0.4247\n",
      "[Pretrain] Epoch 25/75  Loss=1.7728  Acc=0.4213\n",
      "[Pretrain] Epoch 26/75  Loss=1.7469  Acc=0.4287\n",
      "[Pretrain] Epoch 27/75  Loss=1.7295  Acc=0.4314\n",
      "[Pretrain] Epoch 28/75  Loss=1.7067  Acc=0.4436\n",
      "[Pretrain] Epoch 29/75  Loss=1.6835  Acc=0.4520\n",
      "[Pretrain] Epoch 30/75  Loss=1.6743  Acc=0.4574\n",
      "[Pretrain] Epoch 31/75  Loss=1.6184  Acc=0.4682\n",
      "[Pretrain] Epoch 32/75  Loss=1.6101  Acc=0.4718\n",
      "[Pretrain] Epoch 33/75  Loss=1.6004  Acc=0.4756\n",
      "[Pretrain] Epoch 34/75  Loss=1.5767  Acc=0.4847\n",
      "[Pretrain] Epoch 35/75  Loss=1.5682  Acc=0.4912\n",
      "[Pretrain] Epoch 36/75  Loss=1.5421  Acc=0.4995\n",
      "[Pretrain] Epoch 37/75  Loss=1.5206  Acc=0.4941\n",
      "[Pretrain] Epoch 38/75  Loss=1.5094  Acc=0.5090\n",
      "[Pretrain] Epoch 39/75  Loss=1.4810  Acc=0.5196\n",
      "[Pretrain] Epoch 40/75  Loss=1.4656  Acc=0.5198\n",
      "[Pretrain] Epoch 41/75  Loss=1.4483  Acc=0.5244\n",
      "[Pretrain] Epoch 42/75  Loss=1.4184  Acc=0.5366\n",
      "[Pretrain] Epoch 43/75  Loss=1.4278  Acc=0.5284\n",
      "[Pretrain] Epoch 44/75  Loss=1.4108  Acc=0.5417\n",
      "[Pretrain] Epoch 45/75  Loss=1.3797  Acc=0.5494\n",
      "[Pretrain] Epoch 46/75  Loss=1.3796  Acc=0.5420\n",
      "[Pretrain] Epoch 47/75  Loss=1.3716  Acc=0.5487\n",
      "[Pretrain] Epoch 48/75  Loss=1.3399  Acc=0.5679\n",
      "[Pretrain] Epoch 49/75  Loss=1.3399  Acc=0.5627\n",
      "[Pretrain] Epoch 50/75  Loss=1.3219  Acc=0.5657\n",
      "[Pretrain] Epoch 51/75  Loss=1.3152  Acc=0.5672\n",
      "[Pretrain] Epoch 52/75  Loss=1.3060  Acc=0.5708\n",
      "[Pretrain] Epoch 53/75  Loss=1.2795  Acc=0.5760\n",
      "[Pretrain] Epoch 54/75  Loss=1.2716  Acc=0.5812\n",
      "[Pretrain] Epoch 55/75  Loss=1.2812  Acc=0.5832\n",
      "[Pretrain] Epoch 56/75  Loss=1.2512  Acc=0.5814\n",
      "[Pretrain] Epoch 57/75  Loss=1.2725  Acc=0.5839\n",
      "[Pretrain] Epoch 58/75  Loss=1.2340  Acc=0.5954\n",
      "[Pretrain] Epoch 59/75  Loss=1.2487  Acc=0.5941\n",
      "[Pretrain] Epoch 60/75  Loss=1.2329  Acc=0.5934\n",
      "[Pretrain] Epoch 61/75  Loss=1.2464  Acc=0.5894\n",
      "[Pretrain] Epoch 62/75  Loss=1.2181  Acc=0.6024\n",
      "[Pretrain] Epoch 63/75  Loss=1.2108  Acc=0.5991\n",
      "[Pretrain] Epoch 64/75  Loss=1.2095  Acc=0.6045\n",
      "[Pretrain] Epoch 65/75  Loss=1.2056  Acc=0.6024\n",
      "[Pretrain] Epoch 66/75  Loss=1.2020  Acc=0.6015\n",
      "[Pretrain] Epoch 67/75  Loss=1.1948  Acc=0.6094\n",
      "[Pretrain] Epoch 68/75  Loss=1.1790  Acc=0.6079\n",
      "[Pretrain] Epoch 69/75  Loss=1.1882  Acc=0.6040\n",
      "[Pretrain] Epoch 70/75  Loss=1.1700  Acc=0.6130\n",
      "[Pretrain] Epoch 71/75  Loss=1.1694  Acc=0.6121\n",
      "[Pretrain] Epoch 72/75  Loss=1.1717  Acc=0.6173\n",
      "[Pretrain] Epoch 73/75  Loss=1.1698  Acc=0.6158\n",
      "[Pretrain] Epoch 74/75  Loss=1.1656  Acc=0.6230\n",
      "[Pretrain] Epoch 75/75  Loss=1.1585  Acc=0.6131\n",
      "[Fine-tune] Epoch 1/100  Loss=3.1896\n",
      "[Fine-tune] Epoch 2/100  Loss=2.7536\n",
      "[Fine-tune] Epoch 3/100  Loss=2.4511\n",
      "[Fine-tune] Epoch 4/100  Loss=2.2977\n",
      "[Fine-tune] Epoch 5/100  Loss=2.2234\n",
      "[Fine-tune] Epoch 6/100  Loss=2.1539\n",
      "[Fine-tune] Epoch 7/100  Loss=2.0976\n",
      "[Fine-tune] Epoch 8/100  Loss=2.0615\n",
      "[Fine-tune] Epoch 9/100  Loss=2.0447\n",
      "[Fine-tune] Epoch 10/100  Loss=1.9936\n",
      "[Fine-tune] Epoch 11/100  Loss=1.9857\n",
      "[Fine-tune] Epoch 12/100  Loss=1.9493\n",
      "[Fine-tune] Epoch 13/100  Loss=1.9447\n",
      "[Fine-tune] Epoch 14/100  Loss=1.9234\n",
      "[Fine-tune] Epoch 15/100  Loss=1.9195\n",
      "[Fine-tune] Epoch 16/100  Loss=1.8938\n",
      "[Fine-tune] Epoch 17/100  Loss=1.8934\n",
      "[Fine-tune] Epoch 18/100  Loss=1.8808\n",
      "[Fine-tune] Epoch 19/100  Loss=1.8723\n",
      "[Fine-tune] Epoch 20/100  Loss=1.8701\n",
      "[Fine-tune] Epoch 21/100  Loss=1.8485\n",
      "[Fine-tune] Epoch 22/100  Loss=1.8271\n",
      "[Fine-tune] Epoch 23/100  Loss=1.8308\n",
      "[Fine-tune] Epoch 24/100  Loss=1.8231\n",
      "[Fine-tune] Epoch 25/100  Loss=1.8065\n",
      "[Fine-tune] Epoch 26/100  Loss=1.8132\n",
      "[Fine-tune] Epoch 27/100  Loss=1.7837\n",
      "[Fine-tune] Epoch 28/100  Loss=1.7951\n",
      "[Fine-tune] Epoch 29/100  Loss=1.7779\n",
      "[Fine-tune] Epoch 30/100  Loss=1.7866\n",
      "[Fine-tune] Epoch 31/100  Loss=1.7673\n",
      "[Fine-tune] Epoch 32/100  Loss=1.7754\n",
      "[Fine-tune] Epoch 33/100  Loss=1.7597\n",
      "[Fine-tune] Epoch 34/100  Loss=1.7413\n",
      "[Fine-tune] Epoch 35/100  Loss=1.7325\n",
      "[Fine-tune] Epoch 36/100  Loss=1.7416\n",
      "[Fine-tune] Epoch 37/100  Loss=1.7617\n",
      "[Fine-tune] Epoch 38/100  Loss=1.7403\n",
      "[Fine-tune] Epoch 39/100  Loss=1.7421\n",
      "[Fine-tune] Epoch 40/100  Loss=1.7363\n",
      "[Fine-tune] Epoch 41/100  Loss=1.7348\n",
      "[Fine-tune] Epoch 42/100  Loss=1.7275\n",
      "[Fine-tune] Epoch 43/100  Loss=1.7109\n",
      "[Fine-tune] Epoch 44/100  Loss=1.7166\n",
      "[Fine-tune] Epoch 45/100  Loss=1.7058\n",
      "[Fine-tune] Epoch 46/100  Loss=1.7265\n",
      "[Fine-tune] Epoch 47/100  Loss=1.7051\n",
      "[Fine-tune] Epoch 48/100  Loss=1.7040\n",
      "[Fine-tune] Epoch 49/100  Loss=1.7024\n",
      "[Fine-tune] Epoch 50/100  Loss=1.7002\n",
      "[Fine-tune] Epoch 51/100  Loss=1.7119\n",
      "[Fine-tune] Epoch 52/100  Loss=1.6986\n",
      "[Fine-tune] Epoch 53/100  Loss=1.7008\n",
      "[Fine-tune] Epoch 54/100  Loss=1.7013\n",
      "[Fine-tune] Epoch 55/100  Loss=1.6838\n",
      "[Fine-tune] Epoch 56/100  Loss=1.6998\n",
      "[Fine-tune] Epoch 57/100  Loss=1.6981\n",
      "[Fine-tune] Epoch 58/100  Loss=1.7039\n",
      "[Fine-tune] Epoch 59/100  Loss=1.6895\n",
      "[Fine-tune] Epoch 60/100  Loss=1.6975\n",
      "[Fine-tune] Epoch 61/100  Loss=1.6843\n",
      "[Fine-tune] Epoch 62/100  Loss=1.6826\n",
      "[Fine-tune] Epoch 63/100  Loss=1.7048\n",
      "[Fine-tune] Epoch 64/100  Loss=1.6886\n",
      "[Fine-tune] Epoch 65/100  Loss=1.6789\n",
      "[Fine-tune] Epoch 66/100  Loss=1.6814\n",
      "[Fine-tune] Epoch 67/100  Loss=1.6905\n",
      "[Fine-tune] Epoch 68/100  Loss=1.6972\n",
      "[Fine-tune] Epoch 69/100  Loss=1.6822\n",
      "[Fine-tune] Epoch 70/100  Loss=1.6937\n",
      "[Fine-tune] Epoch 71/100  Loss=1.6804\n",
      "[Fine-tune] Epoch 72/100  Loss=1.6809\n",
      "[Fine-tune] Epoch 73/100  Loss=1.6780\n",
      "[Fine-tune] Epoch 74/100  Loss=1.6877\n",
      "[Fine-tune] Epoch 75/100  Loss=1.6790\n",
      "[Fine-tune] Epoch 76/100  Loss=1.6822\n",
      "[Fine-tune] Epoch 77/100  Loss=1.6674\n",
      "[Fine-tune] Epoch 78/100  Loss=1.6716\n",
      "[Fine-tune] Epoch 79/100  Loss=1.6689\n",
      "[Fine-tune] Epoch 80/100  Loss=1.6727\n",
      "[Fine-tune] Epoch 81/100  Loss=1.6779\n",
      "[Fine-tune] Epoch 82/100  Loss=1.6860\n",
      "[Fine-tune] Epoch 83/100  Loss=1.6762\n",
      "[Fine-tune] Epoch 84/100  Loss=1.6879\n",
      "[Fine-tune] Epoch 85/100  Loss=1.6844\n",
      "[Fine-tune] Epoch 86/100  Loss=1.6590\n",
      "[Fine-tune] Epoch 87/100  Loss=1.6694\n",
      "[Fine-tune] Epoch 88/100  Loss=1.6644\n",
      "[Fine-tune] Epoch 89/100  Loss=1.6856\n",
      "[Fine-tune] Epoch 90/100  Loss=1.6633\n",
      "[Fine-tune] Epoch 91/100  Loss=1.6822\n",
      "[Fine-tune] Epoch 92/100  Loss=1.6770\n",
      "[Fine-tune] Epoch 93/100  Loss=1.6891\n",
      "[Fine-tune] Epoch 94/100  Loss=1.6723\n",
      "[Fine-tune] Epoch 95/100  Loss=1.6684\n",
      "[Fine-tune] Epoch 96/100  Loss=1.6621\n",
      "[Fine-tune] Epoch 97/100  Loss=1.6700\n",
      "[Fine-tune] Epoch 98/100  Loss=1.6755\n",
      "[Fine-tune] Epoch 99/100  Loss=1.6604\n",
      "[Fine-tune] Epoch 100/100  Loss=1.6762\n",
      "[Pretrain] Epoch 1/100  Loss=3.2543  Acc=0.0411\n",
      "[Pretrain] Epoch 2/100  Loss=2.9611  Acc=0.0997\n",
      "[Pretrain] Epoch 3/100  Loss=2.6160  Acc=0.1654\n",
      "[Pretrain] Epoch 4/100  Loss=2.5327  Acc=0.1949\n",
      "[Pretrain] Epoch 5/100  Loss=2.3649  Acc=0.2394\n",
      "[Pretrain] Epoch 6/100  Loss=2.2911  Acc=0.2604\n",
      "[Pretrain] Epoch 7/100  Loss=2.2454  Acc=0.2685\n",
      "[Pretrain] Epoch 8/100  Loss=2.1509  Acc=0.2989\n",
      "[Pretrain] Epoch 9/100  Loss=2.1057  Acc=0.3236\n",
      "[Pretrain] Epoch 10/100  Loss=2.0768  Acc=0.3301\n",
      "[Pretrain] Epoch 11/100  Loss=2.0435  Acc=0.3412\n",
      "[Pretrain] Epoch 12/100  Loss=2.0022  Acc=0.3538\n",
      "[Pretrain] Epoch 13/100  Loss=1.9619  Acc=0.3599\n",
      "[Pretrain] Epoch 14/100  Loss=1.9170  Acc=0.3761\n",
      "[Pretrain] Epoch 15/100  Loss=1.8868  Acc=0.3886\n",
      "[Pretrain] Epoch 16/100  Loss=1.8865  Acc=0.3922\n",
      "[Pretrain] Epoch 17/100  Loss=1.8521  Acc=0.4003\n",
      "[Pretrain] Epoch 18/100  Loss=1.8241  Acc=0.4041\n",
      "[Pretrain] Epoch 19/100  Loss=1.8155  Acc=0.4147\n",
      "[Pretrain] Epoch 20/100  Loss=1.7527  Acc=0.4319\n",
      "[Pretrain] Epoch 21/100  Loss=1.7486  Acc=0.4282\n",
      "[Pretrain] Epoch 22/100  Loss=1.7224  Acc=0.4393\n",
      "[Pretrain] Epoch 23/100  Loss=1.6895  Acc=0.4510\n",
      "[Pretrain] Epoch 24/100  Loss=1.6885  Acc=0.4450\n",
      "[Pretrain] Epoch 25/100  Loss=1.6722  Acc=0.4511\n",
      "[Pretrain] Epoch 26/100  Loss=1.6473  Acc=0.4659\n",
      "[Pretrain] Epoch 27/100  Loss=1.6279  Acc=0.4758\n",
      "[Pretrain] Epoch 28/100  Loss=1.6217  Acc=0.4630\n",
      "[Pretrain] Epoch 29/100  Loss=1.6049  Acc=0.4765\n",
      "[Pretrain] Epoch 30/100  Loss=1.5677  Acc=0.4872\n",
      "[Pretrain] Epoch 31/100  Loss=1.5683  Acc=0.4844\n",
      "[Pretrain] Epoch 32/100  Loss=1.5390  Acc=0.4998\n",
      "[Pretrain] Epoch 33/100  Loss=1.5355  Acc=0.5048\n",
      "[Pretrain] Epoch 34/100  Loss=1.5194  Acc=0.4984\n",
      "[Pretrain] Epoch 35/100  Loss=1.4877  Acc=0.5097\n",
      "[Pretrain] Epoch 36/100  Loss=1.5052  Acc=0.5052\n",
      "[Pretrain] Epoch 37/100  Loss=1.4919  Acc=0.5097\n",
      "[Pretrain] Epoch 38/100  Loss=1.4708  Acc=0.5203\n",
      "[Pretrain] Epoch 39/100  Loss=1.4761  Acc=0.5136\n",
      "[Pretrain] Epoch 40/100  Loss=1.4566  Acc=0.5273\n",
      "[Pretrain] Epoch 41/100  Loss=1.4516  Acc=0.5251\n",
      "[Pretrain] Epoch 42/100  Loss=1.4344  Acc=0.5341\n",
      "[Pretrain] Epoch 43/100  Loss=1.4280  Acc=0.5363\n",
      "[Pretrain] Epoch 44/100  Loss=1.4191  Acc=0.5366\n",
      "[Pretrain] Epoch 45/100  Loss=1.4134  Acc=0.5379\n",
      "[Pretrain] Epoch 46/100  Loss=1.4053  Acc=0.5399\n",
      "[Pretrain] Epoch 47/100  Loss=1.3969  Acc=0.5429\n",
      "[Pretrain] Epoch 48/100  Loss=1.3997  Acc=0.5465\n",
      "[Pretrain] Epoch 49/100  Loss=1.3880  Acc=0.5411\n",
      "[Pretrain] Epoch 50/100  Loss=1.3740  Acc=0.5530\n",
      "[Pretrain] Epoch 51/100  Loss=1.3712  Acc=0.5533\n",
      "[Pretrain] Epoch 52/100  Loss=1.3669  Acc=0.5566\n",
      "[Pretrain] Epoch 53/100  Loss=1.3612  Acc=0.5532\n",
      "[Pretrain] Epoch 54/100  Loss=1.3492  Acc=0.5598\n",
      "[Pretrain] Epoch 55/100  Loss=1.3538  Acc=0.5569\n",
      "[Pretrain] Epoch 56/100  Loss=1.3342  Acc=0.5596\n",
      "[Pretrain] Epoch 57/100  Loss=1.3430  Acc=0.5589\n",
      "[Pretrain] Epoch 58/100  Loss=1.3446  Acc=0.5603\n",
      "[Pretrain] Epoch 59/100  Loss=1.3280  Acc=0.5654\n",
      "[Pretrain] Epoch 60/100  Loss=1.3240  Acc=0.5670\n",
      "[Pretrain] Epoch 61/100  Loss=1.3229  Acc=0.5699\n",
      "[Pretrain] Epoch 62/100  Loss=1.3360  Acc=0.5661\n",
      "[Pretrain] Epoch 63/100  Loss=1.3123  Acc=0.5695\n",
      "[Pretrain] Epoch 64/100  Loss=1.3171  Acc=0.5742\n",
      "[Pretrain] Epoch 65/100  Loss=1.3057  Acc=0.5638\n",
      "[Pretrain] Epoch 66/100  Loss=1.3046  Acc=0.5747\n",
      "[Pretrain] Epoch 67/100  Loss=1.2975  Acc=0.5672\n",
      "[Pretrain] Epoch 68/100  Loss=1.2972  Acc=0.5754\n",
      "[Pretrain] Epoch 69/100  Loss=1.2927  Acc=0.5815\n",
      "[Pretrain] Epoch 70/100  Loss=1.3001  Acc=0.5749\n",
      "[Pretrain] Epoch 71/100  Loss=1.2949  Acc=0.5779\n",
      "[Pretrain] Epoch 72/100  Loss=1.2707  Acc=0.5893\n",
      "[Pretrain] Epoch 73/100  Loss=1.2922  Acc=0.5796\n",
      "[Pretrain] Epoch 74/100  Loss=1.2904  Acc=0.5760\n",
      "[Pretrain] Epoch 75/100  Loss=1.2725  Acc=0.5878\n",
      "[Pretrain] Epoch 76/100  Loss=1.2847  Acc=0.5781\n",
      "[Pretrain] Epoch 77/100  Loss=1.2754  Acc=0.5830\n",
      "[Pretrain] Epoch 78/100  Loss=1.2683  Acc=0.5909\n",
      "[Pretrain] Epoch 79/100  Loss=1.2762  Acc=0.5801\n",
      "[Pretrain] Epoch 80/100  Loss=1.2685  Acc=0.5869\n",
      "[Pretrain] Epoch 81/100  Loss=1.2842  Acc=0.5821\n",
      "[Pretrain] Epoch 82/100  Loss=1.2645  Acc=0.5891\n",
      "[Pretrain] Epoch 83/100  Loss=1.2748  Acc=0.5787\n",
      "[Pretrain] Epoch 84/100  Loss=1.2716  Acc=0.5866\n",
      "[Pretrain] Epoch 85/100  Loss=1.2740  Acc=0.5833\n",
      "[Pretrain] Epoch 86/100  Loss=1.2689  Acc=0.5875\n",
      "[Pretrain] Epoch 87/100  Loss=1.2674  Acc=0.5893\n",
      "[Pretrain] Epoch 88/100  Loss=1.2579  Acc=0.5909\n",
      "[Pretrain] Epoch 89/100  Loss=1.2696  Acc=0.5878\n",
      "[Pretrain] Epoch 90/100  Loss=1.2734  Acc=0.5869\n",
      "[Pretrain] Epoch 91/100  Loss=1.2628  Acc=0.5950\n",
      "[Pretrain] Epoch 92/100  Loss=1.2619  Acc=0.5925\n",
      "[Pretrain] Epoch 93/100  Loss=1.2598  Acc=0.5853\n",
      "[Pretrain] Epoch 94/100  Loss=1.2686  Acc=0.5891\n",
      "[Pretrain] Epoch 95/100  Loss=1.2588  Acc=0.5805\n",
      "[Pretrain] Epoch 96/100  Loss=1.2563  Acc=0.5921\n",
      "[Pretrain] Epoch 97/100  Loss=1.2587  Acc=0.5891\n",
      "[Pretrain] Epoch 98/100  Loss=1.2535  Acc=0.5955\n",
      "[Pretrain] Epoch 99/100  Loss=1.2563  Acc=0.5871\n",
      "[Pretrain] Epoch 100/100  Loss=1.2548  Acc=0.5878\n",
      "[Fine-tune] Epoch 1/100  Loss=2.7417\n",
      "[Fine-tune] Epoch 2/100  Loss=2.2794\n",
      "[Fine-tune] Epoch 3/100  Loss=2.1205\n",
      "[Fine-tune] Epoch 4/100  Loss=1.9965\n",
      "[Fine-tune] Epoch 5/100  Loss=1.8859\n",
      "[Fine-tune] Epoch 6/100  Loss=1.8379\n",
      "[Fine-tune] Epoch 7/100  Loss=1.7768\n",
      "[Fine-tune] Epoch 8/100  Loss=1.7456\n",
      "[Fine-tune] Epoch 9/100  Loss=1.6807\n",
      "[Fine-tune] Epoch 10/100  Loss=1.6444\n",
      "[Fine-tune] Epoch 11/100  Loss=1.6068\n",
      "[Fine-tune] Epoch 12/100  Loss=1.5766\n",
      "[Fine-tune] Epoch 13/100  Loss=1.5414\n",
      "[Fine-tune] Epoch 14/100  Loss=1.5219\n",
      "[Fine-tune] Epoch 15/100  Loss=1.4697\n",
      "[Fine-tune] Epoch 16/100  Loss=1.4463\n",
      "[Fine-tune] Epoch 17/100  Loss=1.4315\n",
      "[Fine-tune] Epoch 18/100  Loss=1.3901\n",
      "[Fine-tune] Epoch 19/100  Loss=1.3598\n",
      "[Fine-tune] Epoch 20/100  Loss=1.3251\n",
      "[Fine-tune] Epoch 21/100  Loss=1.3105\n",
      "[Fine-tune] Epoch 22/100  Loss=1.2883\n",
      "[Fine-tune] Epoch 23/100  Loss=1.2734\n",
      "[Fine-tune] Epoch 24/100  Loss=1.2458\n",
      "[Fine-tune] Epoch 25/100  Loss=1.2391\n",
      "[Fine-tune] Epoch 26/100  Loss=1.2037\n",
      "[Fine-tune] Epoch 27/100  Loss=1.2064\n",
      "[Fine-tune] Epoch 28/100  Loss=1.1743\n",
      "[Fine-tune] Epoch 29/100  Loss=1.1394\n",
      "[Fine-tune] Epoch 30/100  Loss=1.1705\n",
      "[Fine-tune] Epoch 31/100  Loss=1.1212\n",
      "[Fine-tune] Epoch 32/100  Loss=1.1195\n",
      "[Fine-tune] Epoch 33/100  Loss=1.1056\n",
      "[Fine-tune] Epoch 34/100  Loss=1.1171\n",
      "[Fine-tune] Epoch 35/100  Loss=1.0969\n",
      "[Fine-tune] Epoch 36/100  Loss=1.0624\n",
      "[Fine-tune] Epoch 37/100  Loss=1.0676\n",
      "[Fine-tune] Epoch 38/100  Loss=1.0642\n",
      "[Fine-tune] Epoch 39/100  Loss=1.0554\n",
      "[Fine-tune] Epoch 40/100  Loss=1.0366\n",
      "[Fine-tune] Epoch 41/100  Loss=1.0385\n",
      "[Fine-tune] Epoch 42/100  Loss=1.0200\n",
      "[Fine-tune] Epoch 43/100  Loss=1.0102\n",
      "[Fine-tune] Epoch 44/100  Loss=1.0031\n",
      "[Fine-tune] Epoch 45/100  Loss=0.9952\n",
      "[Fine-tune] Epoch 46/100  Loss=0.9921\n",
      "[Fine-tune] Epoch 47/100  Loss=0.9869\n",
      "[Fine-tune] Epoch 48/100  Loss=0.9874\n",
      "[Fine-tune] Epoch 49/100  Loss=0.9796\n",
      "[Fine-tune] Epoch 50/100  Loss=0.9724\n",
      "[Fine-tune] Epoch 51/100  Loss=0.9735\n",
      "[Fine-tune] Epoch 52/100  Loss=0.9541\n",
      "[Fine-tune] Epoch 53/100  Loss=0.9650\n",
      "[Fine-tune] Epoch 54/100  Loss=0.9559\n",
      "[Fine-tune] Epoch 55/100  Loss=0.9547\n",
      "[Fine-tune] Epoch 56/100  Loss=0.9500\n",
      "[Fine-tune] Epoch 57/100  Loss=0.9600\n",
      "[Fine-tune] Epoch 58/100  Loss=0.9510\n",
      "[Fine-tune] Epoch 59/100  Loss=0.9521\n",
      "[Fine-tune] Epoch 60/100  Loss=0.9488\n",
      "[Fine-tune] Epoch 61/100  Loss=0.9295\n",
      "[Fine-tune] Epoch 62/100  Loss=0.9344\n",
      "[Fine-tune] Epoch 63/100  Loss=0.9244\n",
      "[Fine-tune] Epoch 64/100  Loss=0.9189\n",
      "[Fine-tune] Epoch 65/100  Loss=0.9452\n",
      "[Fine-tune] Epoch 66/100  Loss=0.9208\n",
      "[Fine-tune] Epoch 67/100  Loss=0.9251\n",
      "[Fine-tune] Epoch 68/100  Loss=0.9264\n",
      "[Fine-tune] Epoch 69/100  Loss=0.9206\n",
      "[Fine-tune] Epoch 70/100  Loss=0.9120\n",
      "[Fine-tune] Epoch 71/100  Loss=0.9312\n",
      "[Fine-tune] Epoch 72/100  Loss=0.9231\n",
      "[Fine-tune] Epoch 73/100  Loss=0.9065\n",
      "[Fine-tune] Epoch 74/100  Loss=0.9066\n",
      "[Fine-tune] Epoch 75/100  Loss=0.8992\n",
      "[Fine-tune] Epoch 76/100  Loss=0.9190\n",
      "[Fine-tune] Epoch 77/100  Loss=0.9087\n",
      "[Fine-tune] Epoch 78/100  Loss=0.9005\n",
      "[Fine-tune] Epoch 79/100  Loss=0.9071\n",
      "[Fine-tune] Epoch 80/100  Loss=0.8960\n",
      "[Fine-tune] Epoch 81/100  Loss=0.9008\n",
      "[Fine-tune] Epoch 82/100  Loss=0.9038\n",
      "[Fine-tune] Epoch 83/100  Loss=0.9047\n",
      "[Fine-tune] Epoch 84/100  Loss=0.9062\n",
      "[Fine-tune] Epoch 85/100  Loss=0.9082\n",
      "[Fine-tune] Epoch 86/100  Loss=0.9103\n",
      "[Fine-tune] Epoch 87/100  Loss=0.8876\n",
      "[Fine-tune] Epoch 88/100  Loss=0.9040\n",
      "[Fine-tune] Epoch 89/100  Loss=0.8945\n",
      "[Fine-tune] Epoch 90/100  Loss=0.8938\n",
      "[Fine-tune] Epoch 91/100  Loss=0.8985\n",
      "[Fine-tune] Epoch 92/100  Loss=0.9010\n",
      "[Fine-tune] Epoch 93/100  Loss=0.8980\n",
      "[Fine-tune] Epoch 94/100  Loss=0.8961\n",
      "[Fine-tune] Epoch 95/100  Loss=0.8891\n",
      "[Fine-tune] Epoch 96/100  Loss=0.8909\n",
      "[Fine-tune] Epoch 97/100  Loss=0.9009\n",
      "[Fine-tune] Epoch 98/100  Loss=0.9072\n",
      "[Fine-tune] Epoch 99/100  Loss=0.8929\n",
      "[Fine-tune] Epoch 100/100  Loss=0.8906\n",
      "[Pretrain] Epoch 1/100  Loss=3.6240  Acc=0.0451\n",
      "[Pretrain] Epoch 2/100  Loss=3.1828  Acc=0.0521\n",
      "[Pretrain] Epoch 3/100  Loss=3.0654  Acc=0.0781\n",
      "[Pretrain] Epoch 4/100  Loss=3.0438  Acc=0.0788\n",
      "[Pretrain] Epoch 5/100  Loss=2.9103  Acc=0.1234\n",
      "[Pretrain] Epoch 6/100  Loss=2.7004  Acc=0.1688\n",
      "[Pretrain] Epoch 7/100  Loss=2.5658  Acc=0.1931\n",
      "[Pretrain] Epoch 8/100  Loss=2.4513  Acc=0.2074\n",
      "[Pretrain] Epoch 9/100  Loss=2.3389  Acc=0.2443\n",
      "[Pretrain] Epoch 10/100  Loss=2.2652  Acc=0.2690\n",
      "[Pretrain] Epoch 11/100  Loss=2.2117  Acc=0.2933\n",
      "[Pretrain] Epoch 12/100  Loss=2.1696  Acc=0.2999\n",
      "[Pretrain] Epoch 13/100  Loss=2.1318  Acc=0.3111\n",
      "[Pretrain] Epoch 14/100  Loss=2.0930  Acc=0.3188\n",
      "[Pretrain] Epoch 15/100  Loss=2.0580  Acc=0.3337\n",
      "[Pretrain] Epoch 16/100  Loss=2.0384  Acc=0.3407\n",
      "[Pretrain] Epoch 17/100  Loss=2.0057  Acc=0.3454\n",
      "[Pretrain] Epoch 18/100  Loss=1.9703  Acc=0.3585\n",
      "[Pretrain] Epoch 19/100  Loss=1.9559  Acc=0.3640\n",
      "[Pretrain] Epoch 20/100  Loss=1.9229  Acc=0.3678\n",
      "[Pretrain] Epoch 21/100  Loss=1.8974  Acc=0.3833\n",
      "[Pretrain] Epoch 22/100  Loss=1.8848  Acc=0.3822\n",
      "[Pretrain] Epoch 23/100  Loss=1.8603  Acc=0.3924\n",
      "[Pretrain] Epoch 24/100  Loss=1.8332  Acc=0.4027\n",
      "[Pretrain] Epoch 25/100  Loss=1.8147  Acc=0.4036\n",
      "[Pretrain] Epoch 26/100  Loss=1.7787  Acc=0.4246\n",
      "[Pretrain] Epoch 27/100  Loss=1.7809  Acc=0.4192\n",
      "[Pretrain] Epoch 28/100  Loss=1.7434  Acc=0.4310\n",
      "[Pretrain] Epoch 29/100  Loss=1.7215  Acc=0.4314\n",
      "[Pretrain] Epoch 30/100  Loss=1.6935  Acc=0.4382\n",
      "[Pretrain] Epoch 31/100  Loss=1.6634  Acc=0.4592\n",
      "[Pretrain] Epoch 32/100  Loss=1.6496  Acc=0.4598\n",
      "[Pretrain] Epoch 33/100  Loss=1.6171  Acc=0.4686\n",
      "[Pretrain] Epoch 34/100  Loss=1.5894  Acc=0.4835\n",
      "[Pretrain] Epoch 35/100  Loss=1.6023  Acc=0.4781\n",
      "[Pretrain] Epoch 36/100  Loss=1.5650  Acc=0.4932\n",
      "[Pretrain] Epoch 37/100  Loss=1.5465  Acc=0.4878\n",
      "[Pretrain] Epoch 38/100  Loss=1.5320  Acc=0.4908\n",
      "[Pretrain] Epoch 39/100  Loss=1.5101  Acc=0.4982\n",
      "[Pretrain] Epoch 40/100  Loss=1.4940  Acc=0.5129\n",
      "[Pretrain] Epoch 41/100  Loss=1.4812  Acc=0.5093\n",
      "[Pretrain] Epoch 42/100  Loss=1.4440  Acc=0.5232\n",
      "[Pretrain] Epoch 43/100  Loss=1.4484  Acc=0.5183\n",
      "[Pretrain] Epoch 44/100  Loss=1.4440  Acc=0.5268\n",
      "[Pretrain] Epoch 45/100  Loss=1.4242  Acc=0.5327\n",
      "[Pretrain] Epoch 46/100  Loss=1.4143  Acc=0.5438\n",
      "[Pretrain] Epoch 47/100  Loss=1.3848  Acc=0.5469\n",
      "[Pretrain] Epoch 48/100  Loss=1.3861  Acc=0.5406\n",
      "[Pretrain] Epoch 49/100  Loss=1.3822  Acc=0.5514\n",
      "[Pretrain] Epoch 50/100  Loss=1.3702  Acc=0.5480\n",
      "[Pretrain] Epoch 51/100  Loss=1.3482  Acc=0.5551\n",
      "[Pretrain] Epoch 52/100  Loss=1.3390  Acc=0.5697\n",
      "[Pretrain] Epoch 53/100  Loss=1.3254  Acc=0.5648\n",
      "[Pretrain] Epoch 54/100  Loss=1.3129  Acc=0.5650\n",
      "[Pretrain] Epoch 55/100  Loss=1.3147  Acc=0.5654\n",
      "[Pretrain] Epoch 56/100  Loss=1.3073  Acc=0.5605\n",
      "[Pretrain] Epoch 57/100  Loss=1.2865  Acc=0.5814\n",
      "[Pretrain] Epoch 58/100  Loss=1.2954  Acc=0.5736\n",
      "[Pretrain] Epoch 59/100  Loss=1.2833  Acc=0.5779\n",
      "[Pretrain] Epoch 60/100  Loss=1.2783  Acc=0.5776\n",
      "[Pretrain] Epoch 61/100  Loss=1.2562  Acc=0.5889\n",
      "[Pretrain] Epoch 62/100  Loss=1.2509  Acc=0.5864\n",
      "[Pretrain] Epoch 63/100  Loss=1.2670  Acc=0.5810\n",
      "[Pretrain] Epoch 64/100  Loss=1.2294  Acc=0.5995\n",
      "[Pretrain] Epoch 65/100  Loss=1.2334  Acc=0.5950\n",
      "[Pretrain] Epoch 66/100  Loss=1.2407  Acc=0.5946\n",
      "[Pretrain] Epoch 67/100  Loss=1.2365  Acc=0.5941\n",
      "[Pretrain] Epoch 68/100  Loss=1.2317  Acc=0.5981\n",
      "[Pretrain] Epoch 69/100  Loss=1.2330  Acc=0.5891\n",
      "[Pretrain] Epoch 70/100  Loss=1.2133  Acc=0.6018\n",
      "[Pretrain] Epoch 71/100  Loss=1.2227  Acc=0.6006\n",
      "[Pretrain] Epoch 72/100  Loss=1.2216  Acc=0.5970\n",
      "[Pretrain] Epoch 73/100  Loss=1.2076  Acc=0.6017\n",
      "[Pretrain] Epoch 74/100  Loss=1.2138  Acc=0.6006\n",
      "[Pretrain] Epoch 75/100  Loss=1.2129  Acc=0.6031\n",
      "[Pretrain] Epoch 76/100  Loss=1.1942  Acc=0.6063\n",
      "[Pretrain] Epoch 77/100  Loss=1.2006  Acc=0.6083\n",
      "[Pretrain] Epoch 78/100  Loss=1.1940  Acc=0.6103\n",
      "[Pretrain] Epoch 79/100  Loss=1.1869  Acc=0.6097\n",
      "[Pretrain] Epoch 80/100  Loss=1.1918  Acc=0.6108\n",
      "[Pretrain] Epoch 81/100  Loss=1.1733  Acc=0.6130\n",
      "[Pretrain] Epoch 82/100  Loss=1.1744  Acc=0.6040\n",
      "[Pretrain] Epoch 83/100  Loss=1.1799  Acc=0.6099\n",
      "[Pretrain] Epoch 84/100  Loss=1.1844  Acc=0.6153\n",
      "[Pretrain] Epoch 85/100  Loss=1.1721  Acc=0.6114\n",
      "[Pretrain] Epoch 86/100  Loss=1.1874  Acc=0.6110\n",
      "[Pretrain] Epoch 87/100  Loss=1.1900  Acc=0.6067\n",
      "[Pretrain] Epoch 88/100  Loss=1.1818  Acc=0.6121\n",
      "[Pretrain] Epoch 89/100  Loss=1.1739  Acc=0.6140\n",
      "[Pretrain] Epoch 90/100  Loss=1.1494  Acc=0.6140\n",
      "[Pretrain] Epoch 91/100  Loss=1.1601  Acc=0.6198\n",
      "[Pretrain] Epoch 92/100  Loss=1.1687  Acc=0.6151\n",
      "[Pretrain] Epoch 93/100  Loss=1.1618  Acc=0.6130\n",
      "[Pretrain] Epoch 94/100  Loss=1.1631  Acc=0.6149\n",
      "[Pretrain] Epoch 95/100  Loss=1.1566  Acc=0.6184\n",
      "[Pretrain] Epoch 96/100  Loss=1.1652  Acc=0.6124\n",
      "[Pretrain] Epoch 97/100  Loss=1.1718  Acc=0.6164\n",
      "[Pretrain] Epoch 98/100  Loss=1.1423  Acc=0.6273\n",
      "[Pretrain] Epoch 99/100  Loss=1.1588  Acc=0.6185\n",
      "[Pretrain] Epoch 100/100  Loss=1.1506  Acc=0.6187\n",
      "[Fine-tune] Epoch 1/100  Loss=3.1251\n",
      "[Fine-tune] Epoch 2/100  Loss=2.5861\n",
      "[Fine-tune] Epoch 3/100  Loss=2.3877\n",
      "[Fine-tune] Epoch 4/100  Loss=2.2784\n",
      "[Fine-tune] Epoch 5/100  Loss=2.2108\n",
      "[Fine-tune] Epoch 6/100  Loss=2.1569\n",
      "[Fine-tune] Epoch 7/100  Loss=2.1078\n",
      "[Fine-tune] Epoch 8/100  Loss=2.0727\n",
      "[Fine-tune] Epoch 9/100  Loss=2.0440\n",
      "[Fine-tune] Epoch 10/100  Loss=2.0141\n",
      "[Fine-tune] Epoch 11/100  Loss=2.0084\n",
      "[Fine-tune] Epoch 12/100  Loss=1.9690\n",
      "[Fine-tune] Epoch 13/100  Loss=1.9549\n",
      "[Fine-tune] Epoch 14/100  Loss=1.9368\n",
      "[Fine-tune] Epoch 15/100  Loss=1.9231\n",
      "[Fine-tune] Epoch 16/100  Loss=1.9151\n",
      "[Fine-tune] Epoch 17/100  Loss=1.8955\n",
      "[Fine-tune] Epoch 18/100  Loss=1.8831\n",
      "[Fine-tune] Epoch 19/100  Loss=1.8804\n",
      "[Fine-tune] Epoch 20/100  Loss=1.8562\n",
      "[Fine-tune] Epoch 21/100  Loss=1.8431\n",
      "[Fine-tune] Epoch 22/100  Loss=1.8487\n",
      "[Fine-tune] Epoch 23/100  Loss=1.8421\n",
      "[Fine-tune] Epoch 24/100  Loss=1.8313\n",
      "[Fine-tune] Epoch 25/100  Loss=1.8330\n",
      "[Fine-tune] Epoch 26/100  Loss=1.8225\n",
      "[Fine-tune] Epoch 27/100  Loss=1.8052\n",
      "[Fine-tune] Epoch 28/100  Loss=1.7887\n",
      "[Fine-tune] Epoch 29/100  Loss=1.7972\n",
      "[Fine-tune] Epoch 30/100  Loss=1.7949\n",
      "[Fine-tune] Epoch 31/100  Loss=1.8001\n",
      "[Fine-tune] Epoch 32/100  Loss=1.7612\n",
      "[Fine-tune] Epoch 33/100  Loss=1.7732\n",
      "[Fine-tune] Epoch 34/100  Loss=1.7708\n",
      "[Fine-tune] Epoch 35/100  Loss=1.7702\n",
      "[Fine-tune] Epoch 36/100  Loss=1.7571\n",
      "[Fine-tune] Epoch 37/100  Loss=1.7486\n",
      "[Fine-tune] Epoch 38/100  Loss=1.7501\n",
      "[Fine-tune] Epoch 39/100  Loss=1.7415\n",
      "[Fine-tune] Epoch 40/100  Loss=1.7435\n",
      "[Fine-tune] Epoch 41/100  Loss=1.7493\n",
      "[Fine-tune] Epoch 42/100  Loss=1.7381\n",
      "[Fine-tune] Epoch 43/100  Loss=1.7348\n",
      "[Fine-tune] Epoch 44/100  Loss=1.7357\n",
      "[Fine-tune] Epoch 45/100  Loss=1.7291\n",
      "[Fine-tune] Epoch 46/100  Loss=1.7300\n",
      "[Fine-tune] Epoch 47/100  Loss=1.7256\n",
      "[Fine-tune] Epoch 48/100  Loss=1.7157\n",
      "[Fine-tune] Epoch 49/100  Loss=1.7086\n",
      "[Fine-tune] Epoch 50/100  Loss=1.7297\n",
      "[Fine-tune] Epoch 51/100  Loss=1.7094\n",
      "[Fine-tune] Epoch 52/100  Loss=1.7061\n",
      "[Fine-tune] Epoch 53/100  Loss=1.7149\n",
      "[Fine-tune] Epoch 54/100  Loss=1.7222\n",
      "[Fine-tune] Epoch 55/100  Loss=1.7093\n",
      "[Fine-tune] Epoch 56/100  Loss=1.6995\n",
      "[Fine-tune] Epoch 57/100  Loss=1.6989\n",
      "[Fine-tune] Epoch 58/100  Loss=1.7069\n",
      "[Fine-tune] Epoch 59/100  Loss=1.7034\n",
      "[Fine-tune] Epoch 60/100  Loss=1.7042\n",
      "[Fine-tune] Epoch 61/100  Loss=1.6979\n",
      "[Fine-tune] Epoch 62/100  Loss=1.7135\n",
      "[Fine-tune] Epoch 63/100  Loss=1.6977\n",
      "[Fine-tune] Epoch 64/100  Loss=1.6954\n",
      "[Fine-tune] Epoch 65/100  Loss=1.7016\n",
      "[Fine-tune] Epoch 66/100  Loss=1.6988\n",
      "[Fine-tune] Epoch 67/100  Loss=1.6923\n",
      "[Fine-tune] Epoch 68/100  Loss=1.6904\n",
      "[Fine-tune] Epoch 69/100  Loss=1.6950\n",
      "[Fine-tune] Epoch 70/100  Loss=1.6884\n",
      "[Fine-tune] Epoch 71/100  Loss=1.6835\n",
      "[Fine-tune] Epoch 72/100  Loss=1.6926\n",
      "[Fine-tune] Epoch 73/100  Loss=1.6930\n",
      "[Fine-tune] Epoch 74/100  Loss=1.6831\n",
      "[Fine-tune] Epoch 75/100  Loss=1.6872\n",
      "[Fine-tune] Epoch 76/100  Loss=1.6877\n",
      "[Fine-tune] Epoch 77/100  Loss=1.6838\n",
      "[Fine-tune] Epoch 78/100  Loss=1.6813\n",
      "[Fine-tune] Epoch 79/100  Loss=1.6929\n",
      "[Fine-tune] Epoch 80/100  Loss=1.6818\n",
      "[Fine-tune] Epoch 81/100  Loss=1.6866\n",
      "[Fine-tune] Epoch 82/100  Loss=1.6870\n",
      "[Fine-tune] Epoch 83/100  Loss=1.6749\n",
      "[Fine-tune] Epoch 84/100  Loss=1.6823\n",
      "[Fine-tune] Epoch 85/100  Loss=1.6827\n",
      "[Fine-tune] Epoch 86/100  Loss=1.6908\n",
      "[Fine-tune] Epoch 87/100  Loss=1.6742\n",
      "[Fine-tune] Epoch 88/100  Loss=1.6847\n",
      "[Fine-tune] Epoch 89/100  Loss=1.6904\n",
      "[Fine-tune] Epoch 90/100  Loss=1.6820\n",
      "[Fine-tune] Epoch 91/100  Loss=1.6725\n",
      "[Fine-tune] Epoch 92/100  Loss=1.6827\n",
      "[Fine-tune] Epoch 93/100  Loss=1.6818\n",
      "[Fine-tune] Epoch 94/100  Loss=1.6839\n",
      "[Fine-tune] Epoch 95/100  Loss=1.6925\n",
      "[Fine-tune] Epoch 96/100  Loss=1.6794\n",
      "[Fine-tune] Epoch 97/100  Loss=1.6654\n",
      "[Fine-tune] Epoch 98/100  Loss=1.6839\n",
      "[Fine-tune] Epoch 99/100  Loss=1.6851\n",
      "[Fine-tune] Epoch 100/100  Loss=1.6712\n",
      "[Pretrain] Epoch 1/150  Loss=3.2512  Acc=0.0408\n",
      "[Pretrain] Epoch 2/150  Loss=3.0811  Acc=0.0781\n",
      "[Pretrain] Epoch 3/150  Loss=3.0317  Acc=0.0833\n",
      "[Pretrain] Epoch 4/150  Loss=2.8836  Acc=0.1182\n",
      "[Pretrain] Epoch 5/150  Loss=2.6688  Acc=0.1656\n",
      "[Pretrain] Epoch 6/150  Loss=2.4939  Acc=0.2078\n",
      "[Pretrain] Epoch 7/150  Loss=2.2784  Acc=0.2690\n",
      "[Pretrain] Epoch 8/150  Loss=2.2080  Acc=0.2918\n",
      "[Pretrain] Epoch 9/150  Loss=2.0954  Acc=0.3227\n",
      "[Pretrain] Epoch 10/150  Loss=2.0540  Acc=0.3315\n",
      "[Pretrain] Epoch 11/150  Loss=2.0360  Acc=0.3385\n",
      "[Pretrain] Epoch 12/150  Loss=1.9868  Acc=0.3543\n",
      "[Pretrain] Epoch 13/150  Loss=1.9641  Acc=0.3635\n",
      "[Pretrain] Epoch 14/150  Loss=1.9310  Acc=0.3734\n",
      "[Pretrain] Epoch 15/150  Loss=1.9044  Acc=0.3797\n",
      "[Pretrain] Epoch 16/150  Loss=1.8590  Acc=0.3962\n",
      "[Pretrain] Epoch 17/150  Loss=1.8529  Acc=0.3971\n",
      "[Pretrain] Epoch 18/150  Loss=1.8109  Acc=0.4163\n",
      "[Pretrain] Epoch 19/150  Loss=1.8188  Acc=0.4167\n",
      "[Pretrain] Epoch 20/150  Loss=1.7650  Acc=0.4348\n",
      "[Pretrain] Epoch 21/150  Loss=1.7646  Acc=0.4319\n",
      "[Pretrain] Epoch 22/150  Loss=1.7512  Acc=0.4343\n",
      "[Pretrain] Epoch 23/150  Loss=1.7298  Acc=0.4370\n",
      "[Pretrain] Epoch 24/150  Loss=1.6921  Acc=0.4598\n",
      "[Pretrain] Epoch 25/150  Loss=1.6755  Acc=0.4538\n",
      "[Pretrain] Epoch 26/150  Loss=1.6795  Acc=0.4634\n",
      "[Pretrain] Epoch 27/150  Loss=1.6509  Acc=0.4716\n",
      "[Pretrain] Epoch 28/150  Loss=1.6488  Acc=0.4616\n",
      "[Pretrain] Epoch 29/150  Loss=1.6328  Acc=0.4702\n",
      "[Pretrain] Epoch 30/150  Loss=1.5930  Acc=0.4851\n",
      "[Pretrain] Epoch 31/150  Loss=1.5861  Acc=0.4878\n",
      "[Pretrain] Epoch 32/150  Loss=1.5850  Acc=0.4837\n",
      "[Pretrain] Epoch 33/150  Loss=1.5424  Acc=0.4975\n",
      "[Pretrain] Epoch 34/150  Loss=1.5435  Acc=0.4930\n",
      "[Pretrain] Epoch 35/150  Loss=1.5460  Acc=0.5057\n",
      "[Pretrain] Epoch 36/150  Loss=1.5046  Acc=0.5052\n",
      "[Pretrain] Epoch 37/150  Loss=1.4932  Acc=0.5074\n",
      "[Pretrain] Epoch 38/150  Loss=1.4983  Acc=0.5043\n",
      "[Pretrain] Epoch 39/150  Loss=1.4745  Acc=0.5199\n",
      "[Pretrain] Epoch 40/150  Loss=1.4565  Acc=0.5269\n",
      "[Pretrain] Epoch 41/150  Loss=1.4540  Acc=0.5302\n",
      "[Pretrain] Epoch 42/150  Loss=1.4548  Acc=0.5257\n",
      "[Pretrain] Epoch 43/150  Loss=1.4230  Acc=0.5370\n",
      "[Pretrain] Epoch 44/150  Loss=1.4113  Acc=0.5388\n",
      "[Pretrain] Epoch 45/150  Loss=1.4140  Acc=0.5359\n",
      "[Pretrain] Epoch 46/150  Loss=1.4019  Acc=0.5427\n",
      "[Pretrain] Epoch 47/150  Loss=1.4070  Acc=0.5399\n",
      "[Pretrain] Epoch 48/150  Loss=1.3935  Acc=0.5476\n",
      "[Pretrain] Epoch 49/150  Loss=1.3756  Acc=0.5508\n",
      "[Pretrain] Epoch 50/150  Loss=1.3840  Acc=0.5512\n",
      "[Pretrain] Epoch 51/150  Loss=1.3802  Acc=0.5478\n",
      "[Pretrain] Epoch 52/150  Loss=1.3686  Acc=0.5469\n",
      "[Pretrain] Epoch 53/150  Loss=1.3741  Acc=0.5577\n",
      "[Pretrain] Epoch 54/150  Loss=1.3500  Acc=0.5589\n",
      "[Pretrain] Epoch 55/150  Loss=1.3545  Acc=0.5668\n",
      "[Pretrain] Epoch 56/150  Loss=1.3443  Acc=0.5571\n",
      "[Pretrain] Epoch 57/150  Loss=1.3432  Acc=0.5600\n",
      "[Pretrain] Epoch 58/150  Loss=1.3367  Acc=0.5690\n",
      "[Pretrain] Epoch 59/150  Loss=1.3229  Acc=0.5717\n",
      "[Pretrain] Epoch 60/150  Loss=1.3536  Acc=0.5591\n",
      "[Pretrain] Epoch 61/150  Loss=1.3268  Acc=0.5693\n",
      "[Pretrain] Epoch 62/150  Loss=1.3046  Acc=0.5754\n",
      "[Pretrain] Epoch 63/150  Loss=1.3119  Acc=0.5722\n",
      "[Pretrain] Epoch 64/150  Loss=1.3109  Acc=0.5722\n",
      "[Pretrain] Epoch 65/150  Loss=1.3037  Acc=0.5772\n",
      "[Pretrain] Epoch 66/150  Loss=1.3033  Acc=0.5783\n",
      "[Pretrain] Epoch 67/150  Loss=1.3064  Acc=0.5675\n",
      "[Pretrain] Epoch 68/150  Loss=1.2977  Acc=0.5761\n",
      "[Pretrain] Epoch 69/150  Loss=1.3033  Acc=0.5814\n",
      "[Pretrain] Epoch 70/150  Loss=1.2943  Acc=0.5801\n",
      "[Pretrain] Epoch 71/150  Loss=1.2916  Acc=0.5805\n",
      "[Pretrain] Epoch 72/150  Loss=1.2873  Acc=0.5801\n",
      "[Pretrain] Epoch 73/150  Loss=1.2810  Acc=0.5880\n",
      "[Pretrain] Epoch 74/150  Loss=1.2810  Acc=0.5871\n",
      "[Pretrain] Epoch 75/150  Loss=1.2767  Acc=0.5839\n",
      "[Pretrain] Epoch 76/150  Loss=1.2799  Acc=0.5819\n",
      "[Pretrain] Epoch 77/150  Loss=1.2777  Acc=0.5835\n",
      "[Pretrain] Epoch 78/150  Loss=1.3020  Acc=0.5758\n",
      "[Pretrain] Epoch 79/150  Loss=1.2814  Acc=0.5760\n",
      "[Pretrain] Epoch 80/150  Loss=1.2668  Acc=0.5866\n",
      "[Pretrain] Epoch 81/150  Loss=1.2763  Acc=0.5849\n",
      "[Pretrain] Epoch 82/150  Loss=1.2659  Acc=0.5909\n",
      "[Pretrain] Epoch 83/150  Loss=1.2657  Acc=0.5889\n",
      "[Pretrain] Epoch 84/150  Loss=1.2896  Acc=0.5801\n",
      "[Pretrain] Epoch 85/150  Loss=1.2702  Acc=0.5844\n",
      "[Pretrain] Epoch 86/150  Loss=1.2699  Acc=0.5848\n",
      "[Pretrain] Epoch 87/150  Loss=1.2643  Acc=0.5857\n",
      "[Pretrain] Epoch 88/150  Loss=1.2669  Acc=0.5869\n",
      "[Pretrain] Epoch 89/150  Loss=1.2684  Acc=0.5851\n",
      "[Pretrain] Epoch 90/150  Loss=1.2596  Acc=0.5905\n",
      "[Pretrain] Epoch 91/150  Loss=1.2549  Acc=0.5905\n",
      "[Pretrain] Epoch 92/150  Loss=1.2849  Acc=0.5787\n",
      "[Pretrain] Epoch 93/150  Loss=1.2828  Acc=0.5851\n",
      "[Pretrain] Epoch 94/150  Loss=1.2675  Acc=0.5814\n",
      "[Pretrain] Epoch 95/150  Loss=1.2603  Acc=0.5900\n",
      "[Pretrain] Epoch 96/150  Loss=1.2678  Acc=0.5887\n",
      "[Pretrain] Epoch 97/150  Loss=1.2558  Acc=0.5936\n",
      "[Pretrain] Epoch 98/150  Loss=1.2622  Acc=0.5945\n",
      "[Pretrain] Epoch 99/150  Loss=1.2546  Acc=0.5880\n",
      "[Pretrain] Epoch 100/150  Loss=1.2623  Acc=0.5903\n",
      "[Pretrain] Epoch 101/150  Loss=1.2640  Acc=0.5898\n",
      "[Pretrain] Epoch 102/150  Loss=1.2600  Acc=0.5891\n",
      "[Pretrain] Epoch 103/150  Loss=1.2674  Acc=0.5907\n",
      "[Pretrain] Epoch 104/150  Loss=1.2665  Acc=0.5855\n",
      "[Pretrain] Epoch 105/150  Loss=1.2604  Acc=0.5835\n",
      "[Pretrain] Epoch 106/150  Loss=1.2510  Acc=0.5961\n",
      "[Pretrain] Epoch 107/150  Loss=1.2644  Acc=0.5853\n",
      "[Pretrain] Epoch 108/150  Loss=1.2542  Acc=0.5921\n",
      "[Pretrain] Epoch 109/150  Loss=1.2510  Acc=0.5911\n",
      "[Pretrain] Epoch 110/150  Loss=1.2639  Acc=0.5887\n",
      "[Pretrain] Epoch 111/150  Loss=1.2441  Acc=0.5939\n",
      "[Pretrain] Epoch 112/150  Loss=1.2561  Acc=0.5875\n",
      "[Pretrain] Epoch 113/150  Loss=1.2536  Acc=0.5918\n",
      "[Pretrain] Epoch 114/150  Loss=1.2661  Acc=0.5851\n",
      "[Pretrain] Epoch 115/150  Loss=1.2519  Acc=0.5941\n",
      "[Pretrain] Epoch 116/150  Loss=1.2413  Acc=0.5952\n",
      "[Pretrain] Epoch 117/150  Loss=1.2484  Acc=0.5950\n",
      "[Pretrain] Epoch 118/150  Loss=1.2538  Acc=0.5903\n",
      "[Pretrain] Epoch 119/150  Loss=1.2559  Acc=0.5896\n",
      "[Pretrain] Epoch 120/150  Loss=1.2682  Acc=0.5864\n",
      "[Pretrain] Epoch 121/150  Loss=1.2497  Acc=0.5929\n",
      "[Pretrain] Epoch 122/150  Loss=1.2522  Acc=0.5891\n",
      "[Pretrain] Epoch 123/150  Loss=1.2430  Acc=0.5948\n",
      "[Pretrain] Epoch 124/150  Loss=1.2598  Acc=0.5929\n",
      "[Pretrain] Epoch 125/150  Loss=1.2719  Acc=0.5851\n",
      "[Pretrain] Epoch 126/150  Loss=1.2536  Acc=0.5912\n",
      "[Pretrain] Epoch 127/150  Loss=1.2504  Acc=0.5948\n",
      "[Pretrain] Epoch 128/150  Loss=1.2627  Acc=0.5902\n",
      "[Pretrain] Epoch 129/150  Loss=1.2507  Acc=0.5903\n",
      "[Pretrain] Epoch 130/150  Loss=1.2736  Acc=0.5860\n",
      "[Pretrain] Epoch 131/150  Loss=1.2456  Acc=0.5846\n",
      "[Pretrain] Epoch 132/150  Loss=1.2432  Acc=0.5896\n",
      "[Pretrain] Epoch 133/150  Loss=1.2426  Acc=0.5972\n",
      "[Pretrain] Epoch 134/150  Loss=1.2546  Acc=0.5936\n",
      "[Pretrain] Epoch 135/150  Loss=1.2584  Acc=0.5914\n",
      "[Pretrain] Epoch 136/150  Loss=1.2736  Acc=0.5862\n",
      "[Pretrain] Epoch 137/150  Loss=1.2581  Acc=0.5876\n",
      "[Pretrain] Epoch 138/150  Loss=1.2547  Acc=0.5873\n",
      "[Pretrain] Epoch 139/150  Loss=1.2587  Acc=0.5927\n",
      "[Pretrain] Epoch 140/150  Loss=1.2634  Acc=0.5858\n",
      "[Pretrain] Epoch 141/150  Loss=1.2602  Acc=0.5878\n",
      "[Pretrain] Epoch 142/150  Loss=1.2507  Acc=0.5916\n",
      "[Pretrain] Epoch 143/150  Loss=1.2549  Acc=0.5961\n",
      "[Pretrain] Epoch 144/150  Loss=1.2537  Acc=0.5894\n",
      "[Pretrain] Epoch 145/150  Loss=1.2465  Acc=0.5914\n",
      "[Pretrain] Epoch 146/150  Loss=1.2490  Acc=0.5882\n",
      "[Pretrain] Epoch 147/150  Loss=1.2548  Acc=0.5966\n",
      "[Pretrain] Epoch 148/150  Loss=1.2444  Acc=0.5900\n",
      "[Pretrain] Epoch 149/150  Loss=1.2598  Acc=0.5873\n",
      "[Pretrain] Epoch 150/150  Loss=1.2493  Acc=0.5957\n",
      "[Fine-tune] Epoch 1/100  Loss=2.7965\n",
      "[Fine-tune] Epoch 2/100  Loss=2.2882\n",
      "[Fine-tune] Epoch 3/100  Loss=2.1208\n",
      "[Fine-tune] Epoch 4/100  Loss=2.0244\n",
      "[Fine-tune] Epoch 5/100  Loss=1.9263\n",
      "[Fine-tune] Epoch 6/100  Loss=1.8701\n",
      "[Fine-tune] Epoch 7/100  Loss=1.8162\n",
      "[Fine-tune] Epoch 8/100  Loss=1.8052\n",
      "[Fine-tune] Epoch 9/100  Loss=1.7237\n",
      "[Fine-tune] Epoch 10/100  Loss=1.6729\n",
      "[Fine-tune] Epoch 11/100  Loss=1.6455\n",
      "[Fine-tune] Epoch 12/100  Loss=1.6089\n",
      "[Fine-tune] Epoch 13/100  Loss=1.5607\n",
      "[Fine-tune] Epoch 14/100  Loss=1.5361\n",
      "[Fine-tune] Epoch 15/100  Loss=1.5041\n",
      "[Fine-tune] Epoch 16/100  Loss=1.4641\n",
      "[Fine-tune] Epoch 17/100  Loss=1.4205\n",
      "[Fine-tune] Epoch 18/100  Loss=1.4208\n",
      "[Fine-tune] Epoch 19/100  Loss=1.3977\n",
      "[Fine-tune] Epoch 20/100  Loss=1.3894\n",
      "[Fine-tune] Epoch 21/100  Loss=1.3480\n",
      "[Fine-tune] Epoch 22/100  Loss=1.3221\n",
      "[Fine-tune] Epoch 23/100  Loss=1.2989\n",
      "[Fine-tune] Epoch 24/100  Loss=1.2825\n",
      "[Fine-tune] Epoch 25/100  Loss=1.2547\n",
      "[Fine-tune] Epoch 26/100  Loss=1.2472\n",
      "[Fine-tune] Epoch 27/100  Loss=1.2086\n",
      "[Fine-tune] Epoch 28/100  Loss=1.2063\n",
      "[Fine-tune] Epoch 29/100  Loss=1.1918\n",
      "[Fine-tune] Epoch 30/100  Loss=1.1743\n",
      "[Fine-tune] Epoch 31/100  Loss=1.1529\n",
      "[Fine-tune] Epoch 32/100  Loss=1.1511\n",
      "[Fine-tune] Epoch 33/100  Loss=1.1385\n",
      "[Fine-tune] Epoch 34/100  Loss=1.1226\n",
      "[Fine-tune] Epoch 35/100  Loss=1.1009\n",
      "[Fine-tune] Epoch 36/100  Loss=1.1111\n",
      "[Fine-tune] Epoch 37/100  Loss=1.0864\n",
      "[Fine-tune] Epoch 38/100  Loss=1.0828\n",
      "[Fine-tune] Epoch 39/100  Loss=1.0703\n",
      "[Fine-tune] Epoch 40/100  Loss=1.0521\n",
      "[Fine-tune] Epoch 41/100  Loss=1.0417\n",
      "[Fine-tune] Epoch 42/100  Loss=1.0520\n",
      "[Fine-tune] Epoch 43/100  Loss=1.0608\n",
      "[Fine-tune] Epoch 44/100  Loss=1.0433\n",
      "[Fine-tune] Epoch 45/100  Loss=1.0397\n",
      "[Fine-tune] Epoch 46/100  Loss=1.0158\n",
      "[Fine-tune] Epoch 47/100  Loss=1.0153\n",
      "[Fine-tune] Epoch 48/100  Loss=1.0075\n",
      "[Fine-tune] Epoch 49/100  Loss=1.0098\n",
      "[Fine-tune] Epoch 50/100  Loss=0.9941\n",
      "[Fine-tune] Epoch 51/100  Loss=1.0006\n",
      "[Fine-tune] Epoch 52/100  Loss=0.9919\n",
      "[Fine-tune] Epoch 53/100  Loss=0.9827\n",
      "[Fine-tune] Epoch 54/100  Loss=0.9679\n",
      "[Fine-tune] Epoch 55/100  Loss=0.9755\n",
      "[Fine-tune] Epoch 56/100  Loss=0.9709\n",
      "[Fine-tune] Epoch 57/100  Loss=0.9755\n",
      "[Fine-tune] Epoch 58/100  Loss=0.9666\n",
      "[Fine-tune] Epoch 59/100  Loss=0.9582\n",
      "[Fine-tune] Epoch 60/100  Loss=0.9616\n",
      "[Fine-tune] Epoch 61/100  Loss=0.9665\n",
      "[Fine-tune] Epoch 62/100  Loss=0.9496\n",
      "[Fine-tune] Epoch 63/100  Loss=0.9538\n",
      "[Fine-tune] Epoch 64/100  Loss=0.9463\n",
      "[Fine-tune] Epoch 65/100  Loss=0.9492\n",
      "[Fine-tune] Epoch 66/100  Loss=0.9493\n",
      "[Fine-tune] Epoch 67/100  Loss=0.9504\n",
      "[Fine-tune] Epoch 68/100  Loss=0.9444\n",
      "[Fine-tune] Epoch 69/100  Loss=0.9382\n",
      "[Fine-tune] Epoch 70/100  Loss=0.9417\n",
      "[Fine-tune] Epoch 71/100  Loss=0.9431\n",
      "[Fine-tune] Epoch 72/100  Loss=0.9381\n",
      "[Fine-tune] Epoch 73/100  Loss=0.9347\n",
      "[Fine-tune] Epoch 74/100  Loss=0.9325\n",
      "[Fine-tune] Epoch 75/100  Loss=0.9252\n",
      "[Fine-tune] Epoch 76/100  Loss=0.9283\n",
      "[Fine-tune] Epoch 77/100  Loss=0.9146\n",
      "[Fine-tune] Epoch 78/100  Loss=0.9234\n",
      "[Fine-tune] Epoch 79/100  Loss=0.9149\n",
      "[Fine-tune] Epoch 80/100  Loss=0.9250\n",
      "[Fine-tune] Epoch 81/100  Loss=0.9228\n",
      "[Fine-tune] Epoch 82/100  Loss=0.9121\n",
      "[Fine-tune] Epoch 83/100  Loss=0.9273\n",
      "[Fine-tune] Epoch 84/100  Loss=0.9234\n",
      "[Fine-tune] Epoch 85/100  Loss=0.9219\n",
      "[Fine-tune] Epoch 86/100  Loss=0.9140\n",
      "[Fine-tune] Epoch 87/100  Loss=0.9133\n",
      "[Fine-tune] Epoch 88/100  Loss=0.9117\n",
      "[Fine-tune] Epoch 89/100  Loss=0.9277\n",
      "[Fine-tune] Epoch 90/100  Loss=0.9107\n",
      "[Fine-tune] Epoch 91/100  Loss=0.9054\n",
      "[Fine-tune] Epoch 92/100  Loss=0.9125\n",
      "[Fine-tune] Epoch 93/100  Loss=0.9106\n",
      "[Fine-tune] Epoch 94/100  Loss=0.9071\n",
      "[Fine-tune] Epoch 95/100  Loss=0.9223\n",
      "[Fine-tune] Epoch 96/100  Loss=0.9308\n",
      "[Fine-tune] Epoch 97/100  Loss=0.9103\n",
      "[Fine-tune] Epoch 98/100  Loss=0.9118\n",
      "[Fine-tune] Epoch 99/100  Loss=0.9221\n",
      "[Fine-tune] Epoch 100/100  Loss=0.9016\n",
      "[Pretrain] Epoch 1/150  Loss=3.6998  Acc=0.0517\n",
      "[Pretrain] Epoch 2/150  Loss=2.9329  Acc=0.1070\n",
      "[Pretrain] Epoch 3/150  Loss=2.6931  Acc=0.1580\n",
      "[Pretrain] Epoch 4/150  Loss=2.5509  Acc=0.1929\n",
      "[Pretrain] Epoch 5/150  Loss=2.4681  Acc=0.2150\n",
      "[Pretrain] Epoch 6/150  Loss=2.3872  Acc=0.2333\n",
      "[Pretrain] Epoch 7/150  Loss=2.3793  Acc=0.2381\n",
      "[Pretrain] Epoch 8/150  Loss=2.3128  Acc=0.2547\n",
      "[Pretrain] Epoch 9/150  Loss=2.2845  Acc=0.2559\n",
      "[Pretrain] Epoch 10/150  Loss=2.2700  Acc=0.2631\n",
      "[Pretrain] Epoch 11/150  Loss=2.2441  Acc=0.2735\n",
      "[Pretrain] Epoch 12/150  Loss=2.2137  Acc=0.2739\n",
      "[Pretrain] Epoch 13/150  Loss=2.1338  Acc=0.3077\n",
      "[Pretrain] Epoch 14/150  Loss=2.0995  Acc=0.3186\n",
      "[Pretrain] Epoch 15/150  Loss=2.0769  Acc=0.3190\n",
      "[Pretrain] Epoch 16/150  Loss=2.0242  Acc=0.3391\n",
      "[Pretrain] Epoch 17/150  Loss=2.0115  Acc=0.3436\n",
      "[Pretrain] Epoch 18/150  Loss=2.0061  Acc=0.3403\n",
      "[Pretrain] Epoch 19/150  Loss=1.9733  Acc=0.3588\n",
      "[Pretrain] Epoch 20/150  Loss=1.9416  Acc=0.3657\n",
      "[Pretrain] Epoch 21/150  Loss=1.9163  Acc=0.3728\n",
      "[Pretrain] Epoch 22/150  Loss=1.8972  Acc=0.3872\n",
      "[Pretrain] Epoch 23/150  Loss=1.8583  Acc=0.3926\n",
      "[Pretrain] Epoch 24/150  Loss=1.8591  Acc=0.3917\n",
      "[Pretrain] Epoch 25/150  Loss=1.8155  Acc=0.4016\n",
      "[Pretrain] Epoch 26/150  Loss=1.8291  Acc=0.4061\n",
      "[Pretrain] Epoch 27/150  Loss=1.7779  Acc=0.4165\n",
      "[Pretrain] Epoch 28/150  Loss=1.7430  Acc=0.4370\n",
      "[Pretrain] Epoch 29/150  Loss=1.7505  Acc=0.4303\n",
      "[Pretrain] Epoch 30/150  Loss=1.7197  Acc=0.4312\n",
      "[Pretrain] Epoch 31/150  Loss=1.6870  Acc=0.4488\n",
      "[Pretrain] Epoch 32/150  Loss=1.6886  Acc=0.4499\n",
      "[Pretrain] Epoch 33/150  Loss=1.6494  Acc=0.4619\n",
      "[Pretrain] Epoch 34/150  Loss=1.6169  Acc=0.4680\n",
      "[Pretrain] Epoch 35/150  Loss=1.6257  Acc=0.4668\n",
      "[Pretrain] Epoch 36/150  Loss=1.5975  Acc=0.4790\n",
      "[Pretrain] Epoch 37/150  Loss=1.5983  Acc=0.4846\n",
      "[Pretrain] Epoch 38/150  Loss=1.5812  Acc=0.4907\n",
      "[Pretrain] Epoch 39/150  Loss=1.5555  Acc=0.4939\n",
      "[Pretrain] Epoch 40/150  Loss=1.5220  Acc=0.5016\n",
      "[Pretrain] Epoch 41/150  Loss=1.5152  Acc=0.5009\n",
      "[Pretrain] Epoch 42/150  Loss=1.4961  Acc=0.5144\n",
      "[Pretrain] Epoch 43/150  Loss=1.4748  Acc=0.5149\n",
      "[Pretrain] Epoch 44/150  Loss=1.4635  Acc=0.5212\n",
      "[Pretrain] Epoch 45/150  Loss=1.4477  Acc=0.5259\n",
      "[Pretrain] Epoch 46/150  Loss=1.4491  Acc=0.5217\n",
      "[Pretrain] Epoch 47/150  Loss=1.4328  Acc=0.5260\n",
      "[Pretrain] Epoch 48/150  Loss=1.4059  Acc=0.5395\n",
      "[Pretrain] Epoch 49/150  Loss=1.4190  Acc=0.5370\n",
      "[Pretrain] Epoch 50/150  Loss=1.4042  Acc=0.5440\n",
      "[Pretrain] Epoch 51/150  Loss=1.3878  Acc=0.5467\n",
      "[Pretrain] Epoch 52/150  Loss=1.3657  Acc=0.5483\n",
      "[Pretrain] Epoch 53/150  Loss=1.3543  Acc=0.5566\n",
      "[Pretrain] Epoch 54/150  Loss=1.3763  Acc=0.5494\n",
      "[Pretrain] Epoch 55/150  Loss=1.3408  Acc=0.5627\n",
      "[Pretrain] Epoch 56/150  Loss=1.3212  Acc=0.5605\n",
      "[Pretrain] Epoch 57/150  Loss=1.3331  Acc=0.5616\n",
      "[Pretrain] Epoch 58/150  Loss=1.3296  Acc=0.5596\n",
      "[Pretrain] Epoch 59/150  Loss=1.3084  Acc=0.5656\n",
      "[Pretrain] Epoch 60/150  Loss=1.3248  Acc=0.5711\n",
      "[Pretrain] Epoch 61/150  Loss=1.2977  Acc=0.5749\n",
      "[Pretrain] Epoch 62/150  Loss=1.3020  Acc=0.5688\n",
      "[Pretrain] Epoch 63/150  Loss=1.2869  Acc=0.5779\n",
      "[Pretrain] Epoch 64/150  Loss=1.2816  Acc=0.5717\n",
      "[Pretrain] Epoch 65/150  Loss=1.2817  Acc=0.5715\n",
      "[Pretrain] Epoch 66/150  Loss=1.2700  Acc=0.5833\n",
      "[Pretrain] Epoch 67/150  Loss=1.2702  Acc=0.5866\n",
      "[Pretrain] Epoch 68/150  Loss=1.2676  Acc=0.5855\n",
      "[Pretrain] Epoch 69/150  Loss=1.2574  Acc=0.5821\n",
      "[Pretrain] Epoch 70/150  Loss=1.2532  Acc=0.5884\n",
      "[Pretrain] Epoch 71/150  Loss=1.2450  Acc=0.5884\n",
      "[Pretrain] Epoch 72/150  Loss=1.2408  Acc=0.5920\n",
      "[Pretrain] Epoch 73/150  Loss=1.2494  Acc=0.5873\n",
      "[Pretrain] Epoch 74/150  Loss=1.2392  Acc=0.5920\n",
      "[Pretrain] Epoch 75/150  Loss=1.2198  Acc=0.6043\n",
      "[Pretrain] Epoch 76/150  Loss=1.2335  Acc=0.5945\n",
      "[Pretrain] Epoch 77/150  Loss=1.2202  Acc=0.5970\n",
      "[Pretrain] Epoch 78/150  Loss=1.2287  Acc=0.5988\n",
      "[Pretrain] Epoch 79/150  Loss=1.2250  Acc=0.5946\n",
      "[Pretrain] Epoch 80/150  Loss=1.2353  Acc=0.5975\n",
      "[Pretrain] Epoch 81/150  Loss=1.2047  Acc=0.6047\n",
      "[Pretrain] Epoch 82/150  Loss=1.2302  Acc=0.5918\n",
      "[Pretrain] Epoch 83/150  Loss=1.2155  Acc=0.6009\n",
      "[Pretrain] Epoch 84/150  Loss=1.2034  Acc=0.6072\n",
      "[Pretrain] Epoch 85/150  Loss=1.1991  Acc=0.6051\n",
      "[Pretrain] Epoch 86/150  Loss=1.2180  Acc=0.6015\n",
      "[Pretrain] Epoch 87/150  Loss=1.2069  Acc=0.6087\n",
      "[Pretrain] Epoch 88/150  Loss=1.2131  Acc=0.5993\n",
      "[Pretrain] Epoch 89/150  Loss=1.2040  Acc=0.6094\n",
      "[Pretrain] Epoch 90/150  Loss=1.1754  Acc=0.6105\n",
      "[Pretrain] Epoch 91/150  Loss=1.1886  Acc=0.6063\n",
      "[Pretrain] Epoch 92/150  Loss=1.2013  Acc=0.6054\n",
      "[Pretrain] Epoch 93/150  Loss=1.2023  Acc=0.6054\n",
      "[Pretrain] Epoch 94/150  Loss=1.1938  Acc=0.6106\n",
      "[Pretrain] Epoch 95/150  Loss=1.2058  Acc=0.6040\n",
      "[Pretrain] Epoch 96/150  Loss=1.2040  Acc=0.6087\n",
      "[Pretrain] Epoch 97/150  Loss=1.1929  Acc=0.6063\n",
      "[Pretrain] Epoch 98/150  Loss=1.1911  Acc=0.6072\n",
      "[Pretrain] Epoch 99/150  Loss=1.1953  Acc=0.6097\n",
      "[Pretrain] Epoch 100/150  Loss=1.1843  Acc=0.6176\n",
      "[Pretrain] Epoch 101/150  Loss=1.1822  Acc=0.6036\n",
      "[Pretrain] Epoch 102/150  Loss=1.1772  Acc=0.6119\n",
      "[Pretrain] Epoch 103/150  Loss=1.1930  Acc=0.6114\n",
      "[Pretrain] Epoch 104/150  Loss=1.1918  Acc=0.6083\n",
      "[Pretrain] Epoch 105/150  Loss=1.1886  Acc=0.6083\n",
      "[Pretrain] Epoch 106/150  Loss=1.1871  Acc=0.6131\n",
      "[Pretrain] Epoch 107/150  Loss=1.1751  Acc=0.6097\n",
      "[Pretrain] Epoch 108/150  Loss=1.1951  Acc=0.6078\n",
      "[Pretrain] Epoch 109/150  Loss=1.1842  Acc=0.6070\n",
      "[Pretrain] Epoch 110/150  Loss=1.1862  Acc=0.6081\n",
      "[Pretrain] Epoch 111/150  Loss=1.1887  Acc=0.6099\n",
      "[Pretrain] Epoch 112/150  Loss=1.1745  Acc=0.6146\n",
      "[Pretrain] Epoch 113/150  Loss=1.1884  Acc=0.6083\n",
      "[Pretrain] Epoch 114/150  Loss=1.1852  Acc=0.6083\n",
      "[Pretrain] Epoch 115/150  Loss=1.1709  Acc=0.6202\n",
      "[Pretrain] Epoch 116/150  Loss=1.1775  Acc=0.6191\n",
      "[Pretrain] Epoch 117/150  Loss=1.1750  Acc=0.6167\n",
      "[Pretrain] Epoch 118/150  Loss=1.1861  Acc=0.6081\n",
      "[Pretrain] Epoch 119/150  Loss=1.1882  Acc=0.6092\n",
      "[Pretrain] Epoch 120/150  Loss=1.1773  Acc=0.6153\n",
      "[Pretrain] Epoch 121/150  Loss=1.1837  Acc=0.6069\n",
      "[Pretrain] Epoch 122/150  Loss=1.1858  Acc=0.6110\n",
      "[Pretrain] Epoch 123/150  Loss=1.1686  Acc=0.6194\n",
      "[Pretrain] Epoch 124/150  Loss=1.1769  Acc=0.6130\n",
      "[Pretrain] Epoch 125/150  Loss=1.1721  Acc=0.6139\n",
      "[Pretrain] Epoch 126/150  Loss=1.1748  Acc=0.6112\n",
      "[Pretrain] Epoch 127/150  Loss=1.1860  Acc=0.6121\n",
      "[Pretrain] Epoch 128/150  Loss=1.1869  Acc=0.6096\n",
      "[Pretrain] Epoch 129/150  Loss=1.1727  Acc=0.6130\n",
      "[Pretrain] Epoch 130/150  Loss=1.1759  Acc=0.6216\n",
      "[Pretrain] Epoch 131/150  Loss=1.1597  Acc=0.6167\n",
      "[Pretrain] Epoch 132/150  Loss=1.1698  Acc=0.6225\n",
      "[Pretrain] Epoch 133/150  Loss=1.1726  Acc=0.6189\n",
      "[Pretrain] Epoch 134/150  Loss=1.1741  Acc=0.6090\n",
      "[Pretrain] Epoch 135/150  Loss=1.1711  Acc=0.6140\n",
      "[Pretrain] Epoch 136/150  Loss=1.1652  Acc=0.6119\n",
      "[Pretrain] Epoch 137/150  Loss=1.1725  Acc=0.6085\n",
      "[Pretrain] Epoch 138/150  Loss=1.1783  Acc=0.6148\n",
      "[Pretrain] Epoch 139/150  Loss=1.1740  Acc=0.6171\n",
      "[Pretrain] Epoch 140/150  Loss=1.1637  Acc=0.6166\n",
      "[Pretrain] Epoch 141/150  Loss=1.1775  Acc=0.6124\n",
      "[Pretrain] Epoch 142/150  Loss=1.1820  Acc=0.6135\n",
      "[Pretrain] Epoch 143/150  Loss=1.1677  Acc=0.6169\n",
      "[Pretrain] Epoch 144/150  Loss=1.1742  Acc=0.6191\n",
      "[Pretrain] Epoch 145/150  Loss=1.1635  Acc=0.6209\n",
      "[Pretrain] Epoch 146/150  Loss=1.1619  Acc=0.6146\n",
      "[Pretrain] Epoch 147/150  Loss=1.1617  Acc=0.6178\n",
      "[Pretrain] Epoch 148/150  Loss=1.1700  Acc=0.6142\n",
      "[Pretrain] Epoch 149/150  Loss=1.1750  Acc=0.6133\n",
      "[Pretrain] Epoch 150/150  Loss=1.1742  Acc=0.6131\n",
      "[Fine-tune] Epoch 1/100  Loss=2.9783\n",
      "[Fine-tune] Epoch 2/100  Loss=2.5939\n",
      "[Fine-tune] Epoch 3/100  Loss=2.4664\n",
      "[Fine-tune] Epoch 4/100  Loss=2.3559\n",
      "[Fine-tune] Epoch 5/100  Loss=2.2509\n",
      "[Fine-tune] Epoch 6/100  Loss=2.1564\n",
      "[Fine-tune] Epoch 7/100  Loss=2.1087\n",
      "[Fine-tune] Epoch 8/100  Loss=2.0553\n",
      "[Fine-tune] Epoch 9/100  Loss=2.0196\n",
      "[Fine-tune] Epoch 10/100  Loss=2.0032\n",
      "[Fine-tune] Epoch 11/100  Loss=1.9705\n",
      "[Fine-tune] Epoch 12/100  Loss=1.9478\n",
      "[Fine-tune] Epoch 13/100  Loss=1.9341\n",
      "[Fine-tune] Epoch 14/100  Loss=1.9140\n",
      "[Fine-tune] Epoch 15/100  Loss=1.8851\n",
      "[Fine-tune] Epoch 16/100  Loss=1.8939\n",
      "[Fine-tune] Epoch 17/100  Loss=1.8676\n",
      "[Fine-tune] Epoch 18/100  Loss=1.8622\n",
      "[Fine-tune] Epoch 19/100  Loss=1.8476\n",
      "[Fine-tune] Epoch 20/100  Loss=1.8316\n",
      "[Fine-tune] Epoch 21/100  Loss=1.8288\n",
      "[Fine-tune] Epoch 22/100  Loss=1.8059\n",
      "[Fine-tune] Epoch 23/100  Loss=1.8104\n",
      "[Fine-tune] Epoch 24/100  Loss=1.8069\n",
      "[Fine-tune] Epoch 25/100  Loss=1.7823\n",
      "[Fine-tune] Epoch 26/100  Loss=1.7867\n",
      "[Fine-tune] Epoch 27/100  Loss=1.7889\n",
      "[Fine-tune] Epoch 28/100  Loss=1.7759\n",
      "[Fine-tune] Epoch 29/100  Loss=1.7686\n",
      "[Fine-tune] Epoch 30/100  Loss=1.7739\n",
      "[Fine-tune] Epoch 31/100  Loss=1.7527\n",
      "[Fine-tune] Epoch 32/100  Loss=1.7581\n",
      "[Fine-tune] Epoch 33/100  Loss=1.7436\n",
      "[Fine-tune] Epoch 34/100  Loss=1.7444\n",
      "[Fine-tune] Epoch 35/100  Loss=1.7245\n",
      "[Fine-tune] Epoch 36/100  Loss=1.7202\n",
      "[Fine-tune] Epoch 37/100  Loss=1.7329\n",
      "[Fine-tune] Epoch 38/100  Loss=1.7142\n",
      "[Fine-tune] Epoch 39/100  Loss=1.7096\n",
      "[Fine-tune] Epoch 40/100  Loss=1.7170\n",
      "[Fine-tune] Epoch 41/100  Loss=1.7132\n",
      "[Fine-tune] Epoch 42/100  Loss=1.7066\n",
      "[Fine-tune] Epoch 43/100  Loss=1.7091\n",
      "[Fine-tune] Epoch 44/100  Loss=1.7096\n",
      "[Fine-tune] Epoch 45/100  Loss=1.7018\n",
      "[Fine-tune] Epoch 46/100  Loss=1.7068\n",
      "[Fine-tune] Epoch 47/100  Loss=1.6883\n",
      "[Fine-tune] Epoch 48/100  Loss=1.6986\n",
      "[Fine-tune] Epoch 49/100  Loss=1.6981\n",
      "[Fine-tune] Epoch 50/100  Loss=1.6880\n",
      "[Fine-tune] Epoch 51/100  Loss=1.6789\n",
      "[Fine-tune] Epoch 52/100  Loss=1.6906\n",
      "[Fine-tune] Epoch 53/100  Loss=1.6899\n",
      "[Fine-tune] Epoch 54/100  Loss=1.6824\n",
      "[Fine-tune] Epoch 55/100  Loss=1.6809\n",
      "[Fine-tune] Epoch 56/100  Loss=1.6770\n",
      "[Fine-tune] Epoch 57/100  Loss=1.6907\n",
      "[Fine-tune] Epoch 58/100  Loss=1.6628\n",
      "[Fine-tune] Epoch 59/100  Loss=1.6867\n",
      "[Fine-tune] Epoch 60/100  Loss=1.6733\n",
      "[Fine-tune] Epoch 61/100  Loss=1.6723\n",
      "[Fine-tune] Epoch 62/100  Loss=1.6563\n",
      "[Fine-tune] Epoch 63/100  Loss=1.6764\n",
      "[Fine-tune] Epoch 64/100  Loss=1.6696\n",
      "[Fine-tune] Epoch 65/100  Loss=1.6657\n",
      "[Fine-tune] Epoch 66/100  Loss=1.6593\n",
      "[Fine-tune] Epoch 67/100  Loss=1.6595\n",
      "[Fine-tune] Epoch 68/100  Loss=1.6609\n",
      "[Fine-tune] Epoch 69/100  Loss=1.6553\n",
      "[Fine-tune] Epoch 70/100  Loss=1.6666\n",
      "[Fine-tune] Epoch 71/100  Loss=1.6721\n",
      "[Fine-tune] Epoch 72/100  Loss=1.6751\n",
      "[Fine-tune] Epoch 73/100  Loss=1.6534\n",
      "[Fine-tune] Epoch 74/100  Loss=1.6572\n",
      "[Fine-tune] Epoch 75/100  Loss=1.6661\n",
      "[Fine-tune] Epoch 76/100  Loss=1.6626\n",
      "[Fine-tune] Epoch 77/100  Loss=1.6579\n",
      "[Fine-tune] Epoch 78/100  Loss=1.6712\n",
      "[Fine-tune] Epoch 79/100  Loss=1.6507\n",
      "[Fine-tune] Epoch 80/100  Loss=1.6642\n",
      "[Fine-tune] Epoch 81/100  Loss=1.6586\n",
      "[Fine-tune] Epoch 82/100  Loss=1.6577\n",
      "[Fine-tune] Epoch 83/100  Loss=1.6597\n",
      "[Fine-tune] Epoch 84/100  Loss=1.6476\n",
      "[Fine-tune] Epoch 85/100  Loss=1.6592\n",
      "[Fine-tune] Epoch 86/100  Loss=1.6544\n",
      "[Fine-tune] Epoch 87/100  Loss=1.6524\n",
      "[Fine-tune] Epoch 88/100  Loss=1.6596\n",
      "[Fine-tune] Epoch 89/100  Loss=1.6564\n",
      "[Fine-tune] Epoch 90/100  Loss=1.6560\n",
      "[Fine-tune] Epoch 91/100  Loss=1.6570\n",
      "[Fine-tune] Epoch 92/100  Loss=1.6517\n",
      "[Fine-tune] Epoch 93/100  Loss=1.6548\n",
      "[Fine-tune] Epoch 94/100  Loss=1.6505\n",
      "[Fine-tune] Epoch 95/100  Loss=1.6448\n",
      "[Fine-tune] Epoch 96/100  Loss=1.6517\n",
      "[Fine-tune] Epoch 97/100  Loss=1.6572\n",
      "[Fine-tune] Epoch 98/100  Loss=1.6572\n",
      "[Fine-tune] Epoch 99/100  Loss=1.6531\n",
      "[Fine-tune] Epoch 100/100  Loss=1.6569\n",
      "[Pretrain] Epoch 1/50  Loss=3.2165  Acc=0.0557\n",
      "[Pretrain] Epoch 2/50  Loss=3.0686  Acc=0.0805\n",
      "[Pretrain] Epoch 3/50  Loss=3.0254  Acc=0.0875\n",
      "[Pretrain] Epoch 4/50  Loss=2.8209  Acc=0.1351\n",
      "[Pretrain] Epoch 5/50  Loss=2.5850  Acc=0.1823\n",
      "[Pretrain] Epoch 6/50  Loss=2.3824  Acc=0.2460\n",
      "[Pretrain] Epoch 7/50  Loss=2.2423  Acc=0.2728\n",
      "[Pretrain] Epoch 8/50  Loss=2.1498  Acc=0.3053\n",
      "[Pretrain] Epoch 9/50  Loss=2.1129  Acc=0.3080\n",
      "[Pretrain] Epoch 10/50  Loss=2.0628  Acc=0.3299\n",
      "[Pretrain] Epoch 11/50  Loss=2.0289  Acc=0.3339\n",
      "[Pretrain] Epoch 12/50  Loss=1.9886  Acc=0.3466\n",
      "[Pretrain] Epoch 13/50  Loss=1.9450  Acc=0.3639\n",
      "[Pretrain] Epoch 14/50  Loss=1.9174  Acc=0.3741\n",
      "[Pretrain] Epoch 15/50  Loss=1.8949  Acc=0.3939\n",
      "[Pretrain] Epoch 16/50  Loss=1.8820  Acc=0.3881\n",
      "[Pretrain] Epoch 17/50  Loss=1.8441  Acc=0.4037\n",
      "[Pretrain] Epoch 18/50  Loss=1.8293  Acc=0.4023\n",
      "[Pretrain] Epoch 19/50  Loss=1.7939  Acc=0.4176\n",
      "[Pretrain] Epoch 20/50  Loss=1.7800  Acc=0.4167\n",
      "[Pretrain] Epoch 21/50  Loss=1.7518  Acc=0.4287\n",
      "[Pretrain] Epoch 22/50  Loss=1.7481  Acc=0.4328\n",
      "[Pretrain] Epoch 23/50  Loss=1.7131  Acc=0.4450\n",
      "[Pretrain] Epoch 24/50  Loss=1.7079  Acc=0.4569\n",
      "[Pretrain] Epoch 25/50  Loss=1.6760  Acc=0.4607\n",
      "[Pretrain] Epoch 26/50  Loss=1.6627  Acc=0.4657\n",
      "[Pretrain] Epoch 27/50  Loss=1.6390  Acc=0.4662\n",
      "[Pretrain] Epoch 28/50  Loss=1.6121  Acc=0.4759\n",
      "[Pretrain] Epoch 29/50  Loss=1.5971  Acc=0.4813\n",
      "[Pretrain] Epoch 30/50  Loss=1.5734  Acc=0.4917\n",
      "[Pretrain] Epoch 31/50  Loss=1.5415  Acc=0.5075\n",
      "[Pretrain] Epoch 32/50  Loss=1.5546  Acc=0.4964\n",
      "[Pretrain] Epoch 33/50  Loss=1.5425  Acc=0.4998\n",
      "[Pretrain] Epoch 34/50  Loss=1.5228  Acc=0.5099\n",
      "[Pretrain] Epoch 35/50  Loss=1.5063  Acc=0.5133\n",
      "[Pretrain] Epoch 36/50  Loss=1.4998  Acc=0.5101\n",
      "[Pretrain] Epoch 37/50  Loss=1.4908  Acc=0.5162\n",
      "[Pretrain] Epoch 38/50  Loss=1.4704  Acc=0.5250\n",
      "[Pretrain] Epoch 39/50  Loss=1.4918  Acc=0.5203\n",
      "[Pretrain] Epoch 40/50  Loss=1.4592  Acc=0.5230\n",
      "[Pretrain] Epoch 41/50  Loss=1.4388  Acc=0.5366\n",
      "[Pretrain] Epoch 42/50  Loss=1.4347  Acc=0.5384\n",
      "[Pretrain] Epoch 43/50  Loss=1.4085  Acc=0.5406\n",
      "[Pretrain] Epoch 44/50  Loss=1.4203  Acc=0.5379\n",
      "[Pretrain] Epoch 45/50  Loss=1.4092  Acc=0.5393\n",
      "[Pretrain] Epoch 46/50  Loss=1.3909  Acc=0.5449\n",
      "[Pretrain] Epoch 47/50  Loss=1.3893  Acc=0.5406\n",
      "[Pretrain] Epoch 48/50  Loss=1.3790  Acc=0.5517\n",
      "[Pretrain] Epoch 49/50  Loss=1.3771  Acc=0.5553\n",
      "[Pretrain] Epoch 50/50  Loss=1.3870  Acc=0.5460\n",
      "[Fine-tune] Epoch 1/100  Loss=3.2929\n",
      "[Fine-tune] Epoch 2/100  Loss=3.1260\n",
      "[Fine-tune] Epoch 3/100  Loss=3.0771\n",
      "[Fine-tune] Epoch 4/100  Loss=3.0662\n",
      "[Fine-tune] Epoch 5/100  Loss=3.0145\n",
      "[Fine-tune] Epoch 6/100  Loss=2.8894\n",
      "[Fine-tune] Epoch 7/100  Loss=2.7992\n",
      "[Fine-tune] Epoch 8/100  Loss=2.6730\n",
      "[Fine-tune] Epoch 9/100  Loss=2.5290\n",
      "[Fine-tune] Epoch 10/100  Loss=2.4710\n",
      "[Fine-tune] Epoch 11/100  Loss=2.4211\n",
      "[Fine-tune] Epoch 12/100  Loss=2.3530\n",
      "[Fine-tune] Epoch 13/100  Loss=2.2953\n",
      "[Fine-tune] Epoch 14/100  Loss=2.2587\n",
      "[Fine-tune] Epoch 15/100  Loss=2.2421\n",
      "[Fine-tune] Epoch 16/100  Loss=2.1852\n",
      "[Fine-tune] Epoch 17/100  Loss=2.1556\n",
      "[Fine-tune] Epoch 18/100  Loss=2.1526\n",
      "[Fine-tune] Epoch 19/100  Loss=2.1017\n",
      "[Fine-tune] Epoch 20/100  Loss=2.0603\n",
      "[Fine-tune] Epoch 21/100  Loss=2.0552\n",
      "[Fine-tune] Epoch 22/100  Loss=2.0290\n",
      "[Fine-tune] Epoch 23/100  Loss=2.0035\n",
      "[Fine-tune] Epoch 24/100  Loss=1.9690\n",
      "[Fine-tune] Epoch 25/100  Loss=1.9583\n",
      "[Fine-tune] Epoch 26/100  Loss=1.9396\n",
      "[Fine-tune] Epoch 27/100  Loss=1.8996\n",
      "[Fine-tune] Epoch 28/100  Loss=1.9060\n",
      "[Fine-tune] Epoch 29/100  Loss=1.8939\n",
      "[Fine-tune] Epoch 30/100  Loss=1.8502\n",
      "[Fine-tune] Epoch 31/100  Loss=1.8310\n",
      "[Fine-tune] Epoch 32/100  Loss=1.8287\n",
      "[Fine-tune] Epoch 33/100  Loss=1.7917\n",
      "[Fine-tune] Epoch 34/100  Loss=1.7601\n",
      "[Fine-tune] Epoch 35/100  Loss=1.7599\n",
      "[Fine-tune] Epoch 36/100  Loss=1.7477\n",
      "[Fine-tune] Epoch 37/100  Loss=1.7504\n",
      "[Fine-tune] Epoch 38/100  Loss=1.6955\n",
      "[Fine-tune] Epoch 39/100  Loss=1.7040\n",
      "[Fine-tune] Epoch 40/100  Loss=1.6776\n",
      "[Fine-tune] Epoch 41/100  Loss=1.6771\n",
      "[Fine-tune] Epoch 42/100  Loss=1.6584\n",
      "[Fine-tune] Epoch 43/100  Loss=1.6597\n",
      "[Fine-tune] Epoch 44/100  Loss=1.6368\n",
      "[Fine-tune] Epoch 45/100  Loss=1.6229\n",
      "[Fine-tune] Epoch 46/100  Loss=1.6008\n",
      "[Fine-tune] Epoch 47/100  Loss=1.5982\n",
      "[Fine-tune] Epoch 48/100  Loss=1.5928\n",
      "[Fine-tune] Epoch 49/100  Loss=1.5698\n",
      "[Fine-tune] Epoch 50/100  Loss=1.5549\n",
      "[Fine-tune] Epoch 51/100  Loss=1.5520\n",
      "[Fine-tune] Epoch 52/100  Loss=1.5477\n",
      "[Fine-tune] Epoch 53/100  Loss=1.5216\n",
      "[Fine-tune] Epoch 54/100  Loss=1.5432\n",
      "[Fine-tune] Epoch 55/100  Loss=1.5156\n",
      "[Fine-tune] Epoch 56/100  Loss=1.5037\n",
      "[Fine-tune] Epoch 57/100  Loss=1.4957\n",
      "[Fine-tune] Epoch 58/100  Loss=1.5152\n",
      "[Fine-tune] Epoch 59/100  Loss=1.4890\n",
      "[Fine-tune] Epoch 60/100  Loss=1.4866\n",
      "[Fine-tune] Epoch 61/100  Loss=1.4874\n",
      "[Fine-tune] Epoch 62/100  Loss=1.4715\n",
      "[Fine-tune] Epoch 63/100  Loss=1.4843\n",
      "[Fine-tune] Epoch 64/100  Loss=1.4764\n",
      "[Fine-tune] Epoch 65/100  Loss=1.4523\n",
      "[Fine-tune] Epoch 66/100  Loss=1.4421\n",
      "[Fine-tune] Epoch 67/100  Loss=1.4494\n",
      "[Fine-tune] Epoch 68/100  Loss=1.4516\n",
      "[Fine-tune] Epoch 69/100  Loss=1.4611\n",
      "[Fine-tune] Epoch 70/100  Loss=1.4248\n",
      "[Fine-tune] Epoch 71/100  Loss=1.4580\n",
      "[Fine-tune] Epoch 72/100  Loss=1.4405\n",
      "[Fine-tune] Epoch 73/100  Loss=1.4343\n",
      "[Fine-tune] Epoch 74/100  Loss=1.4226\n",
      "[Fine-tune] Epoch 75/100  Loss=1.4325\n",
      "[Fine-tune] Epoch 76/100  Loss=1.4113\n",
      "[Fine-tune] Epoch 77/100  Loss=1.4162\n",
      "[Fine-tune] Epoch 78/100  Loss=1.4208\n",
      "[Fine-tune] Epoch 79/100  Loss=1.4213\n",
      "[Fine-tune] Epoch 80/100  Loss=1.4044\n",
      "[Fine-tune] Epoch 81/100  Loss=1.4054\n",
      "[Fine-tune] Epoch 82/100  Loss=1.4211\n",
      "[Fine-tune] Epoch 83/100  Loss=1.4168\n",
      "[Fine-tune] Epoch 84/100  Loss=1.4071\n",
      "[Fine-tune] Epoch 85/100  Loss=1.3935\n",
      "[Fine-tune] Epoch 86/100  Loss=1.3899\n",
      "[Fine-tune] Epoch 87/100  Loss=1.4111\n",
      "[Fine-tune] Epoch 88/100  Loss=1.4021\n",
      "[Fine-tune] Epoch 89/100  Loss=1.3977\n",
      "[Fine-tune] Epoch 90/100  Loss=1.3982\n",
      "[Fine-tune] Epoch 91/100  Loss=1.3981\n",
      "[Fine-tune] Epoch 92/100  Loss=1.3903\n",
      "[Fine-tune] Epoch 93/100  Loss=1.3851\n",
      "[Fine-tune] Epoch 94/100  Loss=1.3824\n",
      "[Fine-tune] Epoch 95/100  Loss=1.3897\n",
      "[Fine-tune] Epoch 96/100  Loss=1.4022\n",
      "[Fine-tune] Epoch 97/100  Loss=1.3967\n",
      "[Fine-tune] Epoch 98/100  Loss=1.3948\n",
      "[Fine-tune] Epoch 99/100  Loss=1.3922\n",
      "[Fine-tune] Epoch 100/100  Loss=1.3863\n",
      "[Pretrain] Epoch 1/50  Loss=3.7424  Acc=0.0392\n",
      "[Pretrain] Epoch 2/50  Loss=3.1214  Acc=0.0677\n",
      "[Pretrain] Epoch 3/50  Loss=3.0385  Acc=0.0846\n",
      "[Pretrain] Epoch 4/50  Loss=2.9788  Acc=0.0905\n",
      "[Pretrain] Epoch 5/50  Loss=2.7827  Acc=0.1297\n",
      "[Pretrain] Epoch 6/50  Loss=2.5804  Acc=0.1762\n",
      "[Pretrain] Epoch 7/50  Loss=2.4765  Acc=0.2055\n",
      "[Pretrain] Epoch 8/50  Loss=2.3918  Acc=0.2355\n",
      "[Pretrain] Epoch 9/50  Loss=2.2833  Acc=0.2649\n",
      "[Pretrain] Epoch 10/50  Loss=2.2250  Acc=0.2807\n",
      "[Pretrain] Epoch 11/50  Loss=2.1799  Acc=0.2951\n",
      "[Pretrain] Epoch 12/50  Loss=2.1428  Acc=0.3035\n",
      "[Pretrain] Epoch 13/50  Loss=2.0884  Acc=0.3218\n",
      "[Pretrain] Epoch 14/50  Loss=2.0638  Acc=0.3323\n",
      "[Pretrain] Epoch 15/50  Loss=1.9933  Acc=0.3488\n",
      "[Pretrain] Epoch 16/50  Loss=2.0032  Acc=0.3515\n",
      "[Pretrain] Epoch 17/50  Loss=1.9676  Acc=0.3549\n",
      "[Pretrain] Epoch 18/50  Loss=1.9558  Acc=0.3671\n",
      "[Pretrain] Epoch 19/50  Loss=1.8959  Acc=0.3784\n",
      "[Pretrain] Epoch 20/50  Loss=1.8701  Acc=0.3912\n",
      "[Pretrain] Epoch 21/50  Loss=1.8359  Acc=0.4003\n",
      "[Pretrain] Epoch 22/50  Loss=1.8154  Acc=0.4045\n",
      "[Pretrain] Epoch 23/50  Loss=1.7837  Acc=0.4097\n",
      "[Pretrain] Epoch 24/50  Loss=1.7562  Acc=0.4298\n",
      "[Pretrain] Epoch 25/50  Loss=1.7520  Acc=0.4310\n",
      "[Pretrain] Epoch 26/50  Loss=1.7232  Acc=0.4397\n",
      "[Pretrain] Epoch 27/50  Loss=1.7001  Acc=0.4519\n",
      "[Pretrain] Epoch 28/50  Loss=1.6695  Acc=0.4537\n",
      "[Pretrain] Epoch 29/50  Loss=1.6495  Acc=0.4626\n",
      "[Pretrain] Epoch 30/50  Loss=1.6305  Acc=0.4666\n",
      "[Pretrain] Epoch 31/50  Loss=1.6095  Acc=0.4668\n",
      "[Pretrain] Epoch 32/50  Loss=1.5830  Acc=0.4813\n",
      "[Pretrain] Epoch 33/50  Loss=1.5811  Acc=0.4862\n",
      "[Pretrain] Epoch 34/50  Loss=1.5502  Acc=0.4896\n",
      "[Pretrain] Epoch 35/50  Loss=1.5078  Acc=0.5036\n",
      "[Pretrain] Epoch 36/50  Loss=1.4934  Acc=0.5115\n",
      "[Pretrain] Epoch 37/50  Loss=1.4929  Acc=0.5084\n",
      "[Pretrain] Epoch 38/50  Loss=1.4564  Acc=0.5169\n",
      "[Pretrain] Epoch 39/50  Loss=1.4208  Acc=0.5341\n",
      "[Pretrain] Epoch 40/50  Loss=1.4196  Acc=0.5402\n",
      "[Pretrain] Epoch 41/50  Loss=1.4091  Acc=0.5363\n",
      "[Pretrain] Epoch 42/50  Loss=1.3963  Acc=0.5388\n",
      "[Pretrain] Epoch 43/50  Loss=1.3578  Acc=0.5483\n",
      "[Pretrain] Epoch 44/50  Loss=1.3222  Acc=0.5623\n",
      "[Pretrain] Epoch 45/50  Loss=1.3425  Acc=0.5632\n",
      "[Pretrain] Epoch 46/50  Loss=1.3355  Acc=0.5638\n",
      "[Pretrain] Epoch 47/50  Loss=1.3099  Acc=0.5733\n",
      "[Pretrain] Epoch 48/50  Loss=1.2996  Acc=0.5722\n",
      "[Pretrain] Epoch 49/50  Loss=1.2776  Acc=0.5891\n",
      "[Pretrain] Epoch 50/50  Loss=1.2719  Acc=0.5814\n",
      "[Fine-tune] Epoch 1/100  Loss=3.3297\n",
      "[Fine-tune] Epoch 2/100  Loss=3.0324\n",
      "[Fine-tune] Epoch 3/100  Loss=2.7268\n",
      "[Fine-tune] Epoch 4/100  Loss=2.6219\n",
      "[Fine-tune] Epoch 5/100  Loss=2.4937\n",
      "[Fine-tune] Epoch 6/100  Loss=2.4207\n",
      "[Fine-tune] Epoch 7/100  Loss=2.3436\n",
      "[Fine-tune] Epoch 8/100  Loss=2.2953\n",
      "[Fine-tune] Epoch 9/100  Loss=2.2702\n",
      "[Fine-tune] Epoch 10/100  Loss=2.2237\n",
      "[Fine-tune] Epoch 11/100  Loss=2.1779\n",
      "[Fine-tune] Epoch 12/100  Loss=2.1508\n",
      "[Fine-tune] Epoch 13/100  Loss=2.1226\n",
      "[Fine-tune] Epoch 14/100  Loss=2.1065\n",
      "[Fine-tune] Epoch 15/100  Loss=2.0694\n",
      "[Fine-tune] Epoch 16/100  Loss=2.0532\n",
      "[Fine-tune] Epoch 17/100  Loss=2.0347\n",
      "[Fine-tune] Epoch 18/100  Loss=1.9987\n",
      "[Fine-tune] Epoch 19/100  Loss=1.9898\n",
      "[Fine-tune] Epoch 20/100  Loss=1.9797\n",
      "[Fine-tune] Epoch 21/100  Loss=1.9584\n",
      "[Fine-tune] Epoch 22/100  Loss=1.9334\n",
      "[Fine-tune] Epoch 23/100  Loss=1.9206\n",
      "[Fine-tune] Epoch 24/100  Loss=1.9020\n",
      "[Fine-tune] Epoch 25/100  Loss=1.8715\n",
      "[Fine-tune] Epoch 26/100  Loss=1.8734\n",
      "[Fine-tune] Epoch 27/100  Loss=1.8566\n",
      "[Fine-tune] Epoch 28/100  Loss=1.8416\n",
      "[Fine-tune] Epoch 29/100  Loss=1.8259\n",
      "[Fine-tune] Epoch 30/100  Loss=1.8151\n",
      "[Fine-tune] Epoch 31/100  Loss=1.8061\n",
      "[Fine-tune] Epoch 32/100  Loss=1.7967\n",
      "[Fine-tune] Epoch 33/100  Loss=1.7893\n",
      "[Fine-tune] Epoch 34/100  Loss=1.7567\n",
      "[Fine-tune] Epoch 35/100  Loss=1.7494\n",
      "[Fine-tune] Epoch 36/100  Loss=1.7296\n",
      "[Fine-tune] Epoch 37/100  Loss=1.7333\n",
      "[Fine-tune] Epoch 38/100  Loss=1.7078\n",
      "[Fine-tune] Epoch 39/100  Loss=1.7122\n",
      "[Fine-tune] Epoch 40/100  Loss=1.6880\n",
      "[Fine-tune] Epoch 41/100  Loss=1.6925\n",
      "[Fine-tune] Epoch 42/100  Loss=1.6891\n",
      "[Fine-tune] Epoch 43/100  Loss=1.6591\n",
      "[Fine-tune] Epoch 44/100  Loss=1.6578\n",
      "[Fine-tune] Epoch 45/100  Loss=1.6542\n",
      "[Fine-tune] Epoch 46/100  Loss=1.6406\n",
      "[Fine-tune] Epoch 47/100  Loss=1.6413\n",
      "[Fine-tune] Epoch 48/100  Loss=1.6154\n",
      "[Fine-tune] Epoch 49/100  Loss=1.6163\n",
      "[Fine-tune] Epoch 50/100  Loss=1.6116\n",
      "[Fine-tune] Epoch 51/100  Loss=1.6138\n",
      "[Fine-tune] Epoch 52/100  Loss=1.6195\n",
      "[Fine-tune] Epoch 53/100  Loss=1.5957\n",
      "[Fine-tune] Epoch 54/100  Loss=1.5922\n",
      "[Fine-tune] Epoch 55/100  Loss=1.5890\n",
      "[Fine-tune] Epoch 56/100  Loss=1.5713\n",
      "[Fine-tune] Epoch 57/100  Loss=1.5777\n",
      "[Fine-tune] Epoch 58/100  Loss=1.5620\n",
      "[Fine-tune] Epoch 59/100  Loss=1.5787\n",
      "[Fine-tune] Epoch 60/100  Loss=1.5742\n",
      "[Fine-tune] Epoch 61/100  Loss=1.5692\n",
      "[Fine-tune] Epoch 62/100  Loss=1.5584\n",
      "[Fine-tune] Epoch 63/100  Loss=1.5487\n",
      "[Fine-tune] Epoch 64/100  Loss=1.5454\n",
      "[Fine-tune] Epoch 65/100  Loss=1.5600\n",
      "[Fine-tune] Epoch 66/100  Loss=1.5627\n",
      "[Fine-tune] Epoch 67/100  Loss=1.5513\n",
      "[Fine-tune] Epoch 68/100  Loss=1.5557\n",
      "[Fine-tune] Epoch 69/100  Loss=1.5395\n",
      "[Fine-tune] Epoch 70/100  Loss=1.5335\n",
      "[Fine-tune] Epoch 71/100  Loss=1.5398\n",
      "[Fine-tune] Epoch 72/100  Loss=1.5430\n",
      "[Fine-tune] Epoch 73/100  Loss=1.5249\n",
      "[Fine-tune] Epoch 74/100  Loss=1.5270\n",
      "[Fine-tune] Epoch 75/100  Loss=1.5311\n",
      "[Fine-tune] Epoch 76/100  Loss=1.5270\n",
      "[Fine-tune] Epoch 77/100  Loss=1.5217\n",
      "[Fine-tune] Epoch 78/100  Loss=1.5311\n",
      "[Fine-tune] Epoch 79/100  Loss=1.5355\n",
      "[Fine-tune] Epoch 80/100  Loss=1.5251\n",
      "[Fine-tune] Epoch 81/100  Loss=1.5139\n",
      "[Fine-tune] Epoch 82/100  Loss=1.5187\n",
      "[Fine-tune] Epoch 83/100  Loss=1.5337\n",
      "[Fine-tune] Epoch 84/100  Loss=1.5241\n",
      "[Fine-tune] Epoch 85/100  Loss=1.5036\n",
      "[Fine-tune] Epoch 86/100  Loss=1.5143\n",
      "[Fine-tune] Epoch 87/100  Loss=1.5115\n",
      "[Fine-tune] Epoch 88/100  Loss=1.5112\n",
      "[Fine-tune] Epoch 89/100  Loss=1.5149\n",
      "[Fine-tune] Epoch 90/100  Loss=1.5199\n",
      "[Fine-tune] Epoch 91/100  Loss=1.4961\n",
      "[Fine-tune] Epoch 92/100  Loss=1.5159\n",
      "[Fine-tune] Epoch 93/100  Loss=1.5035\n",
      "[Fine-tune] Epoch 94/100  Loss=1.5045\n",
      "[Fine-tune] Epoch 95/100  Loss=1.5048\n",
      "[Fine-tune] Epoch 96/100  Loss=1.5125\n",
      "[Fine-tune] Epoch 97/100  Loss=1.5107\n",
      "[Fine-tune] Epoch 98/100  Loss=1.5235\n",
      "[Fine-tune] Epoch 99/100  Loss=1.5079\n",
      "[Fine-tune] Epoch 100/100  Loss=1.5059\n",
      "[Pretrain] Epoch 1/75  Loss=3.2379  Acc=0.0440\n",
      "[Pretrain] Epoch 2/75  Loss=3.0914  Acc=0.0785\n",
      "[Pretrain] Epoch 3/75  Loss=3.0362  Acc=0.0860\n",
      "[Pretrain] Epoch 4/75  Loss=2.7727  Acc=0.1378\n",
      "[Pretrain] Epoch 5/75  Loss=2.5883  Acc=0.1724\n",
      "[Pretrain] Epoch 6/75  Loss=2.4301  Acc=0.2164\n",
      "[Pretrain] Epoch 7/75  Loss=2.3075  Acc=0.2601\n",
      "[Pretrain] Epoch 8/75  Loss=2.2422  Acc=0.2804\n",
      "[Pretrain] Epoch 9/75  Loss=2.1453  Acc=0.3024\n",
      "[Pretrain] Epoch 10/75  Loss=2.0902  Acc=0.3231\n",
      "[Pretrain] Epoch 11/75  Loss=2.0470  Acc=0.3314\n",
      "[Pretrain] Epoch 12/75  Loss=2.0214  Acc=0.3341\n",
      "[Pretrain] Epoch 13/75  Loss=1.9894  Acc=0.3481\n",
      "[Pretrain] Epoch 14/75  Loss=1.9677  Acc=0.3635\n",
      "[Pretrain] Epoch 15/75  Loss=1.9318  Acc=0.3684\n",
      "[Pretrain] Epoch 16/75  Loss=1.8962  Acc=0.3829\n",
      "[Pretrain] Epoch 17/75  Loss=1.8736  Acc=0.3852\n",
      "[Pretrain] Epoch 18/75  Loss=1.8505  Acc=0.4003\n",
      "[Pretrain] Epoch 19/75  Loss=1.8320  Acc=0.4057\n",
      "[Pretrain] Epoch 20/75  Loss=1.8129  Acc=0.4084\n",
      "[Pretrain] Epoch 21/75  Loss=1.7966  Acc=0.4188\n",
      "[Pretrain] Epoch 22/75  Loss=1.7584  Acc=0.4309\n",
      "[Pretrain] Epoch 23/75  Loss=1.7505  Acc=0.4314\n",
      "[Pretrain] Epoch 24/75  Loss=1.7315  Acc=0.4278\n",
      "[Pretrain] Epoch 25/75  Loss=1.7053  Acc=0.4467\n",
      "[Pretrain] Epoch 26/75  Loss=1.7042  Acc=0.4510\n",
      "[Pretrain] Epoch 27/75  Loss=1.6752  Acc=0.4547\n",
      "[Pretrain] Epoch 28/75  Loss=1.6645  Acc=0.4655\n",
      "[Pretrain] Epoch 29/75  Loss=1.6464  Acc=0.4682\n",
      "[Pretrain] Epoch 30/75  Loss=1.6559  Acc=0.4601\n",
      "[Pretrain] Epoch 31/75  Loss=1.6175  Acc=0.4783\n",
      "[Pretrain] Epoch 32/75  Loss=1.6044  Acc=0.4738\n",
      "[Pretrain] Epoch 33/75  Loss=1.5915  Acc=0.4838\n",
      "[Pretrain] Epoch 34/75  Loss=1.5727  Acc=0.4840\n",
      "[Pretrain] Epoch 35/75  Loss=1.5645  Acc=0.4890\n",
      "[Pretrain] Epoch 36/75  Loss=1.5592  Acc=0.4941\n",
      "[Pretrain] Epoch 37/75  Loss=1.5422  Acc=0.4987\n",
      "[Pretrain] Epoch 38/75  Loss=1.5521  Acc=0.4944\n",
      "[Pretrain] Epoch 39/75  Loss=1.5222  Acc=0.5038\n",
      "[Pretrain] Epoch 40/75  Loss=1.5184  Acc=0.5088\n",
      "[Pretrain] Epoch 41/75  Loss=1.5037  Acc=0.5138\n",
      "[Pretrain] Epoch 42/75  Loss=1.4919  Acc=0.5149\n",
      "[Pretrain] Epoch 43/75  Loss=1.4839  Acc=0.5158\n",
      "[Pretrain] Epoch 44/75  Loss=1.4607  Acc=0.5257\n",
      "[Pretrain] Epoch 45/75  Loss=1.4599  Acc=0.5291\n",
      "[Pretrain] Epoch 46/75  Loss=1.4416  Acc=0.5282\n",
      "[Pretrain] Epoch 47/75  Loss=1.4587  Acc=0.5268\n",
      "[Pretrain] Epoch 48/75  Loss=1.4452  Acc=0.5374\n",
      "[Pretrain] Epoch 49/75  Loss=1.4249  Acc=0.5359\n",
      "[Pretrain] Epoch 50/75  Loss=1.4379  Acc=0.5374\n",
      "[Pretrain] Epoch 51/75  Loss=1.4087  Acc=0.5354\n",
      "[Pretrain] Epoch 52/75  Loss=1.4034  Acc=0.5392\n",
      "[Pretrain] Epoch 53/75  Loss=1.4048  Acc=0.5478\n",
      "[Pretrain] Epoch 54/75  Loss=1.3917  Acc=0.5476\n",
      "[Pretrain] Epoch 55/75  Loss=1.3892  Acc=0.5469\n",
      "[Pretrain] Epoch 56/75  Loss=1.3917  Acc=0.5519\n",
      "[Pretrain] Epoch 57/75  Loss=1.4026  Acc=0.5460\n",
      "[Pretrain] Epoch 58/75  Loss=1.3868  Acc=0.5523\n",
      "[Pretrain] Epoch 59/75  Loss=1.3881  Acc=0.5566\n",
      "[Pretrain] Epoch 60/75  Loss=1.3799  Acc=0.5515\n",
      "[Pretrain] Epoch 61/75  Loss=1.3797  Acc=0.5456\n",
      "[Pretrain] Epoch 62/75  Loss=1.3753  Acc=0.5512\n",
      "[Pretrain] Epoch 63/75  Loss=1.3826  Acc=0.5550\n",
      "[Pretrain] Epoch 64/75  Loss=1.3727  Acc=0.5510\n",
      "[Pretrain] Epoch 65/75  Loss=1.3627  Acc=0.5517\n",
      "[Pretrain] Epoch 66/75  Loss=1.3492  Acc=0.5647\n",
      "[Pretrain] Epoch 67/75  Loss=1.3685  Acc=0.5530\n",
      "[Pretrain] Epoch 68/75  Loss=1.3560  Acc=0.5643\n",
      "[Pretrain] Epoch 69/75  Loss=1.3357  Acc=0.5641\n",
      "[Pretrain] Epoch 70/75  Loss=1.3479  Acc=0.5542\n",
      "[Pretrain] Epoch 71/75  Loss=1.3520  Acc=0.5591\n",
      "[Pretrain] Epoch 72/75  Loss=1.3381  Acc=0.5715\n",
      "[Pretrain] Epoch 73/75  Loss=1.3501  Acc=0.5627\n",
      "[Pretrain] Epoch 74/75  Loss=1.3441  Acc=0.5587\n",
      "[Pretrain] Epoch 75/75  Loss=1.3471  Acc=0.5611\n",
      "[Fine-tune] Epoch 1/100  Loss=3.3163\n",
      "[Fine-tune] Epoch 2/100  Loss=3.1918\n",
      "[Fine-tune] Epoch 3/100  Loss=3.0927\n",
      "[Fine-tune] Epoch 4/100  Loss=3.0571\n",
      "[Fine-tune] Epoch 5/100  Loss=2.9257\n",
      "[Fine-tune] Epoch 6/100  Loss=2.7411\n",
      "[Fine-tune] Epoch 7/100  Loss=2.6630\n",
      "[Fine-tune] Epoch 8/100  Loss=2.6052\n",
      "[Fine-tune] Epoch 9/100  Loss=2.5478\n",
      "[Fine-tune] Epoch 10/100  Loss=2.4749\n",
      "[Fine-tune] Epoch 11/100  Loss=2.4091\n",
      "[Fine-tune] Epoch 12/100  Loss=2.3752\n",
      "[Fine-tune] Epoch 13/100  Loss=2.2770\n",
      "[Fine-tune] Epoch 14/100  Loss=2.2200\n",
      "[Fine-tune] Epoch 15/100  Loss=2.2134\n",
      "[Fine-tune] Epoch 16/100  Loss=2.1604\n",
      "[Fine-tune] Epoch 17/100  Loss=2.1441\n",
      "[Fine-tune] Epoch 18/100  Loss=2.1187\n",
      "[Fine-tune] Epoch 19/100  Loss=2.0881\n",
      "[Fine-tune] Epoch 20/100  Loss=2.0604\n",
      "[Fine-tune] Epoch 21/100  Loss=2.0557\n",
      "[Fine-tune] Epoch 22/100  Loss=2.0303\n",
      "[Fine-tune] Epoch 23/100  Loss=2.0176\n",
      "[Fine-tune] Epoch 24/100  Loss=1.9707\n",
      "[Fine-tune] Epoch 25/100  Loss=1.9652\n",
      "[Fine-tune] Epoch 26/100  Loss=1.9427\n",
      "[Fine-tune] Epoch 27/100  Loss=1.9348\n",
      "[Fine-tune] Epoch 28/100  Loss=1.9037\n",
      "[Fine-tune] Epoch 29/100  Loss=1.8991\n",
      "[Fine-tune] Epoch 30/100  Loss=1.8793\n",
      "[Fine-tune] Epoch 31/100  Loss=1.8558\n",
      "[Fine-tune] Epoch 32/100  Loss=1.8543\n",
      "[Fine-tune] Epoch 33/100  Loss=1.8364\n",
      "[Fine-tune] Epoch 34/100  Loss=1.8288\n",
      "[Fine-tune] Epoch 35/100  Loss=1.8107\n",
      "[Fine-tune] Epoch 36/100  Loss=1.8127\n",
      "[Fine-tune] Epoch 37/100  Loss=1.7931\n",
      "[Fine-tune] Epoch 38/100  Loss=1.7714\n",
      "[Fine-tune] Epoch 39/100  Loss=1.7642\n",
      "[Fine-tune] Epoch 40/100  Loss=1.7485\n",
      "[Fine-tune] Epoch 41/100  Loss=1.7259\n",
      "[Fine-tune] Epoch 42/100  Loss=1.7237\n",
      "[Fine-tune] Epoch 43/100  Loss=1.7380\n",
      "[Fine-tune] Epoch 44/100  Loss=1.7222\n",
      "[Fine-tune] Epoch 45/100  Loss=1.7119\n",
      "[Fine-tune] Epoch 46/100  Loss=1.6972\n",
      "[Fine-tune] Epoch 47/100  Loss=1.6814\n",
      "[Fine-tune] Epoch 48/100  Loss=1.6787\n",
      "[Fine-tune] Epoch 49/100  Loss=1.6557\n",
      "[Fine-tune] Epoch 50/100  Loss=1.6529\n",
      "[Fine-tune] Epoch 51/100  Loss=1.6490\n",
      "[Fine-tune] Epoch 52/100  Loss=1.6475\n",
      "[Fine-tune] Epoch 53/100  Loss=1.6358\n",
      "[Fine-tune] Epoch 54/100  Loss=1.6326\n",
      "[Fine-tune] Epoch 55/100  Loss=1.6247\n",
      "[Fine-tune] Epoch 56/100  Loss=1.6254\n",
      "[Fine-tune] Epoch 57/100  Loss=1.6193\n",
      "[Fine-tune] Epoch 58/100  Loss=1.6124\n",
      "[Fine-tune] Epoch 59/100  Loss=1.6105\n",
      "[Fine-tune] Epoch 60/100  Loss=1.6034\n",
      "[Fine-tune] Epoch 61/100  Loss=1.5979\n",
      "[Fine-tune] Epoch 62/100  Loss=1.5939\n",
      "[Fine-tune] Epoch 63/100  Loss=1.5914\n",
      "[Fine-tune] Epoch 64/100  Loss=1.5950\n",
      "[Fine-tune] Epoch 65/100  Loss=1.5846\n",
      "[Fine-tune] Epoch 66/100  Loss=1.5818\n",
      "[Fine-tune] Epoch 67/100  Loss=1.5800\n",
      "[Fine-tune] Epoch 68/100  Loss=1.5744\n",
      "[Fine-tune] Epoch 69/100  Loss=1.5647\n",
      "[Fine-tune] Epoch 70/100  Loss=1.5745\n",
      "[Fine-tune] Epoch 71/100  Loss=1.5780\n",
      "[Fine-tune] Epoch 72/100  Loss=1.5658\n",
      "[Fine-tune] Epoch 73/100  Loss=1.5538\n",
      "[Fine-tune] Epoch 74/100  Loss=1.5569\n",
      "[Fine-tune] Epoch 75/100  Loss=1.5544\n",
      "[Fine-tune] Epoch 76/100  Loss=1.5589\n",
      "[Fine-tune] Epoch 77/100  Loss=1.5470\n",
      "[Fine-tune] Epoch 78/100  Loss=1.5506\n",
      "[Fine-tune] Epoch 79/100  Loss=1.5469\n",
      "[Fine-tune] Epoch 80/100  Loss=1.5562\n",
      "[Fine-tune] Epoch 81/100  Loss=1.5411\n",
      "[Fine-tune] Epoch 82/100  Loss=1.5372\n",
      "[Fine-tune] Epoch 83/100  Loss=1.5424\n",
      "[Fine-tune] Epoch 84/100  Loss=1.5276\n",
      "[Fine-tune] Epoch 85/100  Loss=1.5390\n",
      "[Fine-tune] Epoch 86/100  Loss=1.5324\n",
      "[Fine-tune] Epoch 87/100  Loss=1.5428\n",
      "[Fine-tune] Epoch 88/100  Loss=1.5271\n",
      "[Fine-tune] Epoch 89/100  Loss=1.5331\n",
      "[Fine-tune] Epoch 90/100  Loss=1.5320\n",
      "[Fine-tune] Epoch 91/100  Loss=1.5356\n",
      "[Fine-tune] Epoch 92/100  Loss=1.5283\n",
      "[Fine-tune] Epoch 93/100  Loss=1.5244\n",
      "[Fine-tune] Epoch 94/100  Loss=1.5249\n",
      "[Fine-tune] Epoch 95/100  Loss=1.5300\n",
      "[Fine-tune] Epoch 96/100  Loss=1.5283\n",
      "[Fine-tune] Epoch 97/100  Loss=1.5292\n",
      "[Fine-tune] Epoch 98/100  Loss=1.5280\n",
      "[Fine-tune] Epoch 99/100  Loss=1.5208\n",
      "[Fine-tune] Epoch 100/100  Loss=1.5168\n",
      "[Pretrain] Epoch 1/75  Loss=3.6637  Acc=0.0445\n",
      "[Pretrain] Epoch 2/75  Loss=3.1131  Acc=0.0695\n",
      "[Pretrain] Epoch 3/75  Loss=2.9394  Acc=0.0990\n",
      "[Pretrain] Epoch 4/75  Loss=2.7286  Acc=0.1246\n",
      "[Pretrain] Epoch 5/75  Loss=2.6473  Acc=0.1527\n",
      "[Pretrain] Epoch 6/75  Loss=2.4818  Acc=0.2105\n",
      "[Pretrain] Epoch 7/75  Loss=2.3854  Acc=0.2392\n",
      "[Pretrain] Epoch 8/75  Loss=2.3121  Acc=0.2611\n",
      "[Pretrain] Epoch 9/75  Loss=2.2897  Acc=0.2714\n",
      "[Pretrain] Epoch 10/75  Loss=2.1986  Acc=0.2944\n",
      "[Pretrain] Epoch 11/75  Loss=2.1808  Acc=0.2967\n",
      "[Pretrain] Epoch 12/75  Loss=2.1141  Acc=0.3177\n",
      "[Pretrain] Epoch 13/75  Loss=2.0820  Acc=0.3242\n",
      "[Pretrain] Epoch 14/75  Loss=2.0544  Acc=0.3305\n",
      "[Pretrain] Epoch 15/75  Loss=2.0206  Acc=0.3515\n",
      "[Pretrain] Epoch 16/75  Loss=2.0040  Acc=0.3490\n",
      "[Pretrain] Epoch 17/75  Loss=1.9861  Acc=0.3558\n",
      "[Pretrain] Epoch 18/75  Loss=1.9506  Acc=0.3649\n",
      "[Pretrain] Epoch 19/75  Loss=1.9233  Acc=0.3684\n",
      "[Pretrain] Epoch 20/75  Loss=1.8752  Acc=0.3883\n",
      "[Pretrain] Epoch 21/75  Loss=1.8640  Acc=0.3870\n",
      "[Pretrain] Epoch 22/75  Loss=1.8381  Acc=0.4059\n",
      "[Pretrain] Epoch 23/75  Loss=1.8190  Acc=0.4046\n",
      "[Pretrain] Epoch 24/75  Loss=1.7970  Acc=0.4163\n",
      "[Pretrain] Epoch 25/75  Loss=1.7897  Acc=0.4136\n",
      "[Pretrain] Epoch 26/75  Loss=1.7664  Acc=0.4237\n",
      "[Pretrain] Epoch 27/75  Loss=1.7140  Acc=0.4361\n",
      "[Pretrain] Epoch 28/75  Loss=1.6975  Acc=0.4449\n",
      "[Pretrain] Epoch 29/75  Loss=1.6614  Acc=0.4558\n",
      "[Pretrain] Epoch 30/75  Loss=1.6664  Acc=0.4648\n",
      "[Pretrain] Epoch 31/75  Loss=1.6369  Acc=0.4592\n",
      "[Pretrain] Epoch 32/75  Loss=1.6177  Acc=0.4696\n",
      "[Pretrain] Epoch 33/75  Loss=1.6002  Acc=0.4810\n",
      "[Pretrain] Epoch 34/75  Loss=1.5828  Acc=0.4824\n",
      "[Pretrain] Epoch 35/75  Loss=1.5717  Acc=0.4840\n",
      "[Pretrain] Epoch 36/75  Loss=1.5445  Acc=0.4957\n",
      "[Pretrain] Epoch 37/75  Loss=1.5166  Acc=0.5014\n",
      "[Pretrain] Epoch 38/75  Loss=1.5172  Acc=0.5036\n",
      "[Pretrain] Epoch 39/75  Loss=1.4910  Acc=0.5174\n",
      "[Pretrain] Epoch 40/75  Loss=1.4819  Acc=0.5171\n",
      "[Pretrain] Epoch 41/75  Loss=1.4423  Acc=0.5289\n",
      "[Pretrain] Epoch 42/75  Loss=1.4367  Acc=0.5287\n",
      "[Pretrain] Epoch 43/75  Loss=1.4216  Acc=0.5356\n",
      "[Pretrain] Epoch 44/75  Loss=1.3919  Acc=0.5462\n",
      "[Pretrain] Epoch 45/75  Loss=1.3992  Acc=0.5397\n",
      "[Pretrain] Epoch 46/75  Loss=1.3573  Acc=0.5512\n",
      "[Pretrain] Epoch 47/75  Loss=1.3533  Acc=0.5506\n",
      "[Pretrain] Epoch 48/75  Loss=1.3642  Acc=0.5487\n",
      "[Pretrain] Epoch 49/75  Loss=1.3343  Acc=0.5663\n",
      "[Pretrain] Epoch 50/75  Loss=1.3337  Acc=0.5551\n",
      "[Pretrain] Epoch 51/75  Loss=1.3114  Acc=0.5695\n",
      "[Pretrain] Epoch 52/75  Loss=1.3076  Acc=0.5740\n",
      "[Pretrain] Epoch 53/75  Loss=1.2984  Acc=0.5767\n",
      "[Pretrain] Epoch 54/75  Loss=1.2859  Acc=0.5808\n",
      "[Pretrain] Epoch 55/75  Loss=1.3015  Acc=0.5744\n",
      "[Pretrain] Epoch 56/75  Loss=1.2582  Acc=0.5930\n",
      "[Pretrain] Epoch 57/75  Loss=1.2537  Acc=0.5893\n",
      "[Pretrain] Epoch 58/75  Loss=1.2508  Acc=0.5875\n",
      "[Pretrain] Epoch 59/75  Loss=1.2410  Acc=0.5972\n",
      "[Pretrain] Epoch 60/75  Loss=1.2267  Acc=0.5970\n",
      "[Pretrain] Epoch 61/75  Loss=1.2348  Acc=0.5961\n",
      "[Pretrain] Epoch 62/75  Loss=1.2110  Acc=0.6034\n",
      "[Pretrain] Epoch 63/75  Loss=1.2277  Acc=0.5991\n",
      "[Pretrain] Epoch 64/75  Loss=1.2230  Acc=0.5973\n",
      "[Pretrain] Epoch 65/75  Loss=1.2189  Acc=0.6020\n",
      "[Pretrain] Epoch 66/75  Loss=1.2033  Acc=0.6002\n",
      "[Pretrain] Epoch 67/75  Loss=1.1974  Acc=0.6078\n",
      "[Pretrain] Epoch 68/75  Loss=1.1975  Acc=0.6067\n",
      "[Pretrain] Epoch 69/75  Loss=1.1993  Acc=0.6101\n",
      "[Pretrain] Epoch 70/75  Loss=1.1803  Acc=0.6133\n",
      "[Pretrain] Epoch 71/75  Loss=1.1792  Acc=0.6108\n",
      "[Pretrain] Epoch 72/75  Loss=1.1747  Acc=0.6148\n",
      "[Pretrain] Epoch 73/75  Loss=1.1858  Acc=0.6157\n",
      "[Pretrain] Epoch 74/75  Loss=1.1702  Acc=0.6189\n",
      "[Pretrain] Epoch 75/75  Loss=1.1594  Acc=0.6160\n",
      "[Fine-tune] Epoch 1/100  Loss=3.2937\n",
      "[Fine-tune] Epoch 2/100  Loss=3.0913\n",
      "[Fine-tune] Epoch 3/100  Loss=2.9927\n",
      "[Fine-tune] Epoch 4/100  Loss=2.7892\n",
      "[Fine-tune] Epoch 5/100  Loss=2.6691\n",
      "[Fine-tune] Epoch 6/100  Loss=2.5756\n",
      "[Fine-tune] Epoch 7/100  Loss=2.5335\n",
      "[Fine-tune] Epoch 8/100  Loss=2.4982\n",
      "[Fine-tune] Epoch 9/100  Loss=2.4448\n",
      "[Fine-tune] Epoch 10/100  Loss=2.3830\n",
      "[Fine-tune] Epoch 11/100  Loss=2.3255\n",
      "[Fine-tune] Epoch 12/100  Loss=2.2821\n",
      "[Fine-tune] Epoch 13/100  Loss=2.2315\n",
      "[Fine-tune] Epoch 14/100  Loss=2.1992\n",
      "[Fine-tune] Epoch 15/100  Loss=2.1601\n",
      "[Fine-tune] Epoch 16/100  Loss=2.1311\n",
      "[Fine-tune] Epoch 17/100  Loss=2.1118\n",
      "[Fine-tune] Epoch 18/100  Loss=2.0561\n",
      "[Fine-tune] Epoch 19/100  Loss=2.0396\n",
      "[Fine-tune] Epoch 20/100  Loss=2.0218\n",
      "[Fine-tune] Epoch 21/100  Loss=2.0006\n",
      "[Fine-tune] Epoch 22/100  Loss=1.9702\n",
      "[Fine-tune] Epoch 23/100  Loss=1.9597\n",
      "[Fine-tune] Epoch 24/100  Loss=1.9331\n",
      "[Fine-tune] Epoch 25/100  Loss=1.9151\n",
      "[Fine-tune] Epoch 26/100  Loss=1.8952\n",
      "[Fine-tune] Epoch 27/100  Loss=1.8806\n",
      "[Fine-tune] Epoch 28/100  Loss=1.8572\n",
      "[Fine-tune] Epoch 29/100  Loss=1.8464\n",
      "[Fine-tune] Epoch 30/100  Loss=1.8257\n",
      "[Fine-tune] Epoch 31/100  Loss=1.8006\n",
      "[Fine-tune] Epoch 32/100  Loss=1.8060\n",
      "[Fine-tune] Epoch 33/100  Loss=1.7799\n",
      "[Fine-tune] Epoch 34/100  Loss=1.7686\n",
      "[Fine-tune] Epoch 35/100  Loss=1.7538\n",
      "[Fine-tune] Epoch 36/100  Loss=1.7558\n",
      "[Fine-tune] Epoch 37/100  Loss=1.7384\n",
      "[Fine-tune] Epoch 38/100  Loss=1.7109\n",
      "[Fine-tune] Epoch 39/100  Loss=1.7221\n",
      "[Fine-tune] Epoch 40/100  Loss=1.6986\n",
      "[Fine-tune] Epoch 41/100  Loss=1.7103\n",
      "[Fine-tune] Epoch 42/100  Loss=1.6839\n",
      "[Fine-tune] Epoch 43/100  Loss=1.6672\n",
      "[Fine-tune] Epoch 44/100  Loss=1.6719\n",
      "[Fine-tune] Epoch 45/100  Loss=1.6568\n",
      "[Fine-tune] Epoch 46/100  Loss=1.6532\n",
      "[Fine-tune] Epoch 47/100  Loss=1.6572\n",
      "[Fine-tune] Epoch 48/100  Loss=1.6346\n",
      "[Fine-tune] Epoch 49/100  Loss=1.6276\n",
      "[Fine-tune] Epoch 50/100  Loss=1.6195\n",
      "[Fine-tune] Epoch 51/100  Loss=1.6163\n",
      "[Fine-tune] Epoch 52/100  Loss=1.6114\n",
      "[Fine-tune] Epoch 53/100  Loss=1.6060\n",
      "[Fine-tune] Epoch 54/100  Loss=1.5908\n",
      "[Fine-tune] Epoch 55/100  Loss=1.6027\n",
      "[Fine-tune] Epoch 56/100  Loss=1.6031\n",
      "[Fine-tune] Epoch 57/100  Loss=1.5914\n",
      "[Fine-tune] Epoch 58/100  Loss=1.5852\n",
      "[Fine-tune] Epoch 59/100  Loss=1.5679\n",
      "[Fine-tune] Epoch 60/100  Loss=1.5645\n",
      "[Fine-tune] Epoch 61/100  Loss=1.5757\n",
      "[Fine-tune] Epoch 62/100  Loss=1.5867\n",
      "[Fine-tune] Epoch 63/100  Loss=1.5618\n",
      "[Fine-tune] Epoch 64/100  Loss=1.5660\n",
      "[Fine-tune] Epoch 65/100  Loss=1.5641\n",
      "[Fine-tune] Epoch 66/100  Loss=1.5738\n",
      "[Fine-tune] Epoch 67/100  Loss=1.5539\n",
      "[Fine-tune] Epoch 68/100  Loss=1.5556\n",
      "[Fine-tune] Epoch 69/100  Loss=1.5527\n",
      "[Fine-tune] Epoch 70/100  Loss=1.5496\n",
      "[Fine-tune] Epoch 71/100  Loss=1.5575\n",
      "[Fine-tune] Epoch 72/100  Loss=1.5444\n",
      "[Fine-tune] Epoch 73/100  Loss=1.5440\n",
      "[Fine-tune] Epoch 74/100  Loss=1.5410\n",
      "[Fine-tune] Epoch 75/100  Loss=1.5471\n",
      "[Fine-tune] Epoch 76/100  Loss=1.5405\n",
      "[Fine-tune] Epoch 77/100  Loss=1.5435\n",
      "[Fine-tune] Epoch 78/100  Loss=1.5338\n",
      "[Fine-tune] Epoch 79/100  Loss=1.5309\n",
      "[Fine-tune] Epoch 80/100  Loss=1.5397\n",
      "[Fine-tune] Epoch 81/100  Loss=1.5449\n",
      "[Fine-tune] Epoch 82/100  Loss=1.5345\n",
      "[Fine-tune] Epoch 83/100  Loss=1.5210\n",
      "[Fine-tune] Epoch 84/100  Loss=1.5281\n",
      "[Fine-tune] Epoch 85/100  Loss=1.5129\n",
      "[Fine-tune] Epoch 86/100  Loss=1.5253\n",
      "[Fine-tune] Epoch 87/100  Loss=1.5163\n",
      "[Fine-tune] Epoch 88/100  Loss=1.5304\n",
      "[Fine-tune] Epoch 89/100  Loss=1.5186\n",
      "[Fine-tune] Epoch 90/100  Loss=1.5288\n",
      "[Fine-tune] Epoch 91/100  Loss=1.5263\n",
      "[Fine-tune] Epoch 92/100  Loss=1.5247\n",
      "[Fine-tune] Epoch 93/100  Loss=1.5194\n",
      "[Fine-tune] Epoch 94/100  Loss=1.5242\n",
      "[Fine-tune] Epoch 95/100  Loss=1.5018\n",
      "[Fine-tune] Epoch 96/100  Loss=1.5190\n",
      "[Fine-tune] Epoch 97/100  Loss=1.5084\n",
      "[Fine-tune] Epoch 98/100  Loss=1.5216\n",
      "[Fine-tune] Epoch 99/100  Loss=1.5205\n",
      "[Fine-tune] Epoch 100/100  Loss=1.5056\n",
      "[Pretrain] Epoch 1/100  Loss=3.2200  Acc=0.0501\n",
      "[Pretrain] Epoch 2/100  Loss=3.0506  Acc=0.0810\n",
      "[Pretrain] Epoch 3/100  Loss=2.8112  Acc=0.1189\n",
      "[Pretrain] Epoch 4/100  Loss=2.5819  Acc=0.1791\n",
      "[Pretrain] Epoch 5/100  Loss=2.4025  Acc=0.2250\n",
      "[Pretrain] Epoch 6/100  Loss=2.2920  Acc=0.2644\n",
      "[Pretrain] Epoch 7/100  Loss=2.1975  Acc=0.2879\n",
      "[Pretrain] Epoch 8/100  Loss=2.1472  Acc=0.2967\n",
      "[Pretrain] Epoch 9/100  Loss=2.0793  Acc=0.3202\n",
      "[Pretrain] Epoch 10/100  Loss=2.0619  Acc=0.3274\n",
      "[Pretrain] Epoch 11/100  Loss=2.0181  Acc=0.3360\n",
      "[Pretrain] Epoch 12/100  Loss=1.9922  Acc=0.3416\n",
      "[Pretrain] Epoch 13/100  Loss=1.9839  Acc=0.3590\n",
      "[Pretrain] Epoch 14/100  Loss=1.9535  Acc=0.3644\n",
      "[Pretrain] Epoch 15/100  Loss=1.9068  Acc=0.3813\n",
      "[Pretrain] Epoch 16/100  Loss=1.8799  Acc=0.3895\n",
      "[Pretrain] Epoch 17/100  Loss=1.8558  Acc=0.4005\n",
      "[Pretrain] Epoch 18/100  Loss=1.8358  Acc=0.4055\n",
      "[Pretrain] Epoch 19/100  Loss=1.8161  Acc=0.4100\n",
      "[Pretrain] Epoch 20/100  Loss=1.7989  Acc=0.4199\n",
      "[Pretrain] Epoch 21/100  Loss=1.7697  Acc=0.4210\n",
      "[Pretrain] Epoch 22/100  Loss=1.7514  Acc=0.4289\n",
      "[Pretrain] Epoch 23/100  Loss=1.7148  Acc=0.4522\n",
      "[Pretrain] Epoch 24/100  Loss=1.6975  Acc=0.4513\n",
      "[Pretrain] Epoch 25/100  Loss=1.6961  Acc=0.4468\n",
      "[Pretrain] Epoch 26/100  Loss=1.6843  Acc=0.4522\n",
      "[Pretrain] Epoch 27/100  Loss=1.6663  Acc=0.4619\n",
      "[Pretrain] Epoch 28/100  Loss=1.6401  Acc=0.4704\n",
      "[Pretrain] Epoch 29/100  Loss=1.6421  Acc=0.4686\n",
      "[Pretrain] Epoch 30/100  Loss=1.6109  Acc=0.4759\n",
      "[Pretrain] Epoch 31/100  Loss=1.6034  Acc=0.4738\n",
      "[Pretrain] Epoch 32/100  Loss=1.5785  Acc=0.4862\n",
      "[Pretrain] Epoch 33/100  Loss=1.5640  Acc=0.4917\n",
      "[Pretrain] Epoch 34/100  Loss=1.5509  Acc=0.4984\n",
      "[Pretrain] Epoch 35/100  Loss=1.5368  Acc=0.5068\n",
      "[Pretrain] Epoch 36/100  Loss=1.5310  Acc=0.5108\n",
      "[Pretrain] Epoch 37/100  Loss=1.5131  Acc=0.5093\n",
      "[Pretrain] Epoch 38/100  Loss=1.5090  Acc=0.5181\n",
      "[Pretrain] Epoch 39/100  Loss=1.4963  Acc=0.5147\n",
      "[Pretrain] Epoch 40/100  Loss=1.4742  Acc=0.5198\n",
      "[Pretrain] Epoch 41/100  Loss=1.4607  Acc=0.5239\n",
      "[Pretrain] Epoch 42/100  Loss=1.4651  Acc=0.5295\n",
      "[Pretrain] Epoch 43/100  Loss=1.4563  Acc=0.5268\n",
      "[Pretrain] Epoch 44/100  Loss=1.4333  Acc=0.5321\n",
      "[Pretrain] Epoch 45/100  Loss=1.4396  Acc=0.5357\n",
      "[Pretrain] Epoch 46/100  Loss=1.4141  Acc=0.5402\n",
      "[Pretrain] Epoch 47/100  Loss=1.4129  Acc=0.5427\n",
      "[Pretrain] Epoch 48/100  Loss=1.4044  Acc=0.5422\n",
      "[Pretrain] Epoch 49/100  Loss=1.3945  Acc=0.5445\n",
      "[Pretrain] Epoch 50/100  Loss=1.4203  Acc=0.5442\n",
      "[Pretrain] Epoch 51/100  Loss=1.3773  Acc=0.5524\n",
      "[Pretrain] Epoch 52/100  Loss=1.3735  Acc=0.5517\n",
      "[Pretrain] Epoch 53/100  Loss=1.3615  Acc=0.5623\n",
      "[Pretrain] Epoch 54/100  Loss=1.3841  Acc=0.5532\n",
      "[Pretrain] Epoch 55/100  Loss=1.3458  Acc=0.5668\n",
      "[Pretrain] Epoch 56/100  Loss=1.3809  Acc=0.5533\n",
      "[Pretrain] Epoch 57/100  Loss=1.3486  Acc=0.5629\n",
      "[Pretrain] Epoch 58/100  Loss=1.3474  Acc=0.5611\n",
      "[Pretrain] Epoch 59/100  Loss=1.3276  Acc=0.5625\n",
      "[Pretrain] Epoch 60/100  Loss=1.3455  Acc=0.5612\n",
      "[Pretrain] Epoch 61/100  Loss=1.3484  Acc=0.5568\n",
      "[Pretrain] Epoch 62/100  Loss=1.3209  Acc=0.5733\n",
      "[Pretrain] Epoch 63/100  Loss=1.3256  Acc=0.5684\n",
      "[Pretrain] Epoch 64/100  Loss=1.3351  Acc=0.5659\n",
      "[Pretrain] Epoch 65/100  Loss=1.3255  Acc=0.5630\n",
      "[Pretrain] Epoch 66/100  Loss=1.3177  Acc=0.5776\n",
      "[Pretrain] Epoch 67/100  Loss=1.3257  Acc=0.5718\n",
      "[Pretrain] Epoch 68/100  Loss=1.3237  Acc=0.5715\n",
      "[Pretrain] Epoch 69/100  Loss=1.3049  Acc=0.5790\n",
      "[Pretrain] Epoch 70/100  Loss=1.3272  Acc=0.5675\n",
      "[Pretrain] Epoch 71/100  Loss=1.3132  Acc=0.5740\n",
      "[Pretrain] Epoch 72/100  Loss=1.2994  Acc=0.5803\n",
      "[Pretrain] Epoch 73/100  Loss=1.2916  Acc=0.5808\n",
      "[Pretrain] Epoch 74/100  Loss=1.3157  Acc=0.5731\n",
      "[Pretrain] Epoch 75/100  Loss=1.2959  Acc=0.5736\n",
      "[Pretrain] Epoch 76/100  Loss=1.2970  Acc=0.5799\n",
      "[Pretrain] Epoch 77/100  Loss=1.2974  Acc=0.5842\n",
      "[Pretrain] Epoch 78/100  Loss=1.3123  Acc=0.5779\n",
      "[Pretrain] Epoch 79/100  Loss=1.3125  Acc=0.5717\n",
      "[Pretrain] Epoch 80/100  Loss=1.2991  Acc=0.5758\n",
      "[Pretrain] Epoch 81/100  Loss=1.2829  Acc=0.5783\n",
      "[Pretrain] Epoch 82/100  Loss=1.2993  Acc=0.5720\n",
      "[Pretrain] Epoch 83/100  Loss=1.2956  Acc=0.5772\n",
      "[Pretrain] Epoch 84/100  Loss=1.2820  Acc=0.5878\n",
      "[Pretrain] Epoch 85/100  Loss=1.2826  Acc=0.5817\n",
      "[Pretrain] Epoch 86/100  Loss=1.2959  Acc=0.5846\n",
      "[Pretrain] Epoch 87/100  Loss=1.3100  Acc=0.5772\n",
      "[Pretrain] Epoch 88/100  Loss=1.2823  Acc=0.5733\n",
      "[Pretrain] Epoch 89/100  Loss=1.2862  Acc=0.5806\n",
      "[Pretrain] Epoch 90/100  Loss=1.2887  Acc=0.5848\n",
      "[Pretrain] Epoch 91/100  Loss=1.2931  Acc=0.5815\n",
      "[Pretrain] Epoch 92/100  Loss=1.2861  Acc=0.5806\n",
      "[Pretrain] Epoch 93/100  Loss=1.2720  Acc=0.5943\n",
      "[Pretrain] Epoch 94/100  Loss=1.2735  Acc=0.5853\n",
      "[Pretrain] Epoch 95/100  Loss=1.2760  Acc=0.5844\n",
      "[Pretrain] Epoch 96/100  Loss=1.2722  Acc=0.5857\n",
      "[Pretrain] Epoch 97/100  Loss=1.2768  Acc=0.5835\n",
      "[Pretrain] Epoch 98/100  Loss=1.2592  Acc=0.5914\n",
      "[Pretrain] Epoch 99/100  Loss=1.2885  Acc=0.5745\n",
      "[Pretrain] Epoch 100/100  Loss=1.2805  Acc=0.5878\n",
      "[Fine-tune] Epoch 1/100  Loss=3.3058\n",
      "[Fine-tune] Epoch 2/100  Loss=3.1399\n",
      "[Fine-tune] Epoch 3/100  Loss=3.0807\n",
      "[Fine-tune] Epoch 4/100  Loss=3.0638\n",
      "[Fine-tune] Epoch 5/100  Loss=3.0303\n",
      "[Fine-tune] Epoch 6/100  Loss=2.9109\n",
      "[Fine-tune] Epoch 7/100  Loss=2.7718\n",
      "[Fine-tune] Epoch 8/100  Loss=2.6517\n",
      "[Fine-tune] Epoch 9/100  Loss=2.5686\n",
      "[Fine-tune] Epoch 10/100  Loss=2.5090\n",
      "[Fine-tune] Epoch 11/100  Loss=2.4831\n",
      "[Fine-tune] Epoch 12/100  Loss=2.4011\n",
      "[Fine-tune] Epoch 13/100  Loss=2.3492\n",
      "[Fine-tune] Epoch 14/100  Loss=2.2978\n",
      "[Fine-tune] Epoch 15/100  Loss=2.2837\n",
      "[Fine-tune] Epoch 16/100  Loss=2.2432\n",
      "[Fine-tune] Epoch 17/100  Loss=2.2171\n",
      "[Fine-tune] Epoch 18/100  Loss=2.1702\n",
      "[Fine-tune] Epoch 19/100  Loss=2.1376\n",
      "[Fine-tune] Epoch 20/100  Loss=2.1027\n",
      "[Fine-tune] Epoch 21/100  Loss=2.0797\n",
      "[Fine-tune] Epoch 22/100  Loss=2.0611\n",
      "[Fine-tune] Epoch 23/100  Loss=2.0343\n",
      "[Fine-tune] Epoch 24/100  Loss=1.9943\n",
      "[Fine-tune] Epoch 25/100  Loss=1.9890\n",
      "[Fine-tune] Epoch 26/100  Loss=1.9757\n",
      "[Fine-tune] Epoch 27/100  Loss=1.9587\n",
      "[Fine-tune] Epoch 28/100  Loss=1.9578\n",
      "[Fine-tune] Epoch 29/100  Loss=1.9336\n",
      "[Fine-tune] Epoch 30/100  Loss=1.9025\n",
      "[Fine-tune] Epoch 31/100  Loss=1.8813\n",
      "[Fine-tune] Epoch 32/100  Loss=1.8750\n",
      "[Fine-tune] Epoch 33/100  Loss=1.8671\n",
      "[Fine-tune] Epoch 34/100  Loss=1.8384\n",
      "[Fine-tune] Epoch 35/100  Loss=1.8215\n",
      "[Fine-tune] Epoch 36/100  Loss=1.8155\n",
      "[Fine-tune] Epoch 37/100  Loss=1.7937\n",
      "[Fine-tune] Epoch 38/100  Loss=1.7904\n",
      "[Fine-tune] Epoch 39/100  Loss=1.7817\n",
      "[Fine-tune] Epoch 40/100  Loss=1.7597\n",
      "[Fine-tune] Epoch 41/100  Loss=1.7459\n",
      "[Fine-tune] Epoch 42/100  Loss=1.7307\n",
      "[Fine-tune] Epoch 43/100  Loss=1.7160\n",
      "[Fine-tune] Epoch 44/100  Loss=1.7221\n",
      "[Fine-tune] Epoch 45/100  Loss=1.6958\n",
      "[Fine-tune] Epoch 46/100  Loss=1.7067\n",
      "[Fine-tune] Epoch 47/100  Loss=1.6714\n",
      "[Fine-tune] Epoch 48/100  Loss=1.6691\n",
      "[Fine-tune] Epoch 49/100  Loss=1.6726\n",
      "[Fine-tune] Epoch 50/100  Loss=1.6683\n",
      "[Fine-tune] Epoch 51/100  Loss=1.6583\n",
      "[Fine-tune] Epoch 52/100  Loss=1.6381\n",
      "[Fine-tune] Epoch 53/100  Loss=1.6254\n",
      "[Fine-tune] Epoch 54/100  Loss=1.6331\n",
      "[Fine-tune] Epoch 55/100  Loss=1.6161\n",
      "[Fine-tune] Epoch 56/100  Loss=1.5986\n",
      "[Fine-tune] Epoch 57/100  Loss=1.6103\n",
      "[Fine-tune] Epoch 58/100  Loss=1.5901\n",
      "[Fine-tune] Epoch 59/100  Loss=1.6036\n",
      "[Fine-tune] Epoch 60/100  Loss=1.5836\n",
      "[Fine-tune] Epoch 61/100  Loss=1.5802\n",
      "[Fine-tune] Epoch 62/100  Loss=1.5626\n",
      "[Fine-tune] Epoch 63/100  Loss=1.5671\n",
      "[Fine-tune] Epoch 64/100  Loss=1.5584\n",
      "[Fine-tune] Epoch 65/100  Loss=1.5515\n",
      "[Fine-tune] Epoch 66/100  Loss=1.5844\n",
      "[Fine-tune] Epoch 67/100  Loss=1.5458\n",
      "[Fine-tune] Epoch 68/100  Loss=1.5508\n",
      "[Fine-tune] Epoch 69/100  Loss=1.5528\n",
      "[Fine-tune] Epoch 70/100  Loss=1.5383\n",
      "[Fine-tune] Epoch 71/100  Loss=1.5450\n",
      "[Fine-tune] Epoch 72/100  Loss=1.5455\n",
      "[Fine-tune] Epoch 73/100  Loss=1.5249\n",
      "[Fine-tune] Epoch 74/100  Loss=1.5401\n",
      "[Fine-tune] Epoch 75/100  Loss=1.5359\n",
      "[Fine-tune] Epoch 76/100  Loss=1.5285\n",
      "[Fine-tune] Epoch 77/100  Loss=1.5237\n",
      "[Fine-tune] Epoch 78/100  Loss=1.5227\n",
      "[Fine-tune] Epoch 79/100  Loss=1.5159\n",
      "[Fine-tune] Epoch 80/100  Loss=1.5215\n",
      "[Fine-tune] Epoch 81/100  Loss=1.5145\n",
      "[Fine-tune] Epoch 82/100  Loss=1.5197\n",
      "[Fine-tune] Epoch 83/100  Loss=1.5153\n",
      "[Fine-tune] Epoch 84/100  Loss=1.5214\n",
      "[Fine-tune] Epoch 85/100  Loss=1.5115\n",
      "[Fine-tune] Epoch 86/100  Loss=1.5100\n",
      "[Fine-tune] Epoch 87/100  Loss=1.4994\n",
      "[Fine-tune] Epoch 88/100  Loss=1.5060\n",
      "[Fine-tune] Epoch 89/100  Loss=1.5073\n",
      "[Fine-tune] Epoch 90/100  Loss=1.4962\n",
      "[Fine-tune] Epoch 91/100  Loss=1.5035\n",
      "[Fine-tune] Epoch 92/100  Loss=1.5075\n",
      "[Fine-tune] Epoch 93/100  Loss=1.5162\n",
      "[Fine-tune] Epoch 94/100  Loss=1.4940\n",
      "[Fine-tune] Epoch 95/100  Loss=1.4992\n",
      "[Fine-tune] Epoch 96/100  Loss=1.4894\n",
      "[Fine-tune] Epoch 97/100  Loss=1.5050\n",
      "[Fine-tune] Epoch 98/100  Loss=1.5007\n",
      "[Fine-tune] Epoch 99/100  Loss=1.4832\n",
      "[Fine-tune] Epoch 100/100  Loss=1.4999\n",
      "[Pretrain] Epoch 1/100  Loss=3.5926  Acc=0.0478\n",
      "[Pretrain] Epoch 2/100  Loss=3.0707  Acc=0.0860\n",
      "[Pretrain] Epoch 3/100  Loss=2.8201  Acc=0.1191\n",
      "[Pretrain] Epoch 4/100  Loss=2.6824  Acc=0.1501\n",
      "[Pretrain] Epoch 5/100  Loss=2.5206  Acc=0.1995\n",
      "[Pretrain] Epoch 6/100  Loss=2.4256  Acc=0.2218\n",
      "[Pretrain] Epoch 7/100  Loss=2.3261  Acc=0.2491\n",
      "[Pretrain] Epoch 8/100  Loss=2.2987  Acc=0.2593\n",
      "[Pretrain] Epoch 9/100  Loss=2.2650  Acc=0.2757\n",
      "[Pretrain] Epoch 10/100  Loss=2.2304  Acc=0.2812\n",
      "[Pretrain] Epoch 11/100  Loss=2.1636  Acc=0.2996\n",
      "[Pretrain] Epoch 12/100  Loss=2.1470  Acc=0.3042\n",
      "[Pretrain] Epoch 13/100  Loss=2.1185  Acc=0.3041\n",
      "[Pretrain] Epoch 14/100  Loss=2.0873  Acc=0.3254\n",
      "[Pretrain] Epoch 15/100  Loss=2.0296  Acc=0.3421\n",
      "[Pretrain] Epoch 16/100  Loss=2.0325  Acc=0.3324\n",
      "[Pretrain] Epoch 17/100  Loss=1.9994  Acc=0.3434\n",
      "[Pretrain] Epoch 18/100  Loss=1.9687  Acc=0.3558\n",
      "[Pretrain] Epoch 19/100  Loss=1.9494  Acc=0.3635\n",
      "[Pretrain] Epoch 20/100  Loss=1.9493  Acc=0.3687\n",
      "[Pretrain] Epoch 21/100  Loss=1.9247  Acc=0.3772\n",
      "[Pretrain] Epoch 22/100  Loss=1.9062  Acc=0.3820\n",
      "[Pretrain] Epoch 23/100  Loss=1.8683  Acc=0.3903\n",
      "[Pretrain] Epoch 24/100  Loss=1.8254  Acc=0.4046\n",
      "[Pretrain] Epoch 25/100  Loss=1.8072  Acc=0.4043\n",
      "[Pretrain] Epoch 26/100  Loss=1.7939  Acc=0.4134\n",
      "[Pretrain] Epoch 27/100  Loss=1.7657  Acc=0.4183\n",
      "[Pretrain] Epoch 28/100  Loss=1.7289  Acc=0.4379\n",
      "[Pretrain] Epoch 29/100  Loss=1.7084  Acc=0.4443\n",
      "[Pretrain] Epoch 30/100  Loss=1.7003  Acc=0.4447\n",
      "[Pretrain] Epoch 31/100  Loss=1.6848  Acc=0.4481\n",
      "[Pretrain] Epoch 32/100  Loss=1.6453  Acc=0.4617\n",
      "[Pretrain] Epoch 33/100  Loss=1.6398  Acc=0.4591\n",
      "[Pretrain] Epoch 34/100  Loss=1.6104  Acc=0.4817\n",
      "[Pretrain] Epoch 35/100  Loss=1.5872  Acc=0.4828\n",
      "[Pretrain] Epoch 36/100  Loss=1.5696  Acc=0.4847\n",
      "[Pretrain] Epoch 37/100  Loss=1.5532  Acc=0.4898\n",
      "[Pretrain] Epoch 38/100  Loss=1.5221  Acc=0.5014\n",
      "[Pretrain] Epoch 39/100  Loss=1.5074  Acc=0.5117\n",
      "[Pretrain] Epoch 40/100  Loss=1.4884  Acc=0.5172\n",
      "[Pretrain] Epoch 41/100  Loss=1.4835  Acc=0.5099\n",
      "[Pretrain] Epoch 42/100  Loss=1.4435  Acc=0.5320\n",
      "[Pretrain] Epoch 43/100  Loss=1.4356  Acc=0.5280\n",
      "[Pretrain] Epoch 44/100  Loss=1.4197  Acc=0.5372\n",
      "[Pretrain] Epoch 45/100  Loss=1.4066  Acc=0.5287\n",
      "[Pretrain] Epoch 46/100  Loss=1.3994  Acc=0.5377\n",
      "[Pretrain] Epoch 47/100  Loss=1.3627  Acc=0.5557\n",
      "[Pretrain] Epoch 48/100  Loss=1.3718  Acc=0.5462\n",
      "[Pretrain] Epoch 49/100  Loss=1.3265  Acc=0.5605\n",
      "[Pretrain] Epoch 50/100  Loss=1.3434  Acc=0.5623\n",
      "[Pretrain] Epoch 51/100  Loss=1.3199  Acc=0.5625\n",
      "[Pretrain] Epoch 52/100  Loss=1.3197  Acc=0.5718\n",
      "[Pretrain] Epoch 53/100  Loss=1.3019  Acc=0.5711\n",
      "[Pretrain] Epoch 54/100  Loss=1.2889  Acc=0.5756\n",
      "[Pretrain] Epoch 55/100  Loss=1.2912  Acc=0.5799\n",
      "[Pretrain] Epoch 56/100  Loss=1.2802  Acc=0.5797\n",
      "[Pretrain] Epoch 57/100  Loss=1.2702  Acc=0.5837\n",
      "[Pretrain] Epoch 58/100  Loss=1.2580  Acc=0.5869\n",
      "[Pretrain] Epoch 59/100  Loss=1.2566  Acc=0.5860\n",
      "[Pretrain] Epoch 60/100  Loss=1.2371  Acc=0.5955\n",
      "[Pretrain] Epoch 61/100  Loss=1.2178  Acc=0.6000\n",
      "[Pretrain] Epoch 62/100  Loss=1.2369  Acc=0.5914\n",
      "[Pretrain] Epoch 63/100  Loss=1.2273  Acc=0.5932\n",
      "[Pretrain] Epoch 64/100  Loss=1.2169  Acc=0.6017\n",
      "[Pretrain] Epoch 65/100  Loss=1.2038  Acc=0.6054\n",
      "[Pretrain] Epoch 66/100  Loss=1.2060  Acc=0.6087\n",
      "[Pretrain] Epoch 67/100  Loss=1.2096  Acc=0.6060\n",
      "[Pretrain] Epoch 68/100  Loss=1.1990  Acc=0.6117\n",
      "[Pretrain] Epoch 69/100  Loss=1.1928  Acc=0.6103\n",
      "[Pretrain] Epoch 70/100  Loss=1.1616  Acc=0.6185\n",
      "[Pretrain] Epoch 71/100  Loss=1.1819  Acc=0.6069\n",
      "[Pretrain] Epoch 72/100  Loss=1.1866  Acc=0.6081\n",
      "[Pretrain] Epoch 73/100  Loss=1.1764  Acc=0.6108\n",
      "[Pretrain] Epoch 74/100  Loss=1.1670  Acc=0.6203\n",
      "[Pretrain] Epoch 75/100  Loss=1.1619  Acc=0.6135\n",
      "[Pretrain] Epoch 76/100  Loss=1.1723  Acc=0.6167\n",
      "[Pretrain] Epoch 77/100  Loss=1.1542  Acc=0.6187\n",
      "[Pretrain] Epoch 78/100  Loss=1.1518  Acc=0.6223\n",
      "[Pretrain] Epoch 79/100  Loss=1.1662  Acc=0.6189\n",
      "[Pretrain] Epoch 80/100  Loss=1.1682  Acc=0.6210\n",
      "[Pretrain] Epoch 81/100  Loss=1.1529  Acc=0.6257\n",
      "[Pretrain] Epoch 82/100  Loss=1.1367  Acc=0.6232\n",
      "[Pretrain] Epoch 83/100  Loss=1.1399  Acc=0.6200\n",
      "[Pretrain] Epoch 84/100  Loss=1.1473  Acc=0.6212\n",
      "[Pretrain] Epoch 85/100  Loss=1.1378  Acc=0.6252\n",
      "[Pretrain] Epoch 86/100  Loss=1.1356  Acc=0.6342\n",
      "[Pretrain] Epoch 87/100  Loss=1.1340  Acc=0.6250\n",
      "[Pretrain] Epoch 88/100  Loss=1.1397  Acc=0.6315\n",
      "[Pretrain] Epoch 89/100  Loss=1.1127  Acc=0.6338\n",
      "[Pretrain] Epoch 90/100  Loss=1.1231  Acc=0.6291\n",
      "[Pretrain] Epoch 91/100  Loss=1.1219  Acc=0.6327\n",
      "[Pretrain] Epoch 92/100  Loss=1.1323  Acc=0.6304\n",
      "[Pretrain] Epoch 93/100  Loss=1.1272  Acc=0.6282\n",
      "[Pretrain] Epoch 94/100  Loss=1.1160  Acc=0.6376\n",
      "[Pretrain] Epoch 95/100  Loss=1.1272  Acc=0.6347\n",
      "[Pretrain] Epoch 96/100  Loss=1.1180  Acc=0.6313\n",
      "[Pretrain] Epoch 97/100  Loss=1.1103  Acc=0.6311\n",
      "[Pretrain] Epoch 98/100  Loss=1.1110  Acc=0.6363\n",
      "[Pretrain] Epoch 99/100  Loss=1.1214  Acc=0.6290\n",
      "[Pretrain] Epoch 100/100  Loss=1.1054  Acc=0.6372\n",
      "[Fine-tune] Epoch 1/100  Loss=3.2603\n",
      "[Fine-tune] Epoch 2/100  Loss=3.0686\n",
      "[Fine-tune] Epoch 3/100  Loss=2.8575\n",
      "[Fine-tune] Epoch 4/100  Loss=2.6794\n",
      "[Fine-tune] Epoch 5/100  Loss=2.5675\n",
      "[Fine-tune] Epoch 6/100  Loss=2.4805\n",
      "[Fine-tune] Epoch 7/100  Loss=2.3875\n",
      "[Fine-tune] Epoch 8/100  Loss=2.3177\n",
      "[Fine-tune] Epoch 9/100  Loss=2.2672\n",
      "[Fine-tune] Epoch 10/100  Loss=2.1922\n",
      "[Fine-tune] Epoch 11/100  Loss=2.1627\n",
      "[Fine-tune] Epoch 12/100  Loss=2.1244\n",
      "[Fine-tune] Epoch 13/100  Loss=2.0777\n",
      "[Fine-tune] Epoch 14/100  Loss=2.0412\n",
      "[Fine-tune] Epoch 15/100  Loss=2.0280\n",
      "[Fine-tune] Epoch 16/100  Loss=1.9909\n",
      "[Fine-tune] Epoch 17/100  Loss=1.9823\n",
      "[Fine-tune] Epoch 18/100  Loss=1.9413\n",
      "[Fine-tune] Epoch 19/100  Loss=1.9569\n",
      "[Fine-tune] Epoch 20/100  Loss=1.9071\n",
      "[Fine-tune] Epoch 21/100  Loss=1.8872\n",
      "[Fine-tune] Epoch 22/100  Loss=1.8687\n",
      "[Fine-tune] Epoch 23/100  Loss=1.8543\n",
      "[Fine-tune] Epoch 24/100  Loss=1.8272\n",
      "[Fine-tune] Epoch 25/100  Loss=1.8327\n",
      "[Fine-tune] Epoch 26/100  Loss=1.8155\n",
      "[Fine-tune] Epoch 27/100  Loss=1.8030\n",
      "[Fine-tune] Epoch 28/100  Loss=1.7856\n",
      "[Fine-tune] Epoch 29/100  Loss=1.7657\n",
      "[Fine-tune] Epoch 30/100  Loss=1.7472\n",
      "[Fine-tune] Epoch 31/100  Loss=1.7467\n",
      "[Fine-tune] Epoch 32/100  Loss=1.7287\n",
      "[Fine-tune] Epoch 33/100  Loss=1.7017\n",
      "[Fine-tune] Epoch 34/100  Loss=1.7205\n",
      "[Fine-tune] Epoch 35/100  Loss=1.6916\n",
      "[Fine-tune] Epoch 36/100  Loss=1.6828\n",
      "[Fine-tune] Epoch 37/100  Loss=1.6720\n",
      "[Fine-tune] Epoch 38/100  Loss=1.6565\n",
      "[Fine-tune] Epoch 39/100  Loss=1.6479\n",
      "[Fine-tune] Epoch 40/100  Loss=1.6384\n",
      "[Fine-tune] Epoch 41/100  Loss=1.6195\n",
      "[Fine-tune] Epoch 42/100  Loss=1.6364\n",
      "[Fine-tune] Epoch 43/100  Loss=1.6135\n",
      "[Fine-tune] Epoch 44/100  Loss=1.6078\n",
      "[Fine-tune] Epoch 45/100  Loss=1.6007\n",
      "[Fine-tune] Epoch 46/100  Loss=1.6040\n",
      "[Fine-tune] Epoch 47/100  Loss=1.5759\n",
      "[Fine-tune] Epoch 48/100  Loss=1.5865\n",
      "[Fine-tune] Epoch 49/100  Loss=1.5739\n",
      "[Fine-tune] Epoch 50/100  Loss=1.5772\n",
      "[Fine-tune] Epoch 51/100  Loss=1.5646\n",
      "[Fine-tune] Epoch 52/100  Loss=1.5578\n",
      "[Fine-tune] Epoch 53/100  Loss=1.5595\n",
      "[Fine-tune] Epoch 54/100  Loss=1.5345\n",
      "[Fine-tune] Epoch 55/100  Loss=1.5453\n",
      "[Fine-tune] Epoch 56/100  Loss=1.5521\n",
      "[Fine-tune] Epoch 57/100  Loss=1.5323\n",
      "[Fine-tune] Epoch 58/100  Loss=1.5288\n",
      "[Fine-tune] Epoch 59/100  Loss=1.5308\n",
      "[Fine-tune] Epoch 60/100  Loss=1.5306\n",
      "[Fine-tune] Epoch 61/100  Loss=1.5089\n",
      "[Fine-tune] Epoch 62/100  Loss=1.5243\n",
      "[Fine-tune] Epoch 63/100  Loss=1.5070\n",
      "[Fine-tune] Epoch 64/100  Loss=1.5060\n",
      "[Fine-tune] Epoch 65/100  Loss=1.5081\n",
      "[Fine-tune] Epoch 66/100  Loss=1.4979\n",
      "[Fine-tune] Epoch 67/100  Loss=1.5050\n",
      "[Fine-tune] Epoch 68/100  Loss=1.4956\n",
      "[Fine-tune] Epoch 69/100  Loss=1.4955\n",
      "[Fine-tune] Epoch 70/100  Loss=1.4889\n",
      "[Fine-tune] Epoch 71/100  Loss=1.5019\n",
      "[Fine-tune] Epoch 72/100  Loss=1.4881\n",
      "[Fine-tune] Epoch 73/100  Loss=1.4882\n",
      "[Fine-tune] Epoch 74/100  Loss=1.4873\n",
      "[Fine-tune] Epoch 75/100  Loss=1.4732\n",
      "[Fine-tune] Epoch 76/100  Loss=1.4789\n",
      "[Fine-tune] Epoch 77/100  Loss=1.4751\n",
      "[Fine-tune] Epoch 78/100  Loss=1.4902\n",
      "[Fine-tune] Epoch 79/100  Loss=1.4810\n",
      "[Fine-tune] Epoch 80/100  Loss=1.4802\n",
      "[Fine-tune] Epoch 81/100  Loss=1.4793\n",
      "[Fine-tune] Epoch 82/100  Loss=1.4770\n",
      "[Fine-tune] Epoch 83/100  Loss=1.4730\n",
      "[Fine-tune] Epoch 84/100  Loss=1.4770\n",
      "[Fine-tune] Epoch 85/100  Loss=1.4788\n",
      "[Fine-tune] Epoch 86/100  Loss=1.4548\n",
      "[Fine-tune] Epoch 87/100  Loss=1.4624\n",
      "[Fine-tune] Epoch 88/100  Loss=1.4625\n",
      "[Fine-tune] Epoch 89/100  Loss=1.4765\n",
      "[Fine-tune] Epoch 90/100  Loss=1.4706\n",
      "[Fine-tune] Epoch 91/100  Loss=1.4645\n",
      "[Fine-tune] Epoch 92/100  Loss=1.4684\n",
      "[Fine-tune] Epoch 93/100  Loss=1.4749\n",
      "[Fine-tune] Epoch 94/100  Loss=1.4646\n",
      "[Fine-tune] Epoch 95/100  Loss=1.4771\n",
      "[Fine-tune] Epoch 96/100  Loss=1.4664\n",
      "[Fine-tune] Epoch 97/100  Loss=1.4615\n",
      "[Fine-tune] Epoch 98/100  Loss=1.4626\n",
      "[Fine-tune] Epoch 99/100  Loss=1.4569\n",
      "[Fine-tune] Epoch 100/100  Loss=1.4814\n",
      "[Pretrain] Epoch 1/150  Loss=3.2523  Acc=0.0399\n",
      "[Pretrain] Epoch 2/150  Loss=3.0959  Acc=0.0693\n",
      "[Pretrain] Epoch 3/150  Loss=3.0422  Acc=0.0815\n",
      "[Pretrain] Epoch 4/150  Loss=2.8225  Acc=0.1268\n",
      "[Pretrain] Epoch 5/150  Loss=2.5314  Acc=0.2044\n",
      "[Pretrain] Epoch 6/150  Loss=2.3665  Acc=0.2477\n",
      "[Pretrain] Epoch 7/150  Loss=2.2549  Acc=0.2755\n",
      "[Pretrain] Epoch 8/150  Loss=2.1778  Acc=0.2949\n",
      "[Pretrain] Epoch 9/150  Loss=2.1060  Acc=0.3156\n",
      "[Pretrain] Epoch 10/150  Loss=2.0630  Acc=0.3211\n",
      "[Pretrain] Epoch 11/150  Loss=2.0143  Acc=0.3481\n",
      "[Pretrain] Epoch 12/150  Loss=1.9800  Acc=0.3567\n",
      "[Pretrain] Epoch 13/150  Loss=1.9436  Acc=0.3673\n",
      "[Pretrain] Epoch 14/150  Loss=1.9088  Acc=0.3802\n",
      "[Pretrain] Epoch 15/150  Loss=1.8898  Acc=0.3851\n",
      "[Pretrain] Epoch 16/150  Loss=1.8640  Acc=0.4007\n",
      "[Pretrain] Epoch 17/150  Loss=1.8186  Acc=0.4129\n",
      "[Pretrain] Epoch 18/150  Loss=1.8098  Acc=0.4149\n",
      "[Pretrain] Epoch 19/150  Loss=1.7663  Acc=0.4242\n",
      "[Pretrain] Epoch 20/150  Loss=1.7478  Acc=0.4312\n",
      "[Pretrain] Epoch 21/150  Loss=1.7355  Acc=0.4397\n",
      "[Pretrain] Epoch 22/150  Loss=1.6850  Acc=0.4571\n",
      "[Pretrain] Epoch 23/150  Loss=1.6863  Acc=0.4614\n",
      "[Pretrain] Epoch 24/150  Loss=1.6405  Acc=0.4662\n",
      "[Pretrain] Epoch 25/150  Loss=1.6129  Acc=0.4790\n",
      "[Pretrain] Epoch 26/150  Loss=1.6288  Acc=0.4779\n",
      "[Pretrain] Epoch 27/150  Loss=1.6091  Acc=0.4711\n",
      "[Pretrain] Epoch 28/150  Loss=1.5837  Acc=0.4885\n",
      "[Pretrain] Epoch 29/150  Loss=1.5715  Acc=0.4937\n",
      "[Pretrain] Epoch 30/150  Loss=1.5583  Acc=0.4932\n",
      "[Pretrain] Epoch 31/150  Loss=1.5420  Acc=0.4964\n",
      "[Pretrain] Epoch 32/150  Loss=1.5289  Acc=0.5020\n",
      "[Pretrain] Epoch 33/150  Loss=1.4846  Acc=0.5158\n",
      "[Pretrain] Epoch 34/150  Loss=1.5079  Acc=0.5095\n",
      "[Pretrain] Epoch 35/150  Loss=1.4881  Acc=0.5160\n",
      "[Pretrain] Epoch 36/150  Loss=1.4772  Acc=0.5167\n",
      "[Pretrain] Epoch 37/150  Loss=1.4612  Acc=0.5235\n",
      "[Pretrain] Epoch 38/150  Loss=1.4653  Acc=0.5282\n",
      "[Pretrain] Epoch 39/150  Loss=1.4366  Acc=0.5311\n",
      "[Pretrain] Epoch 40/150  Loss=1.4282  Acc=0.5359\n",
      "[Pretrain] Epoch 41/150  Loss=1.4198  Acc=0.5384\n",
      "[Pretrain] Epoch 42/150  Loss=1.4040  Acc=0.5465\n",
      "[Pretrain] Epoch 43/150  Loss=1.4079  Acc=0.5413\n",
      "[Pretrain] Epoch 44/150  Loss=1.3755  Acc=0.5600\n",
      "[Pretrain] Epoch 45/150  Loss=1.3858  Acc=0.5435\n",
      "[Pretrain] Epoch 46/150  Loss=1.3722  Acc=0.5526\n",
      "[Pretrain] Epoch 47/150  Loss=1.3767  Acc=0.5605\n",
      "[Pretrain] Epoch 48/150  Loss=1.3696  Acc=0.5584\n",
      "[Pretrain] Epoch 49/150  Loss=1.3621  Acc=0.5584\n",
      "[Pretrain] Epoch 50/150  Loss=1.3577  Acc=0.5585\n",
      "[Pretrain] Epoch 51/150  Loss=1.3309  Acc=0.5681\n",
      "[Pretrain] Epoch 52/150  Loss=1.3310  Acc=0.5681\n",
      "[Pretrain] Epoch 53/150  Loss=1.3212  Acc=0.5630\n",
      "[Pretrain] Epoch 54/150  Loss=1.3356  Acc=0.5641\n",
      "[Pretrain] Epoch 55/150  Loss=1.3226  Acc=0.5675\n",
      "[Pretrain] Epoch 56/150  Loss=1.3307  Acc=0.5659\n",
      "[Pretrain] Epoch 57/150  Loss=1.3113  Acc=0.5697\n",
      "[Pretrain] Epoch 58/150  Loss=1.2999  Acc=0.5672\n",
      "[Pretrain] Epoch 59/150  Loss=1.3166  Acc=0.5682\n",
      "[Pretrain] Epoch 60/150  Loss=1.2961  Acc=0.5799\n",
      "[Pretrain] Epoch 61/150  Loss=1.3053  Acc=0.5691\n",
      "[Pretrain] Epoch 62/150  Loss=1.2945  Acc=0.5778\n",
      "[Pretrain] Epoch 63/150  Loss=1.2844  Acc=0.5770\n",
      "[Pretrain] Epoch 64/150  Loss=1.2831  Acc=0.5781\n",
      "[Pretrain] Epoch 65/150  Loss=1.3074  Acc=0.5709\n",
      "[Pretrain] Epoch 66/150  Loss=1.2859  Acc=0.5776\n",
      "[Pretrain] Epoch 67/150  Loss=1.2761  Acc=0.5835\n",
      "[Pretrain] Epoch 68/150  Loss=1.2772  Acc=0.5864\n",
      "[Pretrain] Epoch 69/150  Loss=1.2825  Acc=0.5808\n",
      "[Pretrain] Epoch 70/150  Loss=1.2645  Acc=0.5875\n",
      "[Pretrain] Epoch 71/150  Loss=1.2834  Acc=0.5839\n",
      "[Pretrain] Epoch 72/150  Loss=1.2706  Acc=0.5894\n",
      "[Pretrain] Epoch 73/150  Loss=1.2664  Acc=0.5946\n",
      "[Pretrain] Epoch 74/150  Loss=1.2621  Acc=0.5925\n",
      "[Pretrain] Epoch 75/150  Loss=1.2580  Acc=0.5885\n",
      "[Pretrain] Epoch 76/150  Loss=1.2543  Acc=0.5921\n",
      "[Pretrain] Epoch 77/150  Loss=1.2666  Acc=0.5853\n",
      "[Pretrain] Epoch 78/150  Loss=1.2624  Acc=0.5869\n",
      "[Pretrain] Epoch 79/150  Loss=1.2515  Acc=0.5936\n",
      "[Pretrain] Epoch 80/150  Loss=1.2569  Acc=0.5927\n",
      "[Pretrain] Epoch 81/150  Loss=1.2569  Acc=0.5945\n",
      "[Pretrain] Epoch 82/150  Loss=1.2406  Acc=0.5946\n",
      "[Pretrain] Epoch 83/150  Loss=1.2652  Acc=0.5884\n",
      "[Pretrain] Epoch 84/150  Loss=1.2560  Acc=0.5873\n",
      "[Pretrain] Epoch 85/150  Loss=1.2602  Acc=0.5891\n",
      "[Pretrain] Epoch 86/150  Loss=1.2544  Acc=0.5875\n",
      "[Pretrain] Epoch 87/150  Loss=1.2342  Acc=0.6011\n",
      "[Pretrain] Epoch 88/150  Loss=1.2624  Acc=0.5916\n",
      "[Pretrain] Epoch 89/150  Loss=1.2555  Acc=0.5912\n",
      "[Pretrain] Epoch 90/150  Loss=1.2517  Acc=0.5855\n",
      "[Pretrain] Epoch 91/150  Loss=1.2452  Acc=0.5918\n",
      "[Pretrain] Epoch 92/150  Loss=1.2383  Acc=0.5964\n",
      "[Pretrain] Epoch 93/150  Loss=1.2434  Acc=0.6000\n",
      "[Pretrain] Epoch 94/150  Loss=1.2421  Acc=0.5934\n",
      "[Pretrain] Epoch 95/150  Loss=1.2290  Acc=0.6042\n",
      "[Pretrain] Epoch 96/150  Loss=1.2360  Acc=0.6040\n",
      "[Pretrain] Epoch 97/150  Loss=1.2535  Acc=0.5988\n",
      "[Pretrain] Epoch 98/150  Loss=1.2443  Acc=0.5966\n",
      "[Pretrain] Epoch 99/150  Loss=1.2458  Acc=0.5927\n",
      "[Pretrain] Epoch 100/150  Loss=1.2438  Acc=0.5957\n",
      "[Pretrain] Epoch 101/150  Loss=1.2466  Acc=0.5954\n",
      "[Pretrain] Epoch 102/150  Loss=1.2364  Acc=0.5979\n",
      "[Pretrain] Epoch 103/150  Loss=1.2282  Acc=0.5952\n",
      "[Pretrain] Epoch 104/150  Loss=1.2408  Acc=0.5961\n",
      "[Pretrain] Epoch 105/150  Loss=1.2269  Acc=0.6020\n",
      "[Pretrain] Epoch 106/150  Loss=1.2364  Acc=0.5997\n",
      "[Pretrain] Epoch 107/150  Loss=1.2418  Acc=0.5925\n",
      "[Pretrain] Epoch 108/150  Loss=1.2450  Acc=0.5961\n",
      "[Pretrain] Epoch 109/150  Loss=1.2163  Acc=0.6015\n",
      "[Pretrain] Epoch 110/150  Loss=1.2301  Acc=0.6000\n",
      "[Pretrain] Epoch 111/150  Loss=1.2346  Acc=0.5995\n",
      "[Pretrain] Epoch 112/150  Loss=1.2377  Acc=0.5896\n",
      "[Pretrain] Epoch 113/150  Loss=1.2306  Acc=0.5954\n",
      "[Pretrain] Epoch 114/150  Loss=1.2363  Acc=0.5975\n",
      "[Pretrain] Epoch 115/150  Loss=1.2305  Acc=0.5970\n",
      "[Pretrain] Epoch 116/150  Loss=1.2372  Acc=0.5968\n",
      "[Pretrain] Epoch 117/150  Loss=1.2229  Acc=0.5991\n",
      "[Pretrain] Epoch 118/150  Loss=1.2213  Acc=0.6045\n",
      "[Pretrain] Epoch 119/150  Loss=1.2276  Acc=0.6024\n",
      "[Pretrain] Epoch 120/150  Loss=1.2286  Acc=0.5925\n",
      "[Pretrain] Epoch 121/150  Loss=1.2312  Acc=0.6052\n",
      "[Pretrain] Epoch 122/150  Loss=1.2367  Acc=0.5972\n",
      "[Pretrain] Epoch 123/150  Loss=1.2466  Acc=0.5938\n",
      "[Pretrain] Epoch 124/150  Loss=1.2347  Acc=0.5968\n",
      "[Pretrain] Epoch 125/150  Loss=1.2367  Acc=0.5986\n",
      "[Pretrain] Epoch 126/150  Loss=1.2321  Acc=0.5948\n",
      "[Pretrain] Epoch 127/150  Loss=1.2415  Acc=0.5938\n",
      "[Pretrain] Epoch 128/150  Loss=1.2378  Acc=0.5964\n",
      "[Pretrain] Epoch 129/150  Loss=1.2505  Acc=0.5934\n",
      "[Pretrain] Epoch 130/150  Loss=1.2221  Acc=0.6033\n",
      "[Pretrain] Epoch 131/150  Loss=1.2337  Acc=0.5900\n",
      "[Pretrain] Epoch 132/150  Loss=1.2367  Acc=0.5993\n",
      "[Pretrain] Epoch 133/150  Loss=1.2244  Acc=0.6027\n",
      "[Pretrain] Epoch 134/150  Loss=1.2329  Acc=0.5955\n",
      "[Pretrain] Epoch 135/150  Loss=1.2353  Acc=0.5932\n",
      "[Pretrain] Epoch 136/150  Loss=1.2361  Acc=0.6033\n",
      "[Pretrain] Epoch 137/150  Loss=1.2365  Acc=0.5934\n",
      "[Pretrain] Epoch 138/150  Loss=1.2440  Acc=0.5932\n",
      "[Pretrain] Epoch 139/150  Loss=1.2423  Acc=0.5981\n",
      "[Pretrain] Epoch 140/150  Loss=1.2381  Acc=0.5934\n",
      "[Pretrain] Epoch 141/150  Loss=1.2390  Acc=0.5999\n",
      "[Pretrain] Epoch 142/150  Loss=1.2245  Acc=0.6047\n",
      "[Pretrain] Epoch 143/150  Loss=1.2293  Acc=0.5936\n",
      "[Pretrain] Epoch 144/150  Loss=1.2349  Acc=0.5966\n",
      "[Pretrain] Epoch 145/150  Loss=1.2230  Acc=0.5991\n",
      "[Pretrain] Epoch 146/150  Loss=1.2429  Acc=0.5963\n",
      "[Pretrain] Epoch 147/150  Loss=1.2310  Acc=0.5975\n",
      "[Pretrain] Epoch 148/150  Loss=1.2283  Acc=0.5889\n",
      "[Pretrain] Epoch 149/150  Loss=1.2302  Acc=0.6029\n",
      "[Pretrain] Epoch 150/150  Loss=1.2286  Acc=0.5957\n",
      "[Fine-tune] Epoch 1/100  Loss=3.2957\n",
      "[Fine-tune] Epoch 2/100  Loss=3.1603\n",
      "[Fine-tune] Epoch 3/100  Loss=3.0619\n",
      "[Fine-tune] Epoch 4/100  Loss=3.0143\n",
      "[Fine-tune] Epoch 5/100  Loss=2.9004\n",
      "[Fine-tune] Epoch 6/100  Loss=2.7709\n",
      "[Fine-tune] Epoch 7/100  Loss=2.6829\n",
      "[Fine-tune] Epoch 8/100  Loss=2.5968\n",
      "[Fine-tune] Epoch 9/100  Loss=2.5106\n",
      "[Fine-tune] Epoch 10/100  Loss=2.4807\n",
      "[Fine-tune] Epoch 11/100  Loss=2.4379\n",
      "[Fine-tune] Epoch 12/100  Loss=2.4162\n",
      "[Fine-tune] Epoch 13/100  Loss=2.3908\n",
      "[Fine-tune] Epoch 14/100  Loss=2.3561\n",
      "[Fine-tune] Epoch 15/100  Loss=2.3226\n",
      "[Fine-tune] Epoch 16/100  Loss=2.3102\n",
      "[Fine-tune] Epoch 17/100  Loss=2.2484\n",
      "[Fine-tune] Epoch 18/100  Loss=2.1992\n",
      "[Fine-tune] Epoch 19/100  Loss=2.1622\n",
      "[Fine-tune] Epoch 20/100  Loss=2.1493\n",
      "[Fine-tune] Epoch 21/100  Loss=2.1084\n",
      "[Fine-tune] Epoch 22/100  Loss=2.0746\n",
      "[Fine-tune] Epoch 23/100  Loss=2.0542\n",
      "[Fine-tune] Epoch 24/100  Loss=2.0227\n",
      "[Fine-tune] Epoch 25/100  Loss=2.0153\n",
      "[Fine-tune] Epoch 26/100  Loss=1.9756\n",
      "[Fine-tune] Epoch 27/100  Loss=1.9482\n",
      "[Fine-tune] Epoch 28/100  Loss=1.9416\n",
      "[Fine-tune] Epoch 29/100  Loss=1.9246\n",
      "[Fine-tune] Epoch 30/100  Loss=1.9022\n",
      "[Fine-tune] Epoch 31/100  Loss=1.8782\n",
      "[Fine-tune] Epoch 32/100  Loss=1.8732\n",
      "[Fine-tune] Epoch 33/100  Loss=1.8544\n",
      "[Fine-tune] Epoch 34/100  Loss=1.8430\n",
      "[Fine-tune] Epoch 35/100  Loss=1.8221\n",
      "[Fine-tune] Epoch 36/100  Loss=1.7901\n",
      "[Fine-tune] Epoch 37/100  Loss=1.7937\n",
      "[Fine-tune] Epoch 38/100  Loss=1.7850\n",
      "[Fine-tune] Epoch 39/100  Loss=1.7627\n",
      "[Fine-tune] Epoch 40/100  Loss=1.7697\n",
      "[Fine-tune] Epoch 41/100  Loss=1.7289\n",
      "[Fine-tune] Epoch 42/100  Loss=1.7346\n",
      "[Fine-tune] Epoch 43/100  Loss=1.7259\n",
      "[Fine-tune] Epoch 44/100  Loss=1.7026\n",
      "[Fine-tune] Epoch 45/100  Loss=1.6987\n",
      "[Fine-tune] Epoch 46/100  Loss=1.6896\n",
      "[Fine-tune] Epoch 47/100  Loss=1.6740\n",
      "[Fine-tune] Epoch 48/100  Loss=1.6599\n",
      "[Fine-tune] Epoch 49/100  Loss=1.6577\n",
      "[Fine-tune] Epoch 50/100  Loss=1.6548\n",
      "[Fine-tune] Epoch 51/100  Loss=1.6414\n",
      "[Fine-tune] Epoch 52/100  Loss=1.6211\n",
      "[Fine-tune] Epoch 53/100  Loss=1.6213\n",
      "[Fine-tune] Epoch 54/100  Loss=1.6235\n",
      "[Fine-tune] Epoch 55/100  Loss=1.6194\n",
      "[Fine-tune] Epoch 56/100  Loss=1.6121\n",
      "[Fine-tune] Epoch 57/100  Loss=1.6153\n",
      "[Fine-tune] Epoch 58/100  Loss=1.6089\n",
      "[Fine-tune] Epoch 59/100  Loss=1.5885\n",
      "[Fine-tune] Epoch 60/100  Loss=1.5902\n",
      "[Fine-tune] Epoch 61/100  Loss=1.5828\n",
      "[Fine-tune] Epoch 62/100  Loss=1.5727\n",
      "[Fine-tune] Epoch 63/100  Loss=1.5668\n",
      "[Fine-tune] Epoch 64/100  Loss=1.5569\n",
      "[Fine-tune] Epoch 65/100  Loss=1.5584\n",
      "[Fine-tune] Epoch 66/100  Loss=1.5413\n",
      "[Fine-tune] Epoch 67/100  Loss=1.5507\n",
      "[Fine-tune] Epoch 68/100  Loss=1.5400\n",
      "[Fine-tune] Epoch 69/100  Loss=1.5580\n",
      "[Fine-tune] Epoch 70/100  Loss=1.5313\n",
      "[Fine-tune] Epoch 71/100  Loss=1.5323\n",
      "[Fine-tune] Epoch 72/100  Loss=1.5363\n",
      "[Fine-tune] Epoch 73/100  Loss=1.5280\n",
      "[Fine-tune] Epoch 74/100  Loss=1.5215\n",
      "[Fine-tune] Epoch 75/100  Loss=1.5246\n",
      "[Fine-tune] Epoch 76/100  Loss=1.5182\n",
      "[Fine-tune] Epoch 77/100  Loss=1.5286\n",
      "[Fine-tune] Epoch 78/100  Loss=1.4938\n",
      "[Fine-tune] Epoch 79/100  Loss=1.5213\n",
      "[Fine-tune] Epoch 80/100  Loss=1.5072\n",
      "[Fine-tune] Epoch 81/100  Loss=1.5060\n",
      "[Fine-tune] Epoch 82/100  Loss=1.5125\n",
      "[Fine-tune] Epoch 83/100  Loss=1.5178\n",
      "[Fine-tune] Epoch 84/100  Loss=1.5059\n",
      "[Fine-tune] Epoch 85/100  Loss=1.5091\n",
      "[Fine-tune] Epoch 86/100  Loss=1.5105\n",
      "[Fine-tune] Epoch 87/100  Loss=1.5005\n",
      "[Fine-tune] Epoch 88/100  Loss=1.4969\n",
      "[Fine-tune] Epoch 89/100  Loss=1.4836\n",
      "[Fine-tune] Epoch 90/100  Loss=1.5078\n",
      "[Fine-tune] Epoch 91/100  Loss=1.4994\n",
      "[Fine-tune] Epoch 92/100  Loss=1.4947\n",
      "[Fine-tune] Epoch 93/100  Loss=1.4776\n",
      "[Fine-tune] Epoch 94/100  Loss=1.4745\n",
      "[Fine-tune] Epoch 95/100  Loss=1.4970\n",
      "[Fine-tune] Epoch 96/100  Loss=1.4671\n",
      "[Fine-tune] Epoch 97/100  Loss=1.4853\n",
      "[Fine-tune] Epoch 98/100  Loss=1.4841\n",
      "[Fine-tune] Epoch 99/100  Loss=1.4880\n",
      "[Fine-tune] Epoch 100/100  Loss=1.4853\n",
      "[Pretrain] Epoch 1/150  Loss=3.6119  Acc=0.0551\n",
      "[Pretrain] Epoch 2/150  Loss=3.0071  Acc=0.0855\n",
      "[Pretrain] Epoch 3/150  Loss=2.7388  Acc=0.1485\n",
      "[Pretrain] Epoch 4/150  Loss=2.6629  Acc=0.1554\n",
      "[Pretrain] Epoch 5/150  Loss=2.5381  Acc=0.1879\n",
      "[Pretrain] Epoch 6/150  Loss=2.4210  Acc=0.2177\n",
      "[Pretrain] Epoch 7/150  Loss=2.3847  Acc=0.2333\n",
      "[Pretrain] Epoch 8/150  Loss=2.2816  Acc=0.2667\n",
      "[Pretrain] Epoch 9/150  Loss=2.2608  Acc=0.2651\n",
      "[Pretrain] Epoch 10/150  Loss=2.2451  Acc=0.2735\n",
      "[Pretrain] Epoch 11/150  Loss=2.1834  Acc=0.2981\n",
      "[Pretrain] Epoch 12/150  Loss=2.1204  Acc=0.3059\n",
      "[Pretrain] Epoch 13/150  Loss=2.1261  Acc=0.3055\n",
      "[Pretrain] Epoch 14/150  Loss=2.0886  Acc=0.3213\n",
      "[Pretrain] Epoch 15/150  Loss=2.0524  Acc=0.3348\n",
      "[Pretrain] Epoch 16/150  Loss=2.0124  Acc=0.3427\n",
      "[Pretrain] Epoch 17/150  Loss=1.9870  Acc=0.3551\n",
      "[Pretrain] Epoch 18/150  Loss=1.9592  Acc=0.3628\n",
      "[Pretrain] Epoch 19/150  Loss=1.9612  Acc=0.3563\n",
      "[Pretrain] Epoch 20/150  Loss=1.9204  Acc=0.3755\n",
      "[Pretrain] Epoch 21/150  Loss=1.8943  Acc=0.3779\n",
      "[Pretrain] Epoch 22/150  Loss=1.8490  Acc=0.3957\n",
      "[Pretrain] Epoch 23/150  Loss=1.8296  Acc=0.3989\n",
      "[Pretrain] Epoch 24/150  Loss=1.8203  Acc=0.4000\n",
      "[Pretrain] Epoch 25/150  Loss=1.7965  Acc=0.4106\n",
      "[Pretrain] Epoch 26/150  Loss=1.7794  Acc=0.4240\n",
      "[Pretrain] Epoch 27/150  Loss=1.7530  Acc=0.4265\n",
      "[Pretrain] Epoch 28/150  Loss=1.7249  Acc=0.4407\n",
      "[Pretrain] Epoch 29/150  Loss=1.7298  Acc=0.4348\n",
      "[Pretrain] Epoch 30/150  Loss=1.6819  Acc=0.4506\n",
      "[Pretrain] Epoch 31/150  Loss=1.6482  Acc=0.4589\n",
      "[Pretrain] Epoch 32/150  Loss=1.6268  Acc=0.4677\n",
      "[Pretrain] Epoch 33/150  Loss=1.6130  Acc=0.4776\n",
      "[Pretrain] Epoch 34/150  Loss=1.5777  Acc=0.4837\n",
      "[Pretrain] Epoch 35/150  Loss=1.5970  Acc=0.4767\n",
      "[Pretrain] Epoch 36/150  Loss=1.5775  Acc=0.4890\n",
      "[Pretrain] Epoch 37/150  Loss=1.5166  Acc=0.5066\n",
      "[Pretrain] Epoch 38/150  Loss=1.5051  Acc=0.5052\n",
      "[Pretrain] Epoch 39/150  Loss=1.5123  Acc=0.5036\n",
      "[Pretrain] Epoch 40/150  Loss=1.4805  Acc=0.5122\n",
      "[Pretrain] Epoch 41/150  Loss=1.4761  Acc=0.5203\n",
      "[Pretrain] Epoch 42/150  Loss=1.4524  Acc=0.5052\n",
      "[Pretrain] Epoch 43/150  Loss=1.4494  Acc=0.5228\n",
      "[Pretrain] Epoch 44/150  Loss=1.4450  Acc=0.5210\n",
      "[Pretrain] Epoch 45/150  Loss=1.4231  Acc=0.5352\n",
      "[Pretrain] Epoch 46/150  Loss=1.4028  Acc=0.5392\n",
      "[Pretrain] Epoch 47/150  Loss=1.3633  Acc=0.5571\n",
      "[Pretrain] Epoch 48/150  Loss=1.3818  Acc=0.5528\n",
      "[Pretrain] Epoch 49/150  Loss=1.3633  Acc=0.5553\n",
      "[Pretrain] Epoch 50/150  Loss=1.3501  Acc=0.5578\n",
      "[Pretrain] Epoch 51/150  Loss=1.3436  Acc=0.5602\n",
      "[Pretrain] Epoch 52/150  Loss=1.3269  Acc=0.5672\n",
      "[Pretrain] Epoch 53/150  Loss=1.3301  Acc=0.5686\n",
      "[Pretrain] Epoch 54/150  Loss=1.3083  Acc=0.5708\n",
      "[Pretrain] Epoch 55/150  Loss=1.3047  Acc=0.5715\n",
      "[Pretrain] Epoch 56/150  Loss=1.2868  Acc=0.5715\n",
      "[Pretrain] Epoch 57/150  Loss=1.2695  Acc=0.5837\n",
      "[Pretrain] Epoch 58/150  Loss=1.2658  Acc=0.5889\n",
      "[Pretrain] Epoch 59/150  Loss=1.2673  Acc=0.5808\n",
      "[Pretrain] Epoch 60/150  Loss=1.2508  Acc=0.5896\n",
      "[Pretrain] Epoch 61/150  Loss=1.2539  Acc=0.5866\n",
      "[Pretrain] Epoch 62/150  Loss=1.2561  Acc=0.5871\n",
      "[Pretrain] Epoch 63/150  Loss=1.2488  Acc=0.5896\n",
      "[Pretrain] Epoch 64/150  Loss=1.2403  Acc=0.5900\n",
      "[Pretrain] Epoch 65/150  Loss=1.2215  Acc=0.5923\n",
      "[Pretrain] Epoch 66/150  Loss=1.2103  Acc=0.6070\n",
      "[Pretrain] Epoch 67/150  Loss=1.2272  Acc=0.5955\n",
      "[Pretrain] Epoch 68/150  Loss=1.2204  Acc=0.5959\n",
      "[Pretrain] Epoch 69/150  Loss=1.2179  Acc=0.5914\n",
      "[Pretrain] Epoch 70/150  Loss=1.2008  Acc=0.6056\n",
      "[Pretrain] Epoch 71/150  Loss=1.2034  Acc=0.6078\n",
      "[Pretrain] Epoch 72/150  Loss=1.1900  Acc=0.6108\n",
      "[Pretrain] Epoch 73/150  Loss=1.2008  Acc=0.6045\n",
      "[Pretrain] Epoch 74/150  Loss=1.2030  Acc=0.6036\n",
      "[Pretrain] Epoch 75/150  Loss=1.1853  Acc=0.6036\n",
      "[Pretrain] Epoch 76/150  Loss=1.1717  Acc=0.6162\n",
      "[Pretrain] Epoch 77/150  Loss=1.1687  Acc=0.6142\n",
      "[Pretrain] Epoch 78/150  Loss=1.1844  Acc=0.6135\n",
      "[Pretrain] Epoch 79/150  Loss=1.1702  Acc=0.6151\n",
      "[Pretrain] Epoch 80/150  Loss=1.1717  Acc=0.6083\n",
      "[Pretrain] Epoch 81/150  Loss=1.1622  Acc=0.6166\n",
      "[Pretrain] Epoch 82/150  Loss=1.1638  Acc=0.6175\n",
      "[Pretrain] Epoch 83/150  Loss=1.1743  Acc=0.6164\n",
      "[Pretrain] Epoch 84/150  Loss=1.1691  Acc=0.6160\n",
      "[Pretrain] Epoch 85/150  Loss=1.1744  Acc=0.6160\n",
      "[Pretrain] Epoch 86/150  Loss=1.1627  Acc=0.6200\n",
      "[Pretrain] Epoch 87/150  Loss=1.1583  Acc=0.6230\n",
      "[Pretrain] Epoch 88/150  Loss=1.1517  Acc=0.6205\n",
      "[Pretrain] Epoch 89/150  Loss=1.1474  Acc=0.6219\n",
      "[Pretrain] Epoch 90/150  Loss=1.1593  Acc=0.6182\n",
      "[Pretrain] Epoch 91/150  Loss=1.1413  Acc=0.6261\n",
      "[Pretrain] Epoch 92/150  Loss=1.1288  Acc=0.6300\n",
      "[Pretrain] Epoch 93/150  Loss=1.1517  Acc=0.6187\n",
      "[Pretrain] Epoch 94/150  Loss=1.1384  Acc=0.6162\n",
      "[Pretrain] Epoch 95/150  Loss=1.1544  Acc=0.6241\n",
      "[Pretrain] Epoch 96/150  Loss=1.1343  Acc=0.6295\n",
      "[Pretrain] Epoch 97/150  Loss=1.1333  Acc=0.6298\n",
      "[Pretrain] Epoch 98/150  Loss=1.1213  Acc=0.6356\n",
      "[Pretrain] Epoch 99/150  Loss=1.1446  Acc=0.6286\n",
      "[Pretrain] Epoch 100/150  Loss=1.1301  Acc=0.6342\n",
      "[Pretrain] Epoch 101/150  Loss=1.1430  Acc=0.6272\n",
      "[Pretrain] Epoch 102/150  Loss=1.1301  Acc=0.6302\n",
      "[Pretrain] Epoch 103/150  Loss=1.1326  Acc=0.6239\n",
      "[Pretrain] Epoch 104/150  Loss=1.1419  Acc=0.6218\n",
      "[Pretrain] Epoch 105/150  Loss=1.1384  Acc=0.6205\n",
      "[Pretrain] Epoch 106/150  Loss=1.1407  Acc=0.6232\n",
      "[Pretrain] Epoch 107/150  Loss=1.1325  Acc=0.6223\n",
      "[Pretrain] Epoch 108/150  Loss=1.1299  Acc=0.6257\n",
      "[Pretrain] Epoch 109/150  Loss=1.1365  Acc=0.6322\n",
      "[Pretrain] Epoch 110/150  Loss=1.1408  Acc=0.6288\n",
      "[Pretrain] Epoch 111/150  Loss=1.1333  Acc=0.6252\n",
      "[Pretrain] Epoch 112/150  Loss=1.1296  Acc=0.6304\n",
      "[Pretrain] Epoch 113/150  Loss=1.1217  Acc=0.6307\n",
      "[Pretrain] Epoch 114/150  Loss=1.1399  Acc=0.6207\n",
      "[Pretrain] Epoch 115/150  Loss=1.1334  Acc=0.6290\n",
      "[Pretrain] Epoch 116/150  Loss=1.1185  Acc=0.6333\n",
      "[Pretrain] Epoch 117/150  Loss=1.1353  Acc=0.6237\n",
      "[Pretrain] Epoch 118/150  Loss=1.1299  Acc=0.6259\n",
      "[Pretrain] Epoch 119/150  Loss=1.1253  Acc=0.6298\n",
      "[Pretrain] Epoch 120/150  Loss=1.1235  Acc=0.6230\n",
      "[Pretrain] Epoch 121/150  Loss=1.1068  Acc=0.6363\n",
      "[Pretrain] Epoch 122/150  Loss=1.1085  Acc=0.6336\n",
      "[Pretrain] Epoch 123/150  Loss=1.1274  Acc=0.6315\n",
      "[Pretrain] Epoch 124/150  Loss=1.1311  Acc=0.6327\n",
      "[Pretrain] Epoch 125/150  Loss=1.1327  Acc=0.6257\n",
      "[Pretrain] Epoch 126/150  Loss=1.1350  Acc=0.6286\n",
      "[Pretrain] Epoch 127/150  Loss=1.1290  Acc=0.6295\n",
      "[Pretrain] Epoch 128/150  Loss=1.1140  Acc=0.6365\n",
      "[Pretrain] Epoch 129/150  Loss=1.1405  Acc=0.6268\n",
      "[Pretrain] Epoch 130/150  Loss=1.1293  Acc=0.6252\n",
      "[Pretrain] Epoch 131/150  Loss=1.1183  Acc=0.6316\n",
      "[Pretrain] Epoch 132/150  Loss=1.1321  Acc=0.6307\n",
      "[Pretrain] Epoch 133/150  Loss=1.1143  Acc=0.6298\n",
      "[Pretrain] Epoch 134/150  Loss=1.1263  Acc=0.6302\n",
      "[Pretrain] Epoch 135/150  Loss=1.1405  Acc=0.6180\n",
      "[Pretrain] Epoch 136/150  Loss=1.1262  Acc=0.6295\n",
      "[Pretrain] Epoch 137/150  Loss=1.1154  Acc=0.6331\n",
      "[Pretrain] Epoch 138/150  Loss=1.1214  Acc=0.6290\n",
      "[Pretrain] Epoch 139/150  Loss=1.1237  Acc=0.6237\n",
      "[Pretrain] Epoch 140/150  Loss=1.1208  Acc=0.6343\n",
      "[Pretrain] Epoch 141/150  Loss=1.1314  Acc=0.6250\n",
      "[Pretrain] Epoch 142/150  Loss=1.1187  Acc=0.6394\n",
      "[Pretrain] Epoch 143/150  Loss=1.1110  Acc=0.6309\n",
      "[Pretrain] Epoch 144/150  Loss=1.1229  Acc=0.6313\n",
      "[Pretrain] Epoch 145/150  Loss=1.1194  Acc=0.6345\n",
      "[Pretrain] Epoch 146/150  Loss=1.1260  Acc=0.6307\n",
      "[Pretrain] Epoch 147/150  Loss=1.1149  Acc=0.6347\n",
      "[Pretrain] Epoch 148/150  Loss=1.1077  Acc=0.6370\n",
      "[Pretrain] Epoch 149/150  Loss=1.1252  Acc=0.6327\n",
      "[Pretrain] Epoch 150/150  Loss=1.1249  Acc=0.6390\n",
      "[Fine-tune] Epoch 1/100  Loss=3.2491\n",
      "[Fine-tune] Epoch 2/100  Loss=2.8858\n",
      "[Fine-tune] Epoch 3/100  Loss=2.5906\n",
      "[Fine-tune] Epoch 4/100  Loss=2.4867\n",
      "[Fine-tune] Epoch 5/100  Loss=2.4126\n",
      "[Fine-tune] Epoch 6/100  Loss=2.3436\n",
      "[Fine-tune] Epoch 7/100  Loss=2.2844\n",
      "[Fine-tune] Epoch 8/100  Loss=2.2341\n",
      "[Fine-tune] Epoch 9/100  Loss=2.2115\n",
      "[Fine-tune] Epoch 10/100  Loss=2.1577\n",
      "[Fine-tune] Epoch 11/100  Loss=2.1122\n",
      "[Fine-tune] Epoch 12/100  Loss=2.0807\n",
      "[Fine-tune] Epoch 13/100  Loss=2.0657\n",
      "[Fine-tune] Epoch 14/100  Loss=2.0298\n",
      "[Fine-tune] Epoch 15/100  Loss=2.0078\n",
      "[Fine-tune] Epoch 16/100  Loss=1.9535\n",
      "[Fine-tune] Epoch 17/100  Loss=1.9308\n",
      "[Fine-tune] Epoch 18/100  Loss=1.9160\n",
      "[Fine-tune] Epoch 19/100  Loss=1.8906\n",
      "[Fine-tune] Epoch 20/100  Loss=1.8608\n",
      "[Fine-tune] Epoch 21/100  Loss=1.8463\n",
      "[Fine-tune] Epoch 22/100  Loss=1.8348\n",
      "[Fine-tune] Epoch 23/100  Loss=1.8151\n",
      "[Fine-tune] Epoch 24/100  Loss=1.7960\n",
      "[Fine-tune] Epoch 25/100  Loss=1.7706\n",
      "[Fine-tune] Epoch 26/100  Loss=1.7621\n",
      "[Fine-tune] Epoch 27/100  Loss=1.7397\n",
      "[Fine-tune] Epoch 28/100  Loss=1.7403\n",
      "[Fine-tune] Epoch 29/100  Loss=1.7179\n",
      "[Fine-tune] Epoch 30/100  Loss=1.6909\n",
      "[Fine-tune] Epoch 31/100  Loss=1.6862\n",
      "[Fine-tune] Epoch 32/100  Loss=1.6590\n",
      "[Fine-tune] Epoch 33/100  Loss=1.6514\n",
      "[Fine-tune] Epoch 34/100  Loss=1.6589\n",
      "[Fine-tune] Epoch 35/100  Loss=1.6308\n",
      "[Fine-tune] Epoch 36/100  Loss=1.6302\n",
      "[Fine-tune] Epoch 37/100  Loss=1.6170\n",
      "[Fine-tune] Epoch 38/100  Loss=1.5871\n",
      "[Fine-tune] Epoch 39/100  Loss=1.6012\n",
      "[Fine-tune] Epoch 40/100  Loss=1.5768\n",
      "[Fine-tune] Epoch 41/100  Loss=1.5749\n",
      "[Fine-tune] Epoch 42/100  Loss=1.5750\n",
      "[Fine-tune] Epoch 43/100  Loss=1.5497\n",
      "[Fine-tune] Epoch 44/100  Loss=1.5346\n",
      "[Fine-tune] Epoch 45/100  Loss=1.5434\n",
      "[Fine-tune] Epoch 46/100  Loss=1.5339\n",
      "[Fine-tune] Epoch 47/100  Loss=1.5307\n",
      "[Fine-tune] Epoch 48/100  Loss=1.5195\n",
      "[Fine-tune] Epoch 49/100  Loss=1.5206\n",
      "[Fine-tune] Epoch 50/100  Loss=1.5255\n",
      "[Fine-tune] Epoch 51/100  Loss=1.5235\n",
      "[Fine-tune] Epoch 52/100  Loss=1.4978\n",
      "[Fine-tune] Epoch 53/100  Loss=1.4817\n",
      "[Fine-tune] Epoch 54/100  Loss=1.4913\n",
      "[Fine-tune] Epoch 55/100  Loss=1.4769\n",
      "[Fine-tune] Epoch 56/100  Loss=1.4816\n",
      "[Fine-tune] Epoch 57/100  Loss=1.4688\n",
      "[Fine-tune] Epoch 58/100  Loss=1.4730\n",
      "[Fine-tune] Epoch 59/100  Loss=1.4770\n",
      "[Fine-tune] Epoch 60/100  Loss=1.4597\n",
      "[Fine-tune] Epoch 61/100  Loss=1.4527\n",
      "[Fine-tune] Epoch 62/100  Loss=1.4666\n",
      "[Fine-tune] Epoch 63/100  Loss=1.4474\n",
      "[Fine-tune] Epoch 64/100  Loss=1.4548\n",
      "[Fine-tune] Epoch 65/100  Loss=1.4546\n",
      "[Fine-tune] Epoch 66/100  Loss=1.4358\n",
      "[Fine-tune] Epoch 67/100  Loss=1.4372\n",
      "[Fine-tune] Epoch 68/100  Loss=1.4439\n",
      "[Fine-tune] Epoch 69/100  Loss=1.4421\n",
      "[Fine-tune] Epoch 70/100  Loss=1.4457\n",
      "[Fine-tune] Epoch 71/100  Loss=1.4418\n",
      "[Fine-tune] Epoch 72/100  Loss=1.4188\n",
      "[Fine-tune] Epoch 73/100  Loss=1.4248\n",
      "[Fine-tune] Epoch 74/100  Loss=1.4278\n",
      "[Fine-tune] Epoch 75/100  Loss=1.4339\n",
      "[Fine-tune] Epoch 76/100  Loss=1.4301\n",
      "[Fine-tune] Epoch 77/100  Loss=1.4214\n",
      "[Fine-tune] Epoch 78/100  Loss=1.4164\n",
      "[Fine-tune] Epoch 79/100  Loss=1.4188\n",
      "[Fine-tune] Epoch 80/100  Loss=1.4245\n",
      "[Fine-tune] Epoch 81/100  Loss=1.4167\n",
      "[Fine-tune] Epoch 82/100  Loss=1.4262\n",
      "[Fine-tune] Epoch 83/100  Loss=1.4214\n",
      "[Fine-tune] Epoch 84/100  Loss=1.4164\n",
      "[Fine-tune] Epoch 85/100  Loss=1.4173\n",
      "[Fine-tune] Epoch 86/100  Loss=1.4163\n",
      "[Fine-tune] Epoch 87/100  Loss=1.4081\n",
      "[Fine-tune] Epoch 88/100  Loss=1.4105\n",
      "[Fine-tune] Epoch 89/100  Loss=1.4037\n",
      "[Fine-tune] Epoch 90/100  Loss=1.4107\n",
      "[Fine-tune] Epoch 91/100  Loss=1.4240\n",
      "[Fine-tune] Epoch 92/100  Loss=1.4219\n",
      "[Fine-tune] Epoch 93/100  Loss=1.4064\n",
      "[Fine-tune] Epoch 94/100  Loss=1.4090\n",
      "[Fine-tune] Epoch 95/100  Loss=1.4063\n",
      "[Fine-tune] Epoch 96/100  Loss=1.4167\n",
      "[Fine-tune] Epoch 97/100  Loss=1.4008\n",
      "[Fine-tune] Epoch 98/100  Loss=1.4035\n",
      "[Fine-tune] Epoch 99/100  Loss=1.3996\n",
      "[Fine-tune] Epoch 100/100  Loss=1.4091\n",
      "[Pretrain] Epoch 1/50  Loss=3.2403  Acc=0.0422\n",
      "[Pretrain] Epoch 2/50  Loss=3.0906  Acc=0.0736\n",
      "[Pretrain] Epoch 3/50  Loss=2.8442  Acc=0.1212\n",
      "[Pretrain] Epoch 4/50  Loss=2.5519  Acc=0.1895\n",
      "[Pretrain] Epoch 5/50  Loss=2.3681  Acc=0.2473\n",
      "[Pretrain] Epoch 6/50  Loss=2.2655  Acc=0.2721\n",
      "[Pretrain] Epoch 7/50  Loss=2.1841  Acc=0.2847\n",
      "[Pretrain] Epoch 8/50  Loss=2.1124  Acc=0.3064\n",
      "[Pretrain] Epoch 9/50  Loss=2.0936  Acc=0.3125\n",
      "[Pretrain] Epoch 10/50  Loss=2.0735  Acc=0.3261\n",
      "[Pretrain] Epoch 11/50  Loss=2.0254  Acc=0.3357\n",
      "[Pretrain] Epoch 12/50  Loss=2.0037  Acc=0.3468\n",
      "[Pretrain] Epoch 13/50  Loss=1.9765  Acc=0.3606\n",
      "[Pretrain] Epoch 14/50  Loss=1.9515  Acc=0.3680\n",
      "[Pretrain] Epoch 15/50  Loss=1.9158  Acc=0.3775\n",
      "[Pretrain] Epoch 16/50  Loss=1.9229  Acc=0.3691\n",
      "[Pretrain] Epoch 17/50  Loss=1.8850  Acc=0.3883\n",
      "[Pretrain] Epoch 18/50  Loss=1.8620  Acc=0.3974\n",
      "[Pretrain] Epoch 19/50  Loss=1.8083  Acc=0.4102\n",
      "[Pretrain] Epoch 20/50  Loss=1.8082  Acc=0.4145\n",
      "[Pretrain] Epoch 21/50  Loss=1.7944  Acc=0.4278\n",
      "[Pretrain] Epoch 22/50  Loss=1.7718  Acc=0.4251\n",
      "[Pretrain] Epoch 23/50  Loss=1.7210  Acc=0.4456\n",
      "[Pretrain] Epoch 24/50  Loss=1.7229  Acc=0.4411\n",
      "[Pretrain] Epoch 25/50  Loss=1.7134  Acc=0.4513\n",
      "[Pretrain] Epoch 26/50  Loss=1.6948  Acc=0.4517\n",
      "[Pretrain] Epoch 27/50  Loss=1.6732  Acc=0.4605\n",
      "[Pretrain] Epoch 28/50  Loss=1.6550  Acc=0.4517\n",
      "[Pretrain] Epoch 29/50  Loss=1.6536  Acc=0.4705\n",
      "[Pretrain] Epoch 30/50  Loss=1.6115  Acc=0.4750\n",
      "[Pretrain] Epoch 31/50  Loss=1.6176  Acc=0.4804\n",
      "[Pretrain] Epoch 32/50  Loss=1.5883  Acc=0.4869\n",
      "[Pretrain] Epoch 33/50  Loss=1.5822  Acc=0.4864\n",
      "[Pretrain] Epoch 34/50  Loss=1.5681  Acc=0.4862\n",
      "[Pretrain] Epoch 35/50  Loss=1.5485  Acc=0.4950\n",
      "[Pretrain] Epoch 36/50  Loss=1.5215  Acc=0.5047\n",
      "[Pretrain] Epoch 37/50  Loss=1.5246  Acc=0.5041\n",
      "[Pretrain] Epoch 38/50  Loss=1.5131  Acc=0.5063\n",
      "[Pretrain] Epoch 39/50  Loss=1.5005  Acc=0.5124\n",
      "[Pretrain] Epoch 40/50  Loss=1.4878  Acc=0.5140\n",
      "[Pretrain] Epoch 41/50  Loss=1.4868  Acc=0.5131\n",
      "[Pretrain] Epoch 42/50  Loss=1.4666  Acc=0.5219\n",
      "[Pretrain] Epoch 43/50  Loss=1.4556  Acc=0.5348\n",
      "[Pretrain] Epoch 44/50  Loss=1.4420  Acc=0.5257\n",
      "[Pretrain] Epoch 45/50  Loss=1.4287  Acc=0.5377\n",
      "[Pretrain] Epoch 46/50  Loss=1.4349  Acc=0.5323\n",
      "[Pretrain] Epoch 47/50  Loss=1.4261  Acc=0.5357\n",
      "[Pretrain] Epoch 48/50  Loss=1.4208  Acc=0.5427\n",
      "[Pretrain] Epoch 49/50  Loss=1.4174  Acc=0.5368\n",
      "[Pretrain] Epoch 50/50  Loss=1.3945  Acc=0.5467\n",
      "[Fine-tune] Epoch 1/100  Loss=3.2384\n",
      "[Fine-tune] Epoch 2/100  Loss=3.0517\n",
      "[Fine-tune] Epoch 3/100  Loss=2.9966\n",
      "[Fine-tune] Epoch 4/100  Loss=2.7961\n",
      "[Fine-tune] Epoch 5/100  Loss=2.5935\n",
      "[Fine-tune] Epoch 6/100  Loss=2.4919\n",
      "[Fine-tune] Epoch 7/100  Loss=2.4015\n",
      "[Fine-tune] Epoch 8/100  Loss=2.3307\n",
      "[Fine-tune] Epoch 9/100  Loss=2.2708\n",
      "[Fine-tune] Epoch 10/100  Loss=2.2472\n",
      "[Fine-tune] Epoch 11/100  Loss=2.2290\n",
      "[Fine-tune] Epoch 12/100  Loss=2.1645\n",
      "[Fine-tune] Epoch 13/100  Loss=2.1359\n",
      "[Fine-tune] Epoch 14/100  Loss=2.1019\n",
      "[Fine-tune] Epoch 15/100  Loss=2.0727\n",
      "[Fine-tune] Epoch 16/100  Loss=2.0511\n",
      "[Fine-tune] Epoch 17/100  Loss=1.9973\n",
      "[Fine-tune] Epoch 18/100  Loss=1.9893\n",
      "[Fine-tune] Epoch 19/100  Loss=1.9570\n",
      "[Fine-tune] Epoch 20/100  Loss=1.9274\n",
      "[Fine-tune] Epoch 21/100  Loss=1.9117\n",
      "[Fine-tune] Epoch 22/100  Loss=1.8929\n",
      "[Fine-tune] Epoch 23/100  Loss=1.8946\n",
      "[Fine-tune] Epoch 24/100  Loss=1.8523\n",
      "[Fine-tune] Epoch 25/100  Loss=1.8392\n",
      "[Fine-tune] Epoch 26/100  Loss=1.8101\n",
      "[Fine-tune] Epoch 27/100  Loss=1.8077\n",
      "[Fine-tune] Epoch 28/100  Loss=1.7889\n",
      "[Fine-tune] Epoch 29/100  Loss=1.7678\n",
      "[Fine-tune] Epoch 30/100  Loss=1.7424\n",
      "[Fine-tune] Epoch 31/100  Loss=1.7345\n",
      "[Fine-tune] Epoch 32/100  Loss=1.7166\n",
      "[Fine-tune] Epoch 33/100  Loss=1.7024\n",
      "[Fine-tune] Epoch 34/100  Loss=1.6819\n",
      "[Fine-tune] Epoch 35/100  Loss=1.6745\n",
      "[Fine-tune] Epoch 36/100  Loss=1.6655\n",
      "[Fine-tune] Epoch 37/100  Loss=1.6353\n",
      "[Fine-tune] Epoch 38/100  Loss=1.6340\n",
      "[Fine-tune] Epoch 39/100  Loss=1.6106\n",
      "[Fine-tune] Epoch 40/100  Loss=1.6095\n",
      "[Fine-tune] Epoch 41/100  Loss=1.5923\n",
      "[Fine-tune] Epoch 42/100  Loss=1.5896\n",
      "[Fine-tune] Epoch 43/100  Loss=1.5817\n",
      "[Fine-tune] Epoch 44/100  Loss=1.5828\n",
      "[Fine-tune] Epoch 45/100  Loss=1.5482\n",
      "[Fine-tune] Epoch 46/100  Loss=1.5548\n",
      "[Fine-tune] Epoch 47/100  Loss=1.5387\n",
      "[Fine-tune] Epoch 48/100  Loss=1.5343\n",
      "[Fine-tune] Epoch 49/100  Loss=1.5232\n",
      "[Fine-tune] Epoch 50/100  Loss=1.5222\n",
      "[Fine-tune] Epoch 51/100  Loss=1.5124\n",
      "[Fine-tune] Epoch 52/100  Loss=1.5039\n",
      "[Fine-tune] Epoch 53/100  Loss=1.5065\n",
      "[Fine-tune] Epoch 54/100  Loss=1.4893\n",
      "[Fine-tune] Epoch 55/100  Loss=1.4896\n",
      "[Fine-tune] Epoch 56/100  Loss=1.4790\n",
      "[Fine-tune] Epoch 57/100  Loss=1.4717\n",
      "[Fine-tune] Epoch 58/100  Loss=1.4777\n",
      "[Fine-tune] Epoch 59/100  Loss=1.4697\n",
      "[Fine-tune] Epoch 60/100  Loss=1.4669\n",
      "[Fine-tune] Epoch 61/100  Loss=1.4442\n",
      "[Fine-tune] Epoch 62/100  Loss=1.4508\n",
      "[Fine-tune] Epoch 63/100  Loss=1.4504\n",
      "[Fine-tune] Epoch 64/100  Loss=1.4445\n",
      "[Fine-tune] Epoch 65/100  Loss=1.4470\n",
      "[Fine-tune] Epoch 66/100  Loss=1.4384\n",
      "[Fine-tune] Epoch 67/100  Loss=1.4378\n",
      "[Fine-tune] Epoch 68/100  Loss=1.4335\n",
      "[Fine-tune] Epoch 69/100  Loss=1.4275\n",
      "[Fine-tune] Epoch 70/100  Loss=1.4286\n",
      "[Fine-tune] Epoch 71/100  Loss=1.4394\n",
      "[Fine-tune] Epoch 72/100  Loss=1.4217\n",
      "[Fine-tune] Epoch 73/100  Loss=1.4291\n",
      "[Fine-tune] Epoch 74/100  Loss=1.4010\n",
      "[Fine-tune] Epoch 75/100  Loss=1.4217\n",
      "[Fine-tune] Epoch 76/100  Loss=1.4194\n",
      "[Fine-tune] Epoch 77/100  Loss=1.4161\n",
      "[Fine-tune] Epoch 78/100  Loss=1.4121\n",
      "[Fine-tune] Epoch 79/100  Loss=1.4130\n",
      "[Fine-tune] Epoch 80/100  Loss=1.4111\n",
      "[Fine-tune] Epoch 81/100  Loss=1.4072\n",
      "[Fine-tune] Epoch 82/100  Loss=1.4209\n",
      "[Fine-tune] Epoch 83/100  Loss=1.4149\n",
      "[Fine-tune] Epoch 84/100  Loss=1.4057\n",
      "[Fine-tune] Epoch 85/100  Loss=1.3950\n",
      "[Fine-tune] Epoch 86/100  Loss=1.3869\n",
      "[Fine-tune] Epoch 87/100  Loss=1.4101\n",
      "[Fine-tune] Epoch 88/100  Loss=1.3896\n",
      "[Fine-tune] Epoch 89/100  Loss=1.3904\n",
      "[Fine-tune] Epoch 90/100  Loss=1.3899\n",
      "[Fine-tune] Epoch 91/100  Loss=1.3933\n",
      "[Fine-tune] Epoch 92/100  Loss=1.3930\n",
      "[Fine-tune] Epoch 93/100  Loss=1.3833\n",
      "[Fine-tune] Epoch 94/100  Loss=1.3920\n",
      "[Fine-tune] Epoch 95/100  Loss=1.3882\n",
      "[Fine-tune] Epoch 96/100  Loss=1.3853\n",
      "[Fine-tune] Epoch 97/100  Loss=1.3832\n",
      "[Fine-tune] Epoch 98/100  Loss=1.3917\n",
      "[Fine-tune] Epoch 99/100  Loss=1.3937\n",
      "[Fine-tune] Epoch 100/100  Loss=1.3855\n",
      "[Pretrain] Epoch 1/50  Loss=3.6715  Acc=0.0402\n",
      "[Pretrain] Epoch 2/50  Loss=3.1181  Acc=0.0706\n",
      "[Pretrain] Epoch 3/50  Loss=2.9786  Acc=0.0855\n",
      "[Pretrain] Epoch 4/50  Loss=2.7560  Acc=0.1117\n",
      "[Pretrain] Epoch 5/50  Loss=2.6334  Acc=0.1552\n",
      "[Pretrain] Epoch 6/50  Loss=2.5454  Acc=0.1735\n",
      "[Pretrain] Epoch 7/50  Loss=2.4230  Acc=0.2144\n",
      "[Pretrain] Epoch 8/50  Loss=2.3345  Acc=0.2405\n",
      "[Pretrain] Epoch 9/50  Loss=2.2917  Acc=0.2568\n",
      "[Pretrain] Epoch 10/50  Loss=2.2372  Acc=0.2726\n",
      "[Pretrain] Epoch 11/50  Loss=2.2062  Acc=0.2839\n",
      "[Pretrain] Epoch 12/50  Loss=2.1434  Acc=0.2933\n",
      "[Pretrain] Epoch 13/50  Loss=2.1283  Acc=0.3120\n",
      "[Pretrain] Epoch 14/50  Loss=2.1107  Acc=0.3195\n",
      "[Pretrain] Epoch 15/50  Loss=2.0699  Acc=0.3276\n",
      "[Pretrain] Epoch 16/50  Loss=2.0377  Acc=0.3427\n",
      "[Pretrain] Epoch 17/50  Loss=2.0332  Acc=0.3373\n",
      "[Pretrain] Epoch 18/50  Loss=1.9683  Acc=0.3576\n",
      "[Pretrain] Epoch 19/50  Loss=1.9353  Acc=0.3639\n",
      "[Pretrain] Epoch 20/50  Loss=1.9024  Acc=0.3798\n",
      "[Pretrain] Epoch 21/50  Loss=1.8971  Acc=0.3878\n",
      "[Pretrain] Epoch 22/50  Loss=1.8661  Acc=0.3922\n",
      "[Pretrain] Epoch 23/50  Loss=1.8224  Acc=0.4086\n",
      "[Pretrain] Epoch 24/50  Loss=1.8217  Acc=0.4082\n",
      "[Pretrain] Epoch 25/50  Loss=1.7729  Acc=0.4262\n",
      "[Pretrain] Epoch 26/50  Loss=1.7591  Acc=0.4364\n",
      "[Pretrain] Epoch 27/50  Loss=1.7429  Acc=0.4404\n",
      "[Pretrain] Epoch 28/50  Loss=1.7041  Acc=0.4436\n",
      "[Pretrain] Epoch 29/50  Loss=1.6866  Acc=0.4517\n",
      "[Pretrain] Epoch 30/50  Loss=1.6584  Acc=0.4599\n",
      "[Pretrain] Epoch 31/50  Loss=1.6445  Acc=0.4621\n",
      "[Pretrain] Epoch 32/50  Loss=1.6153  Acc=0.4758\n",
      "[Pretrain] Epoch 33/50  Loss=1.5951  Acc=0.4865\n",
      "[Pretrain] Epoch 34/50  Loss=1.5866  Acc=0.4793\n",
      "[Pretrain] Epoch 35/50  Loss=1.5403  Acc=0.4935\n",
      "[Pretrain] Epoch 36/50  Loss=1.5416  Acc=0.4932\n",
      "[Pretrain] Epoch 37/50  Loss=1.5035  Acc=0.5075\n",
      "[Pretrain] Epoch 38/50  Loss=1.5044  Acc=0.5115\n",
      "[Pretrain] Epoch 39/50  Loss=1.4876  Acc=0.5165\n",
      "[Pretrain] Epoch 40/50  Loss=1.4695  Acc=0.5207\n",
      "[Pretrain] Epoch 41/50  Loss=1.4317  Acc=0.5309\n",
      "[Pretrain] Epoch 42/50  Loss=1.4344  Acc=0.5260\n",
      "[Pretrain] Epoch 43/50  Loss=1.4301  Acc=0.5366\n",
      "[Pretrain] Epoch 44/50  Loss=1.4008  Acc=0.5397\n",
      "[Pretrain] Epoch 45/50  Loss=1.3894  Acc=0.5451\n",
      "[Pretrain] Epoch 46/50  Loss=1.3754  Acc=0.5489\n",
      "[Pretrain] Epoch 47/50  Loss=1.3629  Acc=0.5559\n",
      "[Pretrain] Epoch 48/50  Loss=1.3440  Acc=0.5584\n",
      "[Pretrain] Epoch 49/50  Loss=1.3432  Acc=0.5620\n",
      "[Pretrain] Epoch 50/50  Loss=1.3411  Acc=0.5638\n",
      "[Fine-tune] Epoch 1/100  Loss=2.9864\n",
      "[Fine-tune] Epoch 2/100  Loss=2.4727\n",
      "[Fine-tune] Epoch 3/100  Loss=2.3532\n",
      "[Fine-tune] Epoch 4/100  Loss=2.2199\n",
      "[Fine-tune] Epoch 5/100  Loss=2.1771\n",
      "[Fine-tune] Epoch 6/100  Loss=2.0946\n",
      "[Fine-tune] Epoch 7/100  Loss=2.0444\n",
      "[Fine-tune] Epoch 8/100  Loss=1.9969\n",
      "[Fine-tune] Epoch 9/100  Loss=1.9506\n",
      "[Fine-tune] Epoch 10/100  Loss=1.9247\n",
      "[Fine-tune] Epoch 11/100  Loss=1.8742\n",
      "[Fine-tune] Epoch 12/100  Loss=1.8313\n",
      "[Fine-tune] Epoch 13/100  Loss=1.8046\n",
      "[Fine-tune] Epoch 14/100  Loss=1.7658\n",
      "[Fine-tune] Epoch 15/100  Loss=1.7147\n",
      "[Fine-tune] Epoch 16/100  Loss=1.7011\n",
      "[Fine-tune] Epoch 17/100  Loss=1.6489\n",
      "[Fine-tune] Epoch 18/100  Loss=1.6263\n",
      "[Fine-tune] Epoch 19/100  Loss=1.5983\n",
      "[Fine-tune] Epoch 20/100  Loss=1.5873\n",
      "[Fine-tune] Epoch 21/100  Loss=1.5397\n",
      "[Fine-tune] Epoch 22/100  Loss=1.5248\n",
      "[Fine-tune] Epoch 23/100  Loss=1.4963\n",
      "[Fine-tune] Epoch 24/100  Loss=1.4735\n",
      "[Fine-tune] Epoch 25/100  Loss=1.4617\n",
      "[Fine-tune] Epoch 26/100  Loss=1.4347\n",
      "[Fine-tune] Epoch 27/100  Loss=1.3981\n",
      "[Fine-tune] Epoch 28/100  Loss=1.3875\n",
      "[Fine-tune] Epoch 29/100  Loss=1.3714\n",
      "[Fine-tune] Epoch 30/100  Loss=1.3510\n",
      "[Fine-tune] Epoch 31/100  Loss=1.3296\n",
      "[Fine-tune] Epoch 32/100  Loss=1.3152\n",
      "[Fine-tune] Epoch 33/100  Loss=1.2944\n",
      "[Fine-tune] Epoch 34/100  Loss=1.2862\n",
      "[Fine-tune] Epoch 35/100  Loss=1.2944\n",
      "[Fine-tune] Epoch 36/100  Loss=1.2665\n",
      "[Fine-tune] Epoch 37/100  Loss=1.2520\n",
      "[Fine-tune] Epoch 38/100  Loss=1.2387\n",
      "[Fine-tune] Epoch 39/100  Loss=1.2188\n",
      "[Fine-tune] Epoch 40/100  Loss=1.2345\n",
      "[Fine-tune] Epoch 41/100  Loss=1.2132\n",
      "[Fine-tune] Epoch 42/100  Loss=1.2126\n",
      "[Fine-tune] Epoch 43/100  Loss=1.1853\n",
      "[Fine-tune] Epoch 44/100  Loss=1.1783\n",
      "[Fine-tune] Epoch 45/100  Loss=1.1778\n",
      "[Fine-tune] Epoch 46/100  Loss=1.1764\n",
      "[Fine-tune] Epoch 47/100  Loss=1.1587\n",
      "[Fine-tune] Epoch 48/100  Loss=1.1498\n",
      "[Fine-tune] Epoch 49/100  Loss=1.1427\n",
      "[Fine-tune] Epoch 50/100  Loss=1.1560\n",
      "[Fine-tune] Epoch 51/100  Loss=1.1244\n",
      "[Fine-tune] Epoch 52/100  Loss=1.1344\n",
      "[Fine-tune] Epoch 53/100  Loss=1.1219\n",
      "[Fine-tune] Epoch 54/100  Loss=1.1324\n",
      "[Fine-tune] Epoch 55/100  Loss=1.1102\n",
      "[Fine-tune] Epoch 56/100  Loss=1.1116\n",
      "[Fine-tune] Epoch 57/100  Loss=1.0980\n",
      "[Fine-tune] Epoch 58/100  Loss=1.1047\n",
      "[Fine-tune] Epoch 59/100  Loss=1.0994\n",
      "[Fine-tune] Epoch 60/100  Loss=1.0904\n",
      "[Fine-tune] Epoch 61/100  Loss=1.0943\n",
      "[Fine-tune] Epoch 62/100  Loss=1.0918\n",
      "[Fine-tune] Epoch 63/100  Loss=1.0842\n",
      "[Fine-tune] Epoch 64/100  Loss=1.0842\n",
      "[Fine-tune] Epoch 65/100  Loss=1.0720\n",
      "[Fine-tune] Epoch 66/100  Loss=1.0572\n",
      "[Fine-tune] Epoch 67/100  Loss=1.0784\n",
      "[Fine-tune] Epoch 68/100  Loss=1.0717\n",
      "[Fine-tune] Epoch 69/100  Loss=1.0651\n",
      "[Fine-tune] Epoch 70/100  Loss=1.0740\n",
      "[Fine-tune] Epoch 71/100  Loss=1.0625\n",
      "[Fine-tune] Epoch 72/100  Loss=1.0606\n",
      "[Fine-tune] Epoch 73/100  Loss=1.0671\n",
      "[Fine-tune] Epoch 74/100  Loss=1.0627\n",
      "[Fine-tune] Epoch 75/100  Loss=1.0627\n",
      "[Fine-tune] Epoch 76/100  Loss=1.0727\n",
      "[Fine-tune] Epoch 77/100  Loss=1.0605\n",
      "[Fine-tune] Epoch 78/100  Loss=1.0619\n",
      "[Fine-tune] Epoch 79/100  Loss=1.0548\n",
      "[Fine-tune] Epoch 80/100  Loss=1.0333\n",
      "[Fine-tune] Epoch 81/100  Loss=1.0517\n",
      "[Fine-tune] Epoch 82/100  Loss=1.0618\n",
      "[Fine-tune] Epoch 83/100  Loss=1.0612\n",
      "[Fine-tune] Epoch 84/100  Loss=1.0530\n",
      "[Fine-tune] Epoch 85/100  Loss=1.0399\n",
      "[Fine-tune] Epoch 86/100  Loss=1.0408\n",
      "[Fine-tune] Epoch 87/100  Loss=1.0356\n",
      "[Fine-tune] Epoch 88/100  Loss=1.0431\n",
      "[Fine-tune] Epoch 89/100  Loss=1.0495\n",
      "[Fine-tune] Epoch 90/100  Loss=1.0364\n",
      "[Fine-tune] Epoch 91/100  Loss=1.0334\n",
      "[Fine-tune] Epoch 92/100  Loss=1.0353\n",
      "[Fine-tune] Epoch 93/100  Loss=1.0474\n",
      "[Fine-tune] Epoch 94/100  Loss=1.0317\n",
      "[Fine-tune] Epoch 95/100  Loss=1.0327\n",
      "[Fine-tune] Epoch 96/100  Loss=1.0383\n",
      "[Fine-tune] Epoch 97/100  Loss=1.0342\n",
      "[Fine-tune] Epoch 98/100  Loss=1.0390\n",
      "[Fine-tune] Epoch 99/100  Loss=1.0394\n",
      "[Fine-tune] Epoch 100/100  Loss=1.0290\n",
      "[Pretrain] Epoch 1/75  Loss=3.1994  Acc=0.0539\n",
      "[Pretrain] Epoch 2/75  Loss=3.0624  Acc=0.0787\n",
      "[Pretrain] Epoch 3/75  Loss=2.9759  Acc=0.0984\n",
      "[Pretrain] Epoch 4/75  Loss=2.7062  Acc=0.1643\n",
      "[Pretrain] Epoch 5/75  Loss=2.4885  Acc=0.2049\n",
      "[Pretrain] Epoch 6/75  Loss=2.3715  Acc=0.2392\n",
      "[Pretrain] Epoch 7/75  Loss=2.2707  Acc=0.2651\n",
      "[Pretrain] Epoch 8/75  Loss=2.1666  Acc=0.3026\n",
      "[Pretrain] Epoch 9/75  Loss=2.1102  Acc=0.3112\n",
      "[Pretrain] Epoch 10/75  Loss=2.0444  Acc=0.3387\n",
      "[Pretrain] Epoch 11/75  Loss=2.0217  Acc=0.3420\n",
      "[Pretrain] Epoch 12/75  Loss=2.0003  Acc=0.3612\n",
      "[Pretrain] Epoch 13/75  Loss=1.9544  Acc=0.3667\n",
      "[Pretrain] Epoch 14/75  Loss=1.9226  Acc=0.3732\n",
      "[Pretrain] Epoch 15/75  Loss=1.8915  Acc=0.3913\n",
      "[Pretrain] Epoch 16/75  Loss=1.8655  Acc=0.3870\n",
      "[Pretrain] Epoch 17/75  Loss=1.8200  Acc=0.4111\n",
      "[Pretrain] Epoch 18/75  Loss=1.8134  Acc=0.4125\n",
      "[Pretrain] Epoch 19/75  Loss=1.7902  Acc=0.4172\n",
      "[Pretrain] Epoch 20/75  Loss=1.7597  Acc=0.4296\n",
      "[Pretrain] Epoch 21/75  Loss=1.7397  Acc=0.4420\n",
      "[Pretrain] Epoch 22/75  Loss=1.7443  Acc=0.4388\n",
      "[Pretrain] Epoch 23/75  Loss=1.7094  Acc=0.4440\n",
      "[Pretrain] Epoch 24/75  Loss=1.6906  Acc=0.4495\n",
      "[Pretrain] Epoch 25/75  Loss=1.6721  Acc=0.4560\n",
      "[Pretrain] Epoch 26/75  Loss=1.6365  Acc=0.4675\n",
      "[Pretrain] Epoch 27/75  Loss=1.6155  Acc=0.4765\n",
      "[Pretrain] Epoch 28/75  Loss=1.6109  Acc=0.4804\n",
      "[Pretrain] Epoch 29/75  Loss=1.5860  Acc=0.4878\n",
      "[Pretrain] Epoch 30/75  Loss=1.5713  Acc=0.4991\n",
      "[Pretrain] Epoch 31/75  Loss=1.5507  Acc=0.4953\n",
      "[Pretrain] Epoch 32/75  Loss=1.5605  Acc=0.4921\n",
      "[Pretrain] Epoch 33/75  Loss=1.5320  Acc=0.5068\n",
      "[Pretrain] Epoch 34/75  Loss=1.5148  Acc=0.5120\n",
      "[Pretrain] Epoch 35/75  Loss=1.5067  Acc=0.5106\n",
      "[Pretrain] Epoch 36/75  Loss=1.4929  Acc=0.5167\n",
      "[Pretrain] Epoch 37/75  Loss=1.4852  Acc=0.5133\n",
      "[Pretrain] Epoch 38/75  Loss=1.4730  Acc=0.5250\n",
      "[Pretrain] Epoch 39/75  Loss=1.4492  Acc=0.5325\n",
      "[Pretrain] Epoch 40/75  Loss=1.4558  Acc=0.5251\n",
      "[Pretrain] Epoch 41/75  Loss=1.4286  Acc=0.5357\n",
      "[Pretrain] Epoch 42/75  Loss=1.4154  Acc=0.5417\n",
      "[Pretrain] Epoch 43/75  Loss=1.4167  Acc=0.5354\n",
      "[Pretrain] Epoch 44/75  Loss=1.4075  Acc=0.5402\n",
      "[Pretrain] Epoch 45/75  Loss=1.3993  Acc=0.5465\n",
      "[Pretrain] Epoch 46/75  Loss=1.4052  Acc=0.5415\n",
      "[Pretrain] Epoch 47/75  Loss=1.3775  Acc=0.5539\n",
      "[Pretrain] Epoch 48/75  Loss=1.3753  Acc=0.5562\n",
      "[Pretrain] Epoch 49/75  Loss=1.3868  Acc=0.5532\n",
      "[Pretrain] Epoch 50/75  Loss=1.3767  Acc=0.5476\n",
      "[Pretrain] Epoch 51/75  Loss=1.3556  Acc=0.5573\n",
      "[Pretrain] Epoch 52/75  Loss=1.3490  Acc=0.5578\n",
      "[Pretrain] Epoch 53/75  Loss=1.3481  Acc=0.5627\n",
      "[Pretrain] Epoch 54/75  Loss=1.3425  Acc=0.5621\n",
      "[Pretrain] Epoch 55/75  Loss=1.3198  Acc=0.5704\n",
      "[Pretrain] Epoch 56/75  Loss=1.3232  Acc=0.5736\n",
      "[Pretrain] Epoch 57/75  Loss=1.3309  Acc=0.5679\n",
      "[Pretrain] Epoch 58/75  Loss=1.3203  Acc=0.5627\n",
      "[Pretrain] Epoch 59/75  Loss=1.3285  Acc=0.5650\n",
      "[Pretrain] Epoch 60/75  Loss=1.3197  Acc=0.5641\n",
      "[Pretrain] Epoch 61/75  Loss=1.3096  Acc=0.5679\n",
      "[Pretrain] Epoch 62/75  Loss=1.2948  Acc=0.5806\n",
      "[Pretrain] Epoch 63/75  Loss=1.3194  Acc=0.5760\n",
      "[Pretrain] Epoch 64/75  Loss=1.3027  Acc=0.5801\n",
      "[Pretrain] Epoch 65/75  Loss=1.3055  Acc=0.5729\n",
      "[Pretrain] Epoch 66/75  Loss=1.2950  Acc=0.5778\n",
      "[Pretrain] Epoch 67/75  Loss=1.2967  Acc=0.5772\n",
      "[Pretrain] Epoch 68/75  Loss=1.2904  Acc=0.5830\n",
      "[Pretrain] Epoch 69/75  Loss=1.2935  Acc=0.5763\n",
      "[Pretrain] Epoch 70/75  Loss=1.2729  Acc=0.5916\n",
      "[Pretrain] Epoch 71/75  Loss=1.2886  Acc=0.5905\n",
      "[Pretrain] Epoch 72/75  Loss=1.2827  Acc=0.5842\n",
      "[Pretrain] Epoch 73/75  Loss=1.2901  Acc=0.5819\n",
      "[Pretrain] Epoch 74/75  Loss=1.2795  Acc=0.5736\n",
      "[Pretrain] Epoch 75/75  Loss=1.2824  Acc=0.5837\n",
      "[Fine-tune] Epoch 1/100  Loss=3.2547\n",
      "[Fine-tune] Epoch 2/100  Loss=3.1378\n",
      "[Fine-tune] Epoch 3/100  Loss=3.0733\n",
      "[Fine-tune] Epoch 4/100  Loss=3.0467\n",
      "[Fine-tune] Epoch 5/100  Loss=2.9132\n",
      "[Fine-tune] Epoch 6/100  Loss=2.7338\n",
      "[Fine-tune] Epoch 7/100  Loss=2.6156\n",
      "[Fine-tune] Epoch 8/100  Loss=2.5330\n",
      "[Fine-tune] Epoch 9/100  Loss=2.4737\n",
      "[Fine-tune] Epoch 10/100  Loss=2.3776\n",
      "[Fine-tune] Epoch 11/100  Loss=2.3296\n",
      "[Fine-tune] Epoch 12/100  Loss=2.2844\n",
      "[Fine-tune] Epoch 13/100  Loss=2.2335\n",
      "[Fine-tune] Epoch 14/100  Loss=2.2152\n",
      "[Fine-tune] Epoch 15/100  Loss=2.1845\n",
      "[Fine-tune] Epoch 16/100  Loss=2.1389\n",
      "[Fine-tune] Epoch 17/100  Loss=2.1059\n",
      "[Fine-tune] Epoch 18/100  Loss=2.1052\n",
      "[Fine-tune] Epoch 19/100  Loss=2.0601\n",
      "[Fine-tune] Epoch 20/100  Loss=2.0279\n",
      "[Fine-tune] Epoch 21/100  Loss=2.0067\n",
      "[Fine-tune] Epoch 22/100  Loss=2.0058\n",
      "[Fine-tune] Epoch 23/100  Loss=1.9916\n",
      "[Fine-tune] Epoch 24/100  Loss=1.9701\n",
      "[Fine-tune] Epoch 25/100  Loss=1.9161\n",
      "[Fine-tune] Epoch 26/100  Loss=1.9238\n",
      "[Fine-tune] Epoch 27/100  Loss=1.9227\n",
      "[Fine-tune] Epoch 28/100  Loss=1.8813\n",
      "[Fine-tune] Epoch 29/100  Loss=1.8664\n",
      "[Fine-tune] Epoch 30/100  Loss=1.8520\n",
      "[Fine-tune] Epoch 31/100  Loss=1.8240\n",
      "[Fine-tune] Epoch 32/100  Loss=1.8229\n",
      "[Fine-tune] Epoch 33/100  Loss=1.8087\n",
      "[Fine-tune] Epoch 34/100  Loss=1.8130\n",
      "[Fine-tune] Epoch 35/100  Loss=1.7667\n",
      "[Fine-tune] Epoch 36/100  Loss=1.7583\n",
      "[Fine-tune] Epoch 37/100  Loss=1.7455\n",
      "[Fine-tune] Epoch 38/100  Loss=1.7484\n",
      "[Fine-tune] Epoch 39/100  Loss=1.7288\n",
      "[Fine-tune] Epoch 40/100  Loss=1.7177\n",
      "[Fine-tune] Epoch 41/100  Loss=1.6926\n",
      "[Fine-tune] Epoch 42/100  Loss=1.7049\n",
      "[Fine-tune] Epoch 43/100  Loss=1.6860\n",
      "[Fine-tune] Epoch 44/100  Loss=1.6773\n",
      "[Fine-tune] Epoch 45/100  Loss=1.6778\n",
      "[Fine-tune] Epoch 46/100  Loss=1.6665\n",
      "[Fine-tune] Epoch 47/100  Loss=1.6619\n",
      "[Fine-tune] Epoch 48/100  Loss=1.6462\n",
      "[Fine-tune] Epoch 49/100  Loss=1.6451\n",
      "[Fine-tune] Epoch 50/100  Loss=1.6362\n",
      "[Fine-tune] Epoch 51/100  Loss=1.6256\n",
      "[Fine-tune] Epoch 52/100  Loss=1.6085\n",
      "[Fine-tune] Epoch 53/100  Loss=1.6158\n",
      "[Fine-tune] Epoch 54/100  Loss=1.6067\n",
      "[Fine-tune] Epoch 55/100  Loss=1.6128\n",
      "[Fine-tune] Epoch 56/100  Loss=1.5887\n",
      "[Fine-tune] Epoch 57/100  Loss=1.5931\n",
      "[Fine-tune] Epoch 58/100  Loss=1.5868\n",
      "[Fine-tune] Epoch 59/100  Loss=1.5712\n",
      "[Fine-tune] Epoch 60/100  Loss=1.5821\n",
      "[Fine-tune] Epoch 61/100  Loss=1.5786\n",
      "[Fine-tune] Epoch 62/100  Loss=1.5630\n",
      "[Fine-tune] Epoch 63/100  Loss=1.5777\n",
      "[Fine-tune] Epoch 64/100  Loss=1.5654\n",
      "[Fine-tune] Epoch 65/100  Loss=1.5505\n",
      "[Fine-tune] Epoch 66/100  Loss=1.5685\n",
      "[Fine-tune] Epoch 67/100  Loss=1.5477\n",
      "[Fine-tune] Epoch 68/100  Loss=1.5575\n",
      "[Fine-tune] Epoch 69/100  Loss=1.5413\n",
      "[Fine-tune] Epoch 70/100  Loss=1.5330\n",
      "[Fine-tune] Epoch 71/100  Loss=1.5430\n",
      "[Fine-tune] Epoch 72/100  Loss=1.5517\n",
      "[Fine-tune] Epoch 73/100  Loss=1.5433\n",
      "[Fine-tune] Epoch 74/100  Loss=1.5289\n",
      "[Fine-tune] Epoch 75/100  Loss=1.5345\n",
      "[Fine-tune] Epoch 76/100  Loss=1.5383\n",
      "[Fine-tune] Epoch 77/100  Loss=1.5411\n",
      "[Fine-tune] Epoch 78/100  Loss=1.5328\n",
      "[Fine-tune] Epoch 79/100  Loss=1.5087\n",
      "[Fine-tune] Epoch 80/100  Loss=1.5283\n",
      "[Fine-tune] Epoch 81/100  Loss=1.5183\n",
      "[Fine-tune] Epoch 82/100  Loss=1.5301\n",
      "[Fine-tune] Epoch 83/100  Loss=1.5316\n",
      "[Fine-tune] Epoch 84/100  Loss=1.5182\n",
      "[Fine-tune] Epoch 85/100  Loss=1.5119\n",
      "[Fine-tune] Epoch 86/100  Loss=1.5206\n",
      "[Fine-tune] Epoch 87/100  Loss=1.5073\n",
      "[Fine-tune] Epoch 88/100  Loss=1.5030\n",
      "[Fine-tune] Epoch 89/100  Loss=1.5128\n",
      "[Fine-tune] Epoch 90/100  Loss=1.5045\n",
      "[Fine-tune] Epoch 91/100  Loss=1.5070\n",
      "[Fine-tune] Epoch 92/100  Loss=1.5092\n",
      "[Fine-tune] Epoch 93/100  Loss=1.5205\n",
      "[Fine-tune] Epoch 94/100  Loss=1.5078\n",
      "[Fine-tune] Epoch 95/100  Loss=1.5239\n",
      "[Fine-tune] Epoch 96/100  Loss=1.5103\n",
      "[Fine-tune] Epoch 97/100  Loss=1.5163\n",
      "[Fine-tune] Epoch 98/100  Loss=1.5045\n",
      "[Fine-tune] Epoch 99/100  Loss=1.4974\n",
      "[Fine-tune] Epoch 100/100  Loss=1.5082\n",
      "[Pretrain] Epoch 1/75  Loss=3.6505  Acc=0.0478\n",
      "[Pretrain] Epoch 2/75  Loss=3.1272  Acc=0.0727\n",
      "[Pretrain] Epoch 3/75  Loss=2.8248  Acc=0.1178\n",
      "[Pretrain] Epoch 4/75  Loss=2.5898  Acc=0.1818\n",
      "[Pretrain] Epoch 5/75  Loss=2.4782  Acc=0.2092\n",
      "[Pretrain] Epoch 6/75  Loss=2.3651  Acc=0.2437\n",
      "[Pretrain] Epoch 7/75  Loss=2.3102  Acc=0.2552\n",
      "[Pretrain] Epoch 8/75  Loss=2.2821  Acc=0.2525\n",
      "[Pretrain] Epoch 9/75  Loss=2.2348  Acc=0.2764\n",
      "[Pretrain] Epoch 10/75  Loss=2.2098  Acc=0.2841\n",
      "[Pretrain] Epoch 11/75  Loss=2.1854  Acc=0.2830\n",
      "[Pretrain] Epoch 12/75  Loss=2.1509  Acc=0.3032\n",
      "[Pretrain] Epoch 13/75  Loss=2.1062  Acc=0.3087\n",
      "[Pretrain] Epoch 14/75  Loss=2.0809  Acc=0.3260\n",
      "[Pretrain] Epoch 15/75  Loss=2.0419  Acc=0.3405\n",
      "[Pretrain] Epoch 16/75  Loss=2.0096  Acc=0.3473\n",
      "[Pretrain] Epoch 17/75  Loss=2.0059  Acc=0.3421\n",
      "[Pretrain] Epoch 18/75  Loss=1.9456  Acc=0.3592\n",
      "[Pretrain] Epoch 19/75  Loss=1.9559  Acc=0.3642\n",
      "[Pretrain] Epoch 20/75  Loss=1.8974  Acc=0.3797\n",
      "[Pretrain] Epoch 21/75  Loss=1.8863  Acc=0.3874\n",
      "[Pretrain] Epoch 22/75  Loss=1.8647  Acc=0.3913\n",
      "[Pretrain] Epoch 23/75  Loss=1.8361  Acc=0.3987\n",
      "[Pretrain] Epoch 24/75  Loss=1.8024  Acc=0.4100\n",
      "[Pretrain] Epoch 25/75  Loss=1.7833  Acc=0.4149\n",
      "[Pretrain] Epoch 26/75  Loss=1.7698  Acc=0.4194\n",
      "[Pretrain] Epoch 27/75  Loss=1.7126  Acc=0.4415\n",
      "[Pretrain] Epoch 28/75  Loss=1.7214  Acc=0.4427\n",
      "[Pretrain] Epoch 29/75  Loss=1.6865  Acc=0.4483\n",
      "[Pretrain] Epoch 30/75  Loss=1.6612  Acc=0.4515\n",
      "[Pretrain] Epoch 31/75  Loss=1.6413  Acc=0.4662\n",
      "[Pretrain] Epoch 32/75  Loss=1.6067  Acc=0.4716\n",
      "[Pretrain] Epoch 33/75  Loss=1.5903  Acc=0.4864\n",
      "[Pretrain] Epoch 34/75  Loss=1.5835  Acc=0.4783\n",
      "[Pretrain] Epoch 35/75  Loss=1.5619  Acc=0.4907\n",
      "[Pretrain] Epoch 36/75  Loss=1.5527  Acc=0.4980\n",
      "[Pretrain] Epoch 37/75  Loss=1.5432  Acc=0.5029\n",
      "[Pretrain] Epoch 38/75  Loss=1.4942  Acc=0.5115\n",
      "[Pretrain] Epoch 39/75  Loss=1.4897  Acc=0.5111\n",
      "[Pretrain] Epoch 40/75  Loss=1.4523  Acc=0.5248\n",
      "[Pretrain] Epoch 41/75  Loss=1.4370  Acc=0.5304\n",
      "[Pretrain] Epoch 42/75  Loss=1.4431  Acc=0.5266\n",
      "[Pretrain] Epoch 43/75  Loss=1.4222  Acc=0.5390\n",
      "[Pretrain] Epoch 44/75  Loss=1.3905  Acc=0.5451\n",
      "[Pretrain] Epoch 45/75  Loss=1.4137  Acc=0.5427\n",
      "[Pretrain] Epoch 46/75  Loss=1.3687  Acc=0.5512\n",
      "[Pretrain] Epoch 47/75  Loss=1.3585  Acc=0.5593\n",
      "[Pretrain] Epoch 48/75  Loss=1.3557  Acc=0.5559\n",
      "[Pretrain] Epoch 49/75  Loss=1.3378  Acc=0.5670\n",
      "[Pretrain] Epoch 50/75  Loss=1.3324  Acc=0.5589\n",
      "[Pretrain] Epoch 51/75  Loss=1.3085  Acc=0.5648\n",
      "[Pretrain] Epoch 52/75  Loss=1.3029  Acc=0.5690\n",
      "[Pretrain] Epoch 53/75  Loss=1.2906  Acc=0.5790\n",
      "[Pretrain] Epoch 54/75  Loss=1.2815  Acc=0.5819\n",
      "[Pretrain] Epoch 55/75  Loss=1.2619  Acc=0.5810\n",
      "[Pretrain] Epoch 56/75  Loss=1.2504  Acc=0.5876\n",
      "[Pretrain] Epoch 57/75  Loss=1.2451  Acc=0.5902\n",
      "[Pretrain] Epoch 58/75  Loss=1.2518  Acc=0.5858\n",
      "[Pretrain] Epoch 59/75  Loss=1.2196  Acc=0.6038\n",
      "[Pretrain] Epoch 60/75  Loss=1.2231  Acc=0.6042\n",
      "[Pretrain] Epoch 61/75  Loss=1.2132  Acc=0.6027\n",
      "[Pretrain] Epoch 62/75  Loss=1.2217  Acc=0.5959\n",
      "[Pretrain] Epoch 63/75  Loss=1.1840  Acc=0.6034\n",
      "[Pretrain] Epoch 64/75  Loss=1.2055  Acc=0.6043\n",
      "[Pretrain] Epoch 65/75  Loss=1.1830  Acc=0.6112\n",
      "[Pretrain] Epoch 66/75  Loss=1.1968  Acc=0.5991\n",
      "[Pretrain] Epoch 67/75  Loss=1.1961  Acc=0.6017\n",
      "[Pretrain] Epoch 68/75  Loss=1.1907  Acc=0.6112\n",
      "[Pretrain] Epoch 69/75  Loss=1.1800  Acc=0.6074\n",
      "[Pretrain] Epoch 70/75  Loss=1.1768  Acc=0.6110\n",
      "[Pretrain] Epoch 71/75  Loss=1.1638  Acc=0.6114\n",
      "[Pretrain] Epoch 72/75  Loss=1.1591  Acc=0.6193\n",
      "[Pretrain] Epoch 73/75  Loss=1.1536  Acc=0.6270\n",
      "[Pretrain] Epoch 74/75  Loss=1.1570  Acc=0.6209\n",
      "[Pretrain] Epoch 75/75  Loss=1.1553  Acc=0.6264\n",
      "[Fine-tune] Epoch 1/100  Loss=2.9647\n",
      "[Fine-tune] Epoch 2/100  Loss=2.4941\n",
      "[Fine-tune] Epoch 3/100  Loss=2.3758\n",
      "[Fine-tune] Epoch 4/100  Loss=2.2902\n",
      "[Fine-tune] Epoch 5/100  Loss=2.1906\n",
      "[Fine-tune] Epoch 6/100  Loss=2.1330\n",
      "[Fine-tune] Epoch 7/100  Loss=2.0636\n",
      "[Fine-tune] Epoch 8/100  Loss=2.0027\n",
      "[Fine-tune] Epoch 9/100  Loss=1.9870\n",
      "[Fine-tune] Epoch 10/100  Loss=1.9264\n",
      "[Fine-tune] Epoch 11/100  Loss=1.9109\n",
      "[Fine-tune] Epoch 12/100  Loss=1.8749\n",
      "[Fine-tune] Epoch 13/100  Loss=1.8329\n",
      "[Fine-tune] Epoch 14/100  Loss=1.8309\n",
      "[Fine-tune] Epoch 15/100  Loss=1.7815\n",
      "[Fine-tune] Epoch 16/100  Loss=1.7361\n",
      "[Fine-tune] Epoch 17/100  Loss=1.7204\n",
      "[Fine-tune] Epoch 18/100  Loss=1.6975\n",
      "[Fine-tune] Epoch 19/100  Loss=1.6541\n",
      "[Fine-tune] Epoch 20/100  Loss=1.6239\n",
      "[Fine-tune] Epoch 21/100  Loss=1.6110\n",
      "[Fine-tune] Epoch 22/100  Loss=1.5952\n",
      "[Fine-tune] Epoch 23/100  Loss=1.5660\n",
      "[Fine-tune] Epoch 24/100  Loss=1.5418\n",
      "[Fine-tune] Epoch 25/100  Loss=1.5375\n",
      "[Fine-tune] Epoch 26/100  Loss=1.5033\n",
      "[Fine-tune] Epoch 27/100  Loss=1.5224\n",
      "[Fine-tune] Epoch 28/100  Loss=1.4834\n",
      "[Fine-tune] Epoch 29/100  Loss=1.4484\n",
      "[Fine-tune] Epoch 30/100  Loss=1.4318\n",
      "[Fine-tune] Epoch 31/100  Loss=1.4177\n",
      "[Fine-tune] Epoch 32/100  Loss=1.3991\n",
      "[Fine-tune] Epoch 33/100  Loss=1.3977\n",
      "[Fine-tune] Epoch 34/100  Loss=1.3831\n",
      "[Fine-tune] Epoch 35/100  Loss=1.3773\n",
      "[Fine-tune] Epoch 36/100  Loss=1.3551\n",
      "[Fine-tune] Epoch 37/100  Loss=1.3527\n",
      "[Fine-tune] Epoch 38/100  Loss=1.3232\n",
      "[Fine-tune] Epoch 39/100  Loss=1.3106\n",
      "[Fine-tune] Epoch 40/100  Loss=1.3155\n",
      "[Fine-tune] Epoch 41/100  Loss=1.2962\n",
      "[Fine-tune] Epoch 42/100  Loss=1.2907\n",
      "[Fine-tune] Epoch 43/100  Loss=1.2867\n",
      "[Fine-tune] Epoch 44/100  Loss=1.2630\n",
      "[Fine-tune] Epoch 45/100  Loss=1.2671\n",
      "[Fine-tune] Epoch 46/100  Loss=1.2637\n",
      "[Fine-tune] Epoch 47/100  Loss=1.2478\n",
      "[Fine-tune] Epoch 48/100  Loss=1.2528\n",
      "[Fine-tune] Epoch 49/100  Loss=1.2426\n",
      "[Fine-tune] Epoch 50/100  Loss=1.2211\n",
      "[Fine-tune] Epoch 51/100  Loss=1.2304\n",
      "[Fine-tune] Epoch 52/100  Loss=1.2231\n",
      "[Fine-tune] Epoch 53/100  Loss=1.2170\n",
      "[Fine-tune] Epoch 54/100  Loss=1.2165\n",
      "[Fine-tune] Epoch 55/100  Loss=1.2189\n",
      "[Fine-tune] Epoch 56/100  Loss=1.1815\n",
      "[Fine-tune] Epoch 57/100  Loss=1.1830\n",
      "[Fine-tune] Epoch 58/100  Loss=1.1921\n",
      "[Fine-tune] Epoch 59/100  Loss=1.1838\n",
      "[Fine-tune] Epoch 60/100  Loss=1.1887\n",
      "[Fine-tune] Epoch 61/100  Loss=1.1673\n",
      "[Fine-tune] Epoch 62/100  Loss=1.1780\n",
      "[Fine-tune] Epoch 63/100  Loss=1.1741\n",
      "[Fine-tune] Epoch 64/100  Loss=1.1776\n",
      "[Fine-tune] Epoch 65/100  Loss=1.1637\n",
      "[Fine-tune] Epoch 66/100  Loss=1.1662\n",
      "[Fine-tune] Epoch 67/100  Loss=1.1603\n",
      "[Fine-tune] Epoch 68/100  Loss=1.1691\n",
      "[Fine-tune] Epoch 69/100  Loss=1.1539\n",
      "[Fine-tune] Epoch 70/100  Loss=1.1636\n",
      "[Fine-tune] Epoch 71/100  Loss=1.1470\n",
      "[Fine-tune] Epoch 72/100  Loss=1.1527\n",
      "[Fine-tune] Epoch 73/100  Loss=1.1586\n",
      "[Fine-tune] Epoch 74/100  Loss=1.1432\n",
      "[Fine-tune] Epoch 75/100  Loss=1.1365\n",
      "[Fine-tune] Epoch 76/100  Loss=1.1359\n",
      "[Fine-tune] Epoch 77/100  Loss=1.1369\n",
      "[Fine-tune] Epoch 78/100  Loss=1.1481\n",
      "[Fine-tune] Epoch 79/100  Loss=1.1385\n",
      "[Fine-tune] Epoch 80/100  Loss=1.1285\n",
      "[Fine-tune] Epoch 81/100  Loss=1.1448\n",
      "[Fine-tune] Epoch 82/100  Loss=1.1536\n",
      "[Fine-tune] Epoch 83/100  Loss=1.1402\n",
      "[Fine-tune] Epoch 84/100  Loss=1.1344\n",
      "[Fine-tune] Epoch 85/100  Loss=1.1206\n",
      "[Fine-tune] Epoch 86/100  Loss=1.1293\n",
      "[Fine-tune] Epoch 87/100  Loss=1.1395\n",
      "[Fine-tune] Epoch 88/100  Loss=1.1319\n",
      "[Fine-tune] Epoch 89/100  Loss=1.1410\n",
      "[Fine-tune] Epoch 90/100  Loss=1.1243\n",
      "[Fine-tune] Epoch 91/100  Loss=1.1301\n",
      "[Fine-tune] Epoch 92/100  Loss=1.1321\n",
      "[Fine-tune] Epoch 93/100  Loss=1.1295\n",
      "[Fine-tune] Epoch 94/100  Loss=1.1288\n",
      "[Fine-tune] Epoch 95/100  Loss=1.1305\n",
      "[Fine-tune] Epoch 96/100  Loss=1.1147\n",
      "[Fine-tune] Epoch 97/100  Loss=1.1210\n",
      "[Fine-tune] Epoch 98/100  Loss=1.1107\n",
      "[Fine-tune] Epoch 99/100  Loss=1.1238\n",
      "[Fine-tune] Epoch 100/100  Loss=1.1286\n",
      "[Pretrain] Epoch 1/100  Loss=3.2046  Acc=0.0548\n",
      "[Pretrain] Epoch 2/100  Loss=3.0785  Acc=0.0788\n",
      "[Pretrain] Epoch 3/100  Loss=3.0218  Acc=0.0918\n",
      "[Pretrain] Epoch 4/100  Loss=2.8362  Acc=0.1237\n",
      "[Pretrain] Epoch 5/100  Loss=2.5867  Acc=0.1782\n",
      "[Pretrain] Epoch 6/100  Loss=2.4406  Acc=0.2130\n",
      "[Pretrain] Epoch 7/100  Loss=2.2572  Acc=0.2737\n",
      "[Pretrain] Epoch 8/100  Loss=2.2065  Acc=0.2892\n",
      "[Pretrain] Epoch 9/100  Loss=2.1427  Acc=0.3024\n",
      "[Pretrain] Epoch 10/100  Loss=2.0740  Acc=0.3235\n",
      "[Pretrain] Epoch 11/100  Loss=2.0385  Acc=0.3394\n",
      "[Pretrain] Epoch 12/100  Loss=1.9811  Acc=0.3536\n",
      "[Pretrain] Epoch 13/100  Loss=1.9699  Acc=0.3596\n",
      "[Pretrain] Epoch 14/100  Loss=1.9331  Acc=0.3666\n",
      "[Pretrain] Epoch 15/100  Loss=1.9190  Acc=0.3777\n",
      "[Pretrain] Epoch 16/100  Loss=1.8817  Acc=0.3845\n",
      "[Pretrain] Epoch 17/100  Loss=1.8479  Acc=0.3964\n",
      "[Pretrain] Epoch 18/100  Loss=1.8360  Acc=0.4003\n",
      "[Pretrain] Epoch 19/100  Loss=1.8150  Acc=0.4122\n",
      "[Pretrain] Epoch 20/100  Loss=1.7910  Acc=0.4186\n",
      "[Pretrain] Epoch 21/100  Loss=1.7465  Acc=0.4289\n",
      "[Pretrain] Epoch 22/100  Loss=1.7616  Acc=0.4287\n",
      "[Pretrain] Epoch 23/100  Loss=1.7489  Acc=0.4359\n",
      "[Pretrain] Epoch 24/100  Loss=1.7013  Acc=0.4481\n",
      "[Pretrain] Epoch 25/100  Loss=1.6769  Acc=0.4495\n",
      "[Pretrain] Epoch 26/100  Loss=1.6724  Acc=0.4612\n",
      "[Pretrain] Epoch 27/100  Loss=1.6616  Acc=0.4644\n",
      "[Pretrain] Epoch 28/100  Loss=1.6325  Acc=0.4686\n",
      "[Pretrain] Epoch 29/100  Loss=1.6251  Acc=0.4682\n",
      "[Pretrain] Epoch 30/100  Loss=1.6083  Acc=0.4686\n",
      "[Pretrain] Epoch 31/100  Loss=1.5915  Acc=0.4833\n",
      "[Pretrain] Epoch 32/100  Loss=1.5701  Acc=0.4919\n",
      "[Pretrain] Epoch 33/100  Loss=1.5799  Acc=0.4871\n",
      "[Pretrain] Epoch 34/100  Loss=1.5650  Acc=0.4890\n",
      "[Pretrain] Epoch 35/100  Loss=1.5410  Acc=0.4975\n",
      "[Pretrain] Epoch 36/100  Loss=1.5466  Acc=0.4986\n",
      "[Pretrain] Epoch 37/100  Loss=1.5268  Acc=0.5083\n",
      "[Pretrain] Epoch 38/100  Loss=1.4953  Acc=0.5126\n",
      "[Pretrain] Epoch 39/100  Loss=1.4979  Acc=0.5108\n",
      "[Pretrain] Epoch 40/100  Loss=1.4846  Acc=0.5189\n",
      "[Pretrain] Epoch 41/100  Loss=1.4739  Acc=0.5207\n",
      "[Pretrain] Epoch 42/100  Loss=1.4720  Acc=0.5207\n",
      "[Pretrain] Epoch 43/100  Loss=1.4591  Acc=0.5304\n",
      "[Pretrain] Epoch 44/100  Loss=1.4396  Acc=0.5347\n",
      "[Pretrain] Epoch 45/100  Loss=1.4589  Acc=0.5278\n",
      "[Pretrain] Epoch 46/100  Loss=1.4313  Acc=0.5325\n",
      "[Pretrain] Epoch 47/100  Loss=1.4127  Acc=0.5392\n",
      "[Pretrain] Epoch 48/100  Loss=1.4184  Acc=0.5377\n",
      "[Pretrain] Epoch 49/100  Loss=1.4097  Acc=0.5436\n",
      "[Pretrain] Epoch 50/100  Loss=1.4174  Acc=0.5374\n",
      "[Pretrain] Epoch 51/100  Loss=1.3938  Acc=0.5481\n",
      "[Pretrain] Epoch 52/100  Loss=1.3958  Acc=0.5444\n",
      "[Pretrain] Epoch 53/100  Loss=1.3875  Acc=0.5472\n",
      "[Pretrain] Epoch 54/100  Loss=1.3710  Acc=0.5578\n",
      "[Pretrain] Epoch 55/100  Loss=1.3880  Acc=0.5462\n",
      "[Pretrain] Epoch 56/100  Loss=1.3586  Acc=0.5621\n",
      "[Pretrain] Epoch 57/100  Loss=1.3718  Acc=0.5566\n",
      "[Pretrain] Epoch 58/100  Loss=1.3743  Acc=0.5499\n",
      "[Pretrain] Epoch 59/100  Loss=1.3733  Acc=0.5582\n",
      "[Pretrain] Epoch 60/100  Loss=1.3589  Acc=0.5537\n",
      "[Pretrain] Epoch 61/100  Loss=1.3504  Acc=0.5625\n",
      "[Pretrain] Epoch 62/100  Loss=1.3514  Acc=0.5573\n",
      "[Pretrain] Epoch 63/100  Loss=1.3486  Acc=0.5652\n",
      "[Pretrain] Epoch 64/100  Loss=1.3339  Acc=0.5697\n",
      "[Pretrain] Epoch 65/100  Loss=1.3256  Acc=0.5686\n",
      "[Pretrain] Epoch 66/100  Loss=1.3290  Acc=0.5735\n",
      "[Pretrain] Epoch 67/100  Loss=1.3300  Acc=0.5650\n",
      "[Pretrain] Epoch 68/100  Loss=1.3290  Acc=0.5691\n",
      "[Pretrain] Epoch 69/100  Loss=1.3382  Acc=0.5609\n",
      "[Pretrain] Epoch 70/100  Loss=1.3240  Acc=0.5702\n",
      "[Pretrain] Epoch 71/100  Loss=1.3259  Acc=0.5656\n",
      "[Pretrain] Epoch 72/100  Loss=1.3300  Acc=0.5666\n",
      "[Pretrain] Epoch 73/100  Loss=1.3121  Acc=0.5708\n",
      "[Pretrain] Epoch 74/100  Loss=1.3242  Acc=0.5668\n",
      "[Pretrain] Epoch 75/100  Loss=1.3160  Acc=0.5722\n",
      "[Pretrain] Epoch 76/100  Loss=1.3189  Acc=0.5652\n",
      "[Pretrain] Epoch 77/100  Loss=1.3225  Acc=0.5715\n",
      "[Pretrain] Epoch 78/100  Loss=1.3058  Acc=0.5724\n",
      "[Pretrain] Epoch 79/100  Loss=1.3154  Acc=0.5745\n",
      "[Pretrain] Epoch 80/100  Loss=1.3049  Acc=0.5740\n",
      "[Pretrain] Epoch 81/100  Loss=1.2954  Acc=0.5785\n",
      "[Pretrain] Epoch 82/100  Loss=1.3042  Acc=0.5736\n",
      "[Pretrain] Epoch 83/100  Loss=1.3110  Acc=0.5704\n",
      "[Pretrain] Epoch 84/100  Loss=1.3060  Acc=0.5805\n",
      "[Pretrain] Epoch 85/100  Loss=1.3043  Acc=0.5790\n",
      "[Pretrain] Epoch 86/100  Loss=1.2959  Acc=0.5783\n",
      "[Pretrain] Epoch 87/100  Loss=1.2957  Acc=0.5839\n",
      "[Pretrain] Epoch 88/100  Loss=1.2895  Acc=0.5774\n",
      "[Pretrain] Epoch 89/100  Loss=1.2907  Acc=0.5864\n",
      "[Pretrain] Epoch 90/100  Loss=1.3079  Acc=0.5742\n",
      "[Pretrain] Epoch 91/100  Loss=1.3112  Acc=0.5733\n",
      "[Pretrain] Epoch 92/100  Loss=1.2870  Acc=0.5817\n",
      "[Pretrain] Epoch 93/100  Loss=1.2924  Acc=0.5783\n",
      "[Pretrain] Epoch 94/100  Loss=1.2841  Acc=0.5862\n",
      "[Pretrain] Epoch 95/100  Loss=1.2987  Acc=0.5749\n",
      "[Pretrain] Epoch 96/100  Loss=1.2866  Acc=0.5797\n",
      "[Pretrain] Epoch 97/100  Loss=1.2993  Acc=0.5770\n",
      "[Pretrain] Epoch 98/100  Loss=1.3043  Acc=0.5776\n",
      "[Pretrain] Epoch 99/100  Loss=1.2949  Acc=0.5794\n",
      "[Pretrain] Epoch 100/100  Loss=1.2886  Acc=0.5774\n",
      "[Fine-tune] Epoch 1/100  Loss=3.2717\n",
      "[Fine-tune] Epoch 2/100  Loss=2.9939\n",
      "[Fine-tune] Epoch 3/100  Loss=2.6930\n",
      "[Fine-tune] Epoch 4/100  Loss=2.5753\n",
      "[Fine-tune] Epoch 5/100  Loss=2.4844\n",
      "[Fine-tune] Epoch 6/100  Loss=2.4342\n",
      "[Fine-tune] Epoch 7/100  Loss=2.3839\n",
      "[Fine-tune] Epoch 8/100  Loss=2.3199\n",
      "[Fine-tune] Epoch 9/100  Loss=2.2558\n",
      "[Fine-tune] Epoch 10/100  Loss=2.2132\n",
      "[Fine-tune] Epoch 11/100  Loss=2.1701\n",
      "[Fine-tune] Epoch 12/100  Loss=2.1326\n",
      "[Fine-tune] Epoch 13/100  Loss=2.1017\n",
      "[Fine-tune] Epoch 14/100  Loss=2.0479\n",
      "[Fine-tune] Epoch 15/100  Loss=2.0340\n",
      "[Fine-tune] Epoch 16/100  Loss=2.0018\n",
      "[Fine-tune] Epoch 17/100  Loss=1.9724\n",
      "[Fine-tune] Epoch 18/100  Loss=1.9501\n",
      "[Fine-tune] Epoch 19/100  Loss=1.9392\n",
      "[Fine-tune] Epoch 20/100  Loss=1.9135\n",
      "[Fine-tune] Epoch 21/100  Loss=1.8811\n",
      "[Fine-tune] Epoch 22/100  Loss=1.8682\n",
      "[Fine-tune] Epoch 23/100  Loss=1.8453\n",
      "[Fine-tune] Epoch 24/100  Loss=1.8162\n",
      "[Fine-tune] Epoch 25/100  Loss=1.7994\n",
      "[Fine-tune] Epoch 26/100  Loss=1.7869\n",
      "[Fine-tune] Epoch 27/100  Loss=1.7607\n",
      "[Fine-tune] Epoch 28/100  Loss=1.7410\n",
      "[Fine-tune] Epoch 29/100  Loss=1.7291\n",
      "[Fine-tune] Epoch 30/100  Loss=1.7151\n",
      "[Fine-tune] Epoch 31/100  Loss=1.6893\n",
      "[Fine-tune] Epoch 32/100  Loss=1.6636\n",
      "[Fine-tune] Epoch 33/100  Loss=1.6596\n",
      "[Fine-tune] Epoch 34/100  Loss=1.6416\n",
      "[Fine-tune] Epoch 35/100  Loss=1.6276\n",
      "[Fine-tune] Epoch 36/100  Loss=1.6134\n",
      "[Fine-tune] Epoch 37/100  Loss=1.5969\n",
      "[Fine-tune] Epoch 38/100  Loss=1.5829\n",
      "[Fine-tune] Epoch 39/100  Loss=1.5805\n",
      "[Fine-tune] Epoch 40/100  Loss=1.5651\n",
      "[Fine-tune] Epoch 41/100  Loss=1.5476\n",
      "[Fine-tune] Epoch 42/100  Loss=1.5367\n",
      "[Fine-tune] Epoch 43/100  Loss=1.5365\n",
      "[Fine-tune] Epoch 44/100  Loss=1.5243\n",
      "[Fine-tune] Epoch 45/100  Loss=1.5066\n",
      "[Fine-tune] Epoch 46/100  Loss=1.4964\n",
      "[Fine-tune] Epoch 47/100  Loss=1.4978\n",
      "[Fine-tune] Epoch 48/100  Loss=1.4985\n",
      "[Fine-tune] Epoch 49/100  Loss=1.4828\n",
      "[Fine-tune] Epoch 50/100  Loss=1.4740\n",
      "[Fine-tune] Epoch 51/100  Loss=1.4586\n",
      "[Fine-tune] Epoch 52/100  Loss=1.4418\n",
      "[Fine-tune] Epoch 53/100  Loss=1.4355\n",
      "[Fine-tune] Epoch 54/100  Loss=1.4410\n",
      "[Fine-tune] Epoch 55/100  Loss=1.4365\n",
      "[Fine-tune] Epoch 56/100  Loss=1.4258\n",
      "[Fine-tune] Epoch 57/100  Loss=1.4177\n",
      "[Fine-tune] Epoch 58/100  Loss=1.4301\n",
      "[Fine-tune] Epoch 59/100  Loss=1.4129\n",
      "[Fine-tune] Epoch 60/100  Loss=1.4081\n",
      "[Fine-tune] Epoch 61/100  Loss=1.4147\n",
      "[Fine-tune] Epoch 62/100  Loss=1.4011\n",
      "[Fine-tune] Epoch 63/100  Loss=1.4190\n",
      "[Fine-tune] Epoch 64/100  Loss=1.4005\n",
      "[Fine-tune] Epoch 65/100  Loss=1.3857\n",
      "[Fine-tune] Epoch 66/100  Loss=1.3843\n",
      "[Fine-tune] Epoch 67/100  Loss=1.3724\n",
      "[Fine-tune] Epoch 68/100  Loss=1.3754\n",
      "[Fine-tune] Epoch 69/100  Loss=1.3722\n",
      "[Fine-tune] Epoch 70/100  Loss=1.3744\n",
      "[Fine-tune] Epoch 71/100  Loss=1.3752\n",
      "[Fine-tune] Epoch 72/100  Loss=1.3693\n",
      "[Fine-tune] Epoch 73/100  Loss=1.3649\n",
      "[Fine-tune] Epoch 74/100  Loss=1.3769\n",
      "[Fine-tune] Epoch 75/100  Loss=1.3507\n",
      "[Fine-tune] Epoch 76/100  Loss=1.3670\n",
      "[Fine-tune] Epoch 77/100  Loss=1.3535\n",
      "[Fine-tune] Epoch 78/100  Loss=1.3711\n",
      "[Fine-tune] Epoch 79/100  Loss=1.3533\n",
      "[Fine-tune] Epoch 80/100  Loss=1.3710\n",
      "[Fine-tune] Epoch 81/100  Loss=1.3484\n",
      "[Fine-tune] Epoch 82/100  Loss=1.3511\n",
      "[Fine-tune] Epoch 83/100  Loss=1.3421\n",
      "[Fine-tune] Epoch 84/100  Loss=1.3503\n",
      "[Fine-tune] Epoch 85/100  Loss=1.3606\n",
      "[Fine-tune] Epoch 86/100  Loss=1.3572\n",
      "[Fine-tune] Epoch 87/100  Loss=1.3425\n",
      "[Fine-tune] Epoch 88/100  Loss=1.3491\n",
      "[Fine-tune] Epoch 89/100  Loss=1.3315\n",
      "[Fine-tune] Epoch 90/100  Loss=1.3366\n",
      "[Fine-tune] Epoch 91/100  Loss=1.3331\n",
      "[Fine-tune] Epoch 92/100  Loss=1.3382\n",
      "[Fine-tune] Epoch 93/100  Loss=1.3387\n",
      "[Fine-tune] Epoch 94/100  Loss=1.3403\n",
      "[Fine-tune] Epoch 95/100  Loss=1.3637\n",
      "[Fine-tune] Epoch 96/100  Loss=1.3485\n",
      "[Fine-tune] Epoch 97/100  Loss=1.3451\n",
      "[Fine-tune] Epoch 98/100  Loss=1.3184\n",
      "[Fine-tune] Epoch 99/100  Loss=1.3245\n",
      "[Fine-tune] Epoch 100/100  Loss=1.3355\n",
      "[Pretrain] Epoch 1/100  Loss=3.6491  Acc=0.0413\n",
      "[Pretrain] Epoch 2/100  Loss=3.0522  Acc=0.0792\n",
      "[Pretrain] Epoch 3/100  Loss=2.7325  Acc=0.1464\n",
      "[Pretrain] Epoch 4/100  Loss=2.5365  Acc=0.2001\n",
      "[Pretrain] Epoch 5/100  Loss=2.4340  Acc=0.2213\n",
      "[Pretrain] Epoch 6/100  Loss=2.4082  Acc=0.2232\n",
      "[Pretrain] Epoch 7/100  Loss=2.3411  Acc=0.2486\n",
      "[Pretrain] Epoch 8/100  Loss=2.3100  Acc=0.2489\n",
      "[Pretrain] Epoch 9/100  Loss=2.2567  Acc=0.2638\n",
      "[Pretrain] Epoch 10/100  Loss=2.2083  Acc=0.2874\n",
      "[Pretrain] Epoch 11/100  Loss=2.1465  Acc=0.3064\n",
      "[Pretrain] Epoch 12/100  Loss=2.1468  Acc=0.3037\n",
      "[Pretrain] Epoch 13/100  Loss=2.0883  Acc=0.3215\n",
      "[Pretrain] Epoch 14/100  Loss=2.0576  Acc=0.3292\n",
      "[Pretrain] Epoch 15/100  Loss=2.0204  Acc=0.3524\n",
      "[Pretrain] Epoch 16/100  Loss=2.0022  Acc=0.3495\n",
      "[Pretrain] Epoch 17/100  Loss=1.9808  Acc=0.3579\n",
      "[Pretrain] Epoch 18/100  Loss=1.9263  Acc=0.3680\n",
      "[Pretrain] Epoch 19/100  Loss=1.9149  Acc=0.3761\n",
      "[Pretrain] Epoch 20/100  Loss=1.8919  Acc=0.3838\n",
      "[Pretrain] Epoch 21/100  Loss=1.8438  Acc=0.4016\n",
      "[Pretrain] Epoch 22/100  Loss=1.8270  Acc=0.4007\n",
      "[Pretrain] Epoch 23/100  Loss=1.8142  Acc=0.4136\n",
      "[Pretrain] Epoch 24/100  Loss=1.7856  Acc=0.4237\n",
      "[Pretrain] Epoch 25/100  Loss=1.7458  Acc=0.4301\n",
      "[Pretrain] Epoch 26/100  Loss=1.7297  Acc=0.4330\n",
      "[Pretrain] Epoch 27/100  Loss=1.7129  Acc=0.4359\n",
      "[Pretrain] Epoch 28/100  Loss=1.6723  Acc=0.4569\n",
      "[Pretrain] Epoch 29/100  Loss=1.6497  Acc=0.4587\n",
      "[Pretrain] Epoch 30/100  Loss=1.6293  Acc=0.4707\n",
      "[Pretrain] Epoch 31/100  Loss=1.6111  Acc=0.4684\n",
      "[Pretrain] Epoch 32/100  Loss=1.5895  Acc=0.4883\n",
      "[Pretrain] Epoch 33/100  Loss=1.5551  Acc=0.4855\n",
      "[Pretrain] Epoch 34/100  Loss=1.5420  Acc=0.4957\n",
      "[Pretrain] Epoch 35/100  Loss=1.5336  Acc=0.5061\n",
      "[Pretrain] Epoch 36/100  Loss=1.4855  Acc=0.5047\n",
      "[Pretrain] Epoch 37/100  Loss=1.4720  Acc=0.5162\n",
      "[Pretrain] Epoch 38/100  Loss=1.4669  Acc=0.5196\n",
      "[Pretrain] Epoch 39/100  Loss=1.4499  Acc=0.5214\n",
      "[Pretrain] Epoch 40/100  Loss=1.4138  Acc=0.5329\n",
      "[Pretrain] Epoch 41/100  Loss=1.3984  Acc=0.5471\n",
      "[Pretrain] Epoch 42/100  Loss=1.3848  Acc=0.5503\n",
      "[Pretrain] Epoch 43/100  Loss=1.3636  Acc=0.5548\n",
      "[Pretrain] Epoch 44/100  Loss=1.3546  Acc=0.5519\n",
      "[Pretrain] Epoch 45/100  Loss=1.3309  Acc=0.5602\n",
      "[Pretrain] Epoch 46/100  Loss=1.3339  Acc=0.5618\n",
      "[Pretrain] Epoch 47/100  Loss=1.3070  Acc=0.5715\n",
      "[Pretrain] Epoch 48/100  Loss=1.3086  Acc=0.5673\n",
      "[Pretrain] Epoch 49/100  Loss=1.2957  Acc=0.5758\n",
      "[Pretrain] Epoch 50/100  Loss=1.2716  Acc=0.5824\n",
      "[Pretrain] Epoch 51/100  Loss=1.2700  Acc=0.5857\n",
      "[Pretrain] Epoch 52/100  Loss=1.2498  Acc=0.5909\n",
      "[Pretrain] Epoch 53/100  Loss=1.2292  Acc=0.5990\n",
      "[Pretrain] Epoch 54/100  Loss=1.2249  Acc=0.5952\n",
      "[Pretrain] Epoch 55/100  Loss=1.2080  Acc=0.6121\n",
      "[Pretrain] Epoch 56/100  Loss=1.2044  Acc=0.6049\n",
      "[Pretrain] Epoch 57/100  Loss=1.2042  Acc=0.6061\n",
      "[Pretrain] Epoch 58/100  Loss=1.1994  Acc=0.6038\n",
      "[Pretrain] Epoch 59/100  Loss=1.1876  Acc=0.6148\n",
      "[Pretrain] Epoch 60/100  Loss=1.1687  Acc=0.6142\n",
      "[Pretrain] Epoch 61/100  Loss=1.1640  Acc=0.6160\n",
      "[Pretrain] Epoch 62/100  Loss=1.1593  Acc=0.6169\n",
      "[Pretrain] Epoch 63/100  Loss=1.1618  Acc=0.6169\n",
      "[Pretrain] Epoch 64/100  Loss=1.1387  Acc=0.6237\n",
      "[Pretrain] Epoch 65/100  Loss=1.1289  Acc=0.6316\n",
      "[Pretrain] Epoch 66/100  Loss=1.1461  Acc=0.6225\n",
      "[Pretrain] Epoch 67/100  Loss=1.1158  Acc=0.6316\n",
      "[Pretrain] Epoch 68/100  Loss=1.1089  Acc=0.6356\n",
      "[Pretrain] Epoch 69/100  Loss=1.1195  Acc=0.6320\n",
      "[Pretrain] Epoch 70/100  Loss=1.1276  Acc=0.6295\n",
      "[Pretrain] Epoch 71/100  Loss=1.1104  Acc=0.6338\n",
      "[Pretrain] Epoch 72/100  Loss=1.0919  Acc=0.6412\n",
      "[Pretrain] Epoch 73/100  Loss=1.1074  Acc=0.6370\n",
      "[Pretrain] Epoch 74/100  Loss=1.1199  Acc=0.6302\n",
      "[Pretrain] Epoch 75/100  Loss=1.0885  Acc=0.6424\n",
      "[Pretrain] Epoch 76/100  Loss=1.0882  Acc=0.6435\n",
      "[Pretrain] Epoch 77/100  Loss=1.0958  Acc=0.6360\n",
      "[Pretrain] Epoch 78/100  Loss=1.1050  Acc=0.6342\n",
      "[Pretrain] Epoch 79/100  Loss=1.0836  Acc=0.6417\n",
      "[Pretrain] Epoch 80/100  Loss=1.0755  Acc=0.6440\n",
      "[Pretrain] Epoch 81/100  Loss=1.0928  Acc=0.6408\n",
      "[Pretrain] Epoch 82/100  Loss=1.0701  Acc=0.6483\n",
      "[Pretrain] Epoch 83/100  Loss=1.0677  Acc=0.6483\n",
      "[Pretrain] Epoch 84/100  Loss=1.0751  Acc=0.6485\n",
      "[Pretrain] Epoch 85/100  Loss=1.0799  Acc=0.6541\n",
      "[Pretrain] Epoch 86/100  Loss=1.0513  Acc=0.6412\n",
      "[Pretrain] Epoch 87/100  Loss=1.0546  Acc=0.6525\n",
      "[Pretrain] Epoch 88/100  Loss=1.0537  Acc=0.6516\n",
      "[Pretrain] Epoch 89/100  Loss=1.0451  Acc=0.6588\n",
      "[Pretrain] Epoch 90/100  Loss=1.0711  Acc=0.6462\n",
      "[Pretrain] Epoch 91/100  Loss=1.0565  Acc=0.6451\n",
      "[Pretrain] Epoch 92/100  Loss=1.0504  Acc=0.6557\n",
      "[Pretrain] Epoch 93/100  Loss=1.0664  Acc=0.6534\n",
      "[Pretrain] Epoch 94/100  Loss=1.0683  Acc=0.6525\n",
      "[Pretrain] Epoch 95/100  Loss=1.0477  Acc=0.6509\n",
      "[Pretrain] Epoch 96/100  Loss=1.0614  Acc=0.6467\n",
      "[Pretrain] Epoch 97/100  Loss=1.0403  Acc=0.6586\n",
      "[Pretrain] Epoch 98/100  Loss=1.0400  Acc=0.6595\n",
      "[Pretrain] Epoch 99/100  Loss=1.0484  Acc=0.6616\n",
      "[Pretrain] Epoch 100/100  Loss=1.0236  Acc=0.6640\n",
      "[Fine-tune] Epoch 1/100  Loss=2.9601\n",
      "[Fine-tune] Epoch 2/100  Loss=2.5578\n",
      "[Fine-tune] Epoch 3/100  Loss=2.3535\n",
      "[Fine-tune] Epoch 4/100  Loss=2.2435\n",
      "[Fine-tune] Epoch 5/100  Loss=2.1604\n",
      "[Fine-tune] Epoch 6/100  Loss=2.1003\n",
      "[Fine-tune] Epoch 7/100  Loss=2.0313\n",
      "[Fine-tune] Epoch 8/100  Loss=1.9745\n",
      "[Fine-tune] Epoch 9/100  Loss=1.9428\n",
      "[Fine-tune] Epoch 10/100  Loss=1.9048\n",
      "[Fine-tune] Epoch 11/100  Loss=1.8826\n",
      "[Fine-tune] Epoch 12/100  Loss=1.8351\n",
      "[Fine-tune] Epoch 13/100  Loss=1.8015\n",
      "[Fine-tune] Epoch 14/100  Loss=1.7525\n",
      "[Fine-tune] Epoch 15/100  Loss=1.7534\n",
      "[Fine-tune] Epoch 16/100  Loss=1.7073\n",
      "[Fine-tune] Epoch 17/100  Loss=1.6810\n",
      "[Fine-tune] Epoch 18/100  Loss=1.6316\n",
      "[Fine-tune] Epoch 19/100  Loss=1.6150\n",
      "[Fine-tune] Epoch 20/100  Loss=1.6017\n",
      "[Fine-tune] Epoch 21/100  Loss=1.5637\n",
      "[Fine-tune] Epoch 22/100  Loss=1.5429\n",
      "[Fine-tune] Epoch 23/100  Loss=1.5051\n",
      "[Fine-tune] Epoch 24/100  Loss=1.4823\n",
      "[Fine-tune] Epoch 25/100  Loss=1.4600\n",
      "[Fine-tune] Epoch 26/100  Loss=1.4427\n",
      "[Fine-tune] Epoch 27/100  Loss=1.4182\n",
      "[Fine-tune] Epoch 28/100  Loss=1.3943\n",
      "[Fine-tune] Epoch 29/100  Loss=1.3876\n",
      "[Fine-tune] Epoch 30/100  Loss=1.3648\n",
      "[Fine-tune] Epoch 31/100  Loss=1.3634\n",
      "[Fine-tune] Epoch 32/100  Loss=1.3387\n",
      "[Fine-tune] Epoch 33/100  Loss=1.3056\n",
      "[Fine-tune] Epoch 34/100  Loss=1.2999\n",
      "[Fine-tune] Epoch 35/100  Loss=1.2931\n",
      "[Fine-tune] Epoch 36/100  Loss=1.2557\n",
      "[Fine-tune] Epoch 37/100  Loss=1.2625\n",
      "[Fine-tune] Epoch 38/100  Loss=1.2524\n",
      "[Fine-tune] Epoch 39/100  Loss=1.2385\n",
      "[Fine-tune] Epoch 40/100  Loss=1.2143\n",
      "[Fine-tune] Epoch 41/100  Loss=1.2223\n",
      "[Fine-tune] Epoch 42/100  Loss=1.2211\n",
      "[Fine-tune] Epoch 43/100  Loss=1.1980\n",
      "[Fine-tune] Epoch 44/100  Loss=1.1959\n",
      "[Fine-tune] Epoch 45/100  Loss=1.1929\n",
      "[Fine-tune] Epoch 46/100  Loss=1.1691\n",
      "[Fine-tune] Epoch 47/100  Loss=1.1667\n",
      "[Fine-tune] Epoch 48/100  Loss=1.1691\n",
      "[Fine-tune] Epoch 49/100  Loss=1.1635\n",
      "[Fine-tune] Epoch 50/100  Loss=1.1585\n",
      "[Fine-tune] Epoch 51/100  Loss=1.1557\n",
      "[Fine-tune] Epoch 52/100  Loss=1.1384\n",
      "[Fine-tune] Epoch 53/100  Loss=1.1386\n",
      "[Fine-tune] Epoch 54/100  Loss=1.1262\n",
      "[Fine-tune] Epoch 55/100  Loss=1.1292\n",
      "[Fine-tune] Epoch 56/100  Loss=1.1241\n",
      "[Fine-tune] Epoch 57/100  Loss=1.1154\n",
      "[Fine-tune] Epoch 58/100  Loss=1.1057\n",
      "[Fine-tune] Epoch 59/100  Loss=1.1062\n",
      "[Fine-tune] Epoch 60/100  Loss=1.1004\n",
      "[Fine-tune] Epoch 61/100  Loss=1.1088\n",
      "[Fine-tune] Epoch 62/100  Loss=1.0976\n",
      "[Fine-tune] Epoch 63/100  Loss=1.0956\n",
      "[Fine-tune] Epoch 64/100  Loss=1.0969\n",
      "[Fine-tune] Epoch 65/100  Loss=1.1082\n",
      "[Fine-tune] Epoch 66/100  Loss=1.0809\n",
      "[Fine-tune] Epoch 67/100  Loss=1.0879\n",
      "[Fine-tune] Epoch 68/100  Loss=1.0655\n",
      "[Fine-tune] Epoch 69/100  Loss=1.0835\n",
      "[Fine-tune] Epoch 70/100  Loss=1.0757\n",
      "[Fine-tune] Epoch 71/100  Loss=1.0872\n",
      "[Fine-tune] Epoch 72/100  Loss=1.0707\n",
      "[Fine-tune] Epoch 73/100  Loss=1.0657\n",
      "[Fine-tune] Epoch 74/100  Loss=1.0699\n",
      "[Fine-tune] Epoch 75/100  Loss=1.0806\n",
      "[Fine-tune] Epoch 76/100  Loss=1.0783\n",
      "[Fine-tune] Epoch 77/100  Loss=1.0631\n",
      "[Fine-tune] Epoch 78/100  Loss=1.0741\n",
      "[Fine-tune] Epoch 79/100  Loss=1.0646\n",
      "[Fine-tune] Epoch 80/100  Loss=1.0657\n",
      "[Fine-tune] Epoch 81/100  Loss=1.0526\n",
      "[Fine-tune] Epoch 82/100  Loss=1.0653\n",
      "[Fine-tune] Epoch 83/100  Loss=1.0737\n",
      "[Fine-tune] Epoch 84/100  Loss=1.0561\n",
      "[Fine-tune] Epoch 85/100  Loss=1.0640\n",
      "[Fine-tune] Epoch 86/100  Loss=1.0742\n",
      "[Fine-tune] Epoch 87/100  Loss=1.0535\n",
      "[Fine-tune] Epoch 88/100  Loss=1.0628\n",
      "[Fine-tune] Epoch 89/100  Loss=1.0474\n",
      "[Fine-tune] Epoch 90/100  Loss=1.0507\n",
      "[Fine-tune] Epoch 91/100  Loss=1.0526\n",
      "[Fine-tune] Epoch 92/100  Loss=1.0472\n",
      "[Fine-tune] Epoch 93/100  Loss=1.0458\n",
      "[Fine-tune] Epoch 94/100  Loss=1.0620\n",
      "[Fine-tune] Epoch 95/100  Loss=1.0607\n",
      "[Fine-tune] Epoch 96/100  Loss=1.0530\n",
      "[Fine-tune] Epoch 97/100  Loss=1.0472\n",
      "[Fine-tune] Epoch 98/100  Loss=1.0366\n",
      "[Fine-tune] Epoch 99/100  Loss=1.0505\n",
      "[Fine-tune] Epoch 100/100  Loss=1.0498\n",
      "[Pretrain] Epoch 1/150  Loss=3.2471  Acc=0.0435\n",
      "[Pretrain] Epoch 2/150  Loss=3.0818  Acc=0.0779\n",
      "[Pretrain] Epoch 3/150  Loss=2.7866  Acc=0.1146\n",
      "[Pretrain] Epoch 4/150  Loss=2.5570  Acc=0.1758\n",
      "[Pretrain] Epoch 5/150  Loss=2.3874  Acc=0.2331\n",
      "[Pretrain] Epoch 6/150  Loss=2.2857  Acc=0.2680\n",
      "[Pretrain] Epoch 7/150  Loss=2.2015  Acc=0.2762\n",
      "[Pretrain] Epoch 8/150  Loss=2.1571  Acc=0.3005\n",
      "[Pretrain] Epoch 9/150  Loss=2.1249  Acc=0.3105\n",
      "[Pretrain] Epoch 10/150  Loss=2.0995  Acc=0.3184\n",
      "[Pretrain] Epoch 11/150  Loss=2.0334  Acc=0.3396\n",
      "[Pretrain] Epoch 12/150  Loss=2.0067  Acc=0.3439\n",
      "[Pretrain] Epoch 13/150  Loss=1.9507  Acc=0.3689\n",
      "[Pretrain] Epoch 14/150  Loss=1.9291  Acc=0.3703\n",
      "[Pretrain] Epoch 15/150  Loss=1.9200  Acc=0.3721\n",
      "[Pretrain] Epoch 16/150  Loss=1.8761  Acc=0.3897\n",
      "[Pretrain] Epoch 17/150  Loss=1.8403  Acc=0.4016\n",
      "[Pretrain] Epoch 18/150  Loss=1.7991  Acc=0.4201\n",
      "[Pretrain] Epoch 19/150  Loss=1.7899  Acc=0.4185\n",
      "[Pretrain] Epoch 20/150  Loss=1.7562  Acc=0.4327\n",
      "[Pretrain] Epoch 21/150  Loss=1.7352  Acc=0.4352\n",
      "[Pretrain] Epoch 22/150  Loss=1.7268  Acc=0.4388\n",
      "[Pretrain] Epoch 23/150  Loss=1.6801  Acc=0.4495\n",
      "[Pretrain] Epoch 24/150  Loss=1.6848  Acc=0.4537\n",
      "[Pretrain] Epoch 25/150  Loss=1.6528  Acc=0.4598\n",
      "[Pretrain] Epoch 26/150  Loss=1.6394  Acc=0.4632\n",
      "[Pretrain] Epoch 27/150  Loss=1.6131  Acc=0.4784\n",
      "[Pretrain] Epoch 28/150  Loss=1.5944  Acc=0.4797\n",
      "[Pretrain] Epoch 29/150  Loss=1.5831  Acc=0.4844\n",
      "[Pretrain] Epoch 30/150  Loss=1.5768  Acc=0.4829\n",
      "[Pretrain] Epoch 31/150  Loss=1.5617  Acc=0.4869\n",
      "[Pretrain] Epoch 32/150  Loss=1.5476  Acc=0.4998\n",
      "[Pretrain] Epoch 33/150  Loss=1.5220  Acc=0.5034\n",
      "[Pretrain] Epoch 34/150  Loss=1.5129  Acc=0.5083\n",
      "[Pretrain] Epoch 35/150  Loss=1.4858  Acc=0.5187\n",
      "[Pretrain] Epoch 36/150  Loss=1.4746  Acc=0.5167\n",
      "[Pretrain] Epoch 37/150  Loss=1.4721  Acc=0.5223\n",
      "[Pretrain] Epoch 38/150  Loss=1.4773  Acc=0.5165\n",
      "[Pretrain] Epoch 39/150  Loss=1.4395  Acc=0.5304\n",
      "[Pretrain] Epoch 40/150  Loss=1.4375  Acc=0.5307\n",
      "[Pretrain] Epoch 41/150  Loss=1.4160  Acc=0.5356\n",
      "[Pretrain] Epoch 42/150  Loss=1.4102  Acc=0.5397\n",
      "[Pretrain] Epoch 43/150  Loss=1.4171  Acc=0.5476\n",
      "[Pretrain] Epoch 44/150  Loss=1.3897  Acc=0.5469\n",
      "[Pretrain] Epoch 45/150  Loss=1.3910  Acc=0.5413\n",
      "[Pretrain] Epoch 46/150  Loss=1.3796  Acc=0.5505\n",
      "[Pretrain] Epoch 47/150  Loss=1.3793  Acc=0.5499\n",
      "[Pretrain] Epoch 48/150  Loss=1.3528  Acc=0.5625\n",
      "[Pretrain] Epoch 49/150  Loss=1.3666  Acc=0.5603\n",
      "[Pretrain] Epoch 50/150  Loss=1.3442  Acc=0.5629\n",
      "[Pretrain] Epoch 51/150  Loss=1.3417  Acc=0.5675\n",
      "[Pretrain] Epoch 52/150  Loss=1.3290  Acc=0.5657\n",
      "[Pretrain] Epoch 53/150  Loss=1.3378  Acc=0.5665\n",
      "[Pretrain] Epoch 54/150  Loss=1.3339  Acc=0.5722\n",
      "[Pretrain] Epoch 55/150  Loss=1.3322  Acc=0.5675\n",
      "[Pretrain] Epoch 56/150  Loss=1.3221  Acc=0.5738\n",
      "[Pretrain] Epoch 57/150  Loss=1.3220  Acc=0.5708\n",
      "[Pretrain] Epoch 58/150  Loss=1.2970  Acc=0.5717\n",
      "[Pretrain] Epoch 59/150  Loss=1.3051  Acc=0.5708\n",
      "[Pretrain] Epoch 60/150  Loss=1.3035  Acc=0.5726\n",
      "[Pretrain] Epoch 61/150  Loss=1.3174  Acc=0.5672\n",
      "[Pretrain] Epoch 62/150  Loss=1.2990  Acc=0.5815\n",
      "[Pretrain] Epoch 63/150  Loss=1.2839  Acc=0.5783\n",
      "[Pretrain] Epoch 64/150  Loss=1.3083  Acc=0.5709\n",
      "[Pretrain] Epoch 65/150  Loss=1.2841  Acc=0.5769\n",
      "[Pretrain] Epoch 66/150  Loss=1.2841  Acc=0.5830\n",
      "[Pretrain] Epoch 67/150  Loss=1.2869  Acc=0.5788\n",
      "[Pretrain] Epoch 68/150  Loss=1.2811  Acc=0.5803\n",
      "[Pretrain] Epoch 69/150  Loss=1.2707  Acc=0.5912\n",
      "[Pretrain] Epoch 70/150  Loss=1.2762  Acc=0.5810\n",
      "[Pretrain] Epoch 71/150  Loss=1.2742  Acc=0.5803\n",
      "[Pretrain] Epoch 72/150  Loss=1.2758  Acc=0.5869\n",
      "[Pretrain] Epoch 73/150  Loss=1.2635  Acc=0.5821\n",
      "[Pretrain] Epoch 74/150  Loss=1.2792  Acc=0.5808\n",
      "[Pretrain] Epoch 75/150  Loss=1.2686  Acc=0.5887\n",
      "[Pretrain] Epoch 76/150  Loss=1.2675  Acc=0.5858\n",
      "[Pretrain] Epoch 77/150  Loss=1.2681  Acc=0.5909\n",
      "[Pretrain] Epoch 78/150  Loss=1.2600  Acc=0.5871\n",
      "[Pretrain] Epoch 79/150  Loss=1.2583  Acc=0.5936\n",
      "[Pretrain] Epoch 80/150  Loss=1.2572  Acc=0.5891\n",
      "[Pretrain] Epoch 81/150  Loss=1.2538  Acc=0.5945\n",
      "[Pretrain] Epoch 82/150  Loss=1.2653  Acc=0.5893\n",
      "[Pretrain] Epoch 83/150  Loss=1.2590  Acc=0.5839\n",
      "[Pretrain] Epoch 84/150  Loss=1.2449  Acc=0.6024\n",
      "[Pretrain] Epoch 85/150  Loss=1.2408  Acc=0.5973\n",
      "[Pretrain] Epoch 86/150  Loss=1.2471  Acc=0.5943\n",
      "[Pretrain] Epoch 87/150  Loss=1.2489  Acc=0.5925\n",
      "[Pretrain] Epoch 88/150  Loss=1.2630  Acc=0.5893\n",
      "[Pretrain] Epoch 89/150  Loss=1.2487  Acc=0.5925\n",
      "[Pretrain] Epoch 90/150  Loss=1.2488  Acc=0.5938\n",
      "[Pretrain] Epoch 91/150  Loss=1.2463  Acc=0.5979\n",
      "[Pretrain] Epoch 92/150  Loss=1.2536  Acc=0.5894\n",
      "[Pretrain] Epoch 93/150  Loss=1.2485  Acc=0.5929\n",
      "[Pretrain] Epoch 94/150  Loss=1.2426  Acc=0.5954\n",
      "[Pretrain] Epoch 95/150  Loss=1.2369  Acc=0.5968\n",
      "[Pretrain] Epoch 96/150  Loss=1.2345  Acc=0.6020\n",
      "[Pretrain] Epoch 97/150  Loss=1.2489  Acc=0.5905\n",
      "[Pretrain] Epoch 98/150  Loss=1.2523  Acc=0.5954\n",
      "[Pretrain] Epoch 99/150  Loss=1.2418  Acc=0.5993\n",
      "[Pretrain] Epoch 100/150  Loss=1.2594  Acc=0.5903\n",
      "[Pretrain] Epoch 101/150  Loss=1.2602  Acc=0.5911\n",
      "[Pretrain] Epoch 102/150  Loss=1.2377  Acc=0.5990\n",
      "[Pretrain] Epoch 103/150  Loss=1.2513  Acc=0.5898\n",
      "[Pretrain] Epoch 104/150  Loss=1.2435  Acc=0.5982\n",
      "[Pretrain] Epoch 105/150  Loss=1.2377  Acc=0.5961\n",
      "[Pretrain] Epoch 106/150  Loss=1.2381  Acc=0.5966\n",
      "[Pretrain] Epoch 107/150  Loss=1.2375  Acc=0.5932\n",
      "[Pretrain] Epoch 108/150  Loss=1.2413  Acc=0.5927\n",
      "[Pretrain] Epoch 109/150  Loss=1.2224  Acc=0.6054\n",
      "[Pretrain] Epoch 110/150  Loss=1.2447  Acc=0.5932\n",
      "[Pretrain] Epoch 111/150  Loss=1.2331  Acc=0.5984\n",
      "[Pretrain] Epoch 112/150  Loss=1.2316  Acc=0.6027\n",
      "[Pretrain] Epoch 113/150  Loss=1.2357  Acc=0.5955\n",
      "[Pretrain] Epoch 114/150  Loss=1.2360  Acc=0.5995\n",
      "[Pretrain] Epoch 115/150  Loss=1.2537  Acc=0.5950\n",
      "[Pretrain] Epoch 116/150  Loss=1.2264  Acc=0.5991\n",
      "[Pretrain] Epoch 117/150  Loss=1.2350  Acc=0.6058\n",
      "[Pretrain] Epoch 118/150  Loss=1.2306  Acc=0.6034\n",
      "[Pretrain] Epoch 119/150  Loss=1.2383  Acc=0.6029\n",
      "[Pretrain] Epoch 120/150  Loss=1.2435  Acc=0.6018\n",
      "[Pretrain] Epoch 121/150  Loss=1.2352  Acc=0.5975\n",
      "[Pretrain] Epoch 122/150  Loss=1.2416  Acc=0.5986\n",
      "[Pretrain] Epoch 123/150  Loss=1.2220  Acc=0.6056\n",
      "[Pretrain] Epoch 124/150  Loss=1.2394  Acc=0.5952\n",
      "[Pretrain] Epoch 125/150  Loss=1.2321  Acc=0.5963\n",
      "[Pretrain] Epoch 126/150  Loss=1.2404  Acc=0.5912\n",
      "[Pretrain] Epoch 127/150  Loss=1.2313  Acc=0.6031\n",
      "[Pretrain] Epoch 128/150  Loss=1.2496  Acc=0.5939\n",
      "[Pretrain] Epoch 129/150  Loss=1.2234  Acc=0.6069\n",
      "[Pretrain] Epoch 130/150  Loss=1.2432  Acc=0.5959\n",
      "[Pretrain] Epoch 131/150  Loss=1.2391  Acc=0.5957\n",
      "[Pretrain] Epoch 132/150  Loss=1.2357  Acc=0.5986\n",
      "[Pretrain] Epoch 133/150  Loss=1.2249  Acc=0.6051\n",
      "[Pretrain] Epoch 134/150  Loss=1.2369  Acc=0.5961\n",
      "[Pretrain] Epoch 135/150  Loss=1.2373  Acc=0.5941\n",
      "[Pretrain] Epoch 136/150  Loss=1.2212  Acc=0.5982\n",
      "[Pretrain] Epoch 137/150  Loss=1.2272  Acc=0.6043\n",
      "[Pretrain] Epoch 138/150  Loss=1.2360  Acc=0.5973\n",
      "[Pretrain] Epoch 139/150  Loss=1.2348  Acc=0.6011\n",
      "[Pretrain] Epoch 140/150  Loss=1.2340  Acc=0.5964\n",
      "[Pretrain] Epoch 141/150  Loss=1.2330  Acc=0.5952\n",
      "[Pretrain] Epoch 142/150  Loss=1.2326  Acc=0.5945\n",
      "[Pretrain] Epoch 143/150  Loss=1.2398  Acc=0.5973\n",
      "[Pretrain] Epoch 144/150  Loss=1.2429  Acc=0.6018\n",
      "[Pretrain] Epoch 145/150  Loss=1.2378  Acc=0.5999\n",
      "[Pretrain] Epoch 146/150  Loss=1.2172  Acc=0.6004\n",
      "[Pretrain] Epoch 147/150  Loss=1.2345  Acc=0.6011\n",
      "[Pretrain] Epoch 148/150  Loss=1.2339  Acc=0.5993\n",
      "[Pretrain] Epoch 149/150  Loss=1.2311  Acc=0.5954\n",
      "[Pretrain] Epoch 150/150  Loss=1.2372  Acc=0.5941\n",
      "[Fine-tune] Epoch 1/100  Loss=3.2721\n",
      "[Fine-tune] Epoch 2/100  Loss=3.1940\n",
      "[Fine-tune] Epoch 3/100  Loss=3.0969\n",
      "[Fine-tune] Epoch 4/100  Loss=3.0469\n",
      "[Fine-tune] Epoch 5/100  Loss=3.0163\n",
      "[Fine-tune] Epoch 6/100  Loss=2.8763\n",
      "[Fine-tune] Epoch 7/100  Loss=2.6985\n",
      "[Fine-tune] Epoch 8/100  Loss=2.5993\n",
      "[Fine-tune] Epoch 9/100  Loss=2.5176\n",
      "[Fine-tune] Epoch 10/100  Loss=2.4633\n",
      "[Fine-tune] Epoch 11/100  Loss=2.4337\n",
      "[Fine-tune] Epoch 12/100  Loss=2.4089\n",
      "[Fine-tune] Epoch 13/100  Loss=2.3346\n",
      "[Fine-tune] Epoch 14/100  Loss=2.3024\n",
      "[Fine-tune] Epoch 15/100  Loss=2.2277\n",
      "[Fine-tune] Epoch 16/100  Loss=2.1920\n",
      "[Fine-tune] Epoch 17/100  Loss=2.1343\n",
      "[Fine-tune] Epoch 18/100  Loss=2.1095\n",
      "[Fine-tune] Epoch 19/100  Loss=2.1033\n",
      "[Fine-tune] Epoch 20/100  Loss=2.0575\n",
      "[Fine-tune] Epoch 21/100  Loss=2.0253\n",
      "[Fine-tune] Epoch 22/100  Loss=2.0027\n",
      "[Fine-tune] Epoch 23/100  Loss=2.0056\n",
      "[Fine-tune] Epoch 24/100  Loss=1.9687\n",
      "[Fine-tune] Epoch 25/100  Loss=1.9384\n",
      "[Fine-tune] Epoch 26/100  Loss=1.9206\n",
      "[Fine-tune] Epoch 27/100  Loss=1.8974\n",
      "[Fine-tune] Epoch 28/100  Loss=1.8764\n",
      "[Fine-tune] Epoch 29/100  Loss=1.8711\n",
      "[Fine-tune] Epoch 30/100  Loss=1.8510\n",
      "[Fine-tune] Epoch 31/100  Loss=1.8394\n",
      "[Fine-tune] Epoch 32/100  Loss=1.8261\n",
      "[Fine-tune] Epoch 33/100  Loss=1.8145\n",
      "[Fine-tune] Epoch 34/100  Loss=1.7916\n",
      "[Fine-tune] Epoch 35/100  Loss=1.7859\n",
      "[Fine-tune] Epoch 36/100  Loss=1.7565\n",
      "[Fine-tune] Epoch 37/100  Loss=1.7736\n",
      "[Fine-tune] Epoch 38/100  Loss=1.7514\n",
      "[Fine-tune] Epoch 39/100  Loss=1.7481\n",
      "[Fine-tune] Epoch 40/100  Loss=1.7199\n",
      "[Fine-tune] Epoch 41/100  Loss=1.7086\n",
      "[Fine-tune] Epoch 42/100  Loss=1.7118\n",
      "[Fine-tune] Epoch 43/100  Loss=1.6940\n",
      "[Fine-tune] Epoch 44/100  Loss=1.6861\n",
      "[Fine-tune] Epoch 45/100  Loss=1.6815\n",
      "[Fine-tune] Epoch 46/100  Loss=1.6689\n",
      "[Fine-tune] Epoch 47/100  Loss=1.6634\n",
      "[Fine-tune] Epoch 48/100  Loss=1.6595\n",
      "[Fine-tune] Epoch 49/100  Loss=1.6508\n",
      "[Fine-tune] Epoch 50/100  Loss=1.6317\n",
      "[Fine-tune] Epoch 51/100  Loss=1.6338\n",
      "[Fine-tune] Epoch 52/100  Loss=1.6365\n",
      "[Fine-tune] Epoch 53/100  Loss=1.6320\n",
      "[Fine-tune] Epoch 54/100  Loss=1.6206\n",
      "[Fine-tune] Epoch 55/100  Loss=1.6120\n",
      "[Fine-tune] Epoch 56/100  Loss=1.6088\n",
      "[Fine-tune] Epoch 57/100  Loss=1.5968\n",
      "[Fine-tune] Epoch 58/100  Loss=1.5913\n",
      "[Fine-tune] Epoch 59/100  Loss=1.5905\n",
      "[Fine-tune] Epoch 60/100  Loss=1.5858\n",
      "[Fine-tune] Epoch 61/100  Loss=1.5901\n",
      "[Fine-tune] Epoch 62/100  Loss=1.5891\n",
      "[Fine-tune] Epoch 63/100  Loss=1.5909\n",
      "[Fine-tune] Epoch 64/100  Loss=1.5770\n",
      "[Fine-tune] Epoch 65/100  Loss=1.5678\n",
      "[Fine-tune] Epoch 66/100  Loss=1.5815\n",
      "[Fine-tune] Epoch 67/100  Loss=1.5736\n",
      "[Fine-tune] Epoch 68/100  Loss=1.5646\n",
      "[Fine-tune] Epoch 69/100  Loss=1.5500\n",
      "[Fine-tune] Epoch 70/100  Loss=1.5554\n",
      "[Fine-tune] Epoch 71/100  Loss=1.5595\n",
      "[Fine-tune] Epoch 72/100  Loss=1.5509\n",
      "[Fine-tune] Epoch 73/100  Loss=1.5468\n",
      "[Fine-tune] Epoch 74/100  Loss=1.5586\n",
      "[Fine-tune] Epoch 75/100  Loss=1.5370\n",
      "[Fine-tune] Epoch 76/100  Loss=1.5500\n",
      "[Fine-tune] Epoch 77/100  Loss=1.5532\n",
      "[Fine-tune] Epoch 78/100  Loss=1.5417\n",
      "[Fine-tune] Epoch 79/100  Loss=1.5428\n",
      "[Fine-tune] Epoch 80/100  Loss=1.5395\n",
      "[Fine-tune] Epoch 81/100  Loss=1.5417\n",
      "[Fine-tune] Epoch 82/100  Loss=1.5340\n",
      "[Fine-tune] Epoch 83/100  Loss=1.5467\n",
      "[Fine-tune] Epoch 84/100  Loss=1.5342\n",
      "[Fine-tune] Epoch 85/100  Loss=1.5207\n",
      "[Fine-tune] Epoch 86/100  Loss=1.5340\n",
      "[Fine-tune] Epoch 87/100  Loss=1.5276\n",
      "[Fine-tune] Epoch 88/100  Loss=1.5288\n",
      "[Fine-tune] Epoch 89/100  Loss=1.5327\n",
      "[Fine-tune] Epoch 90/100  Loss=1.5299\n",
      "[Fine-tune] Epoch 91/100  Loss=1.5206\n",
      "[Fine-tune] Epoch 92/100  Loss=1.5375\n",
      "[Fine-tune] Epoch 93/100  Loss=1.5370\n",
      "[Fine-tune] Epoch 94/100  Loss=1.5369\n",
      "[Fine-tune] Epoch 95/100  Loss=1.5244\n",
      "[Fine-tune] Epoch 96/100  Loss=1.5271\n",
      "[Fine-tune] Epoch 97/100  Loss=1.5243\n",
      "[Fine-tune] Epoch 98/100  Loss=1.5362\n",
      "[Fine-tune] Epoch 99/100  Loss=1.5219\n",
      "[Fine-tune] Epoch 100/100  Loss=1.5098\n",
      "[Pretrain] Epoch 1/150  Loss=3.6880  Acc=0.0618\n",
      "[Pretrain] Epoch 2/150  Loss=2.9111  Acc=0.1239\n",
      "[Pretrain] Epoch 3/150  Loss=2.6566  Acc=0.1694\n",
      "[Pretrain] Epoch 4/150  Loss=2.5246  Acc=0.1947\n",
      "[Pretrain] Epoch 5/150  Loss=2.4576  Acc=0.2130\n",
      "[Pretrain] Epoch 6/150  Loss=2.4064  Acc=0.2297\n",
      "[Pretrain] Epoch 7/150  Loss=2.3925  Acc=0.2304\n",
      "[Pretrain] Epoch 8/150  Loss=2.3146  Acc=0.2534\n",
      "[Pretrain] Epoch 9/150  Loss=2.3314  Acc=0.2446\n",
      "[Pretrain] Epoch 10/150  Loss=2.2984  Acc=0.2597\n",
      "[Pretrain] Epoch 11/150  Loss=2.2615  Acc=0.2728\n",
      "[Pretrain] Epoch 12/150  Loss=2.2300  Acc=0.2716\n",
      "[Pretrain] Epoch 13/150  Loss=2.2211  Acc=0.2780\n",
      "[Pretrain] Epoch 14/150  Loss=2.1775  Acc=0.2920\n",
      "[Pretrain] Epoch 15/150  Loss=2.1845  Acc=0.2886\n",
      "[Pretrain] Epoch 16/150  Loss=2.1244  Acc=0.3132\n",
      "[Pretrain] Epoch 17/150  Loss=2.0887  Acc=0.3224\n",
      "[Pretrain] Epoch 18/150  Loss=2.0639  Acc=0.3319\n",
      "[Pretrain] Epoch 19/150  Loss=2.0311  Acc=0.3348\n",
      "[Pretrain] Epoch 20/150  Loss=1.9936  Acc=0.3506\n",
      "[Pretrain] Epoch 21/150  Loss=1.9522  Acc=0.3588\n",
      "[Pretrain] Epoch 22/150  Loss=1.9342  Acc=0.3710\n",
      "[Pretrain] Epoch 23/150  Loss=1.8953  Acc=0.3822\n",
      "[Pretrain] Epoch 24/150  Loss=1.8885  Acc=0.3802\n",
      "[Pretrain] Epoch 25/150  Loss=1.8514  Acc=0.3865\n",
      "[Pretrain] Epoch 26/150  Loss=1.8357  Acc=0.3962\n",
      "[Pretrain] Epoch 27/150  Loss=1.8066  Acc=0.4086\n",
      "[Pretrain] Epoch 28/150  Loss=1.7722  Acc=0.4107\n",
      "[Pretrain] Epoch 29/150  Loss=1.7492  Acc=0.4312\n",
      "[Pretrain] Epoch 30/150  Loss=1.7291  Acc=0.4278\n",
      "[Pretrain] Epoch 31/150  Loss=1.7323  Acc=0.4327\n",
      "[Pretrain] Epoch 32/150  Loss=1.6980  Acc=0.4418\n",
      "[Pretrain] Epoch 33/150  Loss=1.6838  Acc=0.4508\n",
      "[Pretrain] Epoch 34/150  Loss=1.6460  Acc=0.4714\n",
      "[Pretrain] Epoch 35/150  Loss=1.6538  Acc=0.4504\n",
      "[Pretrain] Epoch 36/150  Loss=1.6171  Acc=0.4759\n",
      "[Pretrain] Epoch 37/150  Loss=1.5926  Acc=0.4691\n",
      "[Pretrain] Epoch 38/150  Loss=1.5738  Acc=0.4806\n",
      "[Pretrain] Epoch 39/150  Loss=1.5578  Acc=0.4876\n",
      "[Pretrain] Epoch 40/150  Loss=1.5394  Acc=0.4966\n",
      "[Pretrain] Epoch 41/150  Loss=1.5209  Acc=0.4995\n",
      "[Pretrain] Epoch 42/150  Loss=1.4978  Acc=0.5093\n",
      "[Pretrain] Epoch 43/150  Loss=1.4842  Acc=0.5153\n",
      "[Pretrain] Epoch 44/150  Loss=1.4684  Acc=0.5149\n",
      "[Pretrain] Epoch 45/150  Loss=1.4714  Acc=0.5190\n",
      "[Pretrain] Epoch 46/150  Loss=1.4525  Acc=0.5277\n",
      "[Pretrain] Epoch 47/150  Loss=1.4372  Acc=0.5244\n",
      "[Pretrain] Epoch 48/150  Loss=1.4213  Acc=0.5357\n",
      "[Pretrain] Epoch 49/150  Loss=1.4284  Acc=0.5325\n",
      "[Pretrain] Epoch 50/150  Loss=1.3961  Acc=0.5472\n",
      "[Pretrain] Epoch 51/150  Loss=1.3757  Acc=0.5460\n",
      "[Pretrain] Epoch 52/150  Loss=1.3819  Acc=0.5472\n",
      "[Pretrain] Epoch 53/150  Loss=1.3578  Acc=0.5528\n",
      "[Pretrain] Epoch 54/150  Loss=1.3648  Acc=0.5551\n",
      "[Pretrain] Epoch 55/150  Loss=1.3468  Acc=0.5533\n",
      "[Pretrain] Epoch 56/150  Loss=1.3484  Acc=0.5519\n",
      "[Pretrain] Epoch 57/150  Loss=1.3243  Acc=0.5632\n",
      "[Pretrain] Epoch 58/150  Loss=1.3161  Acc=0.5691\n",
      "[Pretrain] Epoch 59/150  Loss=1.3154  Acc=0.5735\n",
      "[Pretrain] Epoch 60/150  Loss=1.3146  Acc=0.5695\n",
      "[Pretrain] Epoch 61/150  Loss=1.3152  Acc=0.5711\n",
      "[Pretrain] Epoch 62/150  Loss=1.2967  Acc=0.5749\n",
      "[Pretrain] Epoch 63/150  Loss=1.2779  Acc=0.5735\n",
      "[Pretrain] Epoch 64/150  Loss=1.2898  Acc=0.5735\n",
      "[Pretrain] Epoch 65/150  Loss=1.2870  Acc=0.5760\n",
      "[Pretrain] Epoch 66/150  Loss=1.2777  Acc=0.5794\n",
      "[Pretrain] Epoch 67/150  Loss=1.2575  Acc=0.5875\n",
      "[Pretrain] Epoch 68/150  Loss=1.2640  Acc=0.5805\n",
      "[Pretrain] Epoch 69/150  Loss=1.2522  Acc=0.5891\n",
      "[Pretrain] Epoch 70/150  Loss=1.2640  Acc=0.5810\n",
      "[Pretrain] Epoch 71/150  Loss=1.2507  Acc=0.5823\n",
      "[Pretrain] Epoch 72/150  Loss=1.2328  Acc=0.5941\n",
      "[Pretrain] Epoch 73/150  Loss=1.2288  Acc=0.5993\n",
      "[Pretrain] Epoch 74/150  Loss=1.2499  Acc=0.5945\n",
      "[Pretrain] Epoch 75/150  Loss=1.2397  Acc=0.5885\n",
      "[Pretrain] Epoch 76/150  Loss=1.2419  Acc=0.5932\n",
      "[Pretrain] Epoch 77/150  Loss=1.2405  Acc=0.5999\n",
      "[Pretrain] Epoch 78/150  Loss=1.2341  Acc=0.5982\n",
      "[Pretrain] Epoch 79/150  Loss=1.2354  Acc=0.5961\n",
      "[Pretrain] Epoch 80/150  Loss=1.2201  Acc=0.5961\n",
      "[Pretrain] Epoch 81/150  Loss=1.2153  Acc=0.5984\n",
      "[Pretrain] Epoch 82/150  Loss=1.2321  Acc=0.6011\n",
      "[Pretrain] Epoch 83/150  Loss=1.1946  Acc=0.6061\n",
      "[Pretrain] Epoch 84/150  Loss=1.2066  Acc=0.6058\n",
      "[Pretrain] Epoch 85/150  Loss=1.2010  Acc=0.6067\n",
      "[Pretrain] Epoch 86/150  Loss=1.2042  Acc=0.6072\n",
      "[Pretrain] Epoch 87/150  Loss=1.1893  Acc=0.6069\n",
      "[Pretrain] Epoch 88/150  Loss=1.2019  Acc=0.6018\n",
      "[Pretrain] Epoch 89/150  Loss=1.1917  Acc=0.6002\n",
      "[Pretrain] Epoch 90/150  Loss=1.2079  Acc=0.6043\n",
      "[Pretrain] Epoch 91/150  Loss=1.1933  Acc=0.6097\n",
      "[Pretrain] Epoch 92/150  Loss=1.1880  Acc=0.6074\n",
      "[Pretrain] Epoch 93/150  Loss=1.1790  Acc=0.6110\n",
      "[Pretrain] Epoch 94/150  Loss=1.2006  Acc=0.6040\n",
      "[Pretrain] Epoch 95/150  Loss=1.1856  Acc=0.6126\n",
      "[Pretrain] Epoch 96/150  Loss=1.1966  Acc=0.6078\n",
      "[Pretrain] Epoch 97/150  Loss=1.1859  Acc=0.6061\n",
      "[Pretrain] Epoch 98/150  Loss=1.1884  Acc=0.6085\n",
      "[Pretrain] Epoch 99/150  Loss=1.2119  Acc=0.6076\n",
      "[Pretrain] Epoch 100/150  Loss=1.1804  Acc=0.6124\n",
      "[Pretrain] Epoch 101/150  Loss=1.2046  Acc=0.6083\n",
      "[Pretrain] Epoch 102/150  Loss=1.1801  Acc=0.6142\n",
      "[Pretrain] Epoch 103/150  Loss=1.1824  Acc=0.6139\n",
      "[Pretrain] Epoch 104/150  Loss=1.1771  Acc=0.6166\n",
      "[Pretrain] Epoch 105/150  Loss=1.1754  Acc=0.6162\n",
      "[Pretrain] Epoch 106/150  Loss=1.1988  Acc=0.6121\n",
      "[Pretrain] Epoch 107/150  Loss=1.1788  Acc=0.6140\n",
      "[Pretrain] Epoch 108/150  Loss=1.1776  Acc=0.6124\n",
      "[Pretrain] Epoch 109/150  Loss=1.1871  Acc=0.6054\n",
      "[Pretrain] Epoch 110/150  Loss=1.1734  Acc=0.6214\n",
      "[Pretrain] Epoch 111/150  Loss=1.1768  Acc=0.6137\n",
      "[Pretrain] Epoch 112/150  Loss=1.1778  Acc=0.6110\n",
      "[Pretrain] Epoch 113/150  Loss=1.1771  Acc=0.6076\n",
      "[Pretrain] Epoch 114/150  Loss=1.1761  Acc=0.6157\n",
      "[Pretrain] Epoch 115/150  Loss=1.1764  Acc=0.6124\n",
      "[Pretrain] Epoch 116/150  Loss=1.1748  Acc=0.6157\n",
      "[Pretrain] Epoch 117/150  Loss=1.1733  Acc=0.6135\n",
      "[Pretrain] Epoch 118/150  Loss=1.1651  Acc=0.6162\n",
      "[Pretrain] Epoch 119/150  Loss=1.1793  Acc=0.6182\n",
      "[Pretrain] Epoch 120/150  Loss=1.1603  Acc=0.6227\n",
      "[Pretrain] Epoch 121/150  Loss=1.1849  Acc=0.6067\n",
      "[Pretrain] Epoch 122/150  Loss=1.1856  Acc=0.6099\n",
      "[Pretrain] Epoch 123/150  Loss=1.1768  Acc=0.6162\n",
      "[Pretrain] Epoch 124/150  Loss=1.1732  Acc=0.6121\n",
      "[Pretrain] Epoch 125/150  Loss=1.1728  Acc=0.6133\n",
      "[Pretrain] Epoch 126/150  Loss=1.1687  Acc=0.6158\n",
      "[Pretrain] Epoch 127/150  Loss=1.1773  Acc=0.6155\n",
      "[Pretrain] Epoch 128/150  Loss=1.1677  Acc=0.6194\n",
      "[Pretrain] Epoch 129/150  Loss=1.1733  Acc=0.6184\n",
      "[Pretrain] Epoch 130/150  Loss=1.1815  Acc=0.6115\n",
      "[Pretrain] Epoch 131/150  Loss=1.1669  Acc=0.6175\n",
      "[Pretrain] Epoch 132/150  Loss=1.1734  Acc=0.6072\n",
      "[Pretrain] Epoch 133/150  Loss=1.1708  Acc=0.6114\n",
      "[Pretrain] Epoch 134/150  Loss=1.1740  Acc=0.6158\n",
      "[Pretrain] Epoch 135/150  Loss=1.1818  Acc=0.6137\n",
      "[Pretrain] Epoch 136/150  Loss=1.1657  Acc=0.6191\n",
      "[Pretrain] Epoch 137/150  Loss=1.1611  Acc=0.6185\n",
      "[Pretrain] Epoch 138/150  Loss=1.1747  Acc=0.6184\n",
      "[Pretrain] Epoch 139/150  Loss=1.1697  Acc=0.6180\n",
      "[Pretrain] Epoch 140/150  Loss=1.1640  Acc=0.6155\n",
      "[Pretrain] Epoch 141/150  Loss=1.1631  Acc=0.6173\n",
      "[Pretrain] Epoch 142/150  Loss=1.1661  Acc=0.6157\n",
      "[Pretrain] Epoch 143/150  Loss=1.1900  Acc=0.6072\n",
      "[Pretrain] Epoch 144/150  Loss=1.1669  Acc=0.6115\n",
      "[Pretrain] Epoch 145/150  Loss=1.1735  Acc=0.6167\n",
      "[Pretrain] Epoch 146/150  Loss=1.1584  Acc=0.6250\n",
      "[Pretrain] Epoch 147/150  Loss=1.1614  Acc=0.6180\n",
      "[Pretrain] Epoch 148/150  Loss=1.1649  Acc=0.6202\n",
      "[Pretrain] Epoch 149/150  Loss=1.1740  Acc=0.6146\n",
      "[Pretrain] Epoch 150/150  Loss=1.1683  Acc=0.6121\n",
      "[Fine-tune] Epoch 1/100  Loss=2.8014\n",
      "[Fine-tune] Epoch 2/100  Loss=2.4080\n",
      "[Fine-tune] Epoch 3/100  Loss=2.2673\n",
      "[Fine-tune] Epoch 4/100  Loss=2.2070\n",
      "[Fine-tune] Epoch 5/100  Loss=2.1192\n",
      "[Fine-tune] Epoch 6/100  Loss=2.0762\n",
      "[Fine-tune] Epoch 7/100  Loss=2.0179\n",
      "[Fine-tune] Epoch 8/100  Loss=1.9923\n",
      "[Fine-tune] Epoch 9/100  Loss=1.9454\n",
      "[Fine-tune] Epoch 10/100  Loss=1.8964\n",
      "[Fine-tune] Epoch 11/100  Loss=1.8612\n",
      "[Fine-tune] Epoch 12/100  Loss=1.8529\n",
      "[Fine-tune] Epoch 13/100  Loss=1.7803\n",
      "[Fine-tune] Epoch 14/100  Loss=1.7544\n",
      "[Fine-tune] Epoch 15/100  Loss=1.7427\n",
      "[Fine-tune] Epoch 16/100  Loss=1.6892\n",
      "[Fine-tune] Epoch 17/100  Loss=1.6593\n",
      "[Fine-tune] Epoch 18/100  Loss=1.6351\n",
      "[Fine-tune] Epoch 19/100  Loss=1.6155\n",
      "[Fine-tune] Epoch 20/100  Loss=1.5856\n",
      "[Fine-tune] Epoch 21/100  Loss=1.5564\n",
      "[Fine-tune] Epoch 22/100  Loss=1.5408\n",
      "[Fine-tune] Epoch 23/100  Loss=1.5197\n",
      "[Fine-tune] Epoch 24/100  Loss=1.4925\n",
      "[Fine-tune] Epoch 25/100  Loss=1.4768\n",
      "[Fine-tune] Epoch 26/100  Loss=1.4534\n",
      "[Fine-tune] Epoch 27/100  Loss=1.4120\n",
      "[Fine-tune] Epoch 28/100  Loss=1.4195\n",
      "[Fine-tune] Epoch 29/100  Loss=1.3774\n",
      "[Fine-tune] Epoch 30/100  Loss=1.3671\n",
      "[Fine-tune] Epoch 31/100  Loss=1.3655\n",
      "[Fine-tune] Epoch 32/100  Loss=1.3298\n",
      "[Fine-tune] Epoch 33/100  Loss=1.3097\n",
      "[Fine-tune] Epoch 34/100  Loss=1.3034\n",
      "[Fine-tune] Epoch 35/100  Loss=1.2880\n",
      "[Fine-tune] Epoch 36/100  Loss=1.2696\n",
      "[Fine-tune] Epoch 37/100  Loss=1.2629\n",
      "[Fine-tune] Epoch 38/100  Loss=1.2520\n",
      "[Fine-tune] Epoch 39/100  Loss=1.2381\n",
      "[Fine-tune] Epoch 40/100  Loss=1.2271\n",
      "[Fine-tune] Epoch 41/100  Loss=1.2426\n",
      "[Fine-tune] Epoch 42/100  Loss=1.2145\n",
      "[Fine-tune] Epoch 43/100  Loss=1.2068\n",
      "[Fine-tune] Epoch 44/100  Loss=1.1920\n",
      "[Fine-tune] Epoch 45/100  Loss=1.1832\n",
      "[Fine-tune] Epoch 46/100  Loss=1.1711\n",
      "[Fine-tune] Epoch 47/100  Loss=1.1697\n",
      "[Fine-tune] Epoch 48/100  Loss=1.1737\n",
      "[Fine-tune] Epoch 49/100  Loss=1.1575\n",
      "[Fine-tune] Epoch 50/100  Loss=1.1709\n",
      "[Fine-tune] Epoch 51/100  Loss=1.1425\n",
      "[Fine-tune] Epoch 52/100  Loss=1.1437\n",
      "[Fine-tune] Epoch 53/100  Loss=1.1598\n",
      "[Fine-tune] Epoch 54/100  Loss=1.1332\n",
      "[Fine-tune] Epoch 55/100  Loss=1.1311\n",
      "[Fine-tune] Epoch 56/100  Loss=1.1103\n",
      "[Fine-tune] Epoch 57/100  Loss=1.1162\n",
      "[Fine-tune] Epoch 58/100  Loss=1.1185\n",
      "[Fine-tune] Epoch 59/100  Loss=1.1147\n",
      "[Fine-tune] Epoch 60/100  Loss=1.1091\n",
      "[Fine-tune] Epoch 61/100  Loss=1.1029\n",
      "[Fine-tune] Epoch 62/100  Loss=1.1048\n",
      "[Fine-tune] Epoch 63/100  Loss=1.1031\n",
      "[Fine-tune] Epoch 64/100  Loss=1.0972\n",
      "[Fine-tune] Epoch 65/100  Loss=1.1011\n",
      "[Fine-tune] Epoch 66/100  Loss=1.0930\n",
      "[Fine-tune] Epoch 67/100  Loss=1.0908\n",
      "[Fine-tune] Epoch 68/100  Loss=1.0839\n",
      "[Fine-tune] Epoch 69/100  Loss=1.0732\n",
      "[Fine-tune] Epoch 70/100  Loss=1.0758\n",
      "[Fine-tune] Epoch 71/100  Loss=1.0871\n",
      "[Fine-tune] Epoch 72/100  Loss=1.0660\n",
      "[Fine-tune] Epoch 73/100  Loss=1.0854\n",
      "[Fine-tune] Epoch 74/100  Loss=1.0829\n",
      "[Fine-tune] Epoch 75/100  Loss=1.0660\n",
      "[Fine-tune] Epoch 76/100  Loss=1.0724\n",
      "[Fine-tune] Epoch 77/100  Loss=1.0626\n",
      "[Fine-tune] Epoch 78/100  Loss=1.0735\n",
      "[Fine-tune] Epoch 79/100  Loss=1.0672\n",
      "[Fine-tune] Epoch 80/100  Loss=1.0621\n",
      "[Fine-tune] Epoch 81/100  Loss=1.0634\n",
      "[Fine-tune] Epoch 82/100  Loss=1.0666\n",
      "[Fine-tune] Epoch 83/100  Loss=1.0668\n",
      "[Fine-tune] Epoch 84/100  Loss=1.0701\n",
      "[Fine-tune] Epoch 85/100  Loss=1.0602\n",
      "[Fine-tune] Epoch 86/100  Loss=1.0474\n",
      "[Fine-tune] Epoch 87/100  Loss=1.0553\n",
      "[Fine-tune] Epoch 88/100  Loss=1.0548\n",
      "[Fine-tune] Epoch 89/100  Loss=1.0576\n",
      "[Fine-tune] Epoch 90/100  Loss=1.0503\n",
      "[Fine-tune] Epoch 91/100  Loss=1.0616\n",
      "[Fine-tune] Epoch 92/100  Loss=1.0566\n",
      "[Fine-tune] Epoch 93/100  Loss=1.0562\n",
      "[Fine-tune] Epoch 94/100  Loss=1.0612\n",
      "[Fine-tune] Epoch 95/100  Loss=1.0541\n",
      "[Fine-tune] Epoch 96/100  Loss=1.0694\n",
      "[Fine-tune] Epoch 97/100  Loss=1.0468\n",
      "[Fine-tune] Epoch 98/100  Loss=1.0564\n",
      "[Fine-tune] Epoch 99/100  Loss=1.0589\n",
      "[Fine-tune] Epoch 100/100  Loss=1.0506\n",
      "[Pretrain] Epoch 1/50  Loss=3.2405  Acc=0.0440\n",
      "[Pretrain] Epoch 2/50  Loss=3.0762  Acc=0.0765\n",
      "[Pretrain] Epoch 3/50  Loss=3.0354  Acc=0.0903\n",
      "[Pretrain] Epoch 4/50  Loss=2.8931  Acc=0.1243\n",
      "[Pretrain] Epoch 5/50  Loss=2.6041  Acc=0.1884\n",
      "[Pretrain] Epoch 6/50  Loss=2.4331  Acc=0.2216\n",
      "[Pretrain] Epoch 7/50  Loss=2.3142  Acc=0.2613\n",
      "[Pretrain] Epoch 8/50  Loss=2.2572  Acc=0.2809\n",
      "[Pretrain] Epoch 9/50  Loss=2.1808  Acc=0.3044\n",
      "[Pretrain] Epoch 10/50  Loss=2.1304  Acc=0.3181\n",
      "[Pretrain] Epoch 11/50  Loss=2.0825  Acc=0.3226\n",
      "[Pretrain] Epoch 12/50  Loss=2.0255  Acc=0.3502\n",
      "[Pretrain] Epoch 13/50  Loss=2.0185  Acc=0.3518\n",
      "[Pretrain] Epoch 14/50  Loss=1.9742  Acc=0.3597\n",
      "[Pretrain] Epoch 15/50  Loss=1.9391  Acc=0.3651\n",
      "[Pretrain] Epoch 16/50  Loss=1.9033  Acc=0.3840\n",
      "[Pretrain] Epoch 17/50  Loss=1.9016  Acc=0.3879\n",
      "[Pretrain] Epoch 18/50  Loss=1.8734  Acc=0.3930\n",
      "[Pretrain] Epoch 19/50  Loss=1.8352  Acc=0.4068\n",
      "[Pretrain] Epoch 20/50  Loss=1.8291  Acc=0.4131\n",
      "[Pretrain] Epoch 21/50  Loss=1.8004  Acc=0.4246\n",
      "[Pretrain] Epoch 22/50  Loss=1.7780  Acc=0.4228\n",
      "[Pretrain] Epoch 23/50  Loss=1.7395  Acc=0.4359\n",
      "[Pretrain] Epoch 24/50  Loss=1.7549  Acc=0.4362\n",
      "[Pretrain] Epoch 25/50  Loss=1.7214  Acc=0.4432\n",
      "[Pretrain] Epoch 26/50  Loss=1.7088  Acc=0.4459\n",
      "[Pretrain] Epoch 27/50  Loss=1.7008  Acc=0.4535\n",
      "[Pretrain] Epoch 28/50  Loss=1.6768  Acc=0.4608\n",
      "[Pretrain] Epoch 29/50  Loss=1.6568  Acc=0.4668\n",
      "[Pretrain] Epoch 30/50  Loss=1.6263  Acc=0.4732\n",
      "[Pretrain] Epoch 31/50  Loss=1.6231  Acc=0.4713\n",
      "[Pretrain] Epoch 32/50  Loss=1.6119  Acc=0.4880\n",
      "[Pretrain] Epoch 33/50  Loss=1.6082  Acc=0.4799\n",
      "[Pretrain] Epoch 34/50  Loss=1.5978  Acc=0.4817\n",
      "[Pretrain] Epoch 35/50  Loss=1.5855  Acc=0.4903\n",
      "[Pretrain] Epoch 36/50  Loss=1.5475  Acc=0.4964\n",
      "[Pretrain] Epoch 37/50  Loss=1.5567  Acc=0.4907\n",
      "[Pretrain] Epoch 38/50  Loss=1.5499  Acc=0.4973\n",
      "[Pretrain] Epoch 39/50  Loss=1.5377  Acc=0.4989\n",
      "[Pretrain] Epoch 40/50  Loss=1.5339  Acc=0.5022\n",
      "[Pretrain] Epoch 41/50  Loss=1.5017  Acc=0.5126\n",
      "[Pretrain] Epoch 42/50  Loss=1.5029  Acc=0.5097\n",
      "[Pretrain] Epoch 43/50  Loss=1.4804  Acc=0.5255\n",
      "[Pretrain] Epoch 44/50  Loss=1.4940  Acc=0.5106\n",
      "[Pretrain] Epoch 45/50  Loss=1.4670  Acc=0.5248\n",
      "[Pretrain] Epoch 46/50  Loss=1.4742  Acc=0.5208\n",
      "[Pretrain] Epoch 47/50  Loss=1.4714  Acc=0.5237\n",
      "[Pretrain] Epoch 48/50  Loss=1.4568  Acc=0.5323\n",
      "[Pretrain] Epoch 49/50  Loss=1.4462  Acc=0.5269\n",
      "[Pretrain] Epoch 50/50  Loss=1.4462  Acc=0.5278\n",
      "[Fine-tune] Epoch 1/150  Loss=2.6610\n",
      "[Fine-tune] Epoch 2/150  Loss=2.2279\n",
      "[Fine-tune] Epoch 3/150  Loss=2.0631\n",
      "[Fine-tune] Epoch 4/150  Loss=1.9549\n",
      "[Fine-tune] Epoch 5/150  Loss=1.8828\n",
      "[Fine-tune] Epoch 6/150  Loss=1.8371\n",
      "[Fine-tune] Epoch 7/150  Loss=1.7794\n",
      "[Fine-tune] Epoch 8/150  Loss=1.7232\n",
      "[Fine-tune] Epoch 9/150  Loss=1.7062\n",
      "[Fine-tune] Epoch 10/150  Loss=1.6680\n",
      "[Fine-tune] Epoch 11/150  Loss=1.6154\n",
      "[Fine-tune] Epoch 12/150  Loss=1.5887\n",
      "[Fine-tune] Epoch 13/150  Loss=1.5676\n",
      "[Fine-tune] Epoch 14/150  Loss=1.5087\n",
      "[Fine-tune] Epoch 15/150  Loss=1.5197\n",
      "[Fine-tune] Epoch 16/150  Loss=1.4842\n",
      "[Fine-tune] Epoch 17/150  Loss=1.4555\n",
      "[Fine-tune] Epoch 18/150  Loss=1.4336\n",
      "[Fine-tune] Epoch 19/150  Loss=1.3994\n",
      "[Fine-tune] Epoch 20/150  Loss=1.3919\n",
      "[Fine-tune] Epoch 21/150  Loss=1.3655\n",
      "[Fine-tune] Epoch 22/150  Loss=1.3208\n",
      "[Fine-tune] Epoch 23/150  Loss=1.3063\n",
      "[Fine-tune] Epoch 24/150  Loss=1.2919\n",
      "[Fine-tune] Epoch 25/150  Loss=1.2778\n",
      "[Fine-tune] Epoch 26/150  Loss=1.2628\n",
      "[Fine-tune] Epoch 27/150  Loss=1.2515\n",
      "[Fine-tune] Epoch 28/150  Loss=1.2331\n",
      "[Fine-tune] Epoch 29/150  Loss=1.2152\n",
      "[Fine-tune] Epoch 30/150  Loss=1.1968\n",
      "[Fine-tune] Epoch 31/150  Loss=1.1832\n",
      "[Fine-tune] Epoch 32/150  Loss=1.1700\n",
      "[Fine-tune] Epoch 33/150  Loss=1.1679\n",
      "[Fine-tune] Epoch 34/150  Loss=1.1596\n",
      "[Fine-tune] Epoch 35/150  Loss=1.1431\n",
      "[Fine-tune] Epoch 36/150  Loss=1.1528\n",
      "[Fine-tune] Epoch 37/150  Loss=1.1327\n",
      "[Fine-tune] Epoch 38/150  Loss=1.1219\n",
      "[Fine-tune] Epoch 39/150  Loss=1.1031\n",
      "[Fine-tune] Epoch 40/150  Loss=1.0894\n",
      "[Fine-tune] Epoch 41/150  Loss=1.0794\n",
      "[Fine-tune] Epoch 42/150  Loss=1.0904\n",
      "[Fine-tune] Epoch 43/150  Loss=1.0841\n",
      "[Fine-tune] Epoch 44/150  Loss=1.0697\n",
      "[Fine-tune] Epoch 45/150  Loss=1.0611\n",
      "[Fine-tune] Epoch 46/150  Loss=1.0642\n",
      "[Fine-tune] Epoch 47/150  Loss=1.0586\n",
      "[Fine-tune] Epoch 48/150  Loss=1.0539\n",
      "[Fine-tune] Epoch 49/150  Loss=1.0505\n",
      "[Fine-tune] Epoch 50/150  Loss=1.0491\n",
      "[Fine-tune] Epoch 51/150  Loss=1.0358\n",
      "[Fine-tune] Epoch 52/150  Loss=1.0251\n",
      "[Fine-tune] Epoch 53/150  Loss=1.0318\n",
      "[Fine-tune] Epoch 54/150  Loss=1.0314\n",
      "[Fine-tune] Epoch 55/150  Loss=1.0225\n",
      "[Fine-tune] Epoch 56/150  Loss=1.0196\n",
      "[Fine-tune] Epoch 57/150  Loss=1.0161\n",
      "[Fine-tune] Epoch 58/150  Loss=1.0115\n",
      "[Fine-tune] Epoch 59/150  Loss=1.0178\n",
      "[Fine-tune] Epoch 60/150  Loss=0.9970\n",
      "[Fine-tune] Epoch 61/150  Loss=1.0072\n",
      "[Fine-tune] Epoch 62/150  Loss=0.9996\n",
      "[Fine-tune] Epoch 63/150  Loss=0.9991\n",
      "[Fine-tune] Epoch 64/150  Loss=0.9900\n",
      "[Fine-tune] Epoch 65/150  Loss=0.9989\n",
      "[Fine-tune] Epoch 66/150  Loss=0.9930\n",
      "[Fine-tune] Epoch 67/150  Loss=0.9813\n",
      "[Fine-tune] Epoch 68/150  Loss=0.9933\n",
      "[Fine-tune] Epoch 69/150  Loss=0.9769\n",
      "[Fine-tune] Epoch 70/150  Loss=0.9904\n",
      "[Fine-tune] Epoch 71/150  Loss=0.9665\n",
      "[Fine-tune] Epoch 72/150  Loss=0.9868\n",
      "[Fine-tune] Epoch 73/150  Loss=0.9894\n",
      "[Fine-tune] Epoch 74/150  Loss=0.9763\n",
      "[Fine-tune] Epoch 75/150  Loss=0.9794\n",
      "[Fine-tune] Epoch 76/150  Loss=0.9789\n",
      "[Fine-tune] Epoch 77/150  Loss=0.9656\n",
      "[Fine-tune] Epoch 78/150  Loss=0.9768\n",
      "[Fine-tune] Epoch 79/150  Loss=0.9806\n",
      "[Fine-tune] Epoch 80/150  Loss=0.9711\n",
      "[Fine-tune] Epoch 81/150  Loss=0.9765\n",
      "[Fine-tune] Epoch 82/150  Loss=0.9754\n",
      "[Fine-tune] Epoch 83/150  Loss=0.9532\n",
      "[Fine-tune] Epoch 84/150  Loss=0.9646\n",
      "[Fine-tune] Epoch 85/150  Loss=0.9610\n",
      "[Fine-tune] Epoch 86/150  Loss=0.9689\n",
      "[Fine-tune] Epoch 87/150  Loss=0.9679\n",
      "[Fine-tune] Epoch 88/150  Loss=0.9842\n",
      "[Fine-tune] Epoch 89/150  Loss=0.9572\n",
      "[Fine-tune] Epoch 90/150  Loss=0.9633\n",
      "[Fine-tune] Epoch 91/150  Loss=0.9548\n",
      "[Fine-tune] Epoch 92/150  Loss=0.9634\n",
      "[Fine-tune] Epoch 93/150  Loss=0.9586\n",
      "[Fine-tune] Epoch 94/150  Loss=0.9508\n",
      "[Fine-tune] Epoch 95/150  Loss=0.9516\n",
      "[Fine-tune] Epoch 96/150  Loss=0.9425\n",
      "[Fine-tune] Epoch 97/150  Loss=0.9545\n",
      "[Fine-tune] Epoch 98/150  Loss=0.9510\n",
      "[Fine-tune] Epoch 99/150  Loss=0.9590\n",
      "[Fine-tune] Epoch 100/150  Loss=0.9696\n",
      "[Fine-tune] Epoch 101/150  Loss=0.9543\n",
      "[Fine-tune] Epoch 102/150  Loss=0.9502\n",
      "[Fine-tune] Epoch 103/150  Loss=0.9491\n",
      "[Fine-tune] Epoch 104/150  Loss=0.9572\n",
      "[Fine-tune] Epoch 105/150  Loss=0.9660\n",
      "[Fine-tune] Epoch 106/150  Loss=0.9545\n",
      "[Fine-tune] Epoch 107/150  Loss=0.9588\n",
      "[Fine-tune] Epoch 108/150  Loss=0.9575\n",
      "[Fine-tune] Epoch 109/150  Loss=0.9629\n",
      "[Fine-tune] Epoch 110/150  Loss=0.9652\n",
      "[Fine-tune] Epoch 111/150  Loss=0.9530\n",
      "[Fine-tune] Epoch 112/150  Loss=0.9577\n",
      "[Fine-tune] Epoch 113/150  Loss=0.9537\n",
      "[Fine-tune] Epoch 114/150  Loss=0.9398\n",
      "[Fine-tune] Epoch 115/150  Loss=0.9478\n",
      "[Fine-tune] Epoch 116/150  Loss=0.9606\n",
      "[Fine-tune] Epoch 117/150  Loss=0.9587\n",
      "[Fine-tune] Epoch 118/150  Loss=0.9567\n",
      "[Fine-tune] Epoch 119/150  Loss=0.9475\n",
      "[Fine-tune] Epoch 120/150  Loss=0.9438\n",
      "[Fine-tune] Epoch 121/150  Loss=0.9535\n",
      "[Fine-tune] Epoch 122/150  Loss=0.9489\n",
      "[Fine-tune] Epoch 123/150  Loss=0.9386\n",
      "[Fine-tune] Epoch 124/150  Loss=0.9448\n",
      "[Fine-tune] Epoch 125/150  Loss=0.9336\n",
      "[Fine-tune] Epoch 126/150  Loss=0.9524\n",
      "[Fine-tune] Epoch 127/150  Loss=0.9540\n",
      "[Fine-tune] Epoch 128/150  Loss=0.9533\n",
      "[Fine-tune] Epoch 129/150  Loss=0.9537\n",
      "[Fine-tune] Epoch 130/150  Loss=0.9638\n",
      "[Fine-tune] Epoch 131/150  Loss=0.9579\n",
      "[Fine-tune] Epoch 132/150  Loss=0.9550\n",
      "[Fine-tune] Epoch 133/150  Loss=0.9483\n",
      "[Fine-tune] Epoch 134/150  Loss=0.9586\n",
      "[Fine-tune] Epoch 135/150  Loss=0.9503\n",
      "[Fine-tune] Epoch 136/150  Loss=0.9507\n",
      "[Fine-tune] Epoch 137/150  Loss=0.9440\n",
      "[Fine-tune] Epoch 138/150  Loss=0.9519\n",
      "[Fine-tune] Epoch 139/150  Loss=0.9395\n",
      "[Fine-tune] Epoch 140/150  Loss=0.9560\n",
      "[Fine-tune] Epoch 141/150  Loss=0.9438\n",
      "[Fine-tune] Epoch 142/150  Loss=0.9511\n",
      "[Fine-tune] Epoch 143/150  Loss=0.9441\n",
      "[Fine-tune] Epoch 144/150  Loss=0.9567\n",
      "[Fine-tune] Epoch 145/150  Loss=0.9381\n",
      "[Fine-tune] Epoch 146/150  Loss=0.9529\n",
      "[Fine-tune] Epoch 147/150  Loss=0.9611\n",
      "[Fine-tune] Epoch 148/150  Loss=0.9574\n",
      "[Fine-tune] Epoch 149/150  Loss=0.9484\n",
      "[Fine-tune] Epoch 150/150  Loss=0.9525\n",
      "[Pretrain] Epoch 1/50  Loss=3.7082  Acc=0.0395\n",
      "[Pretrain] Epoch 2/50  Loss=3.0839  Acc=0.0808\n",
      "[Pretrain] Epoch 3/50  Loss=2.8188  Acc=0.1115\n",
      "[Pretrain] Epoch 4/50  Loss=2.6621  Acc=0.1591\n",
      "[Pretrain] Epoch 5/50  Loss=2.5312  Acc=0.1986\n",
      "[Pretrain] Epoch 6/50  Loss=2.4558  Acc=0.2204\n",
      "[Pretrain] Epoch 7/50  Loss=2.3493  Acc=0.2468\n",
      "[Pretrain] Epoch 8/50  Loss=2.2918  Acc=0.2635\n",
      "[Pretrain] Epoch 9/50  Loss=2.2545  Acc=0.2732\n",
      "[Pretrain] Epoch 10/50  Loss=2.2026  Acc=0.2883\n",
      "[Pretrain] Epoch 11/50  Loss=2.1465  Acc=0.3028\n",
      "[Pretrain] Epoch 12/50  Loss=2.1306  Acc=0.3053\n",
      "[Pretrain] Epoch 13/50  Loss=2.0895  Acc=0.3285\n",
      "[Pretrain] Epoch 14/50  Loss=2.0208  Acc=0.3441\n",
      "[Pretrain] Epoch 15/50  Loss=1.9867  Acc=0.3633\n",
      "[Pretrain] Epoch 16/50  Loss=1.9880  Acc=0.3531\n",
      "[Pretrain] Epoch 17/50  Loss=1.9565  Acc=0.3696\n",
      "[Pretrain] Epoch 18/50  Loss=1.9232  Acc=0.3737\n",
      "[Pretrain] Epoch 19/50  Loss=1.8905  Acc=0.3822\n",
      "[Pretrain] Epoch 20/50  Loss=1.8620  Acc=0.3836\n",
      "[Pretrain] Epoch 21/50  Loss=1.8525  Acc=0.3966\n",
      "[Pretrain] Epoch 22/50  Loss=1.8216  Acc=0.4088\n",
      "[Pretrain] Epoch 23/50  Loss=1.8127  Acc=0.4213\n",
      "[Pretrain] Epoch 24/50  Loss=1.8034  Acc=0.4215\n",
      "[Pretrain] Epoch 25/50  Loss=1.7688  Acc=0.4287\n",
      "[Pretrain] Epoch 26/50  Loss=1.7264  Acc=0.4371\n",
      "[Pretrain] Epoch 27/50  Loss=1.7264  Acc=0.4371\n",
      "[Pretrain] Epoch 28/50  Loss=1.6903  Acc=0.4517\n",
      "[Pretrain] Epoch 29/50  Loss=1.6709  Acc=0.4515\n",
      "[Pretrain] Epoch 30/50  Loss=1.6452  Acc=0.4637\n",
      "[Pretrain] Epoch 31/50  Loss=1.6257  Acc=0.4695\n",
      "[Pretrain] Epoch 32/50  Loss=1.6032  Acc=0.4784\n",
      "[Pretrain] Epoch 33/50  Loss=1.6042  Acc=0.4797\n",
      "[Pretrain] Epoch 34/50  Loss=1.5783  Acc=0.4793\n",
      "[Pretrain] Epoch 35/50  Loss=1.5188  Acc=0.5059\n",
      "[Pretrain] Epoch 36/50  Loss=1.5185  Acc=0.4998\n",
      "[Pretrain] Epoch 37/50  Loss=1.5228  Acc=0.5041\n",
      "[Pretrain] Epoch 38/50  Loss=1.4867  Acc=0.5126\n",
      "[Pretrain] Epoch 39/50  Loss=1.4653  Acc=0.5163\n",
      "[Pretrain] Epoch 40/50  Loss=1.4607  Acc=0.5253\n",
      "[Pretrain] Epoch 41/50  Loss=1.4383  Acc=0.5264\n",
      "[Pretrain] Epoch 42/50  Loss=1.4127  Acc=0.5330\n",
      "[Pretrain] Epoch 43/50  Loss=1.3879  Acc=0.5481\n",
      "[Pretrain] Epoch 44/50  Loss=1.3966  Acc=0.5420\n",
      "[Pretrain] Epoch 45/50  Loss=1.3747  Acc=0.5517\n",
      "[Pretrain] Epoch 46/50  Loss=1.3725  Acc=0.5487\n",
      "[Pretrain] Epoch 47/50  Loss=1.3379  Acc=0.5593\n",
      "[Pretrain] Epoch 48/50  Loss=1.3188  Acc=0.5700\n",
      "[Pretrain] Epoch 49/50  Loss=1.3114  Acc=0.5659\n",
      "[Pretrain] Epoch 50/50  Loss=1.3173  Acc=0.5647\n",
      "[Fine-tune] Epoch 1/150  Loss=3.1010\n",
      "[Fine-tune] Epoch 2/150  Loss=2.5764\n",
      "[Fine-tune] Epoch 3/150  Loss=2.3503\n",
      "[Fine-tune] Epoch 4/150  Loss=2.2278\n",
      "[Fine-tune] Epoch 5/150  Loss=2.1616\n",
      "[Fine-tune] Epoch 6/150  Loss=2.1054\n",
      "[Fine-tune] Epoch 7/150  Loss=2.0403\n",
      "[Fine-tune] Epoch 8/150  Loss=2.0100\n",
      "[Fine-tune] Epoch 9/150  Loss=1.9809\n",
      "[Fine-tune] Epoch 10/150  Loss=1.9576\n",
      "[Fine-tune] Epoch 11/150  Loss=1.9398\n",
      "[Fine-tune] Epoch 12/150  Loss=1.9001\n",
      "[Fine-tune] Epoch 13/150  Loss=1.8745\n",
      "[Fine-tune] Epoch 14/150  Loss=1.8762\n",
      "[Fine-tune] Epoch 15/150  Loss=1.8756\n",
      "[Fine-tune] Epoch 16/150  Loss=1.8285\n",
      "[Fine-tune] Epoch 17/150  Loss=1.8336\n",
      "[Fine-tune] Epoch 18/150  Loss=1.8117\n",
      "[Fine-tune] Epoch 19/150  Loss=1.7965\n",
      "[Fine-tune] Epoch 20/150  Loss=1.7837\n",
      "[Fine-tune] Epoch 21/150  Loss=1.7568\n",
      "[Fine-tune] Epoch 22/150  Loss=1.7598\n",
      "[Fine-tune] Epoch 23/150  Loss=1.7632\n",
      "[Fine-tune] Epoch 24/150  Loss=1.7628\n",
      "[Fine-tune] Epoch 25/150  Loss=1.7395\n",
      "[Fine-tune] Epoch 26/150  Loss=1.7324\n",
      "[Fine-tune] Epoch 27/150  Loss=1.7293\n",
      "[Fine-tune] Epoch 28/150  Loss=1.7243\n",
      "[Fine-tune] Epoch 29/150  Loss=1.7139\n",
      "[Fine-tune] Epoch 30/150  Loss=1.7046\n",
      "[Fine-tune] Epoch 31/150  Loss=1.7037\n",
      "[Fine-tune] Epoch 32/150  Loss=1.6982\n",
      "[Fine-tune] Epoch 33/150  Loss=1.6850\n",
      "[Fine-tune] Epoch 34/150  Loss=1.6782\n",
      "[Fine-tune] Epoch 35/150  Loss=1.6827\n",
      "[Fine-tune] Epoch 36/150  Loss=1.6809\n",
      "[Fine-tune] Epoch 37/150  Loss=1.6612\n",
      "[Fine-tune] Epoch 38/150  Loss=1.6762\n",
      "[Fine-tune] Epoch 39/150  Loss=1.6576\n",
      "[Fine-tune] Epoch 40/150  Loss=1.6578\n",
      "[Fine-tune] Epoch 41/150  Loss=1.6532\n",
      "[Fine-tune] Epoch 42/150  Loss=1.6673\n",
      "[Fine-tune] Epoch 43/150  Loss=1.6503\n",
      "[Fine-tune] Epoch 44/150  Loss=1.6369\n",
      "[Fine-tune] Epoch 45/150  Loss=1.6546\n",
      "[Fine-tune] Epoch 46/150  Loss=1.6539\n",
      "[Fine-tune] Epoch 47/150  Loss=1.6461\n",
      "[Fine-tune] Epoch 48/150  Loss=1.6516\n",
      "[Fine-tune] Epoch 49/150  Loss=1.6243\n",
      "[Fine-tune] Epoch 50/150  Loss=1.6350\n",
      "[Fine-tune] Epoch 51/150  Loss=1.6319\n",
      "[Fine-tune] Epoch 52/150  Loss=1.6251\n",
      "[Fine-tune] Epoch 53/150  Loss=1.6338\n",
      "[Fine-tune] Epoch 54/150  Loss=1.6256\n",
      "[Fine-tune] Epoch 55/150  Loss=1.6187\n",
      "[Fine-tune] Epoch 56/150  Loss=1.6129\n",
      "[Fine-tune] Epoch 57/150  Loss=1.6077\n",
      "[Fine-tune] Epoch 58/150  Loss=1.6143\n",
      "[Fine-tune] Epoch 59/150  Loss=1.6179\n",
      "[Fine-tune] Epoch 60/150  Loss=1.6247\n",
      "[Fine-tune] Epoch 61/150  Loss=1.6178\n",
      "[Fine-tune] Epoch 62/150  Loss=1.6201\n",
      "[Fine-tune] Epoch 63/150  Loss=1.6155\n",
      "[Fine-tune] Epoch 64/150  Loss=1.6043\n",
      "[Fine-tune] Epoch 65/150  Loss=1.6129\n",
      "[Fine-tune] Epoch 66/150  Loss=1.6181\n",
      "[Fine-tune] Epoch 67/150  Loss=1.6180\n",
      "[Fine-tune] Epoch 68/150  Loss=1.6021\n",
      "[Fine-tune] Epoch 69/150  Loss=1.6063\n",
      "[Fine-tune] Epoch 70/150  Loss=1.6121\n",
      "[Fine-tune] Epoch 71/150  Loss=1.6129\n",
      "[Fine-tune] Epoch 72/150  Loss=1.6069\n",
      "[Fine-tune] Epoch 73/150  Loss=1.5949\n",
      "[Fine-tune] Epoch 74/150  Loss=1.6108\n",
      "[Fine-tune] Epoch 75/150  Loss=1.6008\n",
      "[Fine-tune] Epoch 76/150  Loss=1.6068\n",
      "[Fine-tune] Epoch 77/150  Loss=1.6094\n",
      "[Fine-tune] Epoch 78/150  Loss=1.5979\n",
      "[Fine-tune] Epoch 79/150  Loss=1.5936\n",
      "[Fine-tune] Epoch 80/150  Loss=1.6057\n",
      "[Fine-tune] Epoch 81/150  Loss=1.6155\n",
      "[Fine-tune] Epoch 82/150  Loss=1.6075\n",
      "[Fine-tune] Epoch 83/150  Loss=1.6022\n",
      "[Fine-tune] Epoch 84/150  Loss=1.6058\n",
      "[Fine-tune] Epoch 85/150  Loss=1.6022\n",
      "[Fine-tune] Epoch 86/150  Loss=1.5922\n",
      "[Fine-tune] Epoch 87/150  Loss=1.6048\n",
      "[Fine-tune] Epoch 88/150  Loss=1.6016\n",
      "[Fine-tune] Epoch 89/150  Loss=1.6049\n",
      "[Fine-tune] Epoch 90/150  Loss=1.5893\n",
      "[Fine-tune] Epoch 91/150  Loss=1.5959\n",
      "[Fine-tune] Epoch 92/150  Loss=1.5956\n",
      "[Fine-tune] Epoch 93/150  Loss=1.6039\n",
      "[Fine-tune] Epoch 94/150  Loss=1.6026\n",
      "[Fine-tune] Epoch 95/150  Loss=1.5900\n",
      "[Fine-tune] Epoch 96/150  Loss=1.6182\n",
      "[Fine-tune] Epoch 97/150  Loss=1.5946\n",
      "[Fine-tune] Epoch 98/150  Loss=1.5866\n",
      "[Fine-tune] Epoch 99/150  Loss=1.5958\n",
      "[Fine-tune] Epoch 100/150  Loss=1.5983\n",
      "[Fine-tune] Epoch 101/150  Loss=1.5907\n",
      "[Fine-tune] Epoch 102/150  Loss=1.6106\n",
      "[Fine-tune] Epoch 103/150  Loss=1.6000\n",
      "[Fine-tune] Epoch 104/150  Loss=1.5902\n",
      "[Fine-tune] Epoch 105/150  Loss=1.6059\n",
      "[Fine-tune] Epoch 106/150  Loss=1.5902\n",
      "[Fine-tune] Epoch 107/150  Loss=1.5960\n",
      "[Fine-tune] Epoch 108/150  Loss=1.6065\n",
      "[Fine-tune] Epoch 109/150  Loss=1.6003\n",
      "[Fine-tune] Epoch 110/150  Loss=1.5979\n",
      "[Fine-tune] Epoch 111/150  Loss=1.6097\n",
      "[Fine-tune] Epoch 112/150  Loss=1.5888\n",
      "[Fine-tune] Epoch 113/150  Loss=1.5958\n",
      "[Fine-tune] Epoch 114/150  Loss=1.6033\n",
      "[Fine-tune] Epoch 115/150  Loss=1.6024\n",
      "[Fine-tune] Epoch 116/150  Loss=1.6067\n",
      "[Fine-tune] Epoch 117/150  Loss=1.5943\n",
      "[Fine-tune] Epoch 118/150  Loss=1.5939\n",
      "[Fine-tune] Epoch 119/150  Loss=1.5980\n",
      "[Fine-tune] Epoch 120/150  Loss=1.6058\n",
      "[Fine-tune] Epoch 121/150  Loss=1.5909\n",
      "[Fine-tune] Epoch 122/150  Loss=1.5883\n",
      "[Fine-tune] Epoch 123/150  Loss=1.5883\n",
      "[Fine-tune] Epoch 124/150  Loss=1.6026\n",
      "[Fine-tune] Epoch 125/150  Loss=1.5886\n",
      "[Fine-tune] Epoch 126/150  Loss=1.6035\n",
      "[Fine-tune] Epoch 127/150  Loss=1.5885\n",
      "[Fine-tune] Epoch 128/150  Loss=1.6043\n",
      "[Fine-tune] Epoch 129/150  Loss=1.6098\n",
      "[Fine-tune] Epoch 130/150  Loss=1.5956\n",
      "[Fine-tune] Epoch 131/150  Loss=1.5977\n",
      "[Fine-tune] Epoch 132/150  Loss=1.6033\n",
      "[Fine-tune] Epoch 133/150  Loss=1.6176\n",
      "[Fine-tune] Epoch 134/150  Loss=1.6000\n",
      "[Fine-tune] Epoch 135/150  Loss=1.5799\n",
      "[Fine-tune] Epoch 136/150  Loss=1.5995\n",
      "[Fine-tune] Epoch 137/150  Loss=1.5961\n",
      "[Fine-tune] Epoch 138/150  Loss=1.6042\n",
      "[Fine-tune] Epoch 139/150  Loss=1.5908\n",
      "[Fine-tune] Epoch 140/150  Loss=1.5996\n",
      "[Fine-tune] Epoch 141/150  Loss=1.5926\n",
      "[Fine-tune] Epoch 142/150  Loss=1.5918\n",
      "[Fine-tune] Epoch 143/150  Loss=1.6080\n",
      "[Fine-tune] Epoch 144/150  Loss=1.5891\n",
      "[Fine-tune] Epoch 145/150  Loss=1.5888\n",
      "[Fine-tune] Epoch 146/150  Loss=1.6073\n",
      "[Fine-tune] Epoch 147/150  Loss=1.5937\n",
      "[Fine-tune] Epoch 148/150  Loss=1.5996\n",
      "[Fine-tune] Epoch 149/150  Loss=1.5932\n",
      "[Fine-tune] Epoch 150/150  Loss=1.6007\n",
      "[Pretrain] Epoch 1/75  Loss=3.2446  Acc=0.0420\n",
      "[Pretrain] Epoch 2/75  Loss=3.0845  Acc=0.0772\n",
      "[Pretrain] Epoch 3/75  Loss=2.9975  Acc=0.1045\n",
      "[Pretrain] Epoch 4/75  Loss=2.7649  Acc=0.1338\n",
      "[Pretrain] Epoch 5/75  Loss=2.5480  Acc=0.1961\n",
      "[Pretrain] Epoch 6/75  Loss=2.3528  Acc=0.2552\n",
      "[Pretrain] Epoch 7/75  Loss=2.2571  Acc=0.2830\n",
      "[Pretrain] Epoch 8/75  Loss=2.1530  Acc=0.3017\n",
      "[Pretrain] Epoch 9/75  Loss=2.0796  Acc=0.3328\n",
      "[Pretrain] Epoch 10/75  Loss=2.0083  Acc=0.3448\n",
      "[Pretrain] Epoch 11/75  Loss=1.9867  Acc=0.3707\n",
      "[Pretrain] Epoch 12/75  Loss=1.9537  Acc=0.3727\n",
      "[Pretrain] Epoch 13/75  Loss=1.9138  Acc=0.3746\n",
      "[Pretrain] Epoch 14/75  Loss=1.8948  Acc=0.3933\n",
      "[Pretrain] Epoch 15/75  Loss=1.8665  Acc=0.3976\n",
      "[Pretrain] Epoch 16/75  Loss=1.8340  Acc=0.4145\n",
      "[Pretrain] Epoch 17/75  Loss=1.8099  Acc=0.4188\n",
      "[Pretrain] Epoch 18/75  Loss=1.8035  Acc=0.4151\n",
      "[Pretrain] Epoch 19/75  Loss=1.7413  Acc=0.4406\n",
      "[Pretrain] Epoch 20/75  Loss=1.7298  Acc=0.4431\n",
      "[Pretrain] Epoch 21/75  Loss=1.7248  Acc=0.4447\n",
      "[Pretrain] Epoch 22/75  Loss=1.6867  Acc=0.4538\n",
      "[Pretrain] Epoch 23/75  Loss=1.6691  Acc=0.4605\n",
      "[Pretrain] Epoch 24/75  Loss=1.6640  Acc=0.4637\n",
      "[Pretrain] Epoch 25/75  Loss=1.6535  Acc=0.4587\n",
      "[Pretrain] Epoch 26/75  Loss=1.6124  Acc=0.4788\n",
      "[Pretrain] Epoch 27/75  Loss=1.6134  Acc=0.4741\n",
      "[Pretrain] Epoch 28/75  Loss=1.5993  Acc=0.4837\n",
      "[Pretrain] Epoch 29/75  Loss=1.5663  Acc=0.4856\n",
      "[Pretrain] Epoch 30/75  Loss=1.5517  Acc=0.4932\n",
      "[Pretrain] Epoch 31/75  Loss=1.5410  Acc=0.5004\n",
      "[Pretrain] Epoch 32/75  Loss=1.5276  Acc=0.4989\n",
      "[Pretrain] Epoch 33/75  Loss=1.5337  Acc=0.5013\n",
      "[Pretrain] Epoch 34/75  Loss=1.4978  Acc=0.5126\n",
      "[Pretrain] Epoch 35/75  Loss=1.4815  Acc=0.5192\n",
      "[Pretrain] Epoch 36/75  Loss=1.4940  Acc=0.5153\n",
      "[Pretrain] Epoch 37/75  Loss=1.4869  Acc=0.5142\n",
      "[Pretrain] Epoch 38/75  Loss=1.4676  Acc=0.5246\n",
      "[Pretrain] Epoch 39/75  Loss=1.4541  Acc=0.5232\n",
      "[Pretrain] Epoch 40/75  Loss=1.4207  Acc=0.5390\n",
      "[Pretrain] Epoch 41/75  Loss=1.4286  Acc=0.5445\n",
      "[Pretrain] Epoch 42/75  Loss=1.4221  Acc=0.5374\n",
      "[Pretrain] Epoch 43/75  Loss=1.4176  Acc=0.5406\n",
      "[Pretrain] Epoch 44/75  Loss=1.4024  Acc=0.5402\n",
      "[Pretrain] Epoch 45/75  Loss=1.3820  Acc=0.5524\n",
      "[Pretrain] Epoch 46/75  Loss=1.3981  Acc=0.5417\n",
      "[Pretrain] Epoch 47/75  Loss=1.3743  Acc=0.5542\n",
      "[Pretrain] Epoch 48/75  Loss=1.3682  Acc=0.5532\n",
      "[Pretrain] Epoch 49/75  Loss=1.3733  Acc=0.5501\n",
      "[Pretrain] Epoch 50/75  Loss=1.3719  Acc=0.5481\n",
      "[Pretrain] Epoch 51/75  Loss=1.3605  Acc=0.5562\n",
      "[Pretrain] Epoch 52/75  Loss=1.3460  Acc=0.5666\n",
      "[Pretrain] Epoch 53/75  Loss=1.3377  Acc=0.5614\n",
      "[Pretrain] Epoch 54/75  Loss=1.3383  Acc=0.5609\n",
      "[Pretrain] Epoch 55/75  Loss=1.3432  Acc=0.5596\n",
      "[Pretrain] Epoch 56/75  Loss=1.3350  Acc=0.5677\n",
      "[Pretrain] Epoch 57/75  Loss=1.3276  Acc=0.5666\n",
      "[Pretrain] Epoch 58/75  Loss=1.3174  Acc=0.5686\n",
      "[Pretrain] Epoch 59/75  Loss=1.3243  Acc=0.5672\n",
      "[Pretrain] Epoch 60/75  Loss=1.3058  Acc=0.5668\n",
      "[Pretrain] Epoch 61/75  Loss=1.3131  Acc=0.5711\n",
      "[Pretrain] Epoch 62/75  Loss=1.2866  Acc=0.5783\n",
      "[Pretrain] Epoch 63/75  Loss=1.2909  Acc=0.5767\n",
      "[Pretrain] Epoch 64/75  Loss=1.2994  Acc=0.5758\n",
      "[Pretrain] Epoch 65/75  Loss=1.3038  Acc=0.5785\n",
      "[Pretrain] Epoch 66/75  Loss=1.2939  Acc=0.5735\n",
      "[Pretrain] Epoch 67/75  Loss=1.2978  Acc=0.5814\n",
      "[Pretrain] Epoch 68/75  Loss=1.2922  Acc=0.5758\n",
      "[Pretrain] Epoch 69/75  Loss=1.2823  Acc=0.5788\n",
      "[Pretrain] Epoch 70/75  Loss=1.2697  Acc=0.5887\n",
      "[Pretrain] Epoch 71/75  Loss=1.2789  Acc=0.5749\n",
      "[Pretrain] Epoch 72/75  Loss=1.2749  Acc=0.5830\n",
      "[Pretrain] Epoch 73/75  Loss=1.2785  Acc=0.5797\n",
      "[Pretrain] Epoch 74/75  Loss=1.2786  Acc=0.5810\n",
      "[Pretrain] Epoch 75/75  Loss=1.2817  Acc=0.5871\n",
      "[Fine-tune] Epoch 1/150  Loss=2.6957\n",
      "[Fine-tune] Epoch 2/150  Loss=2.2561\n",
      "[Fine-tune] Epoch 3/150  Loss=2.1433\n",
      "[Fine-tune] Epoch 4/150  Loss=2.0105\n",
      "[Fine-tune] Epoch 5/150  Loss=1.9173\n",
      "[Fine-tune] Epoch 6/150  Loss=1.8831\n",
      "[Fine-tune] Epoch 7/150  Loss=1.8033\n",
      "[Fine-tune] Epoch 8/150  Loss=1.7694\n",
      "[Fine-tune] Epoch 9/150  Loss=1.6984\n",
      "[Fine-tune] Epoch 10/150  Loss=1.6611\n",
      "[Fine-tune] Epoch 11/150  Loss=1.6161\n",
      "[Fine-tune] Epoch 12/150  Loss=1.5969\n",
      "[Fine-tune] Epoch 13/150  Loss=1.5533\n",
      "[Fine-tune] Epoch 14/150  Loss=1.5346\n",
      "[Fine-tune] Epoch 15/150  Loss=1.4932\n",
      "[Fine-tune] Epoch 16/150  Loss=1.4688\n",
      "[Fine-tune] Epoch 17/150  Loss=1.4564\n",
      "[Fine-tune] Epoch 18/150  Loss=1.4368\n",
      "[Fine-tune] Epoch 19/150  Loss=1.3920\n",
      "[Fine-tune] Epoch 20/150  Loss=1.3764\n",
      "[Fine-tune] Epoch 21/150  Loss=1.3581\n",
      "[Fine-tune] Epoch 22/150  Loss=1.3345\n",
      "[Fine-tune] Epoch 23/150  Loss=1.3016\n",
      "[Fine-tune] Epoch 24/150  Loss=1.2795\n",
      "[Fine-tune] Epoch 25/150  Loss=1.2639\n",
      "[Fine-tune] Epoch 26/150  Loss=1.2313\n",
      "[Fine-tune] Epoch 27/150  Loss=1.2247\n",
      "[Fine-tune] Epoch 28/150  Loss=1.2085\n",
      "[Fine-tune] Epoch 29/150  Loss=1.1955\n",
      "[Fine-tune] Epoch 30/150  Loss=1.1768\n",
      "[Fine-tune] Epoch 31/150  Loss=1.1787\n",
      "[Fine-tune] Epoch 32/150  Loss=1.1757\n",
      "[Fine-tune] Epoch 33/150  Loss=1.1441\n",
      "[Fine-tune] Epoch 34/150  Loss=1.1305\n",
      "[Fine-tune] Epoch 35/150  Loss=1.1160\n",
      "[Fine-tune] Epoch 36/150  Loss=1.1113\n",
      "[Fine-tune] Epoch 37/150  Loss=1.1041\n",
      "[Fine-tune] Epoch 38/150  Loss=1.1051\n",
      "[Fine-tune] Epoch 39/150  Loss=1.0786\n",
      "[Fine-tune] Epoch 40/150  Loss=1.0712\n",
      "[Fine-tune] Epoch 41/150  Loss=1.0664\n",
      "[Fine-tune] Epoch 42/150  Loss=1.0577\n",
      "[Fine-tune] Epoch 43/150  Loss=1.0668\n",
      "[Fine-tune] Epoch 44/150  Loss=1.0557\n",
      "[Fine-tune] Epoch 45/150  Loss=1.0475\n",
      "[Fine-tune] Epoch 46/150  Loss=1.0382\n",
      "[Fine-tune] Epoch 47/150  Loss=1.0192\n",
      "[Fine-tune] Epoch 48/150  Loss=1.0133\n",
      "[Fine-tune] Epoch 49/150  Loss=1.0153\n",
      "[Fine-tune] Epoch 50/150  Loss=0.9977\n",
      "[Fine-tune] Epoch 51/150  Loss=1.0018\n",
      "[Fine-tune] Epoch 52/150  Loss=0.9980\n",
      "[Fine-tune] Epoch 53/150  Loss=0.9921\n",
      "[Fine-tune] Epoch 54/150  Loss=0.9885\n",
      "[Fine-tune] Epoch 55/150  Loss=0.9844\n",
      "[Fine-tune] Epoch 56/150  Loss=0.9779\n",
      "[Fine-tune] Epoch 57/150  Loss=0.9765\n",
      "[Fine-tune] Epoch 58/150  Loss=0.9759\n",
      "[Fine-tune] Epoch 59/150  Loss=0.9782\n",
      "[Fine-tune] Epoch 60/150  Loss=0.9721\n",
      "[Fine-tune] Epoch 61/150  Loss=0.9588\n",
      "[Fine-tune] Epoch 62/150  Loss=0.9615\n",
      "[Fine-tune] Epoch 63/150  Loss=0.9721\n",
      "[Fine-tune] Epoch 64/150  Loss=0.9593\n",
      "[Fine-tune] Epoch 65/150  Loss=0.9455\n",
      "[Fine-tune] Epoch 66/150  Loss=0.9606\n",
      "[Fine-tune] Epoch 67/150  Loss=0.9507\n",
      "[Fine-tune] Epoch 68/150  Loss=0.9561\n",
      "[Fine-tune] Epoch 69/150  Loss=0.9475\n",
      "[Fine-tune] Epoch 70/150  Loss=0.9547\n",
      "[Fine-tune] Epoch 71/150  Loss=0.9348\n",
      "[Fine-tune] Epoch 72/150  Loss=0.9504\n",
      "[Fine-tune] Epoch 73/150  Loss=0.9397\n",
      "[Fine-tune] Epoch 74/150  Loss=0.9400\n",
      "[Fine-tune] Epoch 75/150  Loss=0.9487\n",
      "[Fine-tune] Epoch 76/150  Loss=0.9362\n",
      "[Fine-tune] Epoch 77/150  Loss=0.9475\n",
      "[Fine-tune] Epoch 78/150  Loss=0.9367\n",
      "[Fine-tune] Epoch 79/150  Loss=0.9328\n",
      "[Fine-tune] Epoch 80/150  Loss=0.9463\n",
      "[Fine-tune] Epoch 81/150  Loss=0.9248\n",
      "[Fine-tune] Epoch 82/150  Loss=0.9283\n",
      "[Fine-tune] Epoch 83/150  Loss=0.9379\n",
      "[Fine-tune] Epoch 84/150  Loss=0.9202\n",
      "[Fine-tune] Epoch 85/150  Loss=0.9252\n",
      "[Fine-tune] Epoch 86/150  Loss=0.9302\n",
      "[Fine-tune] Epoch 87/150  Loss=0.9308\n",
      "[Fine-tune] Epoch 88/150  Loss=0.9330\n",
      "[Fine-tune] Epoch 89/150  Loss=0.9243\n",
      "[Fine-tune] Epoch 90/150  Loss=0.9275\n",
      "[Fine-tune] Epoch 91/150  Loss=0.9292\n",
      "[Fine-tune] Epoch 92/150  Loss=0.9328\n",
      "[Fine-tune] Epoch 93/150  Loss=0.9227\n",
      "[Fine-tune] Epoch 94/150  Loss=0.9325\n",
      "[Fine-tune] Epoch 95/150  Loss=0.9176\n",
      "[Fine-tune] Epoch 96/150  Loss=0.9311\n",
      "[Fine-tune] Epoch 97/150  Loss=0.9352\n",
      "[Fine-tune] Epoch 98/150  Loss=0.9191\n",
      "[Fine-tune] Epoch 99/150  Loss=0.9168\n",
      "[Fine-tune] Epoch 100/150  Loss=0.9164\n",
      "[Fine-tune] Epoch 101/150  Loss=0.9275\n",
      "[Fine-tune] Epoch 102/150  Loss=0.9269\n",
      "[Fine-tune] Epoch 103/150  Loss=0.9214\n",
      "[Fine-tune] Epoch 104/150  Loss=0.9234\n",
      "[Fine-tune] Epoch 105/150  Loss=0.9100\n",
      "[Fine-tune] Epoch 106/150  Loss=0.9135\n",
      "[Fine-tune] Epoch 107/150  Loss=0.9188\n",
      "[Fine-tune] Epoch 108/150  Loss=0.9141\n",
      "[Fine-tune] Epoch 109/150  Loss=0.9194\n",
      "[Fine-tune] Epoch 110/150  Loss=0.9220\n",
      "[Fine-tune] Epoch 111/150  Loss=0.9400\n",
      "[Fine-tune] Epoch 112/150  Loss=0.9259\n",
      "[Fine-tune] Epoch 113/150  Loss=0.9135\n",
      "[Fine-tune] Epoch 114/150  Loss=0.9127\n",
      "[Fine-tune] Epoch 115/150  Loss=0.9104\n",
      "[Fine-tune] Epoch 116/150  Loss=0.9217\n",
      "[Fine-tune] Epoch 117/150  Loss=0.9152\n",
      "[Fine-tune] Epoch 118/150  Loss=0.9112\n",
      "[Fine-tune] Epoch 119/150  Loss=0.9079\n",
      "[Fine-tune] Epoch 120/150  Loss=0.9262\n",
      "[Fine-tune] Epoch 121/150  Loss=0.9194\n",
      "[Fine-tune] Epoch 122/150  Loss=0.9153\n",
      "[Fine-tune] Epoch 123/150  Loss=0.9160\n",
      "[Fine-tune] Epoch 124/150  Loss=0.9249\n",
      "[Fine-tune] Epoch 125/150  Loss=0.9185\n",
      "[Fine-tune] Epoch 126/150  Loss=0.9075\n",
      "[Fine-tune] Epoch 127/150  Loss=0.9149\n",
      "[Fine-tune] Epoch 128/150  Loss=0.9107\n",
      "[Fine-tune] Epoch 129/150  Loss=0.9288\n",
      "[Fine-tune] Epoch 130/150  Loss=0.9096\n",
      "[Fine-tune] Epoch 131/150  Loss=0.9205\n",
      "[Fine-tune] Epoch 132/150  Loss=0.9165\n",
      "[Fine-tune] Epoch 133/150  Loss=0.9117\n",
      "[Fine-tune] Epoch 134/150  Loss=0.9000\n",
      "[Fine-tune] Epoch 135/150  Loss=0.9218\n",
      "[Fine-tune] Epoch 136/150  Loss=0.9110\n",
      "[Fine-tune] Epoch 137/150  Loss=0.9192\n",
      "[Fine-tune] Epoch 138/150  Loss=0.9073\n",
      "[Fine-tune] Epoch 139/150  Loss=0.9066\n",
      "[Fine-tune] Epoch 140/150  Loss=0.9205\n",
      "[Fine-tune] Epoch 141/150  Loss=0.9186\n",
      "[Fine-tune] Epoch 142/150  Loss=0.9149\n",
      "[Fine-tune] Epoch 143/150  Loss=0.9207\n",
      "[Fine-tune] Epoch 144/150  Loss=0.9141\n",
      "[Fine-tune] Epoch 145/150  Loss=0.9114\n",
      "[Fine-tune] Epoch 146/150  Loss=0.9075\n",
      "[Fine-tune] Epoch 147/150  Loss=0.9010\n",
      "[Fine-tune] Epoch 148/150  Loss=0.9198\n",
      "[Fine-tune] Epoch 149/150  Loss=0.9171\n",
      "[Fine-tune] Epoch 150/150  Loss=0.9076\n",
      "[Pretrain] Epoch 1/75  Loss=3.6252  Acc=0.0449\n",
      "[Pretrain] Epoch 2/75  Loss=3.0871  Acc=0.0652\n",
      "[Pretrain] Epoch 3/75  Loss=2.7360  Acc=0.1413\n",
      "[Pretrain] Epoch 4/75  Loss=2.5550  Acc=0.1805\n",
      "[Pretrain] Epoch 5/75  Loss=2.4678  Acc=0.2144\n",
      "[Pretrain] Epoch 6/75  Loss=2.3889  Acc=0.2277\n",
      "[Pretrain] Epoch 7/75  Loss=2.3348  Acc=0.2452\n",
      "[Pretrain] Epoch 8/75  Loss=2.2690  Acc=0.2629\n",
      "[Pretrain] Epoch 9/75  Loss=2.2183  Acc=0.2777\n",
      "[Pretrain] Epoch 10/75  Loss=2.1759  Acc=0.2863\n",
      "[Pretrain] Epoch 11/75  Loss=2.1732  Acc=0.2917\n",
      "[Pretrain] Epoch 12/75  Loss=2.1620  Acc=0.2935\n",
      "[Pretrain] Epoch 13/75  Loss=2.1048  Acc=0.3111\n",
      "[Pretrain] Epoch 14/75  Loss=2.0985  Acc=0.3161\n",
      "[Pretrain] Epoch 15/75  Loss=2.0589  Acc=0.3245\n",
      "[Pretrain] Epoch 16/75  Loss=2.0347  Acc=0.3342\n",
      "[Pretrain] Epoch 17/75  Loss=2.0189  Acc=0.3394\n",
      "[Pretrain] Epoch 18/75  Loss=1.9769  Acc=0.3565\n",
      "[Pretrain] Epoch 19/75  Loss=1.9492  Acc=0.3597\n",
      "[Pretrain] Epoch 20/75  Loss=1.9422  Acc=0.3615\n",
      "[Pretrain] Epoch 21/75  Loss=1.9280  Acc=0.3700\n",
      "[Pretrain] Epoch 22/75  Loss=1.8748  Acc=0.3858\n",
      "[Pretrain] Epoch 23/75  Loss=1.8541  Acc=0.3885\n",
      "[Pretrain] Epoch 24/75  Loss=1.8146  Acc=0.4059\n",
      "[Pretrain] Epoch 25/75  Loss=1.8236  Acc=0.4028\n",
      "[Pretrain] Epoch 26/75  Loss=1.7907  Acc=0.4163\n",
      "[Pretrain] Epoch 27/75  Loss=1.7566  Acc=0.4269\n",
      "[Pretrain] Epoch 28/75  Loss=1.7288  Acc=0.4327\n",
      "[Pretrain] Epoch 29/75  Loss=1.7160  Acc=0.4388\n",
      "[Pretrain] Epoch 30/75  Loss=1.6892  Acc=0.4398\n",
      "[Pretrain] Epoch 31/75  Loss=1.6427  Acc=0.4648\n",
      "[Pretrain] Epoch 32/75  Loss=1.6292  Acc=0.4707\n",
      "[Pretrain] Epoch 33/75  Loss=1.6193  Acc=0.4727\n",
      "[Pretrain] Epoch 34/75  Loss=1.6041  Acc=0.4743\n",
      "[Pretrain] Epoch 35/75  Loss=1.5638  Acc=0.4867\n",
      "[Pretrain] Epoch 36/75  Loss=1.5489  Acc=0.4883\n",
      "[Pretrain] Epoch 37/75  Loss=1.5361  Acc=0.5063\n",
      "[Pretrain] Epoch 38/75  Loss=1.5211  Acc=0.5101\n",
      "[Pretrain] Epoch 39/75  Loss=1.4885  Acc=0.5135\n",
      "[Pretrain] Epoch 40/75  Loss=1.4742  Acc=0.5212\n",
      "[Pretrain] Epoch 41/75  Loss=1.4598  Acc=0.5158\n",
      "[Pretrain] Epoch 42/75  Loss=1.4283  Acc=0.5314\n",
      "[Pretrain] Epoch 43/75  Loss=1.4161  Acc=0.5359\n",
      "[Pretrain] Epoch 44/75  Loss=1.3956  Acc=0.5408\n",
      "[Pretrain] Epoch 45/75  Loss=1.3903  Acc=0.5386\n",
      "[Pretrain] Epoch 46/75  Loss=1.3849  Acc=0.5471\n",
      "[Pretrain] Epoch 47/75  Loss=1.3617  Acc=0.5481\n",
      "[Pretrain] Epoch 48/75  Loss=1.3556  Acc=0.5519\n",
      "[Pretrain] Epoch 49/75  Loss=1.3431  Acc=0.5550\n",
      "[Pretrain] Epoch 50/75  Loss=1.3044  Acc=0.5684\n",
      "[Pretrain] Epoch 51/75  Loss=1.3073  Acc=0.5713\n",
      "[Pretrain] Epoch 52/75  Loss=1.2989  Acc=0.5688\n",
      "[Pretrain] Epoch 53/75  Loss=1.2713  Acc=0.5808\n",
      "[Pretrain] Epoch 54/75  Loss=1.2657  Acc=0.5841\n",
      "[Pretrain] Epoch 55/75  Loss=1.2660  Acc=0.5815\n",
      "[Pretrain] Epoch 56/75  Loss=1.2554  Acc=0.5893\n",
      "[Pretrain] Epoch 57/75  Loss=1.2401  Acc=0.5934\n",
      "[Pretrain] Epoch 58/75  Loss=1.2300  Acc=0.5968\n",
      "[Pretrain] Epoch 59/75  Loss=1.2267  Acc=0.5972\n",
      "[Pretrain] Epoch 60/75  Loss=1.2202  Acc=0.5986\n",
      "[Pretrain] Epoch 61/75  Loss=1.2124  Acc=0.6033\n",
      "[Pretrain] Epoch 62/75  Loss=1.1975  Acc=0.6103\n",
      "[Pretrain] Epoch 63/75  Loss=1.1780  Acc=0.6114\n",
      "[Pretrain] Epoch 64/75  Loss=1.1915  Acc=0.6103\n",
      "[Pretrain] Epoch 65/75  Loss=1.1753  Acc=0.6092\n",
      "[Pretrain] Epoch 66/75  Loss=1.1871  Acc=0.6049\n",
      "[Pretrain] Epoch 67/75  Loss=1.1695  Acc=0.6078\n",
      "[Pretrain] Epoch 68/75  Loss=1.1897  Acc=0.6087\n",
      "[Pretrain] Epoch 69/75  Loss=1.1635  Acc=0.6142\n",
      "[Pretrain] Epoch 70/75  Loss=1.1517  Acc=0.6149\n",
      "[Pretrain] Epoch 71/75  Loss=1.1766  Acc=0.6135\n",
      "[Pretrain] Epoch 72/75  Loss=1.1608  Acc=0.6139\n",
      "[Pretrain] Epoch 73/75  Loss=1.1490  Acc=0.6202\n",
      "[Pretrain] Epoch 74/75  Loss=1.1563  Acc=0.6198\n",
      "[Pretrain] Epoch 75/75  Loss=1.1561  Acc=0.6169\n",
      "[Fine-tune] Epoch 1/150  Loss=3.1036\n",
      "[Fine-tune] Epoch 2/150  Loss=2.5794\n",
      "[Fine-tune] Epoch 3/150  Loss=2.3874\n",
      "[Fine-tune] Epoch 4/150  Loss=2.2653\n",
      "[Fine-tune] Epoch 5/150  Loss=2.1881\n",
      "[Fine-tune] Epoch 6/150  Loss=2.1286\n",
      "[Fine-tune] Epoch 7/150  Loss=2.0861\n",
      "[Fine-tune] Epoch 8/150  Loss=2.0549\n",
      "[Fine-tune] Epoch 9/150  Loss=2.0208\n",
      "[Fine-tune] Epoch 10/150  Loss=2.0036\n",
      "[Fine-tune] Epoch 11/150  Loss=1.9802\n",
      "[Fine-tune] Epoch 12/150  Loss=1.9683\n",
      "[Fine-tune] Epoch 13/150  Loss=1.9362\n",
      "[Fine-tune] Epoch 14/150  Loss=1.9275\n",
      "[Fine-tune] Epoch 15/150  Loss=1.9014\n",
      "[Fine-tune] Epoch 16/150  Loss=1.8962\n",
      "[Fine-tune] Epoch 17/150  Loss=1.8707\n",
      "[Fine-tune] Epoch 18/150  Loss=1.8644\n",
      "[Fine-tune] Epoch 19/150  Loss=1.8506\n",
      "[Fine-tune] Epoch 20/150  Loss=1.8446\n",
      "[Fine-tune] Epoch 21/150  Loss=1.8286\n",
      "[Fine-tune] Epoch 22/150  Loss=1.8122\n",
      "[Fine-tune] Epoch 23/150  Loss=1.8046\n",
      "[Fine-tune] Epoch 24/150  Loss=1.8026\n",
      "[Fine-tune] Epoch 25/150  Loss=1.7881\n",
      "[Fine-tune] Epoch 26/150  Loss=1.7880\n",
      "[Fine-tune] Epoch 27/150  Loss=1.7678\n",
      "[Fine-tune] Epoch 28/150  Loss=1.7584\n",
      "[Fine-tune] Epoch 29/150  Loss=1.7732\n",
      "[Fine-tune] Epoch 30/150  Loss=1.7617\n",
      "[Fine-tune] Epoch 31/150  Loss=1.7509\n",
      "[Fine-tune] Epoch 32/150  Loss=1.7435\n",
      "[Fine-tune] Epoch 33/150  Loss=1.7304\n",
      "[Fine-tune] Epoch 34/150  Loss=1.7263\n",
      "[Fine-tune] Epoch 35/150  Loss=1.7282\n",
      "[Fine-tune] Epoch 36/150  Loss=1.7212\n",
      "[Fine-tune] Epoch 37/150  Loss=1.7182\n",
      "[Fine-tune] Epoch 38/150  Loss=1.7106\n",
      "[Fine-tune] Epoch 39/150  Loss=1.7216\n",
      "[Fine-tune] Epoch 40/150  Loss=1.7138\n",
      "[Fine-tune] Epoch 41/150  Loss=1.7046\n",
      "[Fine-tune] Epoch 42/150  Loss=1.6996\n",
      "[Fine-tune] Epoch 43/150  Loss=1.6941\n",
      "[Fine-tune] Epoch 44/150  Loss=1.6911\n",
      "[Fine-tune] Epoch 45/150  Loss=1.6841\n",
      "[Fine-tune] Epoch 46/150  Loss=1.6852\n",
      "[Fine-tune] Epoch 47/150  Loss=1.6857\n",
      "[Fine-tune] Epoch 48/150  Loss=1.6958\n",
      "[Fine-tune] Epoch 49/150  Loss=1.6784\n",
      "[Fine-tune] Epoch 50/150  Loss=1.6736\n",
      "[Fine-tune] Epoch 51/150  Loss=1.6872\n",
      "[Fine-tune] Epoch 52/150  Loss=1.6739\n",
      "[Fine-tune] Epoch 53/150  Loss=1.6719\n",
      "[Fine-tune] Epoch 54/150  Loss=1.6770\n",
      "[Fine-tune] Epoch 55/150  Loss=1.6634\n",
      "[Fine-tune] Epoch 56/150  Loss=1.6702\n",
      "[Fine-tune] Epoch 57/150  Loss=1.6828\n",
      "[Fine-tune] Epoch 58/150  Loss=1.6646\n",
      "[Fine-tune] Epoch 59/150  Loss=1.6630\n",
      "[Fine-tune] Epoch 60/150  Loss=1.6627\n",
      "[Fine-tune] Epoch 61/150  Loss=1.6722\n",
      "[Fine-tune] Epoch 62/150  Loss=1.6503\n",
      "[Fine-tune] Epoch 63/150  Loss=1.6443\n",
      "[Fine-tune] Epoch 64/150  Loss=1.6758\n",
      "[Fine-tune] Epoch 65/150  Loss=1.6473\n",
      "[Fine-tune] Epoch 66/150  Loss=1.6499\n",
      "[Fine-tune] Epoch 67/150  Loss=1.6580\n",
      "[Fine-tune] Epoch 68/150  Loss=1.6523\n",
      "[Fine-tune] Epoch 69/150  Loss=1.6543\n",
      "[Fine-tune] Epoch 70/150  Loss=1.6540\n",
      "[Fine-tune] Epoch 71/150  Loss=1.6615\n",
      "[Fine-tune] Epoch 72/150  Loss=1.6499\n",
      "[Fine-tune] Epoch 73/150  Loss=1.6581\n",
      "[Fine-tune] Epoch 74/150  Loss=1.6462\n",
      "[Fine-tune] Epoch 75/150  Loss=1.6416\n",
      "[Fine-tune] Epoch 76/150  Loss=1.6493\n",
      "[Fine-tune] Epoch 77/150  Loss=1.6444\n",
      "[Fine-tune] Epoch 78/150  Loss=1.6439\n",
      "[Fine-tune] Epoch 79/150  Loss=1.6556\n",
      "[Fine-tune] Epoch 80/150  Loss=1.6474\n",
      "[Fine-tune] Epoch 81/150  Loss=1.6415\n",
      "[Fine-tune] Epoch 82/150  Loss=1.6404\n",
      "[Fine-tune] Epoch 83/150  Loss=1.6348\n",
      "[Fine-tune] Epoch 84/150  Loss=1.6408\n",
      "[Fine-tune] Epoch 85/150  Loss=1.6432\n",
      "[Fine-tune] Epoch 86/150  Loss=1.6327\n",
      "[Fine-tune] Epoch 87/150  Loss=1.6447\n",
      "[Fine-tune] Epoch 88/150  Loss=1.6416\n",
      "[Fine-tune] Epoch 89/150  Loss=1.6269\n",
      "[Fine-tune] Epoch 90/150  Loss=1.6370\n",
      "[Fine-tune] Epoch 91/150  Loss=1.6346\n",
      "[Fine-tune] Epoch 92/150  Loss=1.6449\n",
      "[Fine-tune] Epoch 93/150  Loss=1.6357\n",
      "[Fine-tune] Epoch 94/150  Loss=1.6393\n",
      "[Fine-tune] Epoch 95/150  Loss=1.6454\n",
      "[Fine-tune] Epoch 96/150  Loss=1.6390\n",
      "[Fine-tune] Epoch 97/150  Loss=1.6582\n",
      "[Fine-tune] Epoch 98/150  Loss=1.6328\n",
      "[Fine-tune] Epoch 99/150  Loss=1.6468\n",
      "[Fine-tune] Epoch 100/150  Loss=1.6427\n",
      "[Fine-tune] Epoch 101/150  Loss=1.6401\n",
      "[Fine-tune] Epoch 102/150  Loss=1.6387\n",
      "[Fine-tune] Epoch 103/150  Loss=1.6478\n",
      "[Fine-tune] Epoch 104/150  Loss=1.6371\n",
      "[Fine-tune] Epoch 105/150  Loss=1.6470\n",
      "[Fine-tune] Epoch 106/150  Loss=1.6338\n",
      "[Fine-tune] Epoch 107/150  Loss=1.6444\n",
      "[Fine-tune] Epoch 108/150  Loss=1.6505\n",
      "[Fine-tune] Epoch 109/150  Loss=1.6349\n",
      "[Fine-tune] Epoch 110/150  Loss=1.6328\n",
      "[Fine-tune] Epoch 111/150  Loss=1.6412\n",
      "[Fine-tune] Epoch 112/150  Loss=1.6456\n",
      "[Fine-tune] Epoch 113/150  Loss=1.6428\n",
      "[Fine-tune] Epoch 114/150  Loss=1.6432\n",
      "[Fine-tune] Epoch 115/150  Loss=1.6370\n",
      "[Fine-tune] Epoch 116/150  Loss=1.6383\n",
      "[Fine-tune] Epoch 117/150  Loss=1.6316\n",
      "[Fine-tune] Epoch 118/150  Loss=1.6386\n",
      "[Fine-tune] Epoch 119/150  Loss=1.6431\n",
      "[Fine-tune] Epoch 120/150  Loss=1.6286\n",
      "[Fine-tune] Epoch 121/150  Loss=1.6441\n",
      "[Fine-tune] Epoch 122/150  Loss=1.6339\n",
      "[Fine-tune] Epoch 123/150  Loss=1.6395\n",
      "[Fine-tune] Epoch 124/150  Loss=1.6367\n",
      "[Fine-tune] Epoch 125/150  Loss=1.6401\n",
      "[Fine-tune] Epoch 126/150  Loss=1.6386\n",
      "[Fine-tune] Epoch 127/150  Loss=1.6415\n",
      "[Fine-tune] Epoch 128/150  Loss=1.6340\n",
      "[Fine-tune] Epoch 129/150  Loss=1.6515\n",
      "[Fine-tune] Epoch 130/150  Loss=1.6434\n",
      "[Fine-tune] Epoch 131/150  Loss=1.6316\n",
      "[Fine-tune] Epoch 132/150  Loss=1.6438\n",
      "[Fine-tune] Epoch 133/150  Loss=1.6427\n",
      "[Fine-tune] Epoch 134/150  Loss=1.6322\n",
      "[Fine-tune] Epoch 135/150  Loss=1.6262\n",
      "[Fine-tune] Epoch 136/150  Loss=1.6275\n",
      "[Fine-tune] Epoch 137/150  Loss=1.6264\n",
      "[Fine-tune] Epoch 138/150  Loss=1.6334\n",
      "[Fine-tune] Epoch 139/150  Loss=1.6463\n",
      "[Fine-tune] Epoch 140/150  Loss=1.6446\n",
      "[Fine-tune] Epoch 141/150  Loss=1.6447\n",
      "[Fine-tune] Epoch 142/150  Loss=1.6393\n",
      "[Fine-tune] Epoch 143/150  Loss=1.6374\n",
      "[Fine-tune] Epoch 144/150  Loss=1.6345\n",
      "[Fine-tune] Epoch 145/150  Loss=1.6413\n",
      "[Fine-tune] Epoch 146/150  Loss=1.6382\n",
      "[Fine-tune] Epoch 147/150  Loss=1.6516\n",
      "[Fine-tune] Epoch 148/150  Loss=1.6363\n",
      "[Fine-tune] Epoch 149/150  Loss=1.6320\n",
      "[Fine-tune] Epoch 150/150  Loss=1.6327\n",
      "[Pretrain] Epoch 1/100  Loss=3.1984  Acc=0.0537\n",
      "[Pretrain] Epoch 2/100  Loss=2.8464  Acc=0.1160\n",
      "[Pretrain] Epoch 3/100  Loss=2.6340  Acc=0.1624\n",
      "[Pretrain] Epoch 4/100  Loss=2.5308  Acc=0.1891\n",
      "[Pretrain] Epoch 5/100  Loss=2.4246  Acc=0.2205\n",
      "[Pretrain] Epoch 6/100  Loss=2.3713  Acc=0.2419\n",
      "[Pretrain] Epoch 7/100  Loss=2.2769  Acc=0.2674\n",
      "[Pretrain] Epoch 8/100  Loss=2.1763  Acc=0.2938\n",
      "[Pretrain] Epoch 9/100  Loss=2.1425  Acc=0.3032\n",
      "[Pretrain] Epoch 10/100  Loss=2.0926  Acc=0.3253\n",
      "[Pretrain] Epoch 11/100  Loss=2.0672  Acc=0.3281\n",
      "[Pretrain] Epoch 12/100  Loss=2.0301  Acc=0.3288\n",
      "[Pretrain] Epoch 13/100  Loss=1.9860  Acc=0.3533\n",
      "[Pretrain] Epoch 14/100  Loss=1.9765  Acc=0.3626\n",
      "[Pretrain] Epoch 15/100  Loss=1.9366  Acc=0.3719\n",
      "[Pretrain] Epoch 16/100  Loss=1.8948  Acc=0.3901\n",
      "[Pretrain] Epoch 17/100  Loss=1.8959  Acc=0.3809\n",
      "[Pretrain] Epoch 18/100  Loss=1.8491  Acc=0.3957\n",
      "[Pretrain] Epoch 19/100  Loss=1.8255  Acc=0.4088\n",
      "[Pretrain] Epoch 20/100  Loss=1.8253  Acc=0.4142\n",
      "[Pretrain] Epoch 21/100  Loss=1.7933  Acc=0.4158\n",
      "[Pretrain] Epoch 22/100  Loss=1.7555  Acc=0.4307\n",
      "[Pretrain] Epoch 23/100  Loss=1.7475  Acc=0.4341\n",
      "[Pretrain] Epoch 24/100  Loss=1.7205  Acc=0.4450\n",
      "[Pretrain] Epoch 25/100  Loss=1.7049  Acc=0.4544\n",
      "[Pretrain] Epoch 26/100  Loss=1.6745  Acc=0.4608\n",
      "[Pretrain] Epoch 27/100  Loss=1.6984  Acc=0.4515\n",
      "[Pretrain] Epoch 28/100  Loss=1.6578  Acc=0.4679\n",
      "[Pretrain] Epoch 29/100  Loss=1.6517  Acc=0.4675\n",
      "[Pretrain] Epoch 30/100  Loss=1.6229  Acc=0.4679\n",
      "[Pretrain] Epoch 31/100  Loss=1.6032  Acc=0.4815\n",
      "[Pretrain] Epoch 32/100  Loss=1.5973  Acc=0.4844\n",
      "[Pretrain] Epoch 33/100  Loss=1.5822  Acc=0.4837\n",
      "[Pretrain] Epoch 34/100  Loss=1.5671  Acc=0.4894\n",
      "[Pretrain] Epoch 35/100  Loss=1.5361  Acc=0.5011\n",
      "[Pretrain] Epoch 36/100  Loss=1.5424  Acc=0.4998\n",
      "[Pretrain] Epoch 37/100  Loss=1.5174  Acc=0.5081\n",
      "[Pretrain] Epoch 38/100  Loss=1.5077  Acc=0.5131\n",
      "[Pretrain] Epoch 39/100  Loss=1.5035  Acc=0.5136\n",
      "[Pretrain] Epoch 40/100  Loss=1.5035  Acc=0.5057\n",
      "[Pretrain] Epoch 41/100  Loss=1.4767  Acc=0.5221\n",
      "[Pretrain] Epoch 42/100  Loss=1.4608  Acc=0.5190\n",
      "[Pretrain] Epoch 43/100  Loss=1.4661  Acc=0.5293\n",
      "[Pretrain] Epoch 44/100  Loss=1.4373  Acc=0.5311\n",
      "[Pretrain] Epoch 45/100  Loss=1.4470  Acc=0.5390\n",
      "[Pretrain] Epoch 46/100  Loss=1.4346  Acc=0.5293\n",
      "[Pretrain] Epoch 47/100  Loss=1.4269  Acc=0.5300\n",
      "[Pretrain] Epoch 48/100  Loss=1.4129  Acc=0.5363\n",
      "[Pretrain] Epoch 49/100  Loss=1.4071  Acc=0.5401\n",
      "[Pretrain] Epoch 50/100  Loss=1.4150  Acc=0.5374\n",
      "[Pretrain] Epoch 51/100  Loss=1.3968  Acc=0.5413\n",
      "[Pretrain] Epoch 52/100  Loss=1.3836  Acc=0.5499\n",
      "[Pretrain] Epoch 53/100  Loss=1.3763  Acc=0.5496\n",
      "[Pretrain] Epoch 54/100  Loss=1.3921  Acc=0.5528\n",
      "[Pretrain] Epoch 55/100  Loss=1.3741  Acc=0.5571\n",
      "[Pretrain] Epoch 56/100  Loss=1.3752  Acc=0.5501\n",
      "[Pretrain] Epoch 57/100  Loss=1.3605  Acc=0.5607\n",
      "[Pretrain] Epoch 58/100  Loss=1.3538  Acc=0.5580\n",
      "[Pretrain] Epoch 59/100  Loss=1.3703  Acc=0.5501\n",
      "[Pretrain] Epoch 60/100  Loss=1.3503  Acc=0.5630\n",
      "[Pretrain] Epoch 61/100  Loss=1.3458  Acc=0.5577\n",
      "[Pretrain] Epoch 62/100  Loss=1.3505  Acc=0.5639\n",
      "[Pretrain] Epoch 63/100  Loss=1.3463  Acc=0.5614\n",
      "[Pretrain] Epoch 64/100  Loss=1.3274  Acc=0.5718\n",
      "[Pretrain] Epoch 65/100  Loss=1.3423  Acc=0.5704\n",
      "[Pretrain] Epoch 66/100  Loss=1.3322  Acc=0.5697\n",
      "[Pretrain] Epoch 67/100  Loss=1.3267  Acc=0.5690\n",
      "[Pretrain] Epoch 68/100  Loss=1.3383  Acc=0.5607\n",
      "[Pretrain] Epoch 69/100  Loss=1.3305  Acc=0.5718\n",
      "[Pretrain] Epoch 70/100  Loss=1.3231  Acc=0.5688\n",
      "[Pretrain] Epoch 71/100  Loss=1.3139  Acc=0.5770\n",
      "[Pretrain] Epoch 72/100  Loss=1.3174  Acc=0.5727\n",
      "[Pretrain] Epoch 73/100  Loss=1.3283  Acc=0.5686\n",
      "[Pretrain] Epoch 74/100  Loss=1.3062  Acc=0.5717\n",
      "[Pretrain] Epoch 75/100  Loss=1.3108  Acc=0.5826\n",
      "[Pretrain] Epoch 76/100  Loss=1.3067  Acc=0.5756\n",
      "[Pretrain] Epoch 77/100  Loss=1.2953  Acc=0.5776\n",
      "[Pretrain] Epoch 78/100  Loss=1.2971  Acc=0.5729\n",
      "[Pretrain] Epoch 79/100  Loss=1.3060  Acc=0.5745\n",
      "[Pretrain] Epoch 80/100  Loss=1.3051  Acc=0.5805\n",
      "[Pretrain] Epoch 81/100  Loss=1.2982  Acc=0.5785\n",
      "[Pretrain] Epoch 82/100  Loss=1.3050  Acc=0.5781\n",
      "[Pretrain] Epoch 83/100  Loss=1.3052  Acc=0.5842\n",
      "[Pretrain] Epoch 84/100  Loss=1.2967  Acc=0.5763\n",
      "[Pretrain] Epoch 85/100  Loss=1.2892  Acc=0.5849\n",
      "[Pretrain] Epoch 86/100  Loss=1.2927  Acc=0.5812\n",
      "[Pretrain] Epoch 87/100  Loss=1.3000  Acc=0.5945\n",
      "[Pretrain] Epoch 88/100  Loss=1.2875  Acc=0.5819\n",
      "[Pretrain] Epoch 89/100  Loss=1.2918  Acc=0.5792\n",
      "[Pretrain] Epoch 90/100  Loss=1.2873  Acc=0.5867\n",
      "[Pretrain] Epoch 91/100  Loss=1.2757  Acc=0.5869\n",
      "[Pretrain] Epoch 92/100  Loss=1.2843  Acc=0.5844\n",
      "[Pretrain] Epoch 93/100  Loss=1.2848  Acc=0.5779\n",
      "[Pretrain] Epoch 94/100  Loss=1.2791  Acc=0.5948\n",
      "[Pretrain] Epoch 95/100  Loss=1.2854  Acc=0.5810\n",
      "[Pretrain] Epoch 96/100  Loss=1.2858  Acc=0.5812\n",
      "[Pretrain] Epoch 97/100  Loss=1.2959  Acc=0.5740\n",
      "[Pretrain] Epoch 98/100  Loss=1.2904  Acc=0.5803\n",
      "[Pretrain] Epoch 99/100  Loss=1.2904  Acc=0.5761\n",
      "[Pretrain] Epoch 100/100  Loss=1.2896  Acc=0.5835\n",
      "[Fine-tune] Epoch 1/150  Loss=2.7040\n",
      "[Fine-tune] Epoch 2/150  Loss=2.2621\n",
      "[Fine-tune] Epoch 3/150  Loss=2.0580\n",
      "[Fine-tune] Epoch 4/150  Loss=2.0163\n",
      "[Fine-tune] Epoch 5/150  Loss=1.9166\n",
      "[Fine-tune] Epoch 6/150  Loss=1.8300\n",
      "[Fine-tune] Epoch 7/150  Loss=1.7879\n",
      "[Fine-tune] Epoch 8/150  Loss=1.7555\n",
      "[Fine-tune] Epoch 9/150  Loss=1.7055\n",
      "[Fine-tune] Epoch 10/150  Loss=1.6562\n",
      "[Fine-tune] Epoch 11/150  Loss=1.6169\n",
      "[Fine-tune] Epoch 12/150  Loss=1.5970\n",
      "[Fine-tune] Epoch 13/150  Loss=1.5478\n",
      "[Fine-tune] Epoch 14/150  Loss=1.4959\n",
      "[Fine-tune] Epoch 15/150  Loss=1.4754\n",
      "[Fine-tune] Epoch 16/150  Loss=1.4334\n",
      "[Fine-tune] Epoch 17/150  Loss=1.4317\n",
      "[Fine-tune] Epoch 18/150  Loss=1.3960\n",
      "[Fine-tune] Epoch 19/150  Loss=1.3497\n",
      "[Fine-tune] Epoch 20/150  Loss=1.3317\n",
      "[Fine-tune] Epoch 21/150  Loss=1.3228\n",
      "[Fine-tune] Epoch 22/150  Loss=1.3000\n",
      "[Fine-tune] Epoch 23/150  Loss=1.2654\n",
      "[Fine-tune] Epoch 24/150  Loss=1.2376\n",
      "[Fine-tune] Epoch 25/150  Loss=1.2328\n",
      "[Fine-tune] Epoch 26/150  Loss=1.2172\n",
      "[Fine-tune] Epoch 27/150  Loss=1.1998\n",
      "[Fine-tune] Epoch 28/150  Loss=1.1726\n",
      "[Fine-tune] Epoch 29/150  Loss=1.1633\n",
      "[Fine-tune] Epoch 30/150  Loss=1.1525\n",
      "[Fine-tune] Epoch 31/150  Loss=1.1489\n",
      "[Fine-tune] Epoch 32/150  Loss=1.1170\n",
      "[Fine-tune] Epoch 33/150  Loss=1.0951\n",
      "[Fine-tune] Epoch 34/150  Loss=1.0980\n",
      "[Fine-tune] Epoch 35/150  Loss=1.0770\n",
      "[Fine-tune] Epoch 36/150  Loss=1.0609\n",
      "[Fine-tune] Epoch 37/150  Loss=1.0499\n",
      "[Fine-tune] Epoch 38/150  Loss=1.0403\n",
      "[Fine-tune] Epoch 39/150  Loss=1.0428\n",
      "[Fine-tune] Epoch 40/150  Loss=1.0369\n",
      "[Fine-tune] Epoch 41/150  Loss=1.0297\n",
      "[Fine-tune] Epoch 42/150  Loss=1.0267\n",
      "[Fine-tune] Epoch 43/150  Loss=1.0286\n",
      "[Fine-tune] Epoch 44/150  Loss=0.9962\n",
      "[Fine-tune] Epoch 45/150  Loss=1.0140\n",
      "[Fine-tune] Epoch 46/150  Loss=0.9978\n",
      "[Fine-tune] Epoch 47/150  Loss=0.9823\n",
      "[Fine-tune] Epoch 48/150  Loss=0.9760\n",
      "[Fine-tune] Epoch 49/150  Loss=0.9681\n",
      "[Fine-tune] Epoch 50/150  Loss=0.9619\n",
      "[Fine-tune] Epoch 51/150  Loss=0.9914\n",
      "[Fine-tune] Epoch 52/150  Loss=0.9593\n",
      "[Fine-tune] Epoch 53/150  Loss=0.9479\n",
      "[Fine-tune] Epoch 54/150  Loss=0.9591\n",
      "[Fine-tune] Epoch 55/150  Loss=0.9524\n",
      "[Fine-tune] Epoch 56/150  Loss=0.9424\n",
      "[Fine-tune] Epoch 57/150  Loss=0.9468\n",
      "[Fine-tune] Epoch 58/150  Loss=0.9461\n",
      "[Fine-tune] Epoch 59/150  Loss=0.9295\n",
      "[Fine-tune] Epoch 60/150  Loss=0.9403\n",
      "[Fine-tune] Epoch 61/150  Loss=0.9335\n",
      "[Fine-tune] Epoch 62/150  Loss=0.9429\n",
      "[Fine-tune] Epoch 63/150  Loss=0.9137\n",
      "[Fine-tune] Epoch 64/150  Loss=0.9110\n",
      "[Fine-tune] Epoch 65/150  Loss=0.9134\n",
      "[Fine-tune] Epoch 66/150  Loss=0.9240\n",
      "[Fine-tune] Epoch 67/150  Loss=0.9238\n",
      "[Fine-tune] Epoch 68/150  Loss=0.9229\n",
      "[Fine-tune] Epoch 69/150  Loss=0.9383\n",
      "[Fine-tune] Epoch 70/150  Loss=0.9156\n",
      "[Fine-tune] Epoch 71/150  Loss=0.9221\n",
      "[Fine-tune] Epoch 72/150  Loss=0.9049\n",
      "[Fine-tune] Epoch 73/150  Loss=0.9059\n",
      "[Fine-tune] Epoch 74/150  Loss=0.9016\n",
      "[Fine-tune] Epoch 75/150  Loss=0.9180\n",
      "[Fine-tune] Epoch 76/150  Loss=0.9260\n",
      "[Fine-tune] Epoch 77/150  Loss=0.9048\n",
      "[Fine-tune] Epoch 78/150  Loss=0.9137\n",
      "[Fine-tune] Epoch 79/150  Loss=0.8931\n",
      "[Fine-tune] Epoch 80/150  Loss=0.8902\n",
      "[Fine-tune] Epoch 81/150  Loss=0.8994\n",
      "[Fine-tune] Epoch 82/150  Loss=0.9027\n",
      "[Fine-tune] Epoch 83/150  Loss=0.9021\n",
      "[Fine-tune] Epoch 84/150  Loss=0.8845\n",
      "[Fine-tune] Epoch 85/150  Loss=0.8938\n",
      "[Fine-tune] Epoch 86/150  Loss=0.8933\n",
      "[Fine-tune] Epoch 87/150  Loss=0.9024\n",
      "[Fine-tune] Epoch 88/150  Loss=0.8889\n",
      "[Fine-tune] Epoch 89/150  Loss=0.9030\n",
      "[Fine-tune] Epoch 90/150  Loss=0.9068\n",
      "[Fine-tune] Epoch 91/150  Loss=0.8989\n",
      "[Fine-tune] Epoch 92/150  Loss=0.8984\n",
      "[Fine-tune] Epoch 93/150  Loss=0.8941\n",
      "[Fine-tune] Epoch 94/150  Loss=0.8902\n",
      "[Fine-tune] Epoch 95/150  Loss=0.8840\n",
      "[Fine-tune] Epoch 96/150  Loss=0.8885\n",
      "[Fine-tune] Epoch 97/150  Loss=0.8928\n",
      "[Fine-tune] Epoch 98/150  Loss=0.8951\n",
      "[Fine-tune] Epoch 99/150  Loss=0.8760\n",
      "[Fine-tune] Epoch 100/150  Loss=0.8924\n",
      "[Fine-tune] Epoch 101/150  Loss=0.8987\n",
      "[Fine-tune] Epoch 102/150  Loss=0.8862\n",
      "[Fine-tune] Epoch 103/150  Loss=0.8894\n",
      "[Fine-tune] Epoch 104/150  Loss=0.8901\n",
      "[Fine-tune] Epoch 105/150  Loss=0.8820\n",
      "[Fine-tune] Epoch 106/150  Loss=0.8897\n",
      "[Fine-tune] Epoch 107/150  Loss=0.8888\n",
      "[Fine-tune] Epoch 108/150  Loss=0.8832\n",
      "[Fine-tune] Epoch 109/150  Loss=0.8916\n",
      "[Fine-tune] Epoch 110/150  Loss=0.8848\n",
      "[Fine-tune] Epoch 111/150  Loss=0.8944\n",
      "[Fine-tune] Epoch 112/150  Loss=0.8895\n",
      "[Fine-tune] Epoch 113/150  Loss=0.8799\n",
      "[Fine-tune] Epoch 114/150  Loss=0.8872\n",
      "[Fine-tune] Epoch 115/150  Loss=0.8929\n",
      "[Fine-tune] Epoch 116/150  Loss=0.8872\n",
      "[Fine-tune] Epoch 117/150  Loss=0.8870\n",
      "[Fine-tune] Epoch 118/150  Loss=0.8726\n",
      "[Fine-tune] Epoch 119/150  Loss=0.8889\n",
      "[Fine-tune] Epoch 120/150  Loss=0.8789\n",
      "[Fine-tune] Epoch 121/150  Loss=0.8817\n",
      "[Fine-tune] Epoch 122/150  Loss=0.8895\n",
      "[Fine-tune] Epoch 123/150  Loss=0.8798\n",
      "[Fine-tune] Epoch 124/150  Loss=0.8942\n",
      "[Fine-tune] Epoch 125/150  Loss=0.8832\n",
      "[Fine-tune] Epoch 126/150  Loss=0.8765\n",
      "[Fine-tune] Epoch 127/150  Loss=0.8717\n",
      "[Fine-tune] Epoch 128/150  Loss=0.8926\n",
      "[Fine-tune] Epoch 129/150  Loss=0.8752\n",
      "[Fine-tune] Epoch 130/150  Loss=0.8866\n",
      "[Fine-tune] Epoch 131/150  Loss=0.8790\n",
      "[Fine-tune] Epoch 132/150  Loss=0.8817\n",
      "[Fine-tune] Epoch 133/150  Loss=0.8833\n",
      "[Fine-tune] Epoch 134/150  Loss=0.8983\n",
      "[Fine-tune] Epoch 135/150  Loss=0.8789\n",
      "[Fine-tune] Epoch 136/150  Loss=0.8859\n",
      "[Fine-tune] Epoch 137/150  Loss=0.8785\n",
      "[Fine-tune] Epoch 138/150  Loss=0.8821\n",
      "[Fine-tune] Epoch 139/150  Loss=0.8790\n",
      "[Fine-tune] Epoch 140/150  Loss=0.8952\n",
      "[Fine-tune] Epoch 141/150  Loss=0.8840\n",
      "[Fine-tune] Epoch 142/150  Loss=0.8858\n",
      "[Fine-tune] Epoch 143/150  Loss=0.8801\n",
      "[Fine-tune] Epoch 144/150  Loss=0.8935\n",
      "[Fine-tune] Epoch 145/150  Loss=0.8905\n",
      "[Fine-tune] Epoch 146/150  Loss=0.8755\n",
      "[Fine-tune] Epoch 147/150  Loss=0.8704\n",
      "[Fine-tune] Epoch 148/150  Loss=0.8925\n",
      "[Fine-tune] Epoch 149/150  Loss=0.8973\n",
      "[Fine-tune] Epoch 150/150  Loss=0.8826\n",
      "[Pretrain] Epoch 1/100  Loss=3.7778  Acc=0.0417\n",
      "[Pretrain] Epoch 2/100  Loss=3.2175  Acc=0.0408\n",
      "[Pretrain] Epoch 3/100  Loss=2.9548  Acc=0.0900\n",
      "[Pretrain] Epoch 4/100  Loss=2.7203  Acc=0.1473\n",
      "[Pretrain] Epoch 5/100  Loss=2.5912  Acc=0.1756\n",
      "[Pretrain] Epoch 6/100  Loss=2.5046  Acc=0.1925\n",
      "[Pretrain] Epoch 7/100  Loss=2.4144  Acc=0.2184\n",
      "[Pretrain] Epoch 8/100  Loss=2.3257  Acc=0.2610\n",
      "[Pretrain] Epoch 9/100  Loss=2.2654  Acc=0.2619\n",
      "[Pretrain] Epoch 10/100  Loss=2.2230  Acc=0.2820\n",
      "[Pretrain] Epoch 11/100  Loss=2.1914  Acc=0.2953\n",
      "[Pretrain] Epoch 12/100  Loss=2.1291  Acc=0.3089\n",
      "[Pretrain] Epoch 13/100  Loss=2.0993  Acc=0.3206\n",
      "[Pretrain] Epoch 14/100  Loss=2.0866  Acc=0.3315\n",
      "[Pretrain] Epoch 15/100  Loss=2.0380  Acc=0.3346\n",
      "[Pretrain] Epoch 16/100  Loss=2.0172  Acc=0.3464\n",
      "[Pretrain] Epoch 17/100  Loss=2.0061  Acc=0.3457\n",
      "[Pretrain] Epoch 18/100  Loss=1.9457  Acc=0.3649\n",
      "[Pretrain] Epoch 19/100  Loss=1.9230  Acc=0.3791\n",
      "[Pretrain] Epoch 20/100  Loss=1.9172  Acc=0.3743\n",
      "[Pretrain] Epoch 21/100  Loss=1.8701  Acc=0.3899\n",
      "[Pretrain] Epoch 22/100  Loss=1.8482  Acc=0.3976\n",
      "[Pretrain] Epoch 23/100  Loss=1.8640  Acc=0.3944\n",
      "[Pretrain] Epoch 24/100  Loss=1.8179  Acc=0.4082\n",
      "[Pretrain] Epoch 25/100  Loss=1.8114  Acc=0.4037\n",
      "[Pretrain] Epoch 26/100  Loss=1.7703  Acc=0.4158\n",
      "[Pretrain] Epoch 27/100  Loss=1.7536  Acc=0.4344\n",
      "[Pretrain] Epoch 28/100  Loss=1.7284  Acc=0.4318\n",
      "[Pretrain] Epoch 29/100  Loss=1.6972  Acc=0.4407\n",
      "[Pretrain] Epoch 30/100  Loss=1.6909  Acc=0.4449\n",
      "[Pretrain] Epoch 31/100  Loss=1.6775  Acc=0.4490\n",
      "[Pretrain] Epoch 32/100  Loss=1.6448  Acc=0.4632\n",
      "[Pretrain] Epoch 33/100  Loss=1.6455  Acc=0.4662\n",
      "[Pretrain] Epoch 34/100  Loss=1.6047  Acc=0.4736\n",
      "[Pretrain] Epoch 35/100  Loss=1.5750  Acc=0.4797\n",
      "[Pretrain] Epoch 36/100  Loss=1.5715  Acc=0.4878\n",
      "[Pretrain] Epoch 37/100  Loss=1.5534  Acc=0.4889\n",
      "[Pretrain] Epoch 38/100  Loss=1.5392  Acc=0.4946\n",
      "[Pretrain] Epoch 39/100  Loss=1.5090  Acc=0.5048\n",
      "[Pretrain] Epoch 40/100  Loss=1.5145  Acc=0.5014\n",
      "[Pretrain] Epoch 41/100  Loss=1.4691  Acc=0.5223\n",
      "[Pretrain] Epoch 42/100  Loss=1.4636  Acc=0.5201\n",
      "[Pretrain] Epoch 43/100  Loss=1.4651  Acc=0.5214\n",
      "[Pretrain] Epoch 44/100  Loss=1.4223  Acc=0.5341\n",
      "[Pretrain] Epoch 45/100  Loss=1.4051  Acc=0.5422\n",
      "[Pretrain] Epoch 46/100  Loss=1.3991  Acc=0.5462\n",
      "[Pretrain] Epoch 47/100  Loss=1.3933  Acc=0.5375\n",
      "[Pretrain] Epoch 48/100  Loss=1.3791  Acc=0.5440\n",
      "[Pretrain] Epoch 49/100  Loss=1.3712  Acc=0.5481\n",
      "[Pretrain] Epoch 50/100  Loss=1.3348  Acc=0.5562\n",
      "[Pretrain] Epoch 51/100  Loss=1.3411  Acc=0.5602\n",
      "[Pretrain] Epoch 52/100  Loss=1.3040  Acc=0.5695\n",
      "[Pretrain] Epoch 53/100  Loss=1.3114  Acc=0.5729\n",
      "[Pretrain] Epoch 54/100  Loss=1.3145  Acc=0.5672\n",
      "[Pretrain] Epoch 55/100  Loss=1.2953  Acc=0.5781\n",
      "[Pretrain] Epoch 56/100  Loss=1.2856  Acc=0.5717\n",
      "[Pretrain] Epoch 57/100  Loss=1.2678  Acc=0.5787\n",
      "[Pretrain] Epoch 58/100  Loss=1.2788  Acc=0.5745\n",
      "[Pretrain] Epoch 59/100  Loss=1.2692  Acc=0.5797\n",
      "[Pretrain] Epoch 60/100  Loss=1.2672  Acc=0.5857\n",
      "[Pretrain] Epoch 61/100  Loss=1.2533  Acc=0.5905\n",
      "[Pretrain] Epoch 62/100  Loss=1.2431  Acc=0.5929\n",
      "[Pretrain] Epoch 63/100  Loss=1.2282  Acc=0.6011\n",
      "[Pretrain] Epoch 64/100  Loss=1.2358  Acc=0.5981\n",
      "[Pretrain] Epoch 65/100  Loss=1.2242  Acc=0.6022\n",
      "[Pretrain] Epoch 66/100  Loss=1.2139  Acc=0.6026\n",
      "[Pretrain] Epoch 67/100  Loss=1.2182  Acc=0.6026\n",
      "[Pretrain] Epoch 68/100  Loss=1.2007  Acc=0.6051\n",
      "[Pretrain] Epoch 69/100  Loss=1.1915  Acc=0.6056\n",
      "[Pretrain] Epoch 70/100  Loss=1.2062  Acc=0.6036\n",
      "[Pretrain] Epoch 71/100  Loss=1.1974  Acc=0.6038\n",
      "[Pretrain] Epoch 72/100  Loss=1.1888  Acc=0.6106\n",
      "[Pretrain] Epoch 73/100  Loss=1.1841  Acc=0.6087\n",
      "[Pretrain] Epoch 74/100  Loss=1.1797  Acc=0.6115\n",
      "[Pretrain] Epoch 75/100  Loss=1.2000  Acc=0.6004\n",
      "[Pretrain] Epoch 76/100  Loss=1.1791  Acc=0.6088\n",
      "[Pretrain] Epoch 77/100  Loss=1.1647  Acc=0.6130\n",
      "[Pretrain] Epoch 78/100  Loss=1.1621  Acc=0.6205\n",
      "[Pretrain] Epoch 79/100  Loss=1.1552  Acc=0.6193\n",
      "[Pretrain] Epoch 80/100  Loss=1.1816  Acc=0.6076\n",
      "[Pretrain] Epoch 81/100  Loss=1.1590  Acc=0.6184\n",
      "[Pretrain] Epoch 82/100  Loss=1.1683  Acc=0.6182\n",
      "[Pretrain] Epoch 83/100  Loss=1.1357  Acc=0.6281\n",
      "[Pretrain] Epoch 84/100  Loss=1.1471  Acc=0.6255\n",
      "[Pretrain] Epoch 85/100  Loss=1.1429  Acc=0.6214\n",
      "[Pretrain] Epoch 86/100  Loss=1.1519  Acc=0.6236\n",
      "[Pretrain] Epoch 87/100  Loss=1.1244  Acc=0.6275\n",
      "[Pretrain] Epoch 88/100  Loss=1.1316  Acc=0.6216\n",
      "[Pretrain] Epoch 89/100  Loss=1.1497  Acc=0.6230\n",
      "[Pretrain] Epoch 90/100  Loss=1.1382  Acc=0.6309\n",
      "[Pretrain] Epoch 91/100  Loss=1.1198  Acc=0.6295\n",
      "[Pretrain] Epoch 92/100  Loss=1.1413  Acc=0.6205\n",
      "[Pretrain] Epoch 93/100  Loss=1.1350  Acc=0.6207\n",
      "[Pretrain] Epoch 94/100  Loss=1.1411  Acc=0.6288\n",
      "[Pretrain] Epoch 95/100  Loss=1.1186  Acc=0.6300\n",
      "[Pretrain] Epoch 96/100  Loss=1.1393  Acc=0.6279\n",
      "[Pretrain] Epoch 97/100  Loss=1.1272  Acc=0.6343\n",
      "[Pretrain] Epoch 98/100  Loss=1.1530  Acc=0.6254\n",
      "[Pretrain] Epoch 99/100  Loss=1.1371  Acc=0.6221\n",
      "[Pretrain] Epoch 100/100  Loss=1.1301  Acc=0.6227\n",
      "[Fine-tune] Epoch 1/150  Loss=3.0748\n",
      "[Fine-tune] Epoch 2/150  Loss=2.5453\n",
      "[Fine-tune] Epoch 3/150  Loss=2.3540\n",
      "[Fine-tune] Epoch 4/150  Loss=2.2329\n",
      "[Fine-tune] Epoch 5/150  Loss=2.1458\n",
      "[Fine-tune] Epoch 6/150  Loss=2.0912\n",
      "[Fine-tune] Epoch 7/150  Loss=2.0572\n",
      "[Fine-tune] Epoch 8/150  Loss=2.0186\n",
      "[Fine-tune] Epoch 9/150  Loss=1.9854\n",
      "[Fine-tune] Epoch 10/150  Loss=1.9601\n",
      "[Fine-tune] Epoch 11/150  Loss=1.9337\n",
      "[Fine-tune] Epoch 12/150  Loss=1.9219\n",
      "[Fine-tune] Epoch 13/150  Loss=1.8997\n",
      "[Fine-tune] Epoch 14/150  Loss=1.8847\n",
      "[Fine-tune] Epoch 15/150  Loss=1.8685\n",
      "[Fine-tune] Epoch 16/150  Loss=1.8434\n",
      "[Fine-tune] Epoch 17/150  Loss=1.8367\n",
      "[Fine-tune] Epoch 18/150  Loss=1.8314\n",
      "[Fine-tune] Epoch 19/150  Loss=1.8107\n",
      "[Fine-tune] Epoch 20/150  Loss=1.8150\n",
      "[Fine-tune] Epoch 21/150  Loss=1.8015\n",
      "[Fine-tune] Epoch 22/150  Loss=1.7809\n",
      "[Fine-tune] Epoch 23/150  Loss=1.7703\n",
      "[Fine-tune] Epoch 24/150  Loss=1.7559\n",
      "[Fine-tune] Epoch 25/150  Loss=1.7660\n",
      "[Fine-tune] Epoch 26/150  Loss=1.7334\n",
      "[Fine-tune] Epoch 27/150  Loss=1.7489\n",
      "[Fine-tune] Epoch 28/150  Loss=1.7303\n",
      "[Fine-tune] Epoch 29/150  Loss=1.7371\n",
      "[Fine-tune] Epoch 30/150  Loss=1.7340\n",
      "[Fine-tune] Epoch 31/150  Loss=1.7166\n",
      "[Fine-tune] Epoch 32/150  Loss=1.6968\n",
      "[Fine-tune] Epoch 33/150  Loss=1.7087\n",
      "[Fine-tune] Epoch 34/150  Loss=1.6940\n",
      "[Fine-tune] Epoch 35/150  Loss=1.7058\n",
      "[Fine-tune] Epoch 36/150  Loss=1.7070\n",
      "[Fine-tune] Epoch 37/150  Loss=1.6929\n",
      "[Fine-tune] Epoch 38/150  Loss=1.6733\n",
      "[Fine-tune] Epoch 39/150  Loss=1.6795\n",
      "[Fine-tune] Epoch 40/150  Loss=1.6741\n",
      "[Fine-tune] Epoch 41/150  Loss=1.6665\n",
      "[Fine-tune] Epoch 42/150  Loss=1.6750\n",
      "[Fine-tune] Epoch 43/150  Loss=1.6667\n",
      "[Fine-tune] Epoch 44/150  Loss=1.6630\n",
      "[Fine-tune] Epoch 45/150  Loss=1.6627\n",
      "[Fine-tune] Epoch 46/150  Loss=1.6547\n",
      "[Fine-tune] Epoch 47/150  Loss=1.6677\n",
      "[Fine-tune] Epoch 48/150  Loss=1.6562\n",
      "[Fine-tune] Epoch 49/150  Loss=1.6472\n",
      "[Fine-tune] Epoch 50/150  Loss=1.6550\n",
      "[Fine-tune] Epoch 51/150  Loss=1.6436\n",
      "[Fine-tune] Epoch 52/150  Loss=1.6456\n",
      "[Fine-tune] Epoch 53/150  Loss=1.6381\n",
      "[Fine-tune] Epoch 54/150  Loss=1.6445\n",
      "[Fine-tune] Epoch 55/150  Loss=1.6540\n",
      "[Fine-tune] Epoch 56/150  Loss=1.6464\n",
      "[Fine-tune] Epoch 57/150  Loss=1.6462\n",
      "[Fine-tune] Epoch 58/150  Loss=1.6330\n",
      "[Fine-tune] Epoch 59/150  Loss=1.6393\n",
      "[Fine-tune] Epoch 60/150  Loss=1.6382\n",
      "[Fine-tune] Epoch 61/150  Loss=1.6243\n",
      "[Fine-tune] Epoch 62/150  Loss=1.6201\n",
      "[Fine-tune] Epoch 63/150  Loss=1.6329\n",
      "[Fine-tune] Epoch 64/150  Loss=1.6170\n",
      "[Fine-tune] Epoch 65/150  Loss=1.6274\n",
      "[Fine-tune] Epoch 66/150  Loss=1.6335\n",
      "[Fine-tune] Epoch 67/150  Loss=1.6250\n",
      "[Fine-tune] Epoch 68/150  Loss=1.6380\n",
      "[Fine-tune] Epoch 69/150  Loss=1.6249\n",
      "[Fine-tune] Epoch 70/150  Loss=1.6141\n",
      "[Fine-tune] Epoch 71/150  Loss=1.6203\n",
      "[Fine-tune] Epoch 72/150  Loss=1.6276\n",
      "[Fine-tune] Epoch 73/150  Loss=1.6250\n",
      "[Fine-tune] Epoch 74/150  Loss=1.6141\n",
      "[Fine-tune] Epoch 75/150  Loss=1.6189\n",
      "[Fine-tune] Epoch 76/150  Loss=1.6318\n",
      "[Fine-tune] Epoch 77/150  Loss=1.6059\n",
      "[Fine-tune] Epoch 78/150  Loss=1.6113\n",
      "[Fine-tune] Epoch 79/150  Loss=1.6272\n",
      "[Fine-tune] Epoch 80/150  Loss=1.6008\n",
      "[Fine-tune] Epoch 81/150  Loss=1.6170\n",
      "[Fine-tune] Epoch 82/150  Loss=1.6297\n",
      "[Fine-tune] Epoch 83/150  Loss=1.6292\n",
      "[Fine-tune] Epoch 84/150  Loss=1.6239\n",
      "[Fine-tune] Epoch 85/150  Loss=1.6205\n",
      "[Fine-tune] Epoch 86/150  Loss=1.6242\n",
      "[Fine-tune] Epoch 87/150  Loss=1.6262\n",
      "[Fine-tune] Epoch 88/150  Loss=1.6124\n",
      "[Fine-tune] Epoch 89/150  Loss=1.6090\n",
      "[Fine-tune] Epoch 90/150  Loss=1.6107\n",
      "[Fine-tune] Epoch 91/150  Loss=1.6162\n",
      "[Fine-tune] Epoch 92/150  Loss=1.6163\n",
      "[Fine-tune] Epoch 93/150  Loss=1.6238\n",
      "[Fine-tune] Epoch 94/150  Loss=1.5983\n",
      "[Fine-tune] Epoch 95/150  Loss=1.6174\n",
      "[Fine-tune] Epoch 96/150  Loss=1.6116\n",
      "[Fine-tune] Epoch 97/150  Loss=1.6068\n",
      "[Fine-tune] Epoch 98/150  Loss=1.6064\n",
      "[Fine-tune] Epoch 99/150  Loss=1.6208\n",
      "[Fine-tune] Epoch 100/150  Loss=1.6166\n",
      "[Fine-tune] Epoch 101/150  Loss=1.6145\n",
      "[Fine-tune] Epoch 102/150  Loss=1.6143\n",
      "[Fine-tune] Epoch 103/150  Loss=1.6154\n",
      "[Fine-tune] Epoch 104/150  Loss=1.6114\n",
      "[Fine-tune] Epoch 105/150  Loss=1.6077\n",
      "[Fine-tune] Epoch 106/150  Loss=1.5981\n",
      "[Fine-tune] Epoch 107/150  Loss=1.6073\n",
      "[Fine-tune] Epoch 108/150  Loss=1.6195\n",
      "[Fine-tune] Epoch 109/150  Loss=1.6235\n",
      "[Fine-tune] Epoch 110/150  Loss=1.6021\n",
      "[Fine-tune] Epoch 111/150  Loss=1.6071\n",
      "[Fine-tune] Epoch 112/150  Loss=1.6116\n",
      "[Fine-tune] Epoch 113/150  Loss=1.6183\n",
      "[Fine-tune] Epoch 114/150  Loss=1.6145\n",
      "[Fine-tune] Epoch 115/150  Loss=1.6122\n",
      "[Fine-tune] Epoch 116/150  Loss=1.6157\n",
      "[Fine-tune] Epoch 117/150  Loss=1.6185\n",
      "[Fine-tune] Epoch 118/150  Loss=1.6051\n",
      "[Fine-tune] Epoch 119/150  Loss=1.6198\n",
      "[Fine-tune] Epoch 120/150  Loss=1.6178\n",
      "[Fine-tune] Epoch 121/150  Loss=1.6124\n",
      "[Fine-tune] Epoch 122/150  Loss=1.6164\n",
      "[Fine-tune] Epoch 123/150  Loss=1.5971\n",
      "[Fine-tune] Epoch 124/150  Loss=1.5958\n",
      "[Fine-tune] Epoch 125/150  Loss=1.6079\n",
      "[Fine-tune] Epoch 126/150  Loss=1.6132\n",
      "[Fine-tune] Epoch 127/150  Loss=1.6171\n",
      "[Fine-tune] Epoch 128/150  Loss=1.6228\n",
      "[Fine-tune] Epoch 129/150  Loss=1.6255\n",
      "[Fine-tune] Epoch 130/150  Loss=1.6160\n",
      "[Fine-tune] Epoch 131/150  Loss=1.6164\n",
      "[Fine-tune] Epoch 132/150  Loss=1.6156\n",
      "[Fine-tune] Epoch 133/150  Loss=1.6008\n",
      "[Fine-tune] Epoch 134/150  Loss=1.5984\n",
      "[Fine-tune] Epoch 135/150  Loss=1.6103\n",
      "[Fine-tune] Epoch 136/150  Loss=1.6100\n",
      "[Fine-tune] Epoch 137/150  Loss=1.6149\n",
      "[Fine-tune] Epoch 138/150  Loss=1.6264\n",
      "[Fine-tune] Epoch 139/150  Loss=1.6134\n",
      "[Fine-tune] Epoch 140/150  Loss=1.6020\n",
      "[Fine-tune] Epoch 141/150  Loss=1.6141\n",
      "[Fine-tune] Epoch 142/150  Loss=1.6191\n",
      "[Fine-tune] Epoch 143/150  Loss=1.6051\n",
      "[Fine-tune] Epoch 144/150  Loss=1.6186\n",
      "[Fine-tune] Epoch 145/150  Loss=1.6124\n",
      "[Fine-tune] Epoch 146/150  Loss=1.6198\n",
      "[Fine-tune] Epoch 147/150  Loss=1.6095\n",
      "[Fine-tune] Epoch 148/150  Loss=1.6094\n",
      "[Fine-tune] Epoch 149/150  Loss=1.6050\n",
      "[Fine-tune] Epoch 150/150  Loss=1.6003\n",
      "[Pretrain] Epoch 1/150  Loss=3.1840  Acc=0.0603\n",
      "[Pretrain] Epoch 2/150  Loss=3.0459  Acc=0.0855\n",
      "[Pretrain] Epoch 3/150  Loss=2.7690  Acc=0.1451\n",
      "[Pretrain] Epoch 4/150  Loss=2.5240  Acc=0.2071\n",
      "[Pretrain] Epoch 5/150  Loss=2.3671  Acc=0.2511\n",
      "[Pretrain] Epoch 6/150  Loss=2.2887  Acc=0.2624\n",
      "[Pretrain] Epoch 7/150  Loss=2.2036  Acc=0.2868\n",
      "[Pretrain] Epoch 8/150  Loss=2.1592  Acc=0.2992\n",
      "[Pretrain] Epoch 9/150  Loss=2.0984  Acc=0.3267\n",
      "[Pretrain] Epoch 10/150  Loss=2.0629  Acc=0.3360\n",
      "[Pretrain] Epoch 11/150  Loss=1.9918  Acc=0.3526\n",
      "[Pretrain] Epoch 12/150  Loss=1.9880  Acc=0.3612\n",
      "[Pretrain] Epoch 13/150  Loss=1.9387  Acc=0.3714\n",
      "[Pretrain] Epoch 14/150  Loss=1.9046  Acc=0.3908\n",
      "[Pretrain] Epoch 15/150  Loss=1.8845  Acc=0.3904\n",
      "[Pretrain] Epoch 16/150  Loss=1.8635  Acc=0.3998\n",
      "[Pretrain] Epoch 17/150  Loss=1.8181  Acc=0.4143\n",
      "[Pretrain] Epoch 18/150  Loss=1.8085  Acc=0.4109\n",
      "[Pretrain] Epoch 19/150  Loss=1.7835  Acc=0.4217\n",
      "[Pretrain] Epoch 20/150  Loss=1.7552  Acc=0.4314\n",
      "[Pretrain] Epoch 21/150  Loss=1.7403  Acc=0.4391\n",
      "[Pretrain] Epoch 22/150  Loss=1.7285  Acc=0.4441\n",
      "[Pretrain] Epoch 23/150  Loss=1.7104  Acc=0.4515\n",
      "[Pretrain] Epoch 24/150  Loss=1.6822  Acc=0.4519\n",
      "[Pretrain] Epoch 25/150  Loss=1.6529  Acc=0.4696\n",
      "[Pretrain] Epoch 26/150  Loss=1.6483  Acc=0.4637\n",
      "[Pretrain] Epoch 27/150  Loss=1.6417  Acc=0.4603\n",
      "[Pretrain] Epoch 28/150  Loss=1.6184  Acc=0.4767\n",
      "[Pretrain] Epoch 29/150  Loss=1.5951  Acc=0.4862\n",
      "[Pretrain] Epoch 30/150  Loss=1.5894  Acc=0.4865\n",
      "[Pretrain] Epoch 31/150  Loss=1.5761  Acc=0.4903\n",
      "[Pretrain] Epoch 32/150  Loss=1.5561  Acc=0.5004\n",
      "[Pretrain] Epoch 33/150  Loss=1.5460  Acc=0.4960\n",
      "[Pretrain] Epoch 34/150  Loss=1.5178  Acc=0.5023\n",
      "[Pretrain] Epoch 35/150  Loss=1.5081  Acc=0.5032\n",
      "[Pretrain] Epoch 36/150  Loss=1.4997  Acc=0.5120\n",
      "[Pretrain] Epoch 37/150  Loss=1.4829  Acc=0.5126\n",
      "[Pretrain] Epoch 38/150  Loss=1.4713  Acc=0.5230\n",
      "[Pretrain] Epoch 39/150  Loss=1.4631  Acc=0.5199\n",
      "[Pretrain] Epoch 40/150  Loss=1.4463  Acc=0.5257\n",
      "[Pretrain] Epoch 41/150  Loss=1.4450  Acc=0.5323\n",
      "[Pretrain] Epoch 42/150  Loss=1.4420  Acc=0.5357\n",
      "[Pretrain] Epoch 43/150  Loss=1.4113  Acc=0.5318\n",
      "[Pretrain] Epoch 44/150  Loss=1.4158  Acc=0.5372\n",
      "[Pretrain] Epoch 45/150  Loss=1.4162  Acc=0.5418\n",
      "[Pretrain] Epoch 46/150  Loss=1.4046  Acc=0.5395\n",
      "[Pretrain] Epoch 47/150  Loss=1.3900  Acc=0.5472\n",
      "[Pretrain] Epoch 48/150  Loss=1.3838  Acc=0.5469\n",
      "[Pretrain] Epoch 49/150  Loss=1.3742  Acc=0.5499\n",
      "[Pretrain] Epoch 50/150  Loss=1.3733  Acc=0.5528\n",
      "[Pretrain] Epoch 51/150  Loss=1.3653  Acc=0.5546\n",
      "[Pretrain] Epoch 52/150  Loss=1.3740  Acc=0.5467\n",
      "[Pretrain] Epoch 53/150  Loss=1.3577  Acc=0.5596\n",
      "[Pretrain] Epoch 54/150  Loss=1.3519  Acc=0.5555\n",
      "[Pretrain] Epoch 55/150  Loss=1.3349  Acc=0.5609\n",
      "[Pretrain] Epoch 56/150  Loss=1.3357  Acc=0.5661\n",
      "[Pretrain] Epoch 57/150  Loss=1.3437  Acc=0.5652\n",
      "[Pretrain] Epoch 58/150  Loss=1.3383  Acc=0.5634\n",
      "[Pretrain] Epoch 59/150  Loss=1.3193  Acc=0.5632\n",
      "[Pretrain] Epoch 60/150  Loss=1.3214  Acc=0.5695\n",
      "[Pretrain] Epoch 61/150  Loss=1.3210  Acc=0.5675\n",
      "[Pretrain] Epoch 62/150  Loss=1.3165  Acc=0.5736\n",
      "[Pretrain] Epoch 63/150  Loss=1.3120  Acc=0.5709\n",
      "[Pretrain] Epoch 64/150  Loss=1.3119  Acc=0.5749\n",
      "[Pretrain] Epoch 65/150  Loss=1.3159  Acc=0.5727\n",
      "[Pretrain] Epoch 66/150  Loss=1.3003  Acc=0.5781\n",
      "[Pretrain] Epoch 67/150  Loss=1.3144  Acc=0.5684\n",
      "[Pretrain] Epoch 68/150  Loss=1.2901  Acc=0.5860\n",
      "[Pretrain] Epoch 69/150  Loss=1.3003  Acc=0.5738\n",
      "[Pretrain] Epoch 70/150  Loss=1.2977  Acc=0.5805\n",
      "[Pretrain] Epoch 71/150  Loss=1.2830  Acc=0.5869\n",
      "[Pretrain] Epoch 72/150  Loss=1.2890  Acc=0.5805\n",
      "[Pretrain] Epoch 73/150  Loss=1.2898  Acc=0.5756\n",
      "[Pretrain] Epoch 74/150  Loss=1.2776  Acc=0.5849\n",
      "[Pretrain] Epoch 75/150  Loss=1.2839  Acc=0.5819\n",
      "[Pretrain] Epoch 76/150  Loss=1.2916  Acc=0.5832\n",
      "[Pretrain] Epoch 77/150  Loss=1.2828  Acc=0.5779\n",
      "[Pretrain] Epoch 78/150  Loss=1.2762  Acc=0.5889\n",
      "[Pretrain] Epoch 79/150  Loss=1.2765  Acc=0.5882\n",
      "[Pretrain] Epoch 80/150  Loss=1.2815  Acc=0.5846\n",
      "[Pretrain] Epoch 81/150  Loss=1.2806  Acc=0.5788\n",
      "[Pretrain] Epoch 82/150  Loss=1.2573  Acc=0.5946\n",
      "[Pretrain] Epoch 83/150  Loss=1.2748  Acc=0.5781\n",
      "[Pretrain] Epoch 84/150  Loss=1.2716  Acc=0.5930\n",
      "[Pretrain] Epoch 85/150  Loss=1.2695  Acc=0.5894\n",
      "[Pretrain] Epoch 86/150  Loss=1.2766  Acc=0.5853\n",
      "[Pretrain] Epoch 87/150  Loss=1.2706  Acc=0.5878\n",
      "[Pretrain] Epoch 88/150  Loss=1.2601  Acc=0.5878\n",
      "[Pretrain] Epoch 89/150  Loss=1.2640  Acc=0.5853\n",
      "[Pretrain] Epoch 90/150  Loss=1.2668  Acc=0.5880\n",
      "[Pretrain] Epoch 91/150  Loss=1.2683  Acc=0.5876\n",
      "[Pretrain] Epoch 92/150  Loss=1.2573  Acc=0.5902\n",
      "[Pretrain] Epoch 93/150  Loss=1.2666  Acc=0.5932\n",
      "[Pretrain] Epoch 94/150  Loss=1.2564  Acc=0.5907\n",
      "[Pretrain] Epoch 95/150  Loss=1.2595  Acc=0.5939\n",
      "[Pretrain] Epoch 96/150  Loss=1.2654  Acc=0.5873\n",
      "[Pretrain] Epoch 97/150  Loss=1.2531  Acc=0.5851\n",
      "[Pretrain] Epoch 98/150  Loss=1.2607  Acc=0.5835\n",
      "[Pretrain] Epoch 99/150  Loss=1.2618  Acc=0.5972\n",
      "[Pretrain] Epoch 100/150  Loss=1.2794  Acc=0.5805\n",
      "[Pretrain] Epoch 101/150  Loss=1.2583  Acc=0.5833\n",
      "[Pretrain] Epoch 102/150  Loss=1.2639  Acc=0.5873\n",
      "[Pretrain] Epoch 103/150  Loss=1.2645  Acc=0.5929\n",
      "[Pretrain] Epoch 104/150  Loss=1.2606  Acc=0.5898\n",
      "[Pretrain] Epoch 105/150  Loss=1.2450  Acc=0.5896\n",
      "[Pretrain] Epoch 106/150  Loss=1.2619  Acc=0.5878\n",
      "[Pretrain] Epoch 107/150  Loss=1.2742  Acc=0.5842\n",
      "[Pretrain] Epoch 108/150  Loss=1.2458  Acc=0.5961\n",
      "[Pretrain] Epoch 109/150  Loss=1.2556  Acc=0.5912\n",
      "[Pretrain] Epoch 110/150  Loss=1.2503  Acc=0.5946\n",
      "[Pretrain] Epoch 111/150  Loss=1.2497  Acc=0.5934\n",
      "[Pretrain] Epoch 112/150  Loss=1.2606  Acc=0.5882\n",
      "[Pretrain] Epoch 113/150  Loss=1.2512  Acc=0.5957\n",
      "[Pretrain] Epoch 114/150  Loss=1.2469  Acc=0.5957\n",
      "[Pretrain] Epoch 115/150  Loss=1.2630  Acc=0.5871\n",
      "[Pretrain] Epoch 116/150  Loss=1.2620  Acc=0.5878\n",
      "[Pretrain] Epoch 117/150  Loss=1.2574  Acc=0.5925\n",
      "[Pretrain] Epoch 118/150  Loss=1.2513  Acc=0.5938\n",
      "[Pretrain] Epoch 119/150  Loss=1.2588  Acc=0.5902\n",
      "[Pretrain] Epoch 120/150  Loss=1.2372  Acc=0.5939\n",
      "[Pretrain] Epoch 121/150  Loss=1.2646  Acc=0.5907\n",
      "[Pretrain] Epoch 122/150  Loss=1.2530  Acc=0.5867\n",
      "[Pretrain] Epoch 123/150  Loss=1.2536  Acc=0.5948\n",
      "[Pretrain] Epoch 124/150  Loss=1.2642  Acc=0.5873\n",
      "[Pretrain] Epoch 125/150  Loss=1.2451  Acc=0.5981\n",
      "[Pretrain] Epoch 126/150  Loss=1.2583  Acc=0.5873\n",
      "[Pretrain] Epoch 127/150  Loss=1.2499  Acc=0.5932\n",
      "[Pretrain] Epoch 128/150  Loss=1.2695  Acc=0.5837\n",
      "[Pretrain] Epoch 129/150  Loss=1.2562  Acc=0.5900\n",
      "[Pretrain] Epoch 130/150  Loss=1.2509  Acc=0.5961\n",
      "[Pretrain] Epoch 131/150  Loss=1.2534  Acc=0.5938\n",
      "[Pretrain] Epoch 132/150  Loss=1.2509  Acc=0.5914\n",
      "[Pretrain] Epoch 133/150  Loss=1.2709  Acc=0.5794\n",
      "[Pretrain] Epoch 134/150  Loss=1.2376  Acc=0.5990\n",
      "[Pretrain] Epoch 135/150  Loss=1.2647  Acc=0.5876\n",
      "[Pretrain] Epoch 136/150  Loss=1.2451  Acc=0.5907\n",
      "[Pretrain] Epoch 137/150  Loss=1.2612  Acc=0.5961\n",
      "[Pretrain] Epoch 138/150  Loss=1.2554  Acc=0.5893\n",
      "[Pretrain] Epoch 139/150  Loss=1.2552  Acc=0.5871\n",
      "[Pretrain] Epoch 140/150  Loss=1.2581  Acc=0.5903\n",
      "[Pretrain] Epoch 141/150  Loss=1.2505  Acc=0.5939\n",
      "[Pretrain] Epoch 142/150  Loss=1.2618  Acc=0.5880\n",
      "[Pretrain] Epoch 143/150  Loss=1.2572  Acc=0.5832\n",
      "[Pretrain] Epoch 144/150  Loss=1.2506  Acc=0.5855\n",
      "[Pretrain] Epoch 145/150  Loss=1.2554  Acc=0.5858\n",
      "[Pretrain] Epoch 146/150  Loss=1.2611  Acc=0.5857\n",
      "[Pretrain] Epoch 147/150  Loss=1.2602  Acc=0.5878\n",
      "[Pretrain] Epoch 148/150  Loss=1.2485  Acc=0.5939\n",
      "[Pretrain] Epoch 149/150  Loss=1.2541  Acc=0.5902\n",
      "[Pretrain] Epoch 150/150  Loss=1.2528  Acc=0.5902\n",
      "[Fine-tune] Epoch 1/150  Loss=2.6584\n",
      "[Fine-tune] Epoch 2/150  Loss=2.2522\n",
      "[Fine-tune] Epoch 3/150  Loss=2.0931\n",
      "[Fine-tune] Epoch 4/150  Loss=1.9883\n",
      "[Fine-tune] Epoch 5/150  Loss=1.8879\n",
      "[Fine-tune] Epoch 6/150  Loss=1.8331\n",
      "[Fine-tune] Epoch 7/150  Loss=1.7931\n",
      "[Fine-tune] Epoch 8/150  Loss=1.7156\n",
      "[Fine-tune] Epoch 9/150  Loss=1.6852\n",
      "[Fine-tune] Epoch 10/150  Loss=1.6581\n",
      "[Fine-tune] Epoch 11/150  Loss=1.6070\n",
      "[Fine-tune] Epoch 12/150  Loss=1.5835\n",
      "[Fine-tune] Epoch 13/150  Loss=1.5527\n",
      "[Fine-tune] Epoch 14/150  Loss=1.5054\n",
      "[Fine-tune] Epoch 15/150  Loss=1.4621\n",
      "[Fine-tune] Epoch 16/150  Loss=1.4422\n",
      "[Fine-tune] Epoch 17/150  Loss=1.4077\n",
      "[Fine-tune] Epoch 18/150  Loss=1.4003\n",
      "[Fine-tune] Epoch 19/150  Loss=1.3767\n",
      "[Fine-tune] Epoch 20/150  Loss=1.3525\n",
      "[Fine-tune] Epoch 21/150  Loss=1.3174\n",
      "[Fine-tune] Epoch 22/150  Loss=1.2999\n",
      "[Fine-tune] Epoch 23/150  Loss=1.3038\n",
      "[Fine-tune] Epoch 24/150  Loss=1.2529\n",
      "[Fine-tune] Epoch 25/150  Loss=1.2391\n",
      "[Fine-tune] Epoch 26/150  Loss=1.2279\n",
      "[Fine-tune] Epoch 27/150  Loss=1.1967\n",
      "[Fine-tune] Epoch 28/150  Loss=1.1991\n",
      "[Fine-tune] Epoch 29/150  Loss=1.1783\n",
      "[Fine-tune] Epoch 30/150  Loss=1.1597\n",
      "[Fine-tune] Epoch 31/150  Loss=1.1530\n",
      "[Fine-tune] Epoch 32/150  Loss=1.1346\n",
      "[Fine-tune] Epoch 33/150  Loss=1.1141\n",
      "[Fine-tune] Epoch 34/150  Loss=1.1105\n",
      "[Fine-tune] Epoch 35/150  Loss=1.1008\n",
      "[Fine-tune] Epoch 36/150  Loss=1.0899\n",
      "[Fine-tune] Epoch 37/150  Loss=1.0799\n",
      "[Fine-tune] Epoch 38/150  Loss=1.0921\n",
      "[Fine-tune] Epoch 39/150  Loss=1.0686\n",
      "[Fine-tune] Epoch 40/150  Loss=1.0602\n",
      "[Fine-tune] Epoch 41/150  Loss=1.0569\n",
      "[Fine-tune] Epoch 42/150  Loss=1.0298\n",
      "[Fine-tune] Epoch 43/150  Loss=1.0292\n",
      "[Fine-tune] Epoch 44/150  Loss=1.0333\n",
      "[Fine-tune] Epoch 45/150  Loss=1.0163\n",
      "[Fine-tune] Epoch 46/150  Loss=1.0115\n",
      "[Fine-tune] Epoch 47/150  Loss=1.0232\n",
      "[Fine-tune] Epoch 48/150  Loss=1.0086\n",
      "[Fine-tune] Epoch 49/150  Loss=0.9821\n",
      "[Fine-tune] Epoch 50/150  Loss=1.0026\n",
      "[Fine-tune] Epoch 51/150  Loss=0.9777\n",
      "[Fine-tune] Epoch 52/150  Loss=0.9942\n",
      "[Fine-tune] Epoch 53/150  Loss=0.9765\n",
      "[Fine-tune] Epoch 54/150  Loss=0.9646\n",
      "[Fine-tune] Epoch 55/150  Loss=0.9739\n",
      "[Fine-tune] Epoch 56/150  Loss=0.9676\n",
      "[Fine-tune] Epoch 57/150  Loss=0.9728\n",
      "[Fine-tune] Epoch 58/150  Loss=0.9670\n",
      "[Fine-tune] Epoch 59/150  Loss=0.9707\n",
      "[Fine-tune] Epoch 60/150  Loss=0.9699\n",
      "[Fine-tune] Epoch 61/150  Loss=0.9406\n",
      "[Fine-tune] Epoch 62/150  Loss=0.9526\n",
      "[Fine-tune] Epoch 63/150  Loss=0.9335\n",
      "[Fine-tune] Epoch 64/150  Loss=0.9527\n",
      "[Fine-tune] Epoch 65/150  Loss=0.9526\n",
      "[Fine-tune] Epoch 66/150  Loss=0.9420\n",
      "[Fine-tune] Epoch 67/150  Loss=0.9445\n",
      "[Fine-tune] Epoch 68/150  Loss=0.9461\n",
      "[Fine-tune] Epoch 69/150  Loss=0.9434\n",
      "[Fine-tune] Epoch 70/150  Loss=0.9332\n",
      "[Fine-tune] Epoch 71/150  Loss=0.9288\n",
      "[Fine-tune] Epoch 72/150  Loss=0.9282\n",
      "[Fine-tune] Epoch 73/150  Loss=0.9379\n",
      "[Fine-tune] Epoch 74/150  Loss=0.9353\n",
      "[Fine-tune] Epoch 75/150  Loss=0.9481\n",
      "[Fine-tune] Epoch 76/150  Loss=0.9298\n",
      "[Fine-tune] Epoch 77/150  Loss=0.9330\n",
      "[Fine-tune] Epoch 78/150  Loss=0.9213\n",
      "[Fine-tune] Epoch 79/150  Loss=0.9237\n",
      "[Fine-tune] Epoch 80/150  Loss=0.9254\n",
      "[Fine-tune] Epoch 81/150  Loss=0.9240\n",
      "[Fine-tune] Epoch 82/150  Loss=0.9209\n",
      "[Fine-tune] Epoch 83/150  Loss=0.9169\n",
      "[Fine-tune] Epoch 84/150  Loss=0.9025\n",
      "[Fine-tune] Epoch 85/150  Loss=0.9286\n",
      "[Fine-tune] Epoch 86/150  Loss=0.9186\n",
      "[Fine-tune] Epoch 87/150  Loss=0.9080\n",
      "[Fine-tune] Epoch 88/150  Loss=0.9263\n",
      "[Fine-tune] Epoch 89/150  Loss=0.9144\n",
      "[Fine-tune] Epoch 90/150  Loss=0.9074\n",
      "[Fine-tune] Epoch 91/150  Loss=0.9189\n",
      "[Fine-tune] Epoch 92/150  Loss=0.9112\n",
      "[Fine-tune] Epoch 93/150  Loss=0.9159\n",
      "[Fine-tune] Epoch 94/150  Loss=0.9225\n",
      "[Fine-tune] Epoch 95/150  Loss=0.9180\n",
      "[Fine-tune] Epoch 96/150  Loss=0.9149\n",
      "[Fine-tune] Epoch 97/150  Loss=0.9176\n",
      "[Fine-tune] Epoch 98/150  Loss=0.9157\n",
      "[Fine-tune] Epoch 99/150  Loss=0.9115\n",
      "[Fine-tune] Epoch 100/150  Loss=0.9137\n",
      "[Fine-tune] Epoch 101/150  Loss=0.9061\n",
      "[Fine-tune] Epoch 102/150  Loss=0.9046\n",
      "[Fine-tune] Epoch 103/150  Loss=0.9100\n",
      "[Fine-tune] Epoch 104/150  Loss=0.9040\n",
      "[Fine-tune] Epoch 105/150  Loss=0.9183\n",
      "[Fine-tune] Epoch 106/150  Loss=0.9173\n",
      "[Fine-tune] Epoch 107/150  Loss=0.9025\n",
      "[Fine-tune] Epoch 108/150  Loss=0.9043\n",
      "[Fine-tune] Epoch 109/150  Loss=0.9159\n",
      "[Fine-tune] Epoch 110/150  Loss=0.9202\n",
      "[Fine-tune] Epoch 111/150  Loss=0.9100\n",
      "[Fine-tune] Epoch 112/150  Loss=0.9023\n",
      "[Fine-tune] Epoch 113/150  Loss=0.9119\n",
      "[Fine-tune] Epoch 114/150  Loss=0.8958\n",
      "[Fine-tune] Epoch 115/150  Loss=0.8988\n",
      "[Fine-tune] Epoch 116/150  Loss=0.9101\n",
      "[Fine-tune] Epoch 117/150  Loss=0.9022\n",
      "[Fine-tune] Epoch 118/150  Loss=0.9040\n",
      "[Fine-tune] Epoch 119/150  Loss=0.9072\n",
      "[Fine-tune] Epoch 120/150  Loss=0.9143\n",
      "[Fine-tune] Epoch 121/150  Loss=0.8916\n",
      "[Fine-tune] Epoch 122/150  Loss=0.9081\n",
      "[Fine-tune] Epoch 123/150  Loss=0.9034\n",
      "[Fine-tune] Epoch 124/150  Loss=0.8992\n",
      "[Fine-tune] Epoch 125/150  Loss=0.9070\n",
      "[Fine-tune] Epoch 126/150  Loss=0.8984\n",
      "[Fine-tune] Epoch 127/150  Loss=0.8989\n",
      "[Fine-tune] Epoch 128/150  Loss=0.9037\n",
      "[Fine-tune] Epoch 129/150  Loss=0.9098\n",
      "[Fine-tune] Epoch 130/150  Loss=0.9037\n",
      "[Fine-tune] Epoch 131/150  Loss=0.9112\n",
      "[Fine-tune] Epoch 132/150  Loss=0.9128\n",
      "[Fine-tune] Epoch 133/150  Loss=0.9060\n",
      "[Fine-tune] Epoch 134/150  Loss=0.8946\n",
      "[Fine-tune] Epoch 135/150  Loss=0.9000\n",
      "[Fine-tune] Epoch 136/150  Loss=0.9059\n",
      "[Fine-tune] Epoch 137/150  Loss=0.9187\n",
      "[Fine-tune] Epoch 138/150  Loss=0.9012\n",
      "[Fine-tune] Epoch 139/150  Loss=0.9135\n",
      "[Fine-tune] Epoch 140/150  Loss=0.9072\n",
      "[Fine-tune] Epoch 141/150  Loss=0.8898\n",
      "[Fine-tune] Epoch 142/150  Loss=0.9116\n",
      "[Fine-tune] Epoch 143/150  Loss=0.9013\n",
      "[Fine-tune] Epoch 144/150  Loss=0.8951\n",
      "[Fine-tune] Epoch 145/150  Loss=0.9118\n",
      "[Fine-tune] Epoch 146/150  Loss=0.9053\n",
      "[Fine-tune] Epoch 147/150  Loss=0.9117\n",
      "[Fine-tune] Epoch 148/150  Loss=0.9092\n",
      "[Fine-tune] Epoch 149/150  Loss=0.9008\n",
      "[Fine-tune] Epoch 150/150  Loss=0.9089\n",
      "[Pretrain] Epoch 1/150  Loss=3.6461  Acc=0.0409\n",
      "[Pretrain] Epoch 2/150  Loss=3.1770  Acc=0.0533\n",
      "[Pretrain] Epoch 3/150  Loss=3.0626  Acc=0.0779\n",
      "[Pretrain] Epoch 4/150  Loss=3.0430  Acc=0.0839\n",
      "[Pretrain] Epoch 5/150  Loss=3.0289  Acc=0.0817\n",
      "[Pretrain] Epoch 6/150  Loss=2.9913  Acc=0.0948\n",
      "[Pretrain] Epoch 7/150  Loss=2.8051  Acc=0.1349\n",
      "[Pretrain] Epoch 8/150  Loss=2.5426  Acc=0.1936\n",
      "[Pretrain] Epoch 9/150  Loss=2.3973  Acc=0.2358\n",
      "[Pretrain] Epoch 10/150  Loss=2.3530  Acc=0.2399\n",
      "[Pretrain] Epoch 11/150  Loss=2.2447  Acc=0.2633\n",
      "[Pretrain] Epoch 12/150  Loss=2.1799  Acc=0.2940\n",
      "[Pretrain] Epoch 13/150  Loss=2.1389  Acc=0.3087\n",
      "[Pretrain] Epoch 14/150  Loss=2.1165  Acc=0.3102\n",
      "[Pretrain] Epoch 15/150  Loss=2.0684  Acc=0.3213\n",
      "[Pretrain] Epoch 16/150  Loss=2.0522  Acc=0.3229\n",
      "[Pretrain] Epoch 17/150  Loss=1.9997  Acc=0.3536\n",
      "[Pretrain] Epoch 18/150  Loss=2.0033  Acc=0.3468\n",
      "[Pretrain] Epoch 19/150  Loss=1.9521  Acc=0.3579\n",
      "[Pretrain] Epoch 20/150  Loss=1.9475  Acc=0.3554\n",
      "[Pretrain] Epoch 21/150  Loss=1.9230  Acc=0.3678\n",
      "[Pretrain] Epoch 22/150  Loss=1.9089  Acc=0.3759\n",
      "[Pretrain] Epoch 23/150  Loss=1.8734  Acc=0.3813\n",
      "[Pretrain] Epoch 24/150  Loss=1.8460  Acc=0.3915\n",
      "[Pretrain] Epoch 25/150  Loss=1.8256  Acc=0.3989\n",
      "[Pretrain] Epoch 26/150  Loss=1.8051  Acc=0.4057\n",
      "[Pretrain] Epoch 27/150  Loss=1.7687  Acc=0.4212\n",
      "[Pretrain] Epoch 28/150  Loss=1.7701  Acc=0.4255\n",
      "[Pretrain] Epoch 29/150  Loss=1.7212  Acc=0.4364\n",
      "[Pretrain] Epoch 30/150  Loss=1.7141  Acc=0.4427\n",
      "[Pretrain] Epoch 31/150  Loss=1.6974  Acc=0.4418\n",
      "[Pretrain] Epoch 32/150  Loss=1.6672  Acc=0.4546\n",
      "[Pretrain] Epoch 33/150  Loss=1.6434  Acc=0.4562\n",
      "[Pretrain] Epoch 34/150  Loss=1.6325  Acc=0.4643\n",
      "[Pretrain] Epoch 35/150  Loss=1.5965  Acc=0.4758\n",
      "[Pretrain] Epoch 36/150  Loss=1.5685  Acc=0.4846\n",
      "[Pretrain] Epoch 37/150  Loss=1.5570  Acc=0.4837\n",
      "[Pretrain] Epoch 38/150  Loss=1.5509  Acc=0.4917\n",
      "[Pretrain] Epoch 39/150  Loss=1.5346  Acc=0.4953\n",
      "[Pretrain] Epoch 40/150  Loss=1.5160  Acc=0.4939\n",
      "[Pretrain] Epoch 41/150  Loss=1.4696  Acc=0.5221\n",
      "[Pretrain] Epoch 42/150  Loss=1.4641  Acc=0.5156\n",
      "[Pretrain] Epoch 43/150  Loss=1.4634  Acc=0.5208\n",
      "[Pretrain] Epoch 44/150  Loss=1.4528  Acc=0.5217\n",
      "[Pretrain] Epoch 45/150  Loss=1.4461  Acc=0.5287\n",
      "[Pretrain] Epoch 46/150  Loss=1.4009  Acc=0.5420\n",
      "[Pretrain] Epoch 47/150  Loss=1.4085  Acc=0.5499\n",
      "[Pretrain] Epoch 48/150  Loss=1.3872  Acc=0.5390\n",
      "[Pretrain] Epoch 49/150  Loss=1.3875  Acc=0.5415\n",
      "[Pretrain] Epoch 50/150  Loss=1.3581  Acc=0.5566\n",
      "[Pretrain] Epoch 51/150  Loss=1.3669  Acc=0.5503\n",
      "[Pretrain] Epoch 52/150  Loss=1.3420  Acc=0.5546\n",
      "[Pretrain] Epoch 53/150  Loss=1.3334  Acc=0.5625\n",
      "[Pretrain] Epoch 54/150  Loss=1.3269  Acc=0.5638\n",
      "[Pretrain] Epoch 55/150  Loss=1.3144  Acc=0.5702\n",
      "[Pretrain] Epoch 56/150  Loss=1.3097  Acc=0.5708\n",
      "[Pretrain] Epoch 57/150  Loss=1.2914  Acc=0.5697\n",
      "[Pretrain] Epoch 58/150  Loss=1.2862  Acc=0.5781\n",
      "[Pretrain] Epoch 59/150  Loss=1.2817  Acc=0.5778\n",
      "[Pretrain] Epoch 60/150  Loss=1.2754  Acc=0.5814\n",
      "[Pretrain] Epoch 61/150  Loss=1.2729  Acc=0.5857\n",
      "[Pretrain] Epoch 62/150  Loss=1.2554  Acc=0.5914\n",
      "[Pretrain] Epoch 63/150  Loss=1.2557  Acc=0.5912\n",
      "[Pretrain] Epoch 64/150  Loss=1.2613  Acc=0.5832\n",
      "[Pretrain] Epoch 65/150  Loss=1.2447  Acc=0.5948\n",
      "[Pretrain] Epoch 66/150  Loss=1.2415  Acc=0.5964\n",
      "[Pretrain] Epoch 67/150  Loss=1.2449  Acc=0.5916\n",
      "[Pretrain] Epoch 68/150  Loss=1.2341  Acc=0.5921\n",
      "[Pretrain] Epoch 69/150  Loss=1.2495  Acc=0.5875\n",
      "[Pretrain] Epoch 70/150  Loss=1.2213  Acc=0.6000\n",
      "[Pretrain] Epoch 71/150  Loss=1.2165  Acc=0.5973\n",
      "[Pretrain] Epoch 72/150  Loss=1.2229  Acc=0.5946\n",
      "[Pretrain] Epoch 73/150  Loss=1.2005  Acc=0.6078\n",
      "[Pretrain] Epoch 74/150  Loss=1.1900  Acc=0.6027\n",
      "[Pretrain] Epoch 75/150  Loss=1.2064  Acc=0.6024\n",
      "[Pretrain] Epoch 76/150  Loss=1.1925  Acc=0.6006\n",
      "[Pretrain] Epoch 77/150  Loss=1.1928  Acc=0.6105\n",
      "[Pretrain] Epoch 78/150  Loss=1.1879  Acc=0.6087\n",
      "[Pretrain] Epoch 79/150  Loss=1.1812  Acc=0.6153\n",
      "[Pretrain] Epoch 80/150  Loss=1.2058  Acc=0.5977\n",
      "[Pretrain] Epoch 81/150  Loss=1.1746  Acc=0.6087\n",
      "[Pretrain] Epoch 82/150  Loss=1.1822  Acc=0.6131\n",
      "[Pretrain] Epoch 83/150  Loss=1.1802  Acc=0.6187\n",
      "[Pretrain] Epoch 84/150  Loss=1.1713  Acc=0.6194\n",
      "[Pretrain] Epoch 85/150  Loss=1.1739  Acc=0.6191\n",
      "[Pretrain] Epoch 86/150  Loss=1.1915  Acc=0.6058\n",
      "[Pretrain] Epoch 87/150  Loss=1.1782  Acc=0.6184\n",
      "[Pretrain] Epoch 88/150  Loss=1.1513  Acc=0.6175\n",
      "[Pretrain] Epoch 89/150  Loss=1.1702  Acc=0.6194\n",
      "[Pretrain] Epoch 90/150  Loss=1.1816  Acc=0.6103\n",
      "[Pretrain] Epoch 91/150  Loss=1.1740  Acc=0.6135\n",
      "[Pretrain] Epoch 92/150  Loss=1.1676  Acc=0.6189\n",
      "[Pretrain] Epoch 93/150  Loss=1.1642  Acc=0.6173\n",
      "[Pretrain] Epoch 94/150  Loss=1.1445  Acc=0.6214\n",
      "[Pretrain] Epoch 95/150  Loss=1.1587  Acc=0.6227\n",
      "[Pretrain] Epoch 96/150  Loss=1.1513  Acc=0.6246\n",
      "[Pretrain] Epoch 97/150  Loss=1.1578  Acc=0.6175\n",
      "[Pretrain] Epoch 98/150  Loss=1.1561  Acc=0.6221\n",
      "[Pretrain] Epoch 99/150  Loss=1.1473  Acc=0.6250\n",
      "[Pretrain] Epoch 100/150  Loss=1.1678  Acc=0.6198\n",
      "[Pretrain] Epoch 101/150  Loss=1.1620  Acc=0.6169\n",
      "[Pretrain] Epoch 102/150  Loss=1.1491  Acc=0.6221\n",
      "[Pretrain] Epoch 103/150  Loss=1.1523  Acc=0.6236\n",
      "[Pretrain] Epoch 104/150  Loss=1.1661  Acc=0.6158\n",
      "[Pretrain] Epoch 105/150  Loss=1.1517  Acc=0.6236\n",
      "[Pretrain] Epoch 106/150  Loss=1.1613  Acc=0.6237\n",
      "[Pretrain] Epoch 107/150  Loss=1.1537  Acc=0.6203\n",
      "[Pretrain] Epoch 108/150  Loss=1.1514  Acc=0.6237\n",
      "[Pretrain] Epoch 109/150  Loss=1.1517  Acc=0.6225\n",
      "[Pretrain] Epoch 110/150  Loss=1.1452  Acc=0.6252\n",
      "[Pretrain] Epoch 111/150  Loss=1.1554  Acc=0.6291\n",
      "[Pretrain] Epoch 112/150  Loss=1.1395  Acc=0.6266\n",
      "[Pretrain] Epoch 113/150  Loss=1.1398  Acc=0.6288\n",
      "[Pretrain] Epoch 114/150  Loss=1.1544  Acc=0.6110\n",
      "[Pretrain] Epoch 115/150  Loss=1.1425  Acc=0.6241\n",
      "[Pretrain] Epoch 116/150  Loss=1.1409  Acc=0.6259\n",
      "[Pretrain] Epoch 117/150  Loss=1.1583  Acc=0.6198\n",
      "[Pretrain] Epoch 118/150  Loss=1.1457  Acc=0.6171\n",
      "[Pretrain] Epoch 119/150  Loss=1.1513  Acc=0.6232\n",
      "[Pretrain] Epoch 120/150  Loss=1.1369  Acc=0.6255\n",
      "[Pretrain] Epoch 121/150  Loss=1.1276  Acc=0.6358\n",
      "[Pretrain] Epoch 122/150  Loss=1.1524  Acc=0.6221\n",
      "[Pretrain] Epoch 123/150  Loss=1.1448  Acc=0.6340\n",
      "[Pretrain] Epoch 124/150  Loss=1.1396  Acc=0.6230\n",
      "[Pretrain] Epoch 125/150  Loss=1.1599  Acc=0.6245\n",
      "[Pretrain] Epoch 126/150  Loss=1.1406  Acc=0.6257\n",
      "[Pretrain] Epoch 127/150  Loss=1.1585  Acc=0.6205\n",
      "[Pretrain] Epoch 128/150  Loss=1.1395  Acc=0.6252\n",
      "[Pretrain] Epoch 129/150  Loss=1.1468  Acc=0.6196\n",
      "[Pretrain] Epoch 130/150  Loss=1.1541  Acc=0.6203\n",
      "[Pretrain] Epoch 131/150  Loss=1.1419  Acc=0.6194\n",
      "[Pretrain] Epoch 132/150  Loss=1.1403  Acc=0.6243\n",
      "[Pretrain] Epoch 133/150  Loss=1.1392  Acc=0.6230\n",
      "[Pretrain] Epoch 134/150  Loss=1.1393  Acc=0.6234\n",
      "[Pretrain] Epoch 135/150  Loss=1.1378  Acc=0.6243\n",
      "[Pretrain] Epoch 136/150  Loss=1.1367  Acc=0.6264\n",
      "[Pretrain] Epoch 137/150  Loss=1.1560  Acc=0.6214\n",
      "[Pretrain] Epoch 138/150  Loss=1.1440  Acc=0.6261\n",
      "[Pretrain] Epoch 139/150  Loss=1.1420  Acc=0.6273\n",
      "[Pretrain] Epoch 140/150  Loss=1.1528  Acc=0.6176\n",
      "[Pretrain] Epoch 141/150  Loss=1.1530  Acc=0.6164\n",
      "[Pretrain] Epoch 142/150  Loss=1.1389  Acc=0.6295\n",
      "[Pretrain] Epoch 143/150  Loss=1.1530  Acc=0.6230\n",
      "[Pretrain] Epoch 144/150  Loss=1.1375  Acc=0.6275\n",
      "[Pretrain] Epoch 145/150  Loss=1.1393  Acc=0.6223\n",
      "[Pretrain] Epoch 146/150  Loss=1.1538  Acc=0.6209\n",
      "[Pretrain] Epoch 147/150  Loss=1.1519  Acc=0.6295\n",
      "[Pretrain] Epoch 148/150  Loss=1.1489  Acc=0.6302\n",
      "[Pretrain] Epoch 149/150  Loss=1.1406  Acc=0.6230\n",
      "[Pretrain] Epoch 150/150  Loss=1.1470  Acc=0.6228\n",
      "[Fine-tune] Epoch 1/150  Loss=3.2215\n",
      "[Fine-tune] Epoch 2/150  Loss=2.6945\n",
      "[Fine-tune] Epoch 3/150  Loss=2.3603\n",
      "[Fine-tune] Epoch 4/150  Loss=2.2388\n",
      "[Fine-tune] Epoch 5/150  Loss=2.1893\n",
      "[Fine-tune] Epoch 6/150  Loss=2.1389\n",
      "[Fine-tune] Epoch 7/150  Loss=2.0882\n",
      "[Fine-tune] Epoch 8/150  Loss=2.0715\n",
      "[Fine-tune] Epoch 9/150  Loss=2.0283\n",
      "[Fine-tune] Epoch 10/150  Loss=2.0328\n",
      "[Fine-tune] Epoch 11/150  Loss=1.9945\n",
      "[Fine-tune] Epoch 12/150  Loss=1.9684\n",
      "[Fine-tune] Epoch 13/150  Loss=1.9661\n",
      "[Fine-tune] Epoch 14/150  Loss=1.9446\n",
      "[Fine-tune] Epoch 15/150  Loss=1.9177\n",
      "[Fine-tune] Epoch 16/150  Loss=1.9162\n",
      "[Fine-tune] Epoch 17/150  Loss=1.9016\n",
      "[Fine-tune] Epoch 18/150  Loss=1.9051\n",
      "[Fine-tune] Epoch 19/150  Loss=1.8797\n",
      "[Fine-tune] Epoch 20/150  Loss=1.8590\n",
      "[Fine-tune] Epoch 21/150  Loss=1.8711\n",
      "[Fine-tune] Epoch 22/150  Loss=1.8517\n",
      "[Fine-tune] Epoch 23/150  Loss=1.8288\n",
      "[Fine-tune] Epoch 24/150  Loss=1.8308\n",
      "[Fine-tune] Epoch 25/150  Loss=1.8192\n",
      "[Fine-tune] Epoch 26/150  Loss=1.8192\n",
      "[Fine-tune] Epoch 27/150  Loss=1.8060\n",
      "[Fine-tune] Epoch 28/150  Loss=1.8135\n",
      "[Fine-tune] Epoch 29/150  Loss=1.8028\n",
      "[Fine-tune] Epoch 30/150  Loss=1.7759\n",
      "[Fine-tune] Epoch 31/150  Loss=1.8006\n",
      "[Fine-tune] Epoch 32/150  Loss=1.7859\n",
      "[Fine-tune] Epoch 33/150  Loss=1.7681\n",
      "[Fine-tune] Epoch 34/150  Loss=1.7653\n",
      "[Fine-tune] Epoch 35/150  Loss=1.7676\n",
      "[Fine-tune] Epoch 36/150  Loss=1.7582\n",
      "[Fine-tune] Epoch 37/150  Loss=1.7600\n",
      "[Fine-tune] Epoch 38/150  Loss=1.7529\n",
      "[Fine-tune] Epoch 39/150  Loss=1.7463\n",
      "[Fine-tune] Epoch 40/150  Loss=1.7480\n",
      "[Fine-tune] Epoch 41/150  Loss=1.7482\n",
      "[Fine-tune] Epoch 42/150  Loss=1.7418\n",
      "[Fine-tune] Epoch 43/150  Loss=1.7356\n",
      "[Fine-tune] Epoch 44/150  Loss=1.7381\n",
      "[Fine-tune] Epoch 45/150  Loss=1.7234\n",
      "[Fine-tune] Epoch 46/150  Loss=1.7242\n",
      "[Fine-tune] Epoch 47/150  Loss=1.7478\n",
      "[Fine-tune] Epoch 48/150  Loss=1.7350\n",
      "[Fine-tune] Epoch 49/150  Loss=1.7328\n",
      "[Fine-tune] Epoch 50/150  Loss=1.7226\n",
      "[Fine-tune] Epoch 51/150  Loss=1.7127\n",
      "[Fine-tune] Epoch 52/150  Loss=1.7134\n",
      "[Fine-tune] Epoch 53/150  Loss=1.7278\n",
      "[Fine-tune] Epoch 54/150  Loss=1.7154\n",
      "[Fine-tune] Epoch 55/150  Loss=1.7054\n",
      "[Fine-tune] Epoch 56/150  Loss=1.7073\n",
      "[Fine-tune] Epoch 57/150  Loss=1.7175\n",
      "[Fine-tune] Epoch 58/150  Loss=1.7154\n",
      "[Fine-tune] Epoch 59/150  Loss=1.7079\n",
      "[Fine-tune] Epoch 60/150  Loss=1.6976\n",
      "[Fine-tune] Epoch 61/150  Loss=1.7103\n",
      "[Fine-tune] Epoch 62/150  Loss=1.7015\n",
      "[Fine-tune] Epoch 63/150  Loss=1.6891\n",
      "[Fine-tune] Epoch 64/150  Loss=1.7049\n",
      "[Fine-tune] Epoch 65/150  Loss=1.7052\n",
      "[Fine-tune] Epoch 66/150  Loss=1.7007\n",
      "[Fine-tune] Epoch 67/150  Loss=1.6937\n",
      "[Fine-tune] Epoch 68/150  Loss=1.6826\n",
      "[Fine-tune] Epoch 69/150  Loss=1.7038\n",
      "[Fine-tune] Epoch 70/150  Loss=1.6911\n",
      "[Fine-tune] Epoch 71/150  Loss=1.6984\n",
      "[Fine-tune] Epoch 72/150  Loss=1.6858\n",
      "[Fine-tune] Epoch 73/150  Loss=1.6878\n",
      "[Fine-tune] Epoch 74/150  Loss=1.6894\n",
      "[Fine-tune] Epoch 75/150  Loss=1.6919\n",
      "[Fine-tune] Epoch 76/150  Loss=1.6925\n",
      "[Fine-tune] Epoch 77/150  Loss=1.6843\n",
      "[Fine-tune] Epoch 78/150  Loss=1.6941\n",
      "[Fine-tune] Epoch 79/150  Loss=1.6774\n",
      "[Fine-tune] Epoch 80/150  Loss=1.6815\n",
      "[Fine-tune] Epoch 81/150  Loss=1.6824\n",
      "[Fine-tune] Epoch 82/150  Loss=1.6897\n",
      "[Fine-tune] Epoch 83/150  Loss=1.6847\n",
      "[Fine-tune] Epoch 84/150  Loss=1.6924\n",
      "[Fine-tune] Epoch 85/150  Loss=1.6880\n",
      "[Fine-tune] Epoch 86/150  Loss=1.6921\n",
      "[Fine-tune] Epoch 87/150  Loss=1.6805\n",
      "[Fine-tune] Epoch 88/150  Loss=1.6791\n",
      "[Fine-tune] Epoch 89/150  Loss=1.6963\n",
      "[Fine-tune] Epoch 90/150  Loss=1.6806\n",
      "[Fine-tune] Epoch 91/150  Loss=1.6747\n",
      "[Fine-tune] Epoch 92/150  Loss=1.6876\n",
      "[Fine-tune] Epoch 93/150  Loss=1.6934\n",
      "[Fine-tune] Epoch 94/150  Loss=1.6751\n",
      "[Fine-tune] Epoch 95/150  Loss=1.6886\n",
      "[Fine-tune] Epoch 96/150  Loss=1.6894\n",
      "[Fine-tune] Epoch 97/150  Loss=1.6881\n",
      "[Fine-tune] Epoch 98/150  Loss=1.7021\n",
      "[Fine-tune] Epoch 99/150  Loss=1.6699\n",
      "[Fine-tune] Epoch 100/150  Loss=1.6841\n",
      "[Fine-tune] Epoch 101/150  Loss=1.6954\n",
      "[Fine-tune] Epoch 102/150  Loss=1.6834\n",
      "[Fine-tune] Epoch 103/150  Loss=1.6845\n",
      "[Fine-tune] Epoch 104/150  Loss=1.6860\n",
      "[Fine-tune] Epoch 105/150  Loss=1.6895\n",
      "[Fine-tune] Epoch 106/150  Loss=1.6806\n",
      "[Fine-tune] Epoch 107/150  Loss=1.6853\n",
      "[Fine-tune] Epoch 108/150  Loss=1.6888\n",
      "[Fine-tune] Epoch 109/150  Loss=1.6793\n",
      "[Fine-tune] Epoch 110/150  Loss=1.6675\n",
      "[Fine-tune] Epoch 111/150  Loss=1.6944\n",
      "[Fine-tune] Epoch 112/150  Loss=1.6848\n",
      "[Fine-tune] Epoch 113/150  Loss=1.6702\n",
      "[Fine-tune] Epoch 114/150  Loss=1.6736\n",
      "[Fine-tune] Epoch 115/150  Loss=1.6888\n",
      "[Fine-tune] Epoch 116/150  Loss=1.6904\n",
      "[Fine-tune] Epoch 117/150  Loss=1.6784\n",
      "[Fine-tune] Epoch 118/150  Loss=1.6864\n",
      "[Fine-tune] Epoch 119/150  Loss=1.6718\n",
      "[Fine-tune] Epoch 120/150  Loss=1.6923\n",
      "[Fine-tune] Epoch 121/150  Loss=1.6707\n",
      "[Fine-tune] Epoch 122/150  Loss=1.6896\n",
      "[Fine-tune] Epoch 123/150  Loss=1.6741\n",
      "[Fine-tune] Epoch 124/150  Loss=1.6829\n",
      "[Fine-tune] Epoch 125/150  Loss=1.6758\n",
      "[Fine-tune] Epoch 126/150  Loss=1.6805\n",
      "[Fine-tune] Epoch 127/150  Loss=1.6795\n",
      "[Fine-tune] Epoch 128/150  Loss=1.6808\n",
      "[Fine-tune] Epoch 129/150  Loss=1.6783\n",
      "[Fine-tune] Epoch 130/150  Loss=1.6832\n",
      "[Fine-tune] Epoch 131/150  Loss=1.6875\n",
      "[Fine-tune] Epoch 132/150  Loss=1.6804\n",
      "[Fine-tune] Epoch 133/150  Loss=1.6802\n",
      "[Fine-tune] Epoch 134/150  Loss=1.6824\n",
      "[Fine-tune] Epoch 135/150  Loss=1.6866\n",
      "[Fine-tune] Epoch 136/150  Loss=1.6864\n",
      "[Fine-tune] Epoch 137/150  Loss=1.6744\n",
      "[Fine-tune] Epoch 138/150  Loss=1.6764\n",
      "[Fine-tune] Epoch 139/150  Loss=1.6942\n",
      "[Fine-tune] Epoch 140/150  Loss=1.6918\n",
      "[Fine-tune] Epoch 141/150  Loss=1.6791\n",
      "[Fine-tune] Epoch 142/150  Loss=1.6914\n",
      "[Fine-tune] Epoch 143/150  Loss=1.6782\n",
      "[Fine-tune] Epoch 144/150  Loss=1.6915\n",
      "[Fine-tune] Epoch 145/150  Loss=1.6800\n",
      "[Fine-tune] Epoch 146/150  Loss=1.6863\n",
      "[Fine-tune] Epoch 147/150  Loss=1.6824\n",
      "[Fine-tune] Epoch 148/150  Loss=1.6842\n",
      "[Fine-tune] Epoch 149/150  Loss=1.6853\n",
      "[Fine-tune] Epoch 150/150  Loss=1.6762\n",
      "[Pretrain] Epoch 1/50  Loss=3.1882  Acc=0.0602\n",
      "[Pretrain] Epoch 2/50  Loss=3.0597  Acc=0.0826\n",
      "[Pretrain] Epoch 3/50  Loss=2.7851  Acc=0.1372\n",
      "[Pretrain] Epoch 4/50  Loss=2.5272  Acc=0.1886\n",
      "[Pretrain] Epoch 5/50  Loss=2.4202  Acc=0.2259\n",
      "[Pretrain] Epoch 6/50  Loss=2.2875  Acc=0.2640\n",
      "[Pretrain] Epoch 7/50  Loss=2.1986  Acc=0.2904\n",
      "[Pretrain] Epoch 8/50  Loss=2.1215  Acc=0.3087\n",
      "[Pretrain] Epoch 9/50  Loss=2.0798  Acc=0.3233\n",
      "[Pretrain] Epoch 10/50  Loss=2.0283  Acc=0.3459\n",
      "[Pretrain] Epoch 11/50  Loss=2.0086  Acc=0.3385\n",
      "[Pretrain] Epoch 12/50  Loss=1.9718  Acc=0.3522\n",
      "[Pretrain] Epoch 13/50  Loss=1.9157  Acc=0.3698\n",
      "[Pretrain] Epoch 14/50  Loss=1.9291  Acc=0.3667\n",
      "[Pretrain] Epoch 15/50  Loss=1.8713  Acc=0.3861\n",
      "[Pretrain] Epoch 16/50  Loss=1.8710  Acc=0.3883\n",
      "[Pretrain] Epoch 17/50  Loss=1.8218  Acc=0.4115\n",
      "[Pretrain] Epoch 18/50  Loss=1.8081  Acc=0.4124\n",
      "[Pretrain] Epoch 19/50  Loss=1.7784  Acc=0.4249\n",
      "[Pretrain] Epoch 20/50  Loss=1.7759  Acc=0.4310\n",
      "[Pretrain] Epoch 21/50  Loss=1.7343  Acc=0.4362\n",
      "[Pretrain] Epoch 22/50  Loss=1.7286  Acc=0.4388\n",
      "[Pretrain] Epoch 23/50  Loss=1.7124  Acc=0.4470\n",
      "[Pretrain] Epoch 24/50  Loss=1.6767  Acc=0.4580\n",
      "[Pretrain] Epoch 25/50  Loss=1.6760  Acc=0.4657\n",
      "[Pretrain] Epoch 26/50  Loss=1.6488  Acc=0.4689\n",
      "[Pretrain] Epoch 27/50  Loss=1.6429  Acc=0.4675\n",
      "[Pretrain] Epoch 28/50  Loss=1.6303  Acc=0.4668\n",
      "[Pretrain] Epoch 29/50  Loss=1.5955  Acc=0.4774\n",
      "[Pretrain] Epoch 30/50  Loss=1.5882  Acc=0.4795\n",
      "[Pretrain] Epoch 31/50  Loss=1.5634  Acc=0.4917\n",
      "[Pretrain] Epoch 32/50  Loss=1.5418  Acc=0.4964\n",
      "[Pretrain] Epoch 33/50  Loss=1.5339  Acc=0.5018\n",
      "[Pretrain] Epoch 34/50  Loss=1.5241  Acc=0.5007\n",
      "[Pretrain] Epoch 35/50  Loss=1.5289  Acc=0.5061\n",
      "[Pretrain] Epoch 36/50  Loss=1.4982  Acc=0.5129\n",
      "[Pretrain] Epoch 37/50  Loss=1.4795  Acc=0.5201\n",
      "[Pretrain] Epoch 38/50  Loss=1.4792  Acc=0.5207\n",
      "[Pretrain] Epoch 39/50  Loss=1.4643  Acc=0.5266\n",
      "[Pretrain] Epoch 40/50  Loss=1.4322  Acc=0.5413\n",
      "[Pretrain] Epoch 41/50  Loss=1.4556  Acc=0.5217\n",
      "[Pretrain] Epoch 42/50  Loss=1.4343  Acc=0.5321\n",
      "[Pretrain] Epoch 43/50  Loss=1.4251  Acc=0.5401\n",
      "[Pretrain] Epoch 44/50  Loss=1.4165  Acc=0.5401\n",
      "[Pretrain] Epoch 45/50  Loss=1.3919  Acc=0.5445\n",
      "[Pretrain] Epoch 46/50  Loss=1.4148  Acc=0.5404\n",
      "[Pretrain] Epoch 47/50  Loss=1.3914  Acc=0.5426\n",
      "[Pretrain] Epoch 48/50  Loss=1.3907  Acc=0.5487\n",
      "[Pretrain] Epoch 49/50  Loss=1.3670  Acc=0.5542\n",
      "[Pretrain] Epoch 50/50  Loss=1.3741  Acc=0.5537\n",
      "[Fine-tune] Epoch 1/150  Loss=3.2917\n",
      "[Fine-tune] Epoch 2/150  Loss=3.2190\n",
      "[Fine-tune] Epoch 3/150  Loss=3.1087\n",
      "[Fine-tune] Epoch 4/150  Loss=3.0549\n",
      "[Fine-tune] Epoch 5/150  Loss=3.0175\n",
      "[Fine-tune] Epoch 6/150  Loss=2.8606\n",
      "[Fine-tune] Epoch 7/150  Loss=2.7581\n",
      "[Fine-tune] Epoch 8/150  Loss=2.6838\n",
      "[Fine-tune] Epoch 9/150  Loss=2.5854\n",
      "[Fine-tune] Epoch 10/150  Loss=2.5212\n",
      "[Fine-tune] Epoch 11/150  Loss=2.5053\n",
      "[Fine-tune] Epoch 12/150  Loss=2.4531\n",
      "[Fine-tune] Epoch 13/150  Loss=2.4046\n",
      "[Fine-tune] Epoch 14/150  Loss=2.3440\n",
      "[Fine-tune] Epoch 15/150  Loss=2.3157\n",
      "[Fine-tune] Epoch 16/150  Loss=2.2399\n",
      "[Fine-tune] Epoch 17/150  Loss=2.2078\n",
      "[Fine-tune] Epoch 18/150  Loss=2.1738\n",
      "[Fine-tune] Epoch 19/150  Loss=2.1286\n",
      "[Fine-tune] Epoch 20/150  Loss=2.1335\n",
      "[Fine-tune] Epoch 21/150  Loss=2.0703\n",
      "[Fine-tune] Epoch 22/150  Loss=2.0477\n",
      "[Fine-tune] Epoch 23/150  Loss=2.0365\n",
      "[Fine-tune] Epoch 24/150  Loss=2.0040\n",
      "[Fine-tune] Epoch 25/150  Loss=1.9859\n",
      "[Fine-tune] Epoch 26/150  Loss=1.9661\n",
      "[Fine-tune] Epoch 27/150  Loss=1.9474\n",
      "[Fine-tune] Epoch 28/150  Loss=1.9228\n",
      "[Fine-tune] Epoch 29/150  Loss=1.9246\n",
      "[Fine-tune] Epoch 30/150  Loss=1.8879\n",
      "[Fine-tune] Epoch 31/150  Loss=1.8864\n",
      "[Fine-tune] Epoch 32/150  Loss=1.8457\n",
      "[Fine-tune] Epoch 33/150  Loss=1.8457\n",
      "[Fine-tune] Epoch 34/150  Loss=1.8237\n",
      "[Fine-tune] Epoch 35/150  Loss=1.8098\n",
      "[Fine-tune] Epoch 36/150  Loss=1.7847\n",
      "[Fine-tune] Epoch 37/150  Loss=1.7710\n",
      "[Fine-tune] Epoch 38/150  Loss=1.7509\n",
      "[Fine-tune] Epoch 39/150  Loss=1.7510\n",
      "[Fine-tune] Epoch 40/150  Loss=1.7279\n",
      "[Fine-tune] Epoch 41/150  Loss=1.7184\n",
      "[Fine-tune] Epoch 42/150  Loss=1.7162\n",
      "[Fine-tune] Epoch 43/150  Loss=1.6904\n",
      "[Fine-tune] Epoch 44/150  Loss=1.6815\n",
      "[Fine-tune] Epoch 45/150  Loss=1.6785\n",
      "[Fine-tune] Epoch 46/150  Loss=1.6780\n",
      "[Fine-tune] Epoch 47/150  Loss=1.6816\n",
      "[Fine-tune] Epoch 48/150  Loss=1.6499\n",
      "[Fine-tune] Epoch 49/150  Loss=1.6376\n",
      "[Fine-tune] Epoch 50/150  Loss=1.6376\n",
      "[Fine-tune] Epoch 51/150  Loss=1.6367\n",
      "[Fine-tune] Epoch 52/150  Loss=1.6192\n",
      "[Fine-tune] Epoch 53/150  Loss=1.6141\n",
      "[Fine-tune] Epoch 54/150  Loss=1.6018\n",
      "[Fine-tune] Epoch 55/150  Loss=1.6024\n",
      "[Fine-tune] Epoch 56/150  Loss=1.5735\n",
      "[Fine-tune] Epoch 57/150  Loss=1.5660\n",
      "[Fine-tune] Epoch 58/150  Loss=1.5786\n",
      "[Fine-tune] Epoch 59/150  Loss=1.5772\n",
      "[Fine-tune] Epoch 60/150  Loss=1.5798\n",
      "[Fine-tune] Epoch 61/150  Loss=1.5637\n",
      "[Fine-tune] Epoch 62/150  Loss=1.5691\n",
      "[Fine-tune] Epoch 63/150  Loss=1.5553\n",
      "[Fine-tune] Epoch 64/150  Loss=1.5417\n",
      "[Fine-tune] Epoch 65/150  Loss=1.5403\n",
      "[Fine-tune] Epoch 66/150  Loss=1.5495\n",
      "[Fine-tune] Epoch 67/150  Loss=1.5289\n",
      "[Fine-tune] Epoch 68/150  Loss=1.5408\n",
      "[Fine-tune] Epoch 69/150  Loss=1.5237\n",
      "[Fine-tune] Epoch 70/150  Loss=1.5267\n",
      "[Fine-tune] Epoch 71/150  Loss=1.5254\n",
      "[Fine-tune] Epoch 72/150  Loss=1.5230\n",
      "[Fine-tune] Epoch 73/150  Loss=1.5252\n",
      "[Fine-tune] Epoch 74/150  Loss=1.5136\n",
      "[Fine-tune] Epoch 75/150  Loss=1.5091\n",
      "[Fine-tune] Epoch 76/150  Loss=1.5143\n",
      "[Fine-tune] Epoch 77/150  Loss=1.4987\n",
      "[Fine-tune] Epoch 78/150  Loss=1.4987\n",
      "[Fine-tune] Epoch 79/150  Loss=1.5160\n",
      "[Fine-tune] Epoch 80/150  Loss=1.5061\n",
      "[Fine-tune] Epoch 81/150  Loss=1.4936\n",
      "[Fine-tune] Epoch 82/150  Loss=1.4970\n",
      "[Fine-tune] Epoch 83/150  Loss=1.4932\n",
      "[Fine-tune] Epoch 84/150  Loss=1.4920\n",
      "[Fine-tune] Epoch 85/150  Loss=1.5014\n",
      "[Fine-tune] Epoch 86/150  Loss=1.5040\n",
      "[Fine-tune] Epoch 87/150  Loss=1.4854\n",
      "[Fine-tune] Epoch 88/150  Loss=1.4795\n",
      "[Fine-tune] Epoch 89/150  Loss=1.5093\n",
      "[Fine-tune] Epoch 90/150  Loss=1.4773\n",
      "[Fine-tune] Epoch 91/150  Loss=1.4826\n",
      "[Fine-tune] Epoch 92/150  Loss=1.4822\n",
      "[Fine-tune] Epoch 93/150  Loss=1.4948\n",
      "[Fine-tune] Epoch 94/150  Loss=1.4844\n",
      "[Fine-tune] Epoch 95/150  Loss=1.4965\n",
      "[Fine-tune] Epoch 96/150  Loss=1.4825\n",
      "[Fine-tune] Epoch 97/150  Loss=1.4700\n",
      "[Fine-tune] Epoch 98/150  Loss=1.4702\n",
      "[Fine-tune] Epoch 99/150  Loss=1.4704\n",
      "[Fine-tune] Epoch 100/150  Loss=1.4932\n",
      "[Fine-tune] Epoch 101/150  Loss=1.4798\n",
      "[Fine-tune] Epoch 102/150  Loss=1.4824\n",
      "[Fine-tune] Epoch 103/150  Loss=1.4639\n",
      "[Fine-tune] Epoch 104/150  Loss=1.4773\n",
      "[Fine-tune] Epoch 105/150  Loss=1.4690\n",
      "[Fine-tune] Epoch 106/150  Loss=1.4692\n",
      "[Fine-tune] Epoch 107/150  Loss=1.4693\n",
      "[Fine-tune] Epoch 108/150  Loss=1.4745\n",
      "[Fine-tune] Epoch 109/150  Loss=1.4699\n",
      "[Fine-tune] Epoch 110/150  Loss=1.4630\n",
      "[Fine-tune] Epoch 111/150  Loss=1.4711\n",
      "[Fine-tune] Epoch 112/150  Loss=1.4594\n",
      "[Fine-tune] Epoch 113/150  Loss=1.4759\n",
      "[Fine-tune] Epoch 114/150  Loss=1.4697\n",
      "[Fine-tune] Epoch 115/150  Loss=1.4656\n",
      "[Fine-tune] Epoch 116/150  Loss=1.4590\n",
      "[Fine-tune] Epoch 117/150  Loss=1.4782\n",
      "[Fine-tune] Epoch 118/150  Loss=1.4611\n",
      "[Fine-tune] Epoch 119/150  Loss=1.4705\n",
      "[Fine-tune] Epoch 120/150  Loss=1.4545\n",
      "[Fine-tune] Epoch 121/150  Loss=1.4714\n",
      "[Fine-tune] Epoch 122/150  Loss=1.4623\n",
      "[Fine-tune] Epoch 123/150  Loss=1.4563\n",
      "[Fine-tune] Epoch 124/150  Loss=1.4640\n",
      "[Fine-tune] Epoch 125/150  Loss=1.4557\n",
      "[Fine-tune] Epoch 126/150  Loss=1.4741\n",
      "[Fine-tune] Epoch 127/150  Loss=1.4674\n",
      "[Fine-tune] Epoch 128/150  Loss=1.4722\n",
      "[Fine-tune] Epoch 129/150  Loss=1.4921\n",
      "[Fine-tune] Epoch 130/150  Loss=1.4553\n",
      "[Fine-tune] Epoch 131/150  Loss=1.4732\n",
      "[Fine-tune] Epoch 132/150  Loss=1.4678\n",
      "[Fine-tune] Epoch 133/150  Loss=1.4585\n",
      "[Fine-tune] Epoch 134/150  Loss=1.4640\n",
      "[Fine-tune] Epoch 135/150  Loss=1.4690\n",
      "[Fine-tune] Epoch 136/150  Loss=1.4607\n",
      "[Fine-tune] Epoch 137/150  Loss=1.4699\n",
      "[Fine-tune] Epoch 138/150  Loss=1.4573\n",
      "[Fine-tune] Epoch 139/150  Loss=1.4742\n",
      "[Fine-tune] Epoch 140/150  Loss=1.4554\n",
      "[Fine-tune] Epoch 141/150  Loss=1.4645\n",
      "[Fine-tune] Epoch 142/150  Loss=1.4622\n",
      "[Fine-tune] Epoch 143/150  Loss=1.4619\n",
      "[Fine-tune] Epoch 144/150  Loss=1.4665\n",
      "[Fine-tune] Epoch 145/150  Loss=1.4648\n",
      "[Fine-tune] Epoch 146/150  Loss=1.4646\n",
      "[Fine-tune] Epoch 147/150  Loss=1.4481\n",
      "[Fine-tune] Epoch 148/150  Loss=1.4592\n",
      "[Fine-tune] Epoch 149/150  Loss=1.4571\n",
      "[Fine-tune] Epoch 150/150  Loss=1.4733\n",
      "[Pretrain] Epoch 1/50  Loss=3.6290  Acc=0.0420\n",
      "[Pretrain] Epoch 2/50  Loss=3.1564  Acc=0.0706\n",
      "[Pretrain] Epoch 3/50  Loss=3.0313  Acc=0.0934\n",
      "[Pretrain] Epoch 4/50  Loss=2.7099  Acc=0.1494\n",
      "[Pretrain] Epoch 5/50  Loss=2.5243  Acc=0.1967\n",
      "[Pretrain] Epoch 6/50  Loss=2.4189  Acc=0.2290\n",
      "[Pretrain] Epoch 7/50  Loss=2.3285  Acc=0.2527\n",
      "[Pretrain] Epoch 8/50  Loss=2.2704  Acc=0.2658\n",
      "[Pretrain] Epoch 9/50  Loss=2.1726  Acc=0.3010\n",
      "[Pretrain] Epoch 10/50  Loss=2.1728  Acc=0.2980\n",
      "[Pretrain] Epoch 11/50  Loss=2.1044  Acc=0.3188\n",
      "[Pretrain] Epoch 12/50  Loss=2.0838  Acc=0.3215\n",
      "[Pretrain] Epoch 13/50  Loss=2.0418  Acc=0.3369\n",
      "[Pretrain] Epoch 14/50  Loss=2.0122  Acc=0.3464\n",
      "[Pretrain] Epoch 15/50  Loss=1.9694  Acc=0.3560\n",
      "[Pretrain] Epoch 16/50  Loss=1.9609  Acc=0.3635\n",
      "[Pretrain] Epoch 17/50  Loss=1.9350  Acc=0.3754\n",
      "[Pretrain] Epoch 18/50  Loss=1.9044  Acc=0.3906\n",
      "[Pretrain] Epoch 19/50  Loss=1.8858  Acc=0.3921\n",
      "[Pretrain] Epoch 20/50  Loss=1.8736  Acc=0.3851\n",
      "[Pretrain] Epoch 21/50  Loss=1.8353  Acc=0.4071\n",
      "[Pretrain] Epoch 22/50  Loss=1.7949  Acc=0.4174\n",
      "[Pretrain] Epoch 23/50  Loss=1.7838  Acc=0.4255\n",
      "[Pretrain] Epoch 24/50  Loss=1.7489  Acc=0.4260\n",
      "[Pretrain] Epoch 25/50  Loss=1.7456  Acc=0.4375\n",
      "[Pretrain] Epoch 26/50  Loss=1.7172  Acc=0.4423\n",
      "[Pretrain] Epoch 27/50  Loss=1.6967  Acc=0.4511\n",
      "[Pretrain] Epoch 28/50  Loss=1.6553  Acc=0.4625\n",
      "[Pretrain] Epoch 29/50  Loss=1.6217  Acc=0.4768\n",
      "[Pretrain] Epoch 30/50  Loss=1.6382  Acc=0.4722\n",
      "[Pretrain] Epoch 31/50  Loss=1.6195  Acc=0.4655\n",
      "[Pretrain] Epoch 32/50  Loss=1.5605  Acc=0.4941\n",
      "[Pretrain] Epoch 33/50  Loss=1.5306  Acc=0.4995\n",
      "[Pretrain] Epoch 34/50  Loss=1.5363  Acc=0.5018\n",
      "[Pretrain] Epoch 35/50  Loss=1.5170  Acc=0.5102\n",
      "[Pretrain] Epoch 36/50  Loss=1.4900  Acc=0.5145\n",
      "[Pretrain] Epoch 37/50  Loss=1.4596  Acc=0.5268\n",
      "[Pretrain] Epoch 38/50  Loss=1.4394  Acc=0.5286\n",
      "[Pretrain] Epoch 39/50  Loss=1.4162  Acc=0.5348\n",
      "[Pretrain] Epoch 40/50  Loss=1.4260  Acc=0.5418\n",
      "[Pretrain] Epoch 41/50  Loss=1.4031  Acc=0.5436\n",
      "[Pretrain] Epoch 42/50  Loss=1.3642  Acc=0.5580\n",
      "[Pretrain] Epoch 43/50  Loss=1.3545  Acc=0.5564\n",
      "[Pretrain] Epoch 44/50  Loss=1.3493  Acc=0.5575\n",
      "[Pretrain] Epoch 45/50  Loss=1.3128  Acc=0.5751\n",
      "[Pretrain] Epoch 46/50  Loss=1.2984  Acc=0.5805\n",
      "[Pretrain] Epoch 47/50  Loss=1.2877  Acc=0.5745\n",
      "[Pretrain] Epoch 48/50  Loss=1.2954  Acc=0.5776\n",
      "[Pretrain] Epoch 49/50  Loss=1.2950  Acc=0.5785\n",
      "[Pretrain] Epoch 50/50  Loss=1.2815  Acc=0.5823\n",
      "[Fine-tune] Epoch 1/150  Loss=3.3156\n",
      "[Fine-tune] Epoch 2/150  Loss=3.0409\n",
      "[Fine-tune] Epoch 3/150  Loss=2.8062\n",
      "[Fine-tune] Epoch 4/150  Loss=2.6844\n",
      "[Fine-tune] Epoch 5/150  Loss=2.5921\n",
      "[Fine-tune] Epoch 6/150  Loss=2.4922\n",
      "[Fine-tune] Epoch 7/150  Loss=2.4138\n",
      "[Fine-tune] Epoch 8/150  Loss=2.3469\n",
      "[Fine-tune] Epoch 9/150  Loss=2.3255\n",
      "[Fine-tune] Epoch 10/150  Loss=2.2658\n",
      "[Fine-tune] Epoch 11/150  Loss=2.2319\n",
      "[Fine-tune] Epoch 12/150  Loss=2.1620\n",
      "[Fine-tune] Epoch 13/150  Loss=2.1300\n",
      "[Fine-tune] Epoch 14/150  Loss=2.0985\n",
      "[Fine-tune] Epoch 15/150  Loss=2.0644\n",
      "[Fine-tune] Epoch 16/150  Loss=2.0464\n",
      "[Fine-tune] Epoch 17/150  Loss=2.0305\n",
      "[Fine-tune] Epoch 18/150  Loss=1.9779\n",
      "[Fine-tune] Epoch 19/150  Loss=1.9692\n",
      "[Fine-tune] Epoch 20/150  Loss=1.9388\n",
      "[Fine-tune] Epoch 21/150  Loss=1.9255\n",
      "[Fine-tune] Epoch 22/150  Loss=1.8914\n",
      "[Fine-tune] Epoch 23/150  Loss=1.8754\n",
      "[Fine-tune] Epoch 24/150  Loss=1.8632\n",
      "[Fine-tune] Epoch 25/150  Loss=1.8440\n",
      "[Fine-tune] Epoch 26/150  Loss=1.8118\n",
      "[Fine-tune] Epoch 27/150  Loss=1.7955\n",
      "[Fine-tune] Epoch 28/150  Loss=1.7760\n",
      "[Fine-tune] Epoch 29/150  Loss=1.7845\n",
      "[Fine-tune] Epoch 30/150  Loss=1.7493\n",
      "[Fine-tune] Epoch 31/150  Loss=1.7501\n",
      "[Fine-tune] Epoch 32/150  Loss=1.7201\n",
      "[Fine-tune] Epoch 33/150  Loss=1.7116\n",
      "[Fine-tune] Epoch 34/150  Loss=1.7087\n",
      "[Fine-tune] Epoch 35/150  Loss=1.6912\n",
      "[Fine-tune] Epoch 36/150  Loss=1.6825\n",
      "[Fine-tune] Epoch 37/150  Loss=1.6494\n",
      "[Fine-tune] Epoch 38/150  Loss=1.6350\n",
      "[Fine-tune] Epoch 39/150  Loss=1.6321\n",
      "[Fine-tune] Epoch 40/150  Loss=1.6347\n",
      "[Fine-tune] Epoch 41/150  Loss=1.6224\n",
      "[Fine-tune] Epoch 42/150  Loss=1.6069\n",
      "[Fine-tune] Epoch 43/150  Loss=1.5959\n",
      "[Fine-tune] Epoch 44/150  Loss=1.6012\n",
      "[Fine-tune] Epoch 45/150  Loss=1.5864\n",
      "[Fine-tune] Epoch 46/150  Loss=1.5794\n",
      "[Fine-tune] Epoch 47/150  Loss=1.5704\n",
      "[Fine-tune] Epoch 48/150  Loss=1.5701\n",
      "[Fine-tune] Epoch 49/150  Loss=1.5662\n",
      "[Fine-tune] Epoch 50/150  Loss=1.5568\n",
      "[Fine-tune] Epoch 51/150  Loss=1.5510\n",
      "[Fine-tune] Epoch 52/150  Loss=1.5480\n",
      "[Fine-tune] Epoch 53/150  Loss=1.5429\n",
      "[Fine-tune] Epoch 54/150  Loss=1.5282\n",
      "[Fine-tune] Epoch 55/150  Loss=1.5305\n",
      "[Fine-tune] Epoch 56/150  Loss=1.5266\n",
      "[Fine-tune] Epoch 57/150  Loss=1.5329\n",
      "[Fine-tune] Epoch 58/150  Loss=1.5314\n",
      "[Fine-tune] Epoch 59/150  Loss=1.5044\n",
      "[Fine-tune] Epoch 60/150  Loss=1.5110\n",
      "[Fine-tune] Epoch 61/150  Loss=1.4996\n",
      "[Fine-tune] Epoch 62/150  Loss=1.4976\n",
      "[Fine-tune] Epoch 63/150  Loss=1.4833\n",
      "[Fine-tune] Epoch 64/150  Loss=1.4909\n",
      "[Fine-tune] Epoch 65/150  Loss=1.4925\n",
      "[Fine-tune] Epoch 66/150  Loss=1.4911\n",
      "[Fine-tune] Epoch 67/150  Loss=1.4870\n",
      "[Fine-tune] Epoch 68/150  Loss=1.4868\n",
      "[Fine-tune] Epoch 69/150  Loss=1.4875\n",
      "[Fine-tune] Epoch 70/150  Loss=1.4819\n",
      "[Fine-tune] Epoch 71/150  Loss=1.4719\n",
      "[Fine-tune] Epoch 72/150  Loss=1.4745\n",
      "[Fine-tune] Epoch 73/150  Loss=1.4632\n",
      "[Fine-tune] Epoch 74/150  Loss=1.4578\n",
      "[Fine-tune] Epoch 75/150  Loss=1.4602\n",
      "[Fine-tune] Epoch 76/150  Loss=1.4652\n",
      "[Fine-tune] Epoch 77/150  Loss=1.4608\n",
      "[Fine-tune] Epoch 78/150  Loss=1.4671\n",
      "[Fine-tune] Epoch 79/150  Loss=1.4504\n",
      "[Fine-tune] Epoch 80/150  Loss=1.4475\n",
      "[Fine-tune] Epoch 81/150  Loss=1.4680\n",
      "[Fine-tune] Epoch 82/150  Loss=1.4557\n",
      "[Fine-tune] Epoch 83/150  Loss=1.4620\n",
      "[Fine-tune] Epoch 84/150  Loss=1.4539\n",
      "[Fine-tune] Epoch 85/150  Loss=1.4513\n",
      "[Fine-tune] Epoch 86/150  Loss=1.4534\n",
      "[Fine-tune] Epoch 87/150  Loss=1.4484\n",
      "[Fine-tune] Epoch 88/150  Loss=1.4540\n",
      "[Fine-tune] Epoch 89/150  Loss=1.4535\n",
      "[Fine-tune] Epoch 90/150  Loss=1.4481\n",
      "[Fine-tune] Epoch 91/150  Loss=1.4479\n",
      "[Fine-tune] Epoch 92/150  Loss=1.4399\n",
      "[Fine-tune] Epoch 93/150  Loss=1.4608\n",
      "[Fine-tune] Epoch 94/150  Loss=1.4425\n",
      "[Fine-tune] Epoch 95/150  Loss=1.4452\n",
      "[Fine-tune] Epoch 96/150  Loss=1.4483\n",
      "[Fine-tune] Epoch 97/150  Loss=1.4398\n",
      "[Fine-tune] Epoch 98/150  Loss=1.4408\n",
      "[Fine-tune] Epoch 99/150  Loss=1.4304\n",
      "[Fine-tune] Epoch 100/150  Loss=1.4370\n",
      "[Fine-tune] Epoch 101/150  Loss=1.4385\n",
      "[Fine-tune] Epoch 102/150  Loss=1.4357\n",
      "[Fine-tune] Epoch 103/150  Loss=1.4412\n",
      "[Fine-tune] Epoch 104/150  Loss=1.4336\n",
      "[Fine-tune] Epoch 105/150  Loss=1.4433\n",
      "[Fine-tune] Epoch 106/150  Loss=1.4340\n",
      "[Fine-tune] Epoch 107/150  Loss=1.4386\n",
      "[Fine-tune] Epoch 108/150  Loss=1.4437\n",
      "[Fine-tune] Epoch 109/150  Loss=1.4271\n",
      "[Fine-tune] Epoch 110/150  Loss=1.4408\n",
      "[Fine-tune] Epoch 111/150  Loss=1.4395\n",
      "[Fine-tune] Epoch 112/150  Loss=1.4391\n",
      "[Fine-tune] Epoch 113/150  Loss=1.4352\n",
      "[Fine-tune] Epoch 114/150  Loss=1.4487\n",
      "[Fine-tune] Epoch 115/150  Loss=1.4471\n",
      "[Fine-tune] Epoch 116/150  Loss=1.4206\n",
      "[Fine-tune] Epoch 117/150  Loss=1.4348\n",
      "[Fine-tune] Epoch 118/150  Loss=1.4263\n",
      "[Fine-tune] Epoch 119/150  Loss=1.4450\n",
      "[Fine-tune] Epoch 120/150  Loss=1.4352\n",
      "[Fine-tune] Epoch 121/150  Loss=1.4329\n",
      "[Fine-tune] Epoch 122/150  Loss=1.4368\n",
      "[Fine-tune] Epoch 123/150  Loss=1.4227\n",
      "[Fine-tune] Epoch 124/150  Loss=1.4540\n",
      "[Fine-tune] Epoch 125/150  Loss=1.4269\n",
      "[Fine-tune] Epoch 126/150  Loss=1.4339\n",
      "[Fine-tune] Epoch 127/150  Loss=1.4285\n",
      "[Fine-tune] Epoch 128/150  Loss=1.4307\n",
      "[Fine-tune] Epoch 129/150  Loss=1.4192\n",
      "[Fine-tune] Epoch 130/150  Loss=1.4402\n",
      "[Fine-tune] Epoch 131/150  Loss=1.4204\n",
      "[Fine-tune] Epoch 132/150  Loss=1.4358\n",
      "[Fine-tune] Epoch 133/150  Loss=1.4379\n",
      "[Fine-tune] Epoch 134/150  Loss=1.4420\n",
      "[Fine-tune] Epoch 135/150  Loss=1.4336\n",
      "[Fine-tune] Epoch 136/150  Loss=1.4317\n",
      "[Fine-tune] Epoch 137/150  Loss=1.4444\n",
      "[Fine-tune] Epoch 138/150  Loss=1.4294\n",
      "[Fine-tune] Epoch 139/150  Loss=1.4448\n",
      "[Fine-tune] Epoch 140/150  Loss=1.4300\n",
      "[Fine-tune] Epoch 141/150  Loss=1.4250\n",
      "[Fine-tune] Epoch 142/150  Loss=1.4384\n",
      "[Fine-tune] Epoch 143/150  Loss=1.4297\n",
      "[Fine-tune] Epoch 144/150  Loss=1.4338\n",
      "[Fine-tune] Epoch 145/150  Loss=1.4275\n",
      "[Fine-tune] Epoch 146/150  Loss=1.4347\n",
      "[Fine-tune] Epoch 147/150  Loss=1.4210\n",
      "[Fine-tune] Epoch 148/150  Loss=1.4357\n",
      "[Fine-tune] Epoch 149/150  Loss=1.4237\n",
      "[Fine-tune] Epoch 150/150  Loss=1.4417\n",
      "[Pretrain] Epoch 1/75  Loss=3.2101  Acc=0.0474\n",
      "[Pretrain] Epoch 2/75  Loss=3.0721  Acc=0.0753\n",
      "[Pretrain] Epoch 3/75  Loss=2.9691  Acc=0.0981\n",
      "[Pretrain] Epoch 4/75  Loss=2.6585  Acc=0.1642\n",
      "[Pretrain] Epoch 5/75  Loss=2.4494  Acc=0.2189\n",
      "[Pretrain] Epoch 6/75  Loss=2.3231  Acc=0.2615\n",
      "[Pretrain] Epoch 7/75  Loss=2.2454  Acc=0.2760\n",
      "[Pretrain] Epoch 8/75  Loss=2.1330  Acc=0.3039\n",
      "[Pretrain] Epoch 9/75  Loss=2.1103  Acc=0.3188\n",
      "[Pretrain] Epoch 10/75  Loss=2.0528  Acc=0.3337\n",
      "[Pretrain] Epoch 11/75  Loss=2.0236  Acc=0.3446\n",
      "[Pretrain] Epoch 12/75  Loss=1.9802  Acc=0.3540\n",
      "[Pretrain] Epoch 13/75  Loss=1.9431  Acc=0.3657\n",
      "[Pretrain] Epoch 14/75  Loss=1.9261  Acc=0.3737\n",
      "[Pretrain] Epoch 15/75  Loss=1.9037  Acc=0.3766\n",
      "[Pretrain] Epoch 16/75  Loss=1.8646  Acc=0.3874\n",
      "[Pretrain] Epoch 17/75  Loss=1.8403  Acc=0.3926\n",
      "[Pretrain] Epoch 18/75  Loss=1.8104  Acc=0.4106\n",
      "[Pretrain] Epoch 19/75  Loss=1.7890  Acc=0.4224\n",
      "[Pretrain] Epoch 20/75  Loss=1.7692  Acc=0.4262\n",
      "[Pretrain] Epoch 21/75  Loss=1.7529  Acc=0.4327\n",
      "[Pretrain] Epoch 22/75  Loss=1.7386  Acc=0.4310\n",
      "[Pretrain] Epoch 23/75  Loss=1.7194  Acc=0.4479\n",
      "[Pretrain] Epoch 24/75  Loss=1.7068  Acc=0.4499\n",
      "[Pretrain] Epoch 25/75  Loss=1.6799  Acc=0.4574\n",
      "[Pretrain] Epoch 26/75  Loss=1.6691  Acc=0.4616\n",
      "[Pretrain] Epoch 27/75  Loss=1.6425  Acc=0.4657\n",
      "[Pretrain] Epoch 28/75  Loss=1.6247  Acc=0.4790\n",
      "[Pretrain] Epoch 29/75  Loss=1.6093  Acc=0.4788\n",
      "[Pretrain] Epoch 30/75  Loss=1.5855  Acc=0.4874\n",
      "[Pretrain] Epoch 31/75  Loss=1.5924  Acc=0.4784\n",
      "[Pretrain] Epoch 32/75  Loss=1.5804  Acc=0.4855\n",
      "[Pretrain] Epoch 33/75  Loss=1.5736  Acc=0.4844\n",
      "[Pretrain] Epoch 34/75  Loss=1.5423  Acc=0.5074\n",
      "[Pretrain] Epoch 35/75  Loss=1.5046  Acc=0.5086\n",
      "[Pretrain] Epoch 36/75  Loss=1.5087  Acc=0.5122\n",
      "[Pretrain] Epoch 37/75  Loss=1.4932  Acc=0.5167\n",
      "[Pretrain] Epoch 38/75  Loss=1.5034  Acc=0.5124\n",
      "[Pretrain] Epoch 39/75  Loss=1.4905  Acc=0.5135\n",
      "[Pretrain] Epoch 40/75  Loss=1.4543  Acc=0.5309\n",
      "[Pretrain] Epoch 41/75  Loss=1.4472  Acc=0.5262\n",
      "[Pretrain] Epoch 42/75  Loss=1.4717  Acc=0.5286\n",
      "[Pretrain] Epoch 43/75  Loss=1.4419  Acc=0.5277\n",
      "[Pretrain] Epoch 44/75  Loss=1.4391  Acc=0.5298\n",
      "[Pretrain] Epoch 45/75  Loss=1.4267  Acc=0.5381\n",
      "[Pretrain] Epoch 46/75  Loss=1.4329  Acc=0.5318\n",
      "[Pretrain] Epoch 47/75  Loss=1.3942  Acc=0.5390\n",
      "[Pretrain] Epoch 48/75  Loss=1.4056  Acc=0.5454\n",
      "[Pretrain] Epoch 49/75  Loss=1.4017  Acc=0.5564\n",
      "[Pretrain] Epoch 50/75  Loss=1.3891  Acc=0.5508\n",
      "[Pretrain] Epoch 51/75  Loss=1.3733  Acc=0.5596\n",
      "[Pretrain] Epoch 52/75  Loss=1.3723  Acc=0.5521\n",
      "[Pretrain] Epoch 53/75  Loss=1.3889  Acc=0.5467\n",
      "[Pretrain] Epoch 54/75  Loss=1.3664  Acc=0.5559\n",
      "[Pretrain] Epoch 55/75  Loss=1.3618  Acc=0.5557\n",
      "[Pretrain] Epoch 56/75  Loss=1.3560  Acc=0.5625\n",
      "[Pretrain] Epoch 57/75  Loss=1.3597  Acc=0.5654\n",
      "[Pretrain] Epoch 58/75  Loss=1.3431  Acc=0.5657\n",
      "[Pretrain] Epoch 59/75  Loss=1.3384  Acc=0.5665\n",
      "[Pretrain] Epoch 60/75  Loss=1.3385  Acc=0.5623\n",
      "[Pretrain] Epoch 61/75  Loss=1.3375  Acc=0.5656\n",
      "[Pretrain] Epoch 62/75  Loss=1.3447  Acc=0.5600\n",
      "[Pretrain] Epoch 63/75  Loss=1.3402  Acc=0.5673\n",
      "[Pretrain] Epoch 64/75  Loss=1.3406  Acc=0.5706\n",
      "[Pretrain] Epoch 65/75  Loss=1.3333  Acc=0.5625\n",
      "[Pretrain] Epoch 66/75  Loss=1.3323  Acc=0.5654\n",
      "[Pretrain] Epoch 67/75  Loss=1.3096  Acc=0.5765\n",
      "[Pretrain] Epoch 68/75  Loss=1.3067  Acc=0.5709\n",
      "[Pretrain] Epoch 69/75  Loss=1.3080  Acc=0.5738\n",
      "[Pretrain] Epoch 70/75  Loss=1.3129  Acc=0.5717\n",
      "[Pretrain] Epoch 71/75  Loss=1.2994  Acc=0.5778\n",
      "[Pretrain] Epoch 72/75  Loss=1.3006  Acc=0.5735\n",
      "[Pretrain] Epoch 73/75  Loss=1.3067  Acc=0.5736\n",
      "[Pretrain] Epoch 74/75  Loss=1.3082  Acc=0.5688\n",
      "[Pretrain] Epoch 75/75  Loss=1.2971  Acc=0.5805\n",
      "[Fine-tune] Epoch 1/150  Loss=3.2962\n",
      "[Fine-tune] Epoch 2/150  Loss=3.1783\n",
      "[Fine-tune] Epoch 3/150  Loss=3.0911\n",
      "[Fine-tune] Epoch 4/150  Loss=3.0666\n",
      "[Fine-tune] Epoch 5/150  Loss=3.0429\n",
      "[Fine-tune] Epoch 6/150  Loss=2.8928\n",
      "[Fine-tune] Epoch 7/150  Loss=2.8067\n",
      "[Fine-tune] Epoch 8/150  Loss=2.6408\n",
      "[Fine-tune] Epoch 9/150  Loss=2.5449\n",
      "[Fine-tune] Epoch 10/150  Loss=2.4867\n",
      "[Fine-tune] Epoch 11/150  Loss=2.4161\n",
      "[Fine-tune] Epoch 12/150  Loss=2.3774\n",
      "[Fine-tune] Epoch 13/150  Loss=2.3519\n",
      "[Fine-tune] Epoch 14/150  Loss=2.3118\n",
      "[Fine-tune] Epoch 15/150  Loss=2.2988\n",
      "[Fine-tune] Epoch 16/150  Loss=2.2759\n",
      "[Fine-tune] Epoch 17/150  Loss=2.2359\n",
      "[Fine-tune] Epoch 18/150  Loss=2.1690\n",
      "[Fine-tune] Epoch 19/150  Loss=2.1718\n",
      "[Fine-tune] Epoch 20/150  Loss=2.1338\n",
      "[Fine-tune] Epoch 21/150  Loss=2.1223\n",
      "[Fine-tune] Epoch 22/150  Loss=2.1113\n",
      "[Fine-tune] Epoch 23/150  Loss=2.0695\n",
      "[Fine-tune] Epoch 24/150  Loss=2.0456\n",
      "[Fine-tune] Epoch 25/150  Loss=2.0403\n",
      "[Fine-tune] Epoch 26/150  Loss=2.0143\n",
      "[Fine-tune] Epoch 27/150  Loss=2.0028\n",
      "[Fine-tune] Epoch 28/150  Loss=1.9737\n",
      "[Fine-tune] Epoch 29/150  Loss=1.9624\n",
      "[Fine-tune] Epoch 30/150  Loss=1.9557\n",
      "[Fine-tune] Epoch 31/150  Loss=1.9401\n",
      "[Fine-tune] Epoch 32/150  Loss=1.9185\n",
      "[Fine-tune] Epoch 33/150  Loss=1.9205\n",
      "[Fine-tune] Epoch 34/150  Loss=1.8907\n",
      "[Fine-tune] Epoch 35/150  Loss=1.8814\n",
      "[Fine-tune] Epoch 36/150  Loss=1.8708\n",
      "[Fine-tune] Epoch 37/150  Loss=1.8650\n",
      "[Fine-tune] Epoch 38/150  Loss=1.8334\n",
      "[Fine-tune] Epoch 39/150  Loss=1.8140\n",
      "[Fine-tune] Epoch 40/150  Loss=1.7985\n",
      "[Fine-tune] Epoch 41/150  Loss=1.7982\n",
      "[Fine-tune] Epoch 42/150  Loss=1.7960\n",
      "[Fine-tune] Epoch 43/150  Loss=1.7586\n",
      "[Fine-tune] Epoch 44/150  Loss=1.7601\n",
      "[Fine-tune] Epoch 45/150  Loss=1.7667\n",
      "[Fine-tune] Epoch 46/150  Loss=1.7451\n",
      "[Fine-tune] Epoch 47/150  Loss=1.7280\n",
      "[Fine-tune] Epoch 48/150  Loss=1.7207\n",
      "[Fine-tune] Epoch 49/150  Loss=1.7111\n",
      "[Fine-tune] Epoch 50/150  Loss=1.7119\n",
      "[Fine-tune] Epoch 51/150  Loss=1.6785\n",
      "[Fine-tune] Epoch 52/150  Loss=1.6749\n",
      "[Fine-tune] Epoch 53/150  Loss=1.6867\n",
      "[Fine-tune] Epoch 54/150  Loss=1.6766\n",
      "[Fine-tune] Epoch 55/150  Loss=1.6636\n",
      "[Fine-tune] Epoch 56/150  Loss=1.6511\n",
      "[Fine-tune] Epoch 57/150  Loss=1.6539\n",
      "[Fine-tune] Epoch 58/150  Loss=1.6467\n",
      "[Fine-tune] Epoch 59/150  Loss=1.6369\n",
      "[Fine-tune] Epoch 60/150  Loss=1.6342\n",
      "[Fine-tune] Epoch 61/150  Loss=1.6266\n",
      "[Fine-tune] Epoch 62/150  Loss=1.6390\n",
      "[Fine-tune] Epoch 63/150  Loss=1.6188\n",
      "[Fine-tune] Epoch 64/150  Loss=1.6197\n",
      "[Fine-tune] Epoch 65/150  Loss=1.6221\n",
      "[Fine-tune] Epoch 66/150  Loss=1.6109\n",
      "[Fine-tune] Epoch 67/150  Loss=1.6109\n",
      "[Fine-tune] Epoch 68/150  Loss=1.5988\n",
      "[Fine-tune] Epoch 69/150  Loss=1.6058\n",
      "[Fine-tune] Epoch 70/150  Loss=1.5810\n",
      "[Fine-tune] Epoch 71/150  Loss=1.6028\n",
      "[Fine-tune] Epoch 72/150  Loss=1.5927\n",
      "[Fine-tune] Epoch 73/150  Loss=1.5854\n",
      "[Fine-tune] Epoch 74/150  Loss=1.5924\n",
      "[Fine-tune] Epoch 75/150  Loss=1.5879\n",
      "[Fine-tune] Epoch 76/150  Loss=1.5820\n",
      "[Fine-tune] Epoch 77/150  Loss=1.5803\n",
      "[Fine-tune] Epoch 78/150  Loss=1.5862\n",
      "[Fine-tune] Epoch 79/150  Loss=1.5693\n",
      "[Fine-tune] Epoch 80/150  Loss=1.5598\n",
      "[Fine-tune] Epoch 81/150  Loss=1.5722\n",
      "[Fine-tune] Epoch 82/150  Loss=1.5609\n",
      "[Fine-tune] Epoch 83/150  Loss=1.5627\n",
      "[Fine-tune] Epoch 84/150  Loss=1.5651\n",
      "[Fine-tune] Epoch 85/150  Loss=1.5597\n",
      "[Fine-tune] Epoch 86/150  Loss=1.5760\n",
      "[Fine-tune] Epoch 87/150  Loss=1.5602\n",
      "[Fine-tune] Epoch 88/150  Loss=1.5634\n",
      "[Fine-tune] Epoch 89/150  Loss=1.5484\n",
      "[Fine-tune] Epoch 90/150  Loss=1.5549\n",
      "[Fine-tune] Epoch 91/150  Loss=1.5582\n",
      "[Fine-tune] Epoch 92/150  Loss=1.5461\n",
      "[Fine-tune] Epoch 93/150  Loss=1.5471\n",
      "[Fine-tune] Epoch 94/150  Loss=1.5472\n",
      "[Fine-tune] Epoch 95/150  Loss=1.5500\n",
      "[Fine-tune] Epoch 96/150  Loss=1.5557\n",
      "[Fine-tune] Epoch 97/150  Loss=1.5488\n",
      "[Fine-tune] Epoch 98/150  Loss=1.5445\n",
      "[Fine-tune] Epoch 99/150  Loss=1.5426\n",
      "[Fine-tune] Epoch 100/150  Loss=1.5420\n",
      "[Fine-tune] Epoch 101/150  Loss=1.5417\n",
      "[Fine-tune] Epoch 102/150  Loss=1.5465\n",
      "[Fine-tune] Epoch 103/150  Loss=1.5376\n",
      "[Fine-tune] Epoch 104/150  Loss=1.5364\n",
      "[Fine-tune] Epoch 105/150  Loss=1.5345\n",
      "[Fine-tune] Epoch 106/150  Loss=1.5345\n",
      "[Fine-tune] Epoch 107/150  Loss=1.5368\n",
      "[Fine-tune] Epoch 108/150  Loss=1.5395\n",
      "[Fine-tune] Epoch 109/150  Loss=1.5424\n",
      "[Fine-tune] Epoch 110/150  Loss=1.5304\n",
      "[Fine-tune] Epoch 111/150  Loss=1.5436\n",
      "[Fine-tune] Epoch 112/150  Loss=1.5274\n",
      "[Fine-tune] Epoch 113/150  Loss=1.5365\n",
      "[Fine-tune] Epoch 114/150  Loss=1.5414\n",
      "[Fine-tune] Epoch 115/150  Loss=1.5433\n",
      "[Fine-tune] Epoch 116/150  Loss=1.5426\n",
      "[Fine-tune] Epoch 117/150  Loss=1.5414\n",
      "[Fine-tune] Epoch 118/150  Loss=1.5412\n",
      "[Fine-tune] Epoch 119/150  Loss=1.5296\n",
      "[Fine-tune] Epoch 120/150  Loss=1.5444\n",
      "[Fine-tune] Epoch 121/150  Loss=1.5183\n",
      "[Fine-tune] Epoch 122/150  Loss=1.5415\n",
      "[Fine-tune] Epoch 123/150  Loss=1.5259\n",
      "[Fine-tune] Epoch 124/150  Loss=1.5309\n",
      "[Fine-tune] Epoch 125/150  Loss=1.5232\n",
      "[Fine-tune] Epoch 126/150  Loss=1.5415\n",
      "[Fine-tune] Epoch 127/150  Loss=1.5347\n",
      "[Fine-tune] Epoch 128/150  Loss=1.5489\n",
      "[Fine-tune] Epoch 129/150  Loss=1.5317\n",
      "[Fine-tune] Epoch 130/150  Loss=1.5374\n",
      "[Fine-tune] Epoch 131/150  Loss=1.5319\n",
      "[Fine-tune] Epoch 132/150  Loss=1.5308\n",
      "[Fine-tune] Epoch 133/150  Loss=1.5279\n",
      "[Fine-tune] Epoch 134/150  Loss=1.5301\n",
      "[Fine-tune] Epoch 135/150  Loss=1.5400\n",
      "[Fine-tune] Epoch 136/150  Loss=1.5390\n",
      "[Fine-tune] Epoch 137/150  Loss=1.5379\n",
      "[Fine-tune] Epoch 138/150  Loss=1.5386\n",
      "[Fine-tune] Epoch 139/150  Loss=1.5413\n",
      "[Fine-tune] Epoch 140/150  Loss=1.5291\n",
      "[Fine-tune] Epoch 141/150  Loss=1.5285\n",
      "[Fine-tune] Epoch 142/150  Loss=1.5143\n",
      "[Fine-tune] Epoch 143/150  Loss=1.5081\n",
      "[Fine-tune] Epoch 144/150  Loss=1.5224\n",
      "[Fine-tune] Epoch 145/150  Loss=1.5364\n",
      "[Fine-tune] Epoch 146/150  Loss=1.5285\n",
      "[Fine-tune] Epoch 147/150  Loss=1.5305\n",
      "[Fine-tune] Epoch 148/150  Loss=1.5383\n",
      "[Fine-tune] Epoch 149/150  Loss=1.5178\n",
      "[Fine-tune] Epoch 150/150  Loss=1.5313\n",
      "[Pretrain] Epoch 1/75  Loss=3.6543  Acc=0.0406\n",
      "[Pretrain] Epoch 2/75  Loss=3.1693  Acc=0.0578\n",
      "[Pretrain] Epoch 3/75  Loss=2.8184  Acc=0.1144\n",
      "[Pretrain] Epoch 4/75  Loss=2.6839  Acc=0.1476\n",
      "[Pretrain] Epoch 5/75  Loss=2.5830  Acc=0.1643\n",
      "[Pretrain] Epoch 6/75  Loss=2.4974  Acc=0.2004\n",
      "[Pretrain] Epoch 7/75  Loss=2.4267  Acc=0.2195\n",
      "[Pretrain] Epoch 8/75  Loss=2.3806  Acc=0.2374\n",
      "[Pretrain] Epoch 9/75  Loss=2.3088  Acc=0.2480\n",
      "[Pretrain] Epoch 10/75  Loss=2.2626  Acc=0.2656\n",
      "[Pretrain] Epoch 11/75  Loss=2.1961  Acc=0.2805\n",
      "[Pretrain] Epoch 12/75  Loss=2.1744  Acc=0.2859\n",
      "[Pretrain] Epoch 13/75  Loss=2.1576  Acc=0.3001\n",
      "[Pretrain] Epoch 14/75  Loss=2.1172  Acc=0.3030\n",
      "[Pretrain] Epoch 15/75  Loss=2.0846  Acc=0.3267\n",
      "[Pretrain] Epoch 16/75  Loss=2.0544  Acc=0.3285\n",
      "[Pretrain] Epoch 17/75  Loss=2.0512  Acc=0.3339\n",
      "[Pretrain] Epoch 18/75  Loss=2.0153  Acc=0.3398\n",
      "[Pretrain] Epoch 19/75  Loss=1.9640  Acc=0.3534\n",
      "[Pretrain] Epoch 20/75  Loss=1.9647  Acc=0.3565\n",
      "[Pretrain] Epoch 21/75  Loss=1.9227  Acc=0.3691\n",
      "[Pretrain] Epoch 22/75  Loss=1.8809  Acc=0.3770\n",
      "[Pretrain] Epoch 23/75  Loss=1.8479  Acc=0.3987\n",
      "[Pretrain] Epoch 24/75  Loss=1.8261  Acc=0.4027\n",
      "[Pretrain] Epoch 25/75  Loss=1.8129  Acc=0.4000\n",
      "[Pretrain] Epoch 26/75  Loss=1.7958  Acc=0.4064\n",
      "[Pretrain] Epoch 27/75  Loss=1.7596  Acc=0.4231\n",
      "[Pretrain] Epoch 28/75  Loss=1.7332  Acc=0.4301\n",
      "[Pretrain] Epoch 29/75  Loss=1.7192  Acc=0.4386\n",
      "[Pretrain] Epoch 30/75  Loss=1.6846  Acc=0.4449\n",
      "[Pretrain] Epoch 31/75  Loss=1.6613  Acc=0.4528\n",
      "[Pretrain] Epoch 32/75  Loss=1.6573  Acc=0.4470\n",
      "[Pretrain] Epoch 33/75  Loss=1.6248  Acc=0.4671\n",
      "[Pretrain] Epoch 34/75  Loss=1.6104  Acc=0.4722\n",
      "[Pretrain] Epoch 35/75  Loss=1.5891  Acc=0.4761\n",
      "[Pretrain] Epoch 36/75  Loss=1.5647  Acc=0.4946\n",
      "[Pretrain] Epoch 37/75  Loss=1.5450  Acc=0.4914\n",
      "[Pretrain] Epoch 38/75  Loss=1.5184  Acc=0.4996\n",
      "[Pretrain] Epoch 39/75  Loss=1.4964  Acc=0.5068\n",
      "[Pretrain] Epoch 40/75  Loss=1.4776  Acc=0.5224\n",
      "[Pretrain] Epoch 41/75  Loss=1.4718  Acc=0.5212\n",
      "[Pretrain] Epoch 42/75  Loss=1.4433  Acc=0.5241\n",
      "[Pretrain] Epoch 43/75  Loss=1.4320  Acc=0.5379\n",
      "[Pretrain] Epoch 44/75  Loss=1.4198  Acc=0.5354\n",
      "[Pretrain] Epoch 45/75  Loss=1.4035  Acc=0.5379\n",
      "[Pretrain] Epoch 46/75  Loss=1.3801  Acc=0.5438\n",
      "[Pretrain] Epoch 47/75  Loss=1.3695  Acc=0.5501\n",
      "[Pretrain] Epoch 48/75  Loss=1.3614  Acc=0.5533\n",
      "[Pretrain] Epoch 49/75  Loss=1.3617  Acc=0.5510\n",
      "[Pretrain] Epoch 50/75  Loss=1.3366  Acc=0.5666\n",
      "[Pretrain] Epoch 51/75  Loss=1.3392  Acc=0.5616\n",
      "[Pretrain] Epoch 52/75  Loss=1.3076  Acc=0.5647\n",
      "[Pretrain] Epoch 53/75  Loss=1.3144  Acc=0.5729\n",
      "[Pretrain] Epoch 54/75  Loss=1.2932  Acc=0.5702\n",
      "[Pretrain] Epoch 55/75  Loss=1.2886  Acc=0.5770\n",
      "[Pretrain] Epoch 56/75  Loss=1.2844  Acc=0.5803\n",
      "[Pretrain] Epoch 57/75  Loss=1.2717  Acc=0.5849\n",
      "[Pretrain] Epoch 58/75  Loss=1.2720  Acc=0.5858\n",
      "[Pretrain] Epoch 59/75  Loss=1.2564  Acc=0.5866\n",
      "[Pretrain] Epoch 60/75  Loss=1.2597  Acc=0.5867\n",
      "[Pretrain] Epoch 61/75  Loss=1.2374  Acc=0.5995\n",
      "[Pretrain] Epoch 62/75  Loss=1.2499  Acc=0.5938\n",
      "[Pretrain] Epoch 63/75  Loss=1.2086  Acc=0.5982\n",
      "[Pretrain] Epoch 64/75  Loss=1.2198  Acc=0.5973\n",
      "[Pretrain] Epoch 65/75  Loss=1.2048  Acc=0.6051\n",
      "[Pretrain] Epoch 66/75  Loss=1.2047  Acc=0.6036\n",
      "[Pretrain] Epoch 67/75  Loss=1.2138  Acc=0.6002\n",
      "[Pretrain] Epoch 68/75  Loss=1.2118  Acc=0.6034\n",
      "[Pretrain] Epoch 69/75  Loss=1.1940  Acc=0.6061\n",
      "[Pretrain] Epoch 70/75  Loss=1.1890  Acc=0.6070\n",
      "[Pretrain] Epoch 71/75  Loss=1.1953  Acc=0.6085\n",
      "[Pretrain] Epoch 72/75  Loss=1.2033  Acc=0.5961\n",
      "[Pretrain] Epoch 73/75  Loss=1.1888  Acc=0.6146\n",
      "[Pretrain] Epoch 74/75  Loss=1.1826  Acc=0.6065\n",
      "[Pretrain] Epoch 75/75  Loss=1.1919  Acc=0.6112\n",
      "[Fine-tune] Epoch 1/150  Loss=3.2992\n",
      "[Fine-tune] Epoch 2/150  Loss=3.0935\n",
      "[Fine-tune] Epoch 3/150  Loss=2.9772\n",
      "[Fine-tune] Epoch 4/150  Loss=2.7654\n",
      "[Fine-tune] Epoch 5/150  Loss=2.6765\n",
      "[Fine-tune] Epoch 6/150  Loss=2.5806\n",
      "[Fine-tune] Epoch 7/150  Loss=2.5075\n",
      "[Fine-tune] Epoch 8/150  Loss=2.4227\n",
      "[Fine-tune] Epoch 9/150  Loss=2.3357\n",
      "[Fine-tune] Epoch 10/150  Loss=2.2713\n",
      "[Fine-tune] Epoch 11/150  Loss=2.2241\n",
      "[Fine-tune] Epoch 12/150  Loss=2.1669\n",
      "[Fine-tune] Epoch 13/150  Loss=2.1420\n",
      "[Fine-tune] Epoch 14/150  Loss=2.1092\n",
      "[Fine-tune] Epoch 15/150  Loss=2.0951\n",
      "[Fine-tune] Epoch 16/150  Loss=2.0706\n",
      "[Fine-tune] Epoch 17/150  Loss=2.0548\n",
      "[Fine-tune] Epoch 18/150  Loss=2.0081\n",
      "[Fine-tune] Epoch 19/150  Loss=1.9691\n",
      "[Fine-tune] Epoch 20/150  Loss=1.9723\n",
      "[Fine-tune] Epoch 21/150  Loss=1.9594\n",
      "[Fine-tune] Epoch 22/150  Loss=1.9150\n",
      "[Fine-tune] Epoch 23/150  Loss=1.8989\n",
      "[Fine-tune] Epoch 24/150  Loss=1.8898\n",
      "[Fine-tune] Epoch 25/150  Loss=1.8663\n",
      "[Fine-tune] Epoch 26/150  Loss=1.8438\n",
      "[Fine-tune] Epoch 27/150  Loss=1.8447\n",
      "[Fine-tune] Epoch 28/150  Loss=1.8286\n",
      "[Fine-tune] Epoch 29/150  Loss=1.8065\n",
      "[Fine-tune] Epoch 30/150  Loss=1.7993\n",
      "[Fine-tune] Epoch 31/150  Loss=1.7859\n",
      "[Fine-tune] Epoch 32/150  Loss=1.7851\n",
      "[Fine-tune] Epoch 33/150  Loss=1.7665\n",
      "[Fine-tune] Epoch 34/150  Loss=1.7558\n",
      "[Fine-tune] Epoch 35/150  Loss=1.7463\n",
      "[Fine-tune] Epoch 36/150  Loss=1.7362\n",
      "[Fine-tune] Epoch 37/150  Loss=1.7139\n",
      "[Fine-tune] Epoch 38/150  Loss=1.7175\n",
      "[Fine-tune] Epoch 39/150  Loss=1.6940\n",
      "[Fine-tune] Epoch 40/150  Loss=1.6779\n",
      "[Fine-tune] Epoch 41/150  Loss=1.6951\n",
      "[Fine-tune] Epoch 42/150  Loss=1.6655\n",
      "[Fine-tune] Epoch 43/150  Loss=1.6647\n",
      "[Fine-tune] Epoch 44/150  Loss=1.6707\n",
      "[Fine-tune] Epoch 45/150  Loss=1.6514\n",
      "[Fine-tune] Epoch 46/150  Loss=1.6424\n",
      "[Fine-tune] Epoch 47/150  Loss=1.6505\n",
      "[Fine-tune] Epoch 48/150  Loss=1.6209\n",
      "[Fine-tune] Epoch 49/150  Loss=1.6082\n",
      "[Fine-tune] Epoch 50/150  Loss=1.6136\n",
      "[Fine-tune] Epoch 51/150  Loss=1.6065\n",
      "[Fine-tune] Epoch 52/150  Loss=1.6039\n",
      "[Fine-tune] Epoch 53/150  Loss=1.6012\n",
      "[Fine-tune] Epoch 54/150  Loss=1.5958\n",
      "[Fine-tune] Epoch 55/150  Loss=1.6006\n",
      "[Fine-tune] Epoch 56/150  Loss=1.5747\n",
      "[Fine-tune] Epoch 57/150  Loss=1.5848\n",
      "[Fine-tune] Epoch 58/150  Loss=1.5873\n",
      "[Fine-tune] Epoch 59/150  Loss=1.5903\n",
      "[Fine-tune] Epoch 60/150  Loss=1.5702\n",
      "[Fine-tune] Epoch 61/150  Loss=1.5627\n",
      "[Fine-tune] Epoch 62/150  Loss=1.5587\n",
      "[Fine-tune] Epoch 63/150  Loss=1.5737\n",
      "[Fine-tune] Epoch 64/150  Loss=1.5611\n",
      "[Fine-tune] Epoch 65/150  Loss=1.5638\n",
      "[Fine-tune] Epoch 66/150  Loss=1.5545\n",
      "[Fine-tune] Epoch 67/150  Loss=1.5555\n",
      "[Fine-tune] Epoch 68/150  Loss=1.5586\n",
      "[Fine-tune] Epoch 69/150  Loss=1.5612\n",
      "[Fine-tune] Epoch 70/150  Loss=1.5608\n",
      "[Fine-tune] Epoch 71/150  Loss=1.5454\n",
      "[Fine-tune] Epoch 72/150  Loss=1.5302\n",
      "[Fine-tune] Epoch 73/150  Loss=1.5415\n",
      "[Fine-tune] Epoch 74/150  Loss=1.5511\n",
      "[Fine-tune] Epoch 75/150  Loss=1.5405\n",
      "[Fine-tune] Epoch 76/150  Loss=1.5361\n",
      "[Fine-tune] Epoch 77/150  Loss=1.5275\n",
      "[Fine-tune] Epoch 78/150  Loss=1.5359\n",
      "[Fine-tune] Epoch 79/150  Loss=1.5295\n",
      "[Fine-tune] Epoch 80/150  Loss=1.5154\n",
      "[Fine-tune] Epoch 81/150  Loss=1.5238\n",
      "[Fine-tune] Epoch 82/150  Loss=1.5322\n",
      "[Fine-tune] Epoch 83/150  Loss=1.5394\n",
      "[Fine-tune] Epoch 84/150  Loss=1.5110\n",
      "[Fine-tune] Epoch 85/150  Loss=1.5327\n",
      "[Fine-tune] Epoch 86/150  Loss=1.5237\n",
      "[Fine-tune] Epoch 87/150  Loss=1.5051\n",
      "[Fine-tune] Epoch 88/150  Loss=1.5368\n",
      "[Fine-tune] Epoch 89/150  Loss=1.5204\n",
      "[Fine-tune] Epoch 90/150  Loss=1.5172\n",
      "[Fine-tune] Epoch 91/150  Loss=1.5229\n",
      "[Fine-tune] Epoch 92/150  Loss=1.5028\n",
      "[Fine-tune] Epoch 93/150  Loss=1.5136\n",
      "[Fine-tune] Epoch 94/150  Loss=1.5198\n",
      "[Fine-tune] Epoch 95/150  Loss=1.5274\n",
      "[Fine-tune] Epoch 96/150  Loss=1.5142\n",
      "[Fine-tune] Epoch 97/150  Loss=1.5192\n",
      "[Fine-tune] Epoch 98/150  Loss=1.5117\n",
      "[Fine-tune] Epoch 99/150  Loss=1.5098\n",
      "[Fine-tune] Epoch 100/150  Loss=1.5206\n",
      "[Fine-tune] Epoch 101/150  Loss=1.5226\n",
      "[Fine-tune] Epoch 102/150  Loss=1.5130\n",
      "[Fine-tune] Epoch 103/150  Loss=1.5311\n",
      "[Fine-tune] Epoch 104/150  Loss=1.4946\n",
      "[Fine-tune] Epoch 105/150  Loss=1.5040\n",
      "[Fine-tune] Epoch 106/150  Loss=1.5042\n",
      "[Fine-tune] Epoch 107/150  Loss=1.5057\n",
      "[Fine-tune] Epoch 108/150  Loss=1.5126\n",
      "[Fine-tune] Epoch 109/150  Loss=1.5090\n",
      "[Fine-tune] Epoch 110/150  Loss=1.5106\n",
      "[Fine-tune] Epoch 111/150  Loss=1.5144\n",
      "[Fine-tune] Epoch 112/150  Loss=1.5017\n",
      "[Fine-tune] Epoch 113/150  Loss=1.5128\n",
      "[Fine-tune] Epoch 114/150  Loss=1.5133\n",
      "[Fine-tune] Epoch 115/150  Loss=1.5004\n",
      "[Fine-tune] Epoch 116/150  Loss=1.5107\n",
      "[Fine-tune] Epoch 117/150  Loss=1.5079\n",
      "[Fine-tune] Epoch 118/150  Loss=1.5319\n",
      "[Fine-tune] Epoch 119/150  Loss=1.5068\n",
      "[Fine-tune] Epoch 120/150  Loss=1.4872\n",
      "[Fine-tune] Epoch 121/150  Loss=1.5144\n",
      "[Fine-tune] Epoch 122/150  Loss=1.5060\n",
      "[Fine-tune] Epoch 123/150  Loss=1.4955\n",
      "[Fine-tune] Epoch 124/150  Loss=1.5051\n",
      "[Fine-tune] Epoch 125/150  Loss=1.5029\n",
      "[Fine-tune] Epoch 126/150  Loss=1.4992\n",
      "[Fine-tune] Epoch 127/150  Loss=1.5066\n",
      "[Fine-tune] Epoch 128/150  Loss=1.4971\n",
      "[Fine-tune] Epoch 129/150  Loss=1.5148\n",
      "[Fine-tune] Epoch 130/150  Loss=1.5007\n",
      "[Fine-tune] Epoch 131/150  Loss=1.4965\n",
      "[Fine-tune] Epoch 132/150  Loss=1.5007\n",
      "[Fine-tune] Epoch 133/150  Loss=1.5049\n",
      "[Fine-tune] Epoch 134/150  Loss=1.5192\n",
      "[Fine-tune] Epoch 135/150  Loss=1.4965\n",
      "[Fine-tune] Epoch 136/150  Loss=1.5110\n",
      "[Fine-tune] Epoch 137/150  Loss=1.5110\n",
      "[Fine-tune] Epoch 138/150  Loss=1.5095\n",
      "[Fine-tune] Epoch 139/150  Loss=1.5038\n",
      "[Fine-tune] Epoch 140/150  Loss=1.4989\n",
      "[Fine-tune] Epoch 141/150  Loss=1.5065\n",
      "[Fine-tune] Epoch 142/150  Loss=1.5224\n",
      "[Fine-tune] Epoch 143/150  Loss=1.5130\n",
      "[Fine-tune] Epoch 144/150  Loss=1.5183\n",
      "[Fine-tune] Epoch 145/150  Loss=1.5031\n",
      "[Fine-tune] Epoch 146/150  Loss=1.5068\n",
      "[Fine-tune] Epoch 147/150  Loss=1.5105\n",
      "[Fine-tune] Epoch 148/150  Loss=1.5021\n",
      "[Fine-tune] Epoch 149/150  Loss=1.4955\n",
      "[Fine-tune] Epoch 150/150  Loss=1.5043\n",
      "[Pretrain] Epoch 1/100  Loss=3.2013  Acc=0.0571\n",
      "[Pretrain] Epoch 2/100  Loss=2.9333  Acc=0.0846\n",
      "[Pretrain] Epoch 3/100  Loss=2.6998  Acc=0.1464\n",
      "[Pretrain] Epoch 4/100  Loss=2.5605  Acc=0.1832\n",
      "[Pretrain] Epoch 5/100  Loss=2.4809  Acc=0.2143\n",
      "[Pretrain] Epoch 6/100  Loss=2.3338  Acc=0.2493\n",
      "[Pretrain] Epoch 7/100  Loss=2.2863  Acc=0.2671\n",
      "[Pretrain] Epoch 8/100  Loss=2.1821  Acc=0.2901\n",
      "[Pretrain] Epoch 9/100  Loss=2.1401  Acc=0.3082\n",
      "[Pretrain] Epoch 10/100  Loss=2.0913  Acc=0.3206\n",
      "[Pretrain] Epoch 11/100  Loss=2.0528  Acc=0.3260\n",
      "[Pretrain] Epoch 12/100  Loss=2.0165  Acc=0.3421\n",
      "[Pretrain] Epoch 13/100  Loss=1.9827  Acc=0.3556\n",
      "[Pretrain] Epoch 14/100  Loss=1.9594  Acc=0.3605\n",
      "[Pretrain] Epoch 15/100  Loss=1.9253  Acc=0.3748\n",
      "[Pretrain] Epoch 16/100  Loss=1.8853  Acc=0.3901\n",
      "[Pretrain] Epoch 17/100  Loss=1.8591  Acc=0.3994\n",
      "[Pretrain] Epoch 18/100  Loss=1.8462  Acc=0.4041\n",
      "[Pretrain] Epoch 19/100  Loss=1.8255  Acc=0.4034\n",
      "[Pretrain] Epoch 20/100  Loss=1.7809  Acc=0.4190\n",
      "[Pretrain] Epoch 21/100  Loss=1.7665  Acc=0.4291\n",
      "[Pretrain] Epoch 22/100  Loss=1.7357  Acc=0.4352\n",
      "[Pretrain] Epoch 23/100  Loss=1.7315  Acc=0.4402\n",
      "[Pretrain] Epoch 24/100  Loss=1.7381  Acc=0.4418\n",
      "[Pretrain] Epoch 25/100  Loss=1.6960  Acc=0.4546\n",
      "[Pretrain] Epoch 26/100  Loss=1.6787  Acc=0.4511\n",
      "[Pretrain] Epoch 27/100  Loss=1.6781  Acc=0.4555\n",
      "[Pretrain] Epoch 28/100  Loss=1.6462  Acc=0.4666\n",
      "[Pretrain] Epoch 29/100  Loss=1.6188  Acc=0.4820\n",
      "[Pretrain] Epoch 30/100  Loss=1.6192  Acc=0.4705\n",
      "[Pretrain] Epoch 31/100  Loss=1.6046  Acc=0.4824\n",
      "[Pretrain] Epoch 32/100  Loss=1.5696  Acc=0.4934\n",
      "[Pretrain] Epoch 33/100  Loss=1.5643  Acc=0.4962\n",
      "[Pretrain] Epoch 34/100  Loss=1.5542  Acc=0.4969\n",
      "[Pretrain] Epoch 35/100  Loss=1.5450  Acc=0.5018\n",
      "[Pretrain] Epoch 36/100  Loss=1.5341  Acc=0.5057\n",
      "[Pretrain] Epoch 37/100  Loss=1.5207  Acc=0.5005\n",
      "[Pretrain] Epoch 38/100  Loss=1.4971  Acc=0.5160\n",
      "[Pretrain] Epoch 39/100  Loss=1.5122  Acc=0.5079\n",
      "[Pretrain] Epoch 40/100  Loss=1.4832  Acc=0.5174\n",
      "[Pretrain] Epoch 41/100  Loss=1.4930  Acc=0.5138\n",
      "[Pretrain] Epoch 42/100  Loss=1.4772  Acc=0.5192\n",
      "[Pretrain] Epoch 43/100  Loss=1.4646  Acc=0.5216\n",
      "[Pretrain] Epoch 44/100  Loss=1.4546  Acc=0.5302\n",
      "[Pretrain] Epoch 45/100  Loss=1.4361  Acc=0.5275\n",
      "[Pretrain] Epoch 46/100  Loss=1.4276  Acc=0.5365\n",
      "[Pretrain] Epoch 47/100  Loss=1.4263  Acc=0.5402\n",
      "[Pretrain] Epoch 48/100  Loss=1.4172  Acc=0.5375\n",
      "[Pretrain] Epoch 49/100  Loss=1.4085  Acc=0.5399\n",
      "[Pretrain] Epoch 50/100  Loss=1.4187  Acc=0.5384\n",
      "[Pretrain] Epoch 51/100  Loss=1.4091  Acc=0.5356\n",
      "[Pretrain] Epoch 52/100  Loss=1.3910  Acc=0.5494\n",
      "[Pretrain] Epoch 53/100  Loss=1.3777  Acc=0.5578\n",
      "[Pretrain] Epoch 54/100  Loss=1.3841  Acc=0.5501\n",
      "[Pretrain] Epoch 55/100  Loss=1.3735  Acc=0.5541\n",
      "[Pretrain] Epoch 56/100  Loss=1.3640  Acc=0.5526\n",
      "[Pretrain] Epoch 57/100  Loss=1.3733  Acc=0.5564\n",
      "[Pretrain] Epoch 58/100  Loss=1.3723  Acc=0.5548\n",
      "[Pretrain] Epoch 59/100  Loss=1.3838  Acc=0.5523\n",
      "[Pretrain] Epoch 60/100  Loss=1.3704  Acc=0.5645\n",
      "[Pretrain] Epoch 61/100  Loss=1.3544  Acc=0.5587\n",
      "[Pretrain] Epoch 62/100  Loss=1.3477  Acc=0.5605\n",
      "[Pretrain] Epoch 63/100  Loss=1.3533  Acc=0.5559\n",
      "[Pretrain] Epoch 64/100  Loss=1.3410  Acc=0.5682\n",
      "[Pretrain] Epoch 65/100  Loss=1.3445  Acc=0.5659\n",
      "[Pretrain] Epoch 66/100  Loss=1.3277  Acc=0.5713\n",
      "[Pretrain] Epoch 67/100  Loss=1.3422  Acc=0.5611\n",
      "[Pretrain] Epoch 68/100  Loss=1.3126  Acc=0.5749\n",
      "[Pretrain] Epoch 69/100  Loss=1.3388  Acc=0.5616\n",
      "[Pretrain] Epoch 70/100  Loss=1.3494  Acc=0.5605\n",
      "[Pretrain] Epoch 71/100  Loss=1.3373  Acc=0.5718\n",
      "[Pretrain] Epoch 72/100  Loss=1.3099  Acc=0.5704\n",
      "[Pretrain] Epoch 73/100  Loss=1.3295  Acc=0.5659\n",
      "[Pretrain] Epoch 74/100  Loss=1.3199  Acc=0.5704\n",
      "[Pretrain] Epoch 75/100  Loss=1.3116  Acc=0.5731\n",
      "[Pretrain] Epoch 76/100  Loss=1.3112  Acc=0.5742\n",
      "[Pretrain] Epoch 77/100  Loss=1.3110  Acc=0.5700\n",
      "[Pretrain] Epoch 78/100  Loss=1.3108  Acc=0.5717\n",
      "[Pretrain] Epoch 79/100  Loss=1.3088  Acc=0.5742\n",
      "[Pretrain] Epoch 80/100  Loss=1.3042  Acc=0.5738\n",
      "[Pretrain] Epoch 81/100  Loss=1.3031  Acc=0.5774\n",
      "[Pretrain] Epoch 82/100  Loss=1.3025  Acc=0.5788\n",
      "[Pretrain] Epoch 83/100  Loss=1.3190  Acc=0.5735\n",
      "[Pretrain] Epoch 84/100  Loss=1.3098  Acc=0.5769\n",
      "[Pretrain] Epoch 85/100  Loss=1.2957  Acc=0.5799\n",
      "[Pretrain] Epoch 86/100  Loss=1.2974  Acc=0.5790\n",
      "[Pretrain] Epoch 87/100  Loss=1.3096  Acc=0.5717\n",
      "[Pretrain] Epoch 88/100  Loss=1.2949  Acc=0.5715\n",
      "[Pretrain] Epoch 89/100  Loss=1.3006  Acc=0.5788\n",
      "[Pretrain] Epoch 90/100  Loss=1.3159  Acc=0.5761\n",
      "[Pretrain] Epoch 91/100  Loss=1.2964  Acc=0.5819\n",
      "[Pretrain] Epoch 92/100  Loss=1.2861  Acc=0.5849\n",
      "[Pretrain] Epoch 93/100  Loss=1.2907  Acc=0.5844\n",
      "[Pretrain] Epoch 94/100  Loss=1.2927  Acc=0.5785\n",
      "[Pretrain] Epoch 95/100  Loss=1.2912  Acc=0.5810\n",
      "[Pretrain] Epoch 96/100  Loss=1.3025  Acc=0.5787\n",
      "[Pretrain] Epoch 97/100  Loss=1.2898  Acc=0.5857\n",
      "[Pretrain] Epoch 98/100  Loss=1.2790  Acc=0.5884\n",
      "[Pretrain] Epoch 99/100  Loss=1.2816  Acc=0.5824\n",
      "[Pretrain] Epoch 100/100  Loss=1.2824  Acc=0.5911\n",
      "[Fine-tune] Epoch 1/150  Loss=3.3206\n",
      "[Fine-tune] Epoch 2/150  Loss=3.1929\n",
      "[Fine-tune] Epoch 3/150  Loss=3.0908\n",
      "[Fine-tune] Epoch 4/150  Loss=3.0582\n",
      "[Fine-tune] Epoch 5/150  Loss=2.9787\n",
      "[Fine-tune] Epoch 6/150  Loss=2.8385\n",
      "[Fine-tune] Epoch 7/150  Loss=2.7357\n",
      "[Fine-tune] Epoch 8/150  Loss=2.6333\n",
      "[Fine-tune] Epoch 9/150  Loss=2.5535\n",
      "[Fine-tune] Epoch 10/150  Loss=2.4893\n",
      "[Fine-tune] Epoch 11/150  Loss=2.4559\n",
      "[Fine-tune] Epoch 12/150  Loss=2.3980\n",
      "[Fine-tune] Epoch 13/150  Loss=2.3239\n",
      "[Fine-tune] Epoch 14/150  Loss=2.2896\n",
      "[Fine-tune] Epoch 15/150  Loss=2.2575\n",
      "[Fine-tune] Epoch 16/150  Loss=2.2111\n",
      "[Fine-tune] Epoch 17/150  Loss=2.1854\n",
      "[Fine-tune] Epoch 18/150  Loss=2.1576\n",
      "[Fine-tune] Epoch 19/150  Loss=2.1364\n",
      "[Fine-tune] Epoch 20/150  Loss=2.0936\n",
      "[Fine-tune] Epoch 21/150  Loss=2.1091\n",
      "[Fine-tune] Epoch 22/150  Loss=2.0770\n",
      "[Fine-tune] Epoch 23/150  Loss=2.0457\n",
      "[Fine-tune] Epoch 24/150  Loss=2.0473\n",
      "[Fine-tune] Epoch 25/150  Loss=2.0292\n",
      "[Fine-tune] Epoch 26/150  Loss=2.0108\n",
      "[Fine-tune] Epoch 27/150  Loss=1.9936\n",
      "[Fine-tune] Epoch 28/150  Loss=1.9629\n",
      "[Fine-tune] Epoch 29/150  Loss=1.9506\n",
      "[Fine-tune] Epoch 30/150  Loss=1.9576\n",
      "[Fine-tune] Epoch 31/150  Loss=1.9229\n",
      "[Fine-tune] Epoch 32/150  Loss=1.8975\n",
      "[Fine-tune] Epoch 33/150  Loss=1.9020\n",
      "[Fine-tune] Epoch 34/150  Loss=1.8796\n",
      "[Fine-tune] Epoch 35/150  Loss=1.8621\n",
      "[Fine-tune] Epoch 36/150  Loss=1.8526\n",
      "[Fine-tune] Epoch 37/150  Loss=1.8365\n",
      "[Fine-tune] Epoch 38/150  Loss=1.8260\n",
      "[Fine-tune] Epoch 39/150  Loss=1.8112\n",
      "[Fine-tune] Epoch 40/150  Loss=1.8025\n",
      "[Fine-tune] Epoch 41/150  Loss=1.8072\n",
      "[Fine-tune] Epoch 42/150  Loss=1.7852\n",
      "[Fine-tune] Epoch 43/150  Loss=1.7775\n",
      "[Fine-tune] Epoch 44/150  Loss=1.7665\n",
      "[Fine-tune] Epoch 45/150  Loss=1.7581\n",
      "[Fine-tune] Epoch 46/150  Loss=1.7485\n",
      "[Fine-tune] Epoch 47/150  Loss=1.7391\n",
      "[Fine-tune] Epoch 48/150  Loss=1.7190\n",
      "[Fine-tune] Epoch 49/150  Loss=1.7231\n",
      "[Fine-tune] Epoch 50/150  Loss=1.7124\n",
      "[Fine-tune] Epoch 51/150  Loss=1.7129\n",
      "[Fine-tune] Epoch 52/150  Loss=1.7005\n",
      "[Fine-tune] Epoch 53/150  Loss=1.6868\n",
      "[Fine-tune] Epoch 54/150  Loss=1.6703\n",
      "[Fine-tune] Epoch 55/150  Loss=1.6922\n",
      "[Fine-tune] Epoch 56/150  Loss=1.6701\n",
      "[Fine-tune] Epoch 57/150  Loss=1.6587\n",
      "[Fine-tune] Epoch 58/150  Loss=1.6609\n",
      "[Fine-tune] Epoch 59/150  Loss=1.6545\n",
      "[Fine-tune] Epoch 60/150  Loss=1.6506\n",
      "[Fine-tune] Epoch 61/150  Loss=1.6406\n",
      "[Fine-tune] Epoch 62/150  Loss=1.6377\n",
      "[Fine-tune] Epoch 63/150  Loss=1.6335\n",
      "[Fine-tune] Epoch 64/150  Loss=1.6516\n",
      "[Fine-tune] Epoch 65/150  Loss=1.6297\n",
      "[Fine-tune] Epoch 66/150  Loss=1.6294\n",
      "[Fine-tune] Epoch 67/150  Loss=1.6094\n",
      "[Fine-tune] Epoch 68/150  Loss=1.6264\n",
      "[Fine-tune] Epoch 69/150  Loss=1.6305\n",
      "[Fine-tune] Epoch 70/150  Loss=1.6110\n",
      "[Fine-tune] Epoch 71/150  Loss=1.6235\n",
      "[Fine-tune] Epoch 72/150  Loss=1.6032\n",
      "[Fine-tune] Epoch 73/150  Loss=1.6103\n",
      "[Fine-tune] Epoch 74/150  Loss=1.6040\n",
      "[Fine-tune] Epoch 75/150  Loss=1.5958\n",
      "[Fine-tune] Epoch 76/150  Loss=1.5948\n",
      "[Fine-tune] Epoch 77/150  Loss=1.5910\n",
      "[Fine-tune] Epoch 78/150  Loss=1.6028\n",
      "[Fine-tune] Epoch 79/150  Loss=1.5982\n",
      "[Fine-tune] Epoch 80/150  Loss=1.5926\n",
      "[Fine-tune] Epoch 81/150  Loss=1.5968\n",
      "[Fine-tune] Epoch 82/150  Loss=1.5721\n",
      "[Fine-tune] Epoch 83/150  Loss=1.5801\n",
      "[Fine-tune] Epoch 84/150  Loss=1.5733\n",
      "[Fine-tune] Epoch 85/150  Loss=1.5869\n",
      "[Fine-tune] Epoch 86/150  Loss=1.5826\n",
      "[Fine-tune] Epoch 87/150  Loss=1.5866\n",
      "[Fine-tune] Epoch 88/150  Loss=1.5787\n",
      "[Fine-tune] Epoch 89/150  Loss=1.5799\n",
      "[Fine-tune] Epoch 90/150  Loss=1.5706\n",
      "[Fine-tune] Epoch 91/150  Loss=1.5765\n",
      "[Fine-tune] Epoch 92/150  Loss=1.5663\n",
      "[Fine-tune] Epoch 93/150  Loss=1.5866\n",
      "[Fine-tune] Epoch 94/150  Loss=1.5783\n",
      "[Fine-tune] Epoch 95/150  Loss=1.5649\n",
      "[Fine-tune] Epoch 96/150  Loss=1.5773\n",
      "[Fine-tune] Epoch 97/150  Loss=1.5733\n",
      "[Fine-tune] Epoch 98/150  Loss=1.5666\n",
      "[Fine-tune] Epoch 99/150  Loss=1.5535\n",
      "[Fine-tune] Epoch 100/150  Loss=1.5704\n",
      "[Fine-tune] Epoch 101/150  Loss=1.5670\n",
      "[Fine-tune] Epoch 102/150  Loss=1.5766\n",
      "[Fine-tune] Epoch 103/150  Loss=1.5670\n",
      "[Fine-tune] Epoch 104/150  Loss=1.5745\n",
      "[Fine-tune] Epoch 105/150  Loss=1.5594\n",
      "[Fine-tune] Epoch 106/150  Loss=1.5648\n",
      "[Fine-tune] Epoch 107/150  Loss=1.5543\n",
      "[Fine-tune] Epoch 108/150  Loss=1.5713\n",
      "[Fine-tune] Epoch 109/150  Loss=1.5668\n",
      "[Fine-tune] Epoch 110/150  Loss=1.5664\n",
      "[Fine-tune] Epoch 111/150  Loss=1.5598\n",
      "[Fine-tune] Epoch 112/150  Loss=1.5604\n",
      "[Fine-tune] Epoch 113/150  Loss=1.5630\n",
      "[Fine-tune] Epoch 114/150  Loss=1.5625\n",
      "[Fine-tune] Epoch 115/150  Loss=1.5514\n",
      "[Fine-tune] Epoch 116/150  Loss=1.5777\n",
      "[Fine-tune] Epoch 117/150  Loss=1.5621\n",
      "[Fine-tune] Epoch 118/150  Loss=1.5541\n",
      "[Fine-tune] Epoch 119/150  Loss=1.5641\n",
      "[Fine-tune] Epoch 120/150  Loss=1.5639\n",
      "[Fine-tune] Epoch 121/150  Loss=1.5454\n",
      "[Fine-tune] Epoch 122/150  Loss=1.5459\n",
      "[Fine-tune] Epoch 123/150  Loss=1.5696\n",
      "[Fine-tune] Epoch 124/150  Loss=1.5678\n",
      "[Fine-tune] Epoch 125/150  Loss=1.5646\n",
      "[Fine-tune] Epoch 126/150  Loss=1.5470\n",
      "[Fine-tune] Epoch 127/150  Loss=1.5581\n",
      "[Fine-tune] Epoch 128/150  Loss=1.5602\n",
      "[Fine-tune] Epoch 129/150  Loss=1.5486\n",
      "[Fine-tune] Epoch 130/150  Loss=1.5493\n",
      "[Fine-tune] Epoch 131/150  Loss=1.5503\n",
      "[Fine-tune] Epoch 132/150  Loss=1.5554\n",
      "[Fine-tune] Epoch 133/150  Loss=1.5536\n",
      "[Fine-tune] Epoch 134/150  Loss=1.5586\n",
      "[Fine-tune] Epoch 135/150  Loss=1.5481\n",
      "[Fine-tune] Epoch 136/150  Loss=1.5557\n",
      "[Fine-tune] Epoch 137/150  Loss=1.5545\n",
      "[Fine-tune] Epoch 138/150  Loss=1.5536\n",
      "[Fine-tune] Epoch 139/150  Loss=1.5460\n",
      "[Fine-tune] Epoch 140/150  Loss=1.5644\n",
      "[Fine-tune] Epoch 141/150  Loss=1.5479\n",
      "[Fine-tune] Epoch 142/150  Loss=1.5570\n",
      "[Fine-tune] Epoch 143/150  Loss=1.5582\n",
      "[Fine-tune] Epoch 144/150  Loss=1.5522\n",
      "[Fine-tune] Epoch 145/150  Loss=1.5640\n",
      "[Fine-tune] Epoch 146/150  Loss=1.5524\n",
      "[Fine-tune] Epoch 147/150  Loss=1.5571\n",
      "[Fine-tune] Epoch 148/150  Loss=1.5484\n",
      "[Fine-tune] Epoch 149/150  Loss=1.5455\n",
      "[Fine-tune] Epoch 150/150  Loss=1.5507\n",
      "[Pretrain] Epoch 1/100  Loss=3.8321  Acc=0.0411\n",
      "[Pretrain] Epoch 2/100  Loss=3.1067  Acc=0.0709\n",
      "[Pretrain] Epoch 3/100  Loss=2.9312  Acc=0.0968\n",
      "[Pretrain] Epoch 4/100  Loss=2.6997  Acc=0.1410\n",
      "[Pretrain] Epoch 5/100  Loss=2.6191  Acc=0.1701\n",
      "[Pretrain] Epoch 6/100  Loss=2.5223  Acc=0.1920\n",
      "[Pretrain] Epoch 7/100  Loss=2.4141  Acc=0.2227\n",
      "[Pretrain] Epoch 8/100  Loss=2.3725  Acc=0.2398\n",
      "[Pretrain] Epoch 9/100  Loss=2.2911  Acc=0.2525\n",
      "[Pretrain] Epoch 10/100  Loss=2.2151  Acc=0.2786\n",
      "[Pretrain] Epoch 11/100  Loss=2.1889  Acc=0.2877\n",
      "[Pretrain] Epoch 12/100  Loss=2.1340  Acc=0.3001\n",
      "[Pretrain] Epoch 13/100  Loss=2.1037  Acc=0.3123\n",
      "[Pretrain] Epoch 14/100  Loss=2.0577  Acc=0.3364\n",
      "[Pretrain] Epoch 15/100  Loss=2.0453  Acc=0.3305\n",
      "[Pretrain] Epoch 16/100  Loss=2.0282  Acc=0.3432\n",
      "[Pretrain] Epoch 17/100  Loss=1.9611  Acc=0.3635\n",
      "[Pretrain] Epoch 18/100  Loss=1.9408  Acc=0.3691\n",
      "[Pretrain] Epoch 19/100  Loss=1.9090  Acc=0.3797\n",
      "[Pretrain] Epoch 20/100  Loss=1.8893  Acc=0.3815\n",
      "[Pretrain] Epoch 21/100  Loss=1.8706  Acc=0.3890\n",
      "[Pretrain] Epoch 22/100  Loss=1.8480  Acc=0.4034\n",
      "[Pretrain] Epoch 23/100  Loss=1.8273  Acc=0.4102\n",
      "[Pretrain] Epoch 24/100  Loss=1.8252  Acc=0.4107\n",
      "[Pretrain] Epoch 25/100  Loss=1.7747  Acc=0.4217\n",
      "[Pretrain] Epoch 26/100  Loss=1.7479  Acc=0.4370\n",
      "[Pretrain] Epoch 27/100  Loss=1.7321  Acc=0.4364\n",
      "[Pretrain] Epoch 28/100  Loss=1.7077  Acc=0.4445\n",
      "[Pretrain] Epoch 29/100  Loss=1.6583  Acc=0.4603\n",
      "[Pretrain] Epoch 30/100  Loss=1.6428  Acc=0.4612\n",
      "[Pretrain] Epoch 31/100  Loss=1.6260  Acc=0.4689\n",
      "[Pretrain] Epoch 32/100  Loss=1.6058  Acc=0.4813\n",
      "[Pretrain] Epoch 33/100  Loss=1.5833  Acc=0.4838\n",
      "[Pretrain] Epoch 34/100  Loss=1.5579  Acc=0.4969\n",
      "[Pretrain] Epoch 35/100  Loss=1.5482  Acc=0.4948\n",
      "[Pretrain] Epoch 36/100  Loss=1.5085  Acc=0.5092\n",
      "[Pretrain] Epoch 37/100  Loss=1.5019  Acc=0.5054\n",
      "[Pretrain] Epoch 38/100  Loss=1.4838  Acc=0.5199\n",
      "[Pretrain] Epoch 39/100  Loss=1.4495  Acc=0.5278\n",
      "[Pretrain] Epoch 40/100  Loss=1.4369  Acc=0.5241\n",
      "[Pretrain] Epoch 41/100  Loss=1.4310  Acc=0.5381\n",
      "[Pretrain] Epoch 42/100  Loss=1.3995  Acc=0.5392\n",
      "[Pretrain] Epoch 43/100  Loss=1.3867  Acc=0.5474\n",
      "[Pretrain] Epoch 44/100  Loss=1.3725  Acc=0.5515\n",
      "[Pretrain] Epoch 45/100  Loss=1.3606  Acc=0.5555\n",
      "[Pretrain] Epoch 46/100  Loss=1.3358  Acc=0.5609\n",
      "[Pretrain] Epoch 47/100  Loss=1.3403  Acc=0.5623\n",
      "[Pretrain] Epoch 48/100  Loss=1.3045  Acc=0.5751\n",
      "[Pretrain] Epoch 49/100  Loss=1.3040  Acc=0.5767\n",
      "[Pretrain] Epoch 50/100  Loss=1.2881  Acc=0.5760\n",
      "[Pretrain] Epoch 51/100  Loss=1.2887  Acc=0.5833\n",
      "[Pretrain] Epoch 52/100  Loss=1.2650  Acc=0.5866\n",
      "[Pretrain] Epoch 53/100  Loss=1.2493  Acc=0.5945\n",
      "[Pretrain] Epoch 54/100  Loss=1.2334  Acc=0.5986\n",
      "[Pretrain] Epoch 55/100  Loss=1.2241  Acc=0.6036\n",
      "[Pretrain] Epoch 56/100  Loss=1.2241  Acc=0.5939\n",
      "[Pretrain] Epoch 57/100  Loss=1.2150  Acc=0.6047\n",
      "[Pretrain] Epoch 58/100  Loss=1.2197  Acc=0.6040\n",
      "[Pretrain] Epoch 59/100  Loss=1.2026  Acc=0.6101\n",
      "[Pretrain] Epoch 60/100  Loss=1.1861  Acc=0.6072\n",
      "[Pretrain] Epoch 61/100  Loss=1.1777  Acc=0.6185\n",
      "[Pretrain] Epoch 62/100  Loss=1.1686  Acc=0.6191\n",
      "[Pretrain] Epoch 63/100  Loss=1.1616  Acc=0.6157\n",
      "[Pretrain] Epoch 64/100  Loss=1.1623  Acc=0.6180\n",
      "[Pretrain] Epoch 65/100  Loss=1.1722  Acc=0.6148\n",
      "[Pretrain] Epoch 66/100  Loss=1.1449  Acc=0.6273\n",
      "[Pretrain] Epoch 67/100  Loss=1.1370  Acc=0.6261\n",
      "[Pretrain] Epoch 68/100  Loss=1.1393  Acc=0.6250\n",
      "[Pretrain] Epoch 69/100  Loss=1.1340  Acc=0.6309\n",
      "[Pretrain] Epoch 70/100  Loss=1.1422  Acc=0.6343\n",
      "[Pretrain] Epoch 71/100  Loss=1.1263  Acc=0.6273\n",
      "[Pretrain] Epoch 72/100  Loss=1.1238  Acc=0.6345\n",
      "[Pretrain] Epoch 73/100  Loss=1.1177  Acc=0.6352\n",
      "[Pretrain] Epoch 74/100  Loss=1.1130  Acc=0.6356\n",
      "[Pretrain] Epoch 75/100  Loss=1.1172  Acc=0.6361\n",
      "[Pretrain] Epoch 76/100  Loss=1.1138  Acc=0.6331\n",
      "[Pretrain] Epoch 77/100  Loss=1.0962  Acc=0.6444\n",
      "[Pretrain] Epoch 78/100  Loss=1.1013  Acc=0.6347\n",
      "[Pretrain] Epoch 79/100  Loss=1.1035  Acc=0.6370\n",
      "[Pretrain] Epoch 80/100  Loss=1.0825  Acc=0.6428\n",
      "[Pretrain] Epoch 81/100  Loss=1.1004  Acc=0.6358\n",
      "[Pretrain] Epoch 82/100  Loss=1.0926  Acc=0.6370\n",
      "[Pretrain] Epoch 83/100  Loss=1.0861  Acc=0.6446\n",
      "[Pretrain] Epoch 84/100  Loss=1.0811  Acc=0.6417\n",
      "[Pretrain] Epoch 85/100  Loss=1.0881  Acc=0.6446\n",
      "[Pretrain] Epoch 86/100  Loss=1.0910  Acc=0.6428\n",
      "[Pretrain] Epoch 87/100  Loss=1.0857  Acc=0.6431\n",
      "[Pretrain] Epoch 88/100  Loss=1.0734  Acc=0.6444\n",
      "[Pretrain] Epoch 89/100  Loss=1.0667  Acc=0.6466\n",
      "[Pretrain] Epoch 90/100  Loss=1.0874  Acc=0.6426\n",
      "[Pretrain] Epoch 91/100  Loss=1.0715  Acc=0.6478\n",
      "[Pretrain] Epoch 92/100  Loss=1.0723  Acc=0.6453\n",
      "[Pretrain] Epoch 93/100  Loss=1.0873  Acc=0.6417\n",
      "[Pretrain] Epoch 94/100  Loss=1.0619  Acc=0.6545\n",
      "[Pretrain] Epoch 95/100  Loss=1.0799  Acc=0.6431\n",
      "[Pretrain] Epoch 96/100  Loss=1.0693  Acc=0.6478\n",
      "[Pretrain] Epoch 97/100  Loss=1.0631  Acc=0.6458\n",
      "[Pretrain] Epoch 98/100  Loss=1.0639  Acc=0.6489\n",
      "[Pretrain] Epoch 99/100  Loss=1.0572  Acc=0.6491\n",
      "[Pretrain] Epoch 100/100  Loss=1.0836  Acc=0.6449\n",
      "[Fine-tune] Epoch 1/150  Loss=3.2945\n",
      "[Fine-tune] Epoch 2/150  Loss=3.0684\n",
      "[Fine-tune] Epoch 3/150  Loss=2.8724\n",
      "[Fine-tune] Epoch 4/150  Loss=2.7441\n",
      "[Fine-tune] Epoch 5/150  Loss=2.6722\n",
      "[Fine-tune] Epoch 6/150  Loss=2.6116\n",
      "[Fine-tune] Epoch 7/150  Loss=2.5074\n",
      "[Fine-tune] Epoch 8/150  Loss=2.4685\n",
      "[Fine-tune] Epoch 9/150  Loss=2.4249\n",
      "[Fine-tune] Epoch 10/150  Loss=2.3529\n",
      "[Fine-tune] Epoch 11/150  Loss=2.3064\n",
      "[Fine-tune] Epoch 12/150  Loss=2.2698\n",
      "[Fine-tune] Epoch 13/150  Loss=2.2347\n",
      "[Fine-tune] Epoch 14/150  Loss=2.1640\n",
      "[Fine-tune] Epoch 15/150  Loss=2.1380\n",
      "[Fine-tune] Epoch 16/150  Loss=2.1348\n",
      "[Fine-tune] Epoch 17/150  Loss=2.0831\n",
      "[Fine-tune] Epoch 18/150  Loss=2.0520\n",
      "[Fine-tune] Epoch 19/150  Loss=2.0178\n",
      "[Fine-tune] Epoch 20/150  Loss=1.9922\n",
      "[Fine-tune] Epoch 21/150  Loss=1.9702\n",
      "[Fine-tune] Epoch 22/150  Loss=1.9679\n",
      "[Fine-tune] Epoch 23/150  Loss=1.9382\n",
      "[Fine-tune] Epoch 24/150  Loss=1.9147\n",
      "[Fine-tune] Epoch 25/150  Loss=1.8822\n",
      "[Fine-tune] Epoch 26/150  Loss=1.8802\n",
      "[Fine-tune] Epoch 27/150  Loss=1.8555\n",
      "[Fine-tune] Epoch 28/150  Loss=1.8347\n",
      "[Fine-tune] Epoch 29/150  Loss=1.8195\n",
      "[Fine-tune] Epoch 30/150  Loss=1.8080\n",
      "[Fine-tune] Epoch 31/150  Loss=1.7742\n",
      "[Fine-tune] Epoch 32/150  Loss=1.7717\n",
      "[Fine-tune] Epoch 33/150  Loss=1.7582\n",
      "[Fine-tune] Epoch 34/150  Loss=1.7350\n",
      "[Fine-tune] Epoch 35/150  Loss=1.7353\n",
      "[Fine-tune] Epoch 36/150  Loss=1.7260\n",
      "[Fine-tune] Epoch 37/150  Loss=1.7077\n",
      "[Fine-tune] Epoch 38/150  Loss=1.6899\n",
      "[Fine-tune] Epoch 39/150  Loss=1.6719\n",
      "[Fine-tune] Epoch 40/150  Loss=1.6701\n",
      "[Fine-tune] Epoch 41/150  Loss=1.6558\n",
      "[Fine-tune] Epoch 42/150  Loss=1.6451\n",
      "[Fine-tune] Epoch 43/150  Loss=1.6498\n",
      "[Fine-tune] Epoch 44/150  Loss=1.6404\n",
      "[Fine-tune] Epoch 45/150  Loss=1.6296\n",
      "[Fine-tune] Epoch 46/150  Loss=1.6115\n",
      "[Fine-tune] Epoch 47/150  Loss=1.6038\n",
      "[Fine-tune] Epoch 48/150  Loss=1.5977\n",
      "[Fine-tune] Epoch 49/150  Loss=1.5977\n",
      "[Fine-tune] Epoch 50/150  Loss=1.5895\n",
      "[Fine-tune] Epoch 51/150  Loss=1.5690\n",
      "[Fine-tune] Epoch 52/150  Loss=1.5737\n",
      "[Fine-tune] Epoch 53/150  Loss=1.5729\n",
      "[Fine-tune] Epoch 54/150  Loss=1.5659\n",
      "[Fine-tune] Epoch 55/150  Loss=1.5650\n",
      "[Fine-tune] Epoch 56/150  Loss=1.5611\n",
      "[Fine-tune] Epoch 57/150  Loss=1.5612\n",
      "[Fine-tune] Epoch 58/150  Loss=1.5418\n",
      "[Fine-tune] Epoch 59/150  Loss=1.5557\n",
      "[Fine-tune] Epoch 60/150  Loss=1.5421\n",
      "[Fine-tune] Epoch 61/150  Loss=1.5488\n",
      "[Fine-tune] Epoch 62/150  Loss=1.5443\n",
      "[Fine-tune] Epoch 63/150  Loss=1.5305\n",
      "[Fine-tune] Epoch 64/150  Loss=1.5213\n",
      "[Fine-tune] Epoch 65/150  Loss=1.5185\n",
      "[Fine-tune] Epoch 66/150  Loss=1.5147\n",
      "[Fine-tune] Epoch 67/150  Loss=1.5260\n",
      "[Fine-tune] Epoch 68/150  Loss=1.5107\n",
      "[Fine-tune] Epoch 69/150  Loss=1.5039\n",
      "[Fine-tune] Epoch 70/150  Loss=1.4993\n",
      "[Fine-tune] Epoch 71/150  Loss=1.5014\n",
      "[Fine-tune] Epoch 72/150  Loss=1.5177\n",
      "[Fine-tune] Epoch 73/150  Loss=1.4939\n",
      "[Fine-tune] Epoch 74/150  Loss=1.4969\n",
      "[Fine-tune] Epoch 75/150  Loss=1.5027\n",
      "[Fine-tune] Epoch 76/150  Loss=1.4787\n",
      "[Fine-tune] Epoch 77/150  Loss=1.4899\n",
      "[Fine-tune] Epoch 78/150  Loss=1.5073\n",
      "[Fine-tune] Epoch 79/150  Loss=1.4948\n",
      "[Fine-tune] Epoch 80/150  Loss=1.4833\n",
      "[Fine-tune] Epoch 81/150  Loss=1.4767\n",
      "[Fine-tune] Epoch 82/150  Loss=1.4823\n",
      "[Fine-tune] Epoch 83/150  Loss=1.4904\n",
      "[Fine-tune] Epoch 84/150  Loss=1.4838\n",
      "[Fine-tune] Epoch 85/150  Loss=1.4880\n",
      "[Fine-tune] Epoch 86/150  Loss=1.4811\n",
      "[Fine-tune] Epoch 87/150  Loss=1.4948\n",
      "[Fine-tune] Epoch 88/150  Loss=1.4739\n",
      "[Fine-tune] Epoch 89/150  Loss=1.4804\n",
      "[Fine-tune] Epoch 90/150  Loss=1.4781\n",
      "[Fine-tune] Epoch 91/150  Loss=1.4767\n",
      "[Fine-tune] Epoch 92/150  Loss=1.4725\n",
      "[Fine-tune] Epoch 93/150  Loss=1.4726\n",
      "[Fine-tune] Epoch 94/150  Loss=1.4697\n",
      "[Fine-tune] Epoch 95/150  Loss=1.4708\n",
      "[Fine-tune] Epoch 96/150  Loss=1.4647\n",
      "[Fine-tune] Epoch 97/150  Loss=1.4702\n",
      "[Fine-tune] Epoch 98/150  Loss=1.4749\n",
      "[Fine-tune] Epoch 99/150  Loss=1.4711\n",
      "[Fine-tune] Epoch 100/150  Loss=1.4673\n",
      "[Fine-tune] Epoch 101/150  Loss=1.4710\n",
      "[Fine-tune] Epoch 102/150  Loss=1.4705\n",
      "[Fine-tune] Epoch 103/150  Loss=1.4785\n",
      "[Fine-tune] Epoch 104/150  Loss=1.4641\n",
      "[Fine-tune] Epoch 105/150  Loss=1.4640\n",
      "[Fine-tune] Epoch 106/150  Loss=1.4753\n",
      "[Fine-tune] Epoch 107/150  Loss=1.4612\n",
      "[Fine-tune] Epoch 108/150  Loss=1.4662\n",
      "[Fine-tune] Epoch 109/150  Loss=1.4710\n",
      "[Fine-tune] Epoch 110/150  Loss=1.4637\n",
      "[Fine-tune] Epoch 111/150  Loss=1.4619\n",
      "[Fine-tune] Epoch 112/150  Loss=1.4665\n",
      "[Fine-tune] Epoch 113/150  Loss=1.4701\n",
      "[Fine-tune] Epoch 114/150  Loss=1.4539\n",
      "[Fine-tune] Epoch 115/150  Loss=1.4660\n",
      "[Fine-tune] Epoch 116/150  Loss=1.4559\n",
      "[Fine-tune] Epoch 117/150  Loss=1.4614\n",
      "[Fine-tune] Epoch 118/150  Loss=1.4611\n",
      "[Fine-tune] Epoch 119/150  Loss=1.4663\n",
      "[Fine-tune] Epoch 120/150  Loss=1.4653\n",
      "[Fine-tune] Epoch 121/150  Loss=1.4644\n",
      "[Fine-tune] Epoch 122/150  Loss=1.4572\n",
      "[Fine-tune] Epoch 123/150  Loss=1.4591\n",
      "[Fine-tune] Epoch 124/150  Loss=1.4695\n",
      "[Fine-tune] Epoch 125/150  Loss=1.4606\n",
      "[Fine-tune] Epoch 126/150  Loss=1.4699\n",
      "[Fine-tune] Epoch 127/150  Loss=1.4703\n",
      "[Fine-tune] Epoch 128/150  Loss=1.4473\n",
      "[Fine-tune] Epoch 129/150  Loss=1.4754\n",
      "[Fine-tune] Epoch 130/150  Loss=1.4649\n",
      "[Fine-tune] Epoch 131/150  Loss=1.4516\n",
      "[Fine-tune] Epoch 132/150  Loss=1.4658\n",
      "[Fine-tune] Epoch 133/150  Loss=1.4628\n",
      "[Fine-tune] Epoch 134/150  Loss=1.4587\n",
      "[Fine-tune] Epoch 135/150  Loss=1.4585\n",
      "[Fine-tune] Epoch 136/150  Loss=1.4663\n",
      "[Fine-tune] Epoch 137/150  Loss=1.4693\n",
      "[Fine-tune] Epoch 138/150  Loss=1.4536\n",
      "[Fine-tune] Epoch 139/150  Loss=1.4598\n",
      "[Fine-tune] Epoch 140/150  Loss=1.4668\n",
      "[Fine-tune] Epoch 141/150  Loss=1.4619\n",
      "[Fine-tune] Epoch 142/150  Loss=1.4542\n",
      "[Fine-tune] Epoch 143/150  Loss=1.4702\n",
      "[Fine-tune] Epoch 144/150  Loss=1.4610\n",
      "[Fine-tune] Epoch 145/150  Loss=1.4492\n",
      "[Fine-tune] Epoch 146/150  Loss=1.4624\n",
      "[Fine-tune] Epoch 147/150  Loss=1.4484\n",
      "[Fine-tune] Epoch 148/150  Loss=1.4633\n",
      "[Fine-tune] Epoch 149/150  Loss=1.4659\n",
      "[Fine-tune] Epoch 150/150  Loss=1.4589\n",
      "[Pretrain] Epoch 1/150  Loss=3.2067  Acc=0.0514\n",
      "[Pretrain] Epoch 2/150  Loss=2.8357  Acc=0.1049\n",
      "[Pretrain] Epoch 3/150  Loss=2.6003  Acc=0.1670\n",
      "[Pretrain] Epoch 4/150  Loss=2.4856  Acc=0.2078\n",
      "[Pretrain] Epoch 5/150  Loss=2.3522  Acc=0.2452\n",
      "[Pretrain] Epoch 6/150  Loss=2.2835  Acc=0.2662\n",
      "[Pretrain] Epoch 7/150  Loss=2.2043  Acc=0.2884\n",
      "[Pretrain] Epoch 8/150  Loss=2.1701  Acc=0.2938\n",
      "[Pretrain] Epoch 9/150  Loss=2.0935  Acc=0.3281\n",
      "[Pretrain] Epoch 10/150  Loss=2.0529  Acc=0.3335\n",
      "[Pretrain] Epoch 11/150  Loss=2.0075  Acc=0.3448\n",
      "[Pretrain] Epoch 12/150  Loss=1.9644  Acc=0.3648\n",
      "[Pretrain] Epoch 13/150  Loss=1.9529  Acc=0.3723\n",
      "[Pretrain] Epoch 14/150  Loss=1.8993  Acc=0.3847\n",
      "[Pretrain] Epoch 15/150  Loss=1.8649  Acc=0.3976\n",
      "[Pretrain] Epoch 16/150  Loss=1.8454  Acc=0.4057\n",
      "[Pretrain] Epoch 17/150  Loss=1.8300  Acc=0.4030\n",
      "[Pretrain] Epoch 18/150  Loss=1.8094  Acc=0.4177\n",
      "[Pretrain] Epoch 19/150  Loss=1.7769  Acc=0.4273\n",
      "[Pretrain] Epoch 20/150  Loss=1.7633  Acc=0.4285\n",
      "[Pretrain] Epoch 21/150  Loss=1.7442  Acc=0.4409\n",
      "[Pretrain] Epoch 22/150  Loss=1.7202  Acc=0.4423\n",
      "[Pretrain] Epoch 23/150  Loss=1.6813  Acc=0.4537\n",
      "[Pretrain] Epoch 24/150  Loss=1.6626  Acc=0.4607\n",
      "[Pretrain] Epoch 25/150  Loss=1.6583  Acc=0.4695\n",
      "[Pretrain] Epoch 26/150  Loss=1.6596  Acc=0.4617\n",
      "[Pretrain] Epoch 27/150  Loss=1.6236  Acc=0.4740\n",
      "[Pretrain] Epoch 28/150  Loss=1.5879  Acc=0.4865\n",
      "[Pretrain] Epoch 29/150  Loss=1.5838  Acc=0.4905\n",
      "[Pretrain] Epoch 30/150  Loss=1.5575  Acc=0.4952\n",
      "[Pretrain] Epoch 31/150  Loss=1.5489  Acc=0.5007\n",
      "[Pretrain] Epoch 32/150  Loss=1.5478  Acc=0.4962\n",
      "[Pretrain] Epoch 33/150  Loss=1.5208  Acc=0.5102\n",
      "[Pretrain] Epoch 34/150  Loss=1.5164  Acc=0.5025\n",
      "[Pretrain] Epoch 35/150  Loss=1.5070  Acc=0.5133\n",
      "[Pretrain] Epoch 36/150  Loss=1.4874  Acc=0.5162\n",
      "[Pretrain] Epoch 37/150  Loss=1.4716  Acc=0.5180\n",
      "[Pretrain] Epoch 38/150  Loss=1.4508  Acc=0.5216\n",
      "[Pretrain] Epoch 39/150  Loss=1.4469  Acc=0.5271\n",
      "[Pretrain] Epoch 40/150  Loss=1.4358  Acc=0.5359\n",
      "[Pretrain] Epoch 41/150  Loss=1.4105  Acc=0.5388\n",
      "[Pretrain] Epoch 42/150  Loss=1.4175  Acc=0.5409\n",
      "[Pretrain] Epoch 43/150  Loss=1.4011  Acc=0.5481\n",
      "[Pretrain] Epoch 44/150  Loss=1.3956  Acc=0.5436\n",
      "[Pretrain] Epoch 45/150  Loss=1.4079  Acc=0.5368\n",
      "[Pretrain] Epoch 46/150  Loss=1.3733  Acc=0.5569\n",
      "[Pretrain] Epoch 47/150  Loss=1.3706  Acc=0.5524\n",
      "[Pretrain] Epoch 48/150  Loss=1.3652  Acc=0.5569\n",
      "[Pretrain] Epoch 49/150  Loss=1.3600  Acc=0.5594\n",
      "[Pretrain] Epoch 50/150  Loss=1.3330  Acc=0.5668\n",
      "[Pretrain] Epoch 51/150  Loss=1.3451  Acc=0.5609\n",
      "[Pretrain] Epoch 52/150  Loss=1.3427  Acc=0.5663\n",
      "[Pretrain] Epoch 53/150  Loss=1.3235  Acc=0.5738\n",
      "[Pretrain] Epoch 54/150  Loss=1.3394  Acc=0.5632\n",
      "[Pretrain] Epoch 55/150  Loss=1.3271  Acc=0.5639\n",
      "[Pretrain] Epoch 56/150  Loss=1.3271  Acc=0.5713\n",
      "[Pretrain] Epoch 57/150  Loss=1.3257  Acc=0.5634\n",
      "[Pretrain] Epoch 58/150  Loss=1.3174  Acc=0.5763\n",
      "[Pretrain] Epoch 59/150  Loss=1.3001  Acc=0.5756\n",
      "[Pretrain] Epoch 60/150  Loss=1.2960  Acc=0.5711\n",
      "[Pretrain] Epoch 61/150  Loss=1.2860  Acc=0.5781\n",
      "[Pretrain] Epoch 62/150  Loss=1.2972  Acc=0.5726\n",
      "[Pretrain] Epoch 63/150  Loss=1.2979  Acc=0.5740\n",
      "[Pretrain] Epoch 64/150  Loss=1.2901  Acc=0.5790\n",
      "[Pretrain] Epoch 65/150  Loss=1.2937  Acc=0.5763\n",
      "[Pretrain] Epoch 66/150  Loss=1.2923  Acc=0.5833\n",
      "[Pretrain] Epoch 67/150  Loss=1.2928  Acc=0.5810\n",
      "[Pretrain] Epoch 68/150  Loss=1.2900  Acc=0.5776\n",
      "[Pretrain] Epoch 69/150  Loss=1.2821  Acc=0.5876\n",
      "[Pretrain] Epoch 70/150  Loss=1.2615  Acc=0.5855\n",
      "[Pretrain] Epoch 71/150  Loss=1.2847  Acc=0.5787\n",
      "[Pretrain] Epoch 72/150  Loss=1.2603  Acc=0.5867\n",
      "[Pretrain] Epoch 73/150  Loss=1.2673  Acc=0.5878\n",
      "[Pretrain] Epoch 74/150  Loss=1.2583  Acc=0.5977\n",
      "[Pretrain] Epoch 75/150  Loss=1.2561  Acc=0.5912\n",
      "[Pretrain] Epoch 76/150  Loss=1.2683  Acc=0.5903\n",
      "[Pretrain] Epoch 77/150  Loss=1.2639  Acc=0.5880\n",
      "[Pretrain] Epoch 78/150  Loss=1.2536  Acc=0.5970\n",
      "[Pretrain] Epoch 79/150  Loss=1.2542  Acc=0.5920\n",
      "[Pretrain] Epoch 80/150  Loss=1.2503  Acc=0.5941\n",
      "[Pretrain] Epoch 81/150  Loss=1.2602  Acc=0.5880\n",
      "[Pretrain] Epoch 82/150  Loss=1.2660  Acc=0.5943\n",
      "[Pretrain] Epoch 83/150  Loss=1.2531  Acc=0.5900\n",
      "[Pretrain] Epoch 84/150  Loss=1.2583  Acc=0.5923\n",
      "[Pretrain] Epoch 85/150  Loss=1.2478  Acc=0.5943\n",
      "[Pretrain] Epoch 86/150  Loss=1.2499  Acc=0.6002\n",
      "[Pretrain] Epoch 87/150  Loss=1.2505  Acc=0.5923\n",
      "[Pretrain] Epoch 88/150  Loss=1.2546  Acc=0.5925\n",
      "[Pretrain] Epoch 89/150  Loss=1.2438  Acc=0.5984\n",
      "[Pretrain] Epoch 90/150  Loss=1.2367  Acc=0.5972\n",
      "[Pretrain] Epoch 91/150  Loss=1.2445  Acc=0.5927\n",
      "[Pretrain] Epoch 92/150  Loss=1.2535  Acc=0.5911\n",
      "[Pretrain] Epoch 93/150  Loss=1.2467  Acc=0.5968\n",
      "[Pretrain] Epoch 94/150  Loss=1.2430  Acc=0.5930\n",
      "[Pretrain] Epoch 95/150  Loss=1.2394  Acc=0.5973\n",
      "[Pretrain] Epoch 96/150  Loss=1.2425  Acc=0.5936\n",
      "[Pretrain] Epoch 97/150  Loss=1.2344  Acc=0.6000\n",
      "[Pretrain] Epoch 98/150  Loss=1.2433  Acc=0.5954\n",
      "[Pretrain] Epoch 99/150  Loss=1.2485  Acc=0.5860\n",
      "[Pretrain] Epoch 100/150  Loss=1.2363  Acc=0.5986\n",
      "[Pretrain] Epoch 101/150  Loss=1.2427  Acc=0.5968\n",
      "[Pretrain] Epoch 102/150  Loss=1.2292  Acc=0.6049\n",
      "[Pretrain] Epoch 103/150  Loss=1.2409  Acc=0.6004\n",
      "[Pretrain] Epoch 104/150  Loss=1.2337  Acc=0.5946\n",
      "[Pretrain] Epoch 105/150  Loss=1.2479  Acc=0.5900\n",
      "[Pretrain] Epoch 106/150  Loss=1.2349  Acc=0.5997\n",
      "[Pretrain] Epoch 107/150  Loss=1.2448  Acc=0.5932\n",
      "[Pretrain] Epoch 108/150  Loss=1.2403  Acc=0.5991\n",
      "[Pretrain] Epoch 109/150  Loss=1.2426  Acc=0.5964\n",
      "[Pretrain] Epoch 110/150  Loss=1.2406  Acc=0.5936\n",
      "[Pretrain] Epoch 111/150  Loss=1.2581  Acc=0.5887\n",
      "[Pretrain] Epoch 112/150  Loss=1.2239  Acc=0.6018\n",
      "[Pretrain] Epoch 113/150  Loss=1.2445  Acc=0.5990\n",
      "[Pretrain] Epoch 114/150  Loss=1.2433  Acc=0.5982\n",
      "[Pretrain] Epoch 115/150  Loss=1.2392  Acc=0.5982\n",
      "[Pretrain] Epoch 116/150  Loss=1.2493  Acc=0.5930\n",
      "[Pretrain] Epoch 117/150  Loss=1.2417  Acc=0.5903\n",
      "[Pretrain] Epoch 118/150  Loss=1.2136  Acc=0.6063\n",
      "[Pretrain] Epoch 119/150  Loss=1.2504  Acc=0.5925\n",
      "[Pretrain] Epoch 120/150  Loss=1.2099  Acc=0.6045\n",
      "[Pretrain] Epoch 121/150  Loss=1.2408  Acc=0.5961\n",
      "[Pretrain] Epoch 122/150  Loss=1.2310  Acc=0.6015\n",
      "[Pretrain] Epoch 123/150  Loss=1.2218  Acc=0.6000\n",
      "[Pretrain] Epoch 124/150  Loss=1.2438  Acc=0.5925\n",
      "[Pretrain] Epoch 125/150  Loss=1.2328  Acc=0.5963\n",
      "[Pretrain] Epoch 126/150  Loss=1.2334  Acc=0.5955\n",
      "[Pretrain] Epoch 127/150  Loss=1.2308  Acc=0.6008\n",
      "[Pretrain] Epoch 128/150  Loss=1.2401  Acc=0.6026\n",
      "[Pretrain] Epoch 129/150  Loss=1.2333  Acc=0.5979\n",
      "[Pretrain] Epoch 130/150  Loss=1.2254  Acc=0.5972\n",
      "[Pretrain] Epoch 131/150  Loss=1.2291  Acc=0.5975\n",
      "[Pretrain] Epoch 132/150  Loss=1.2219  Acc=0.6027\n",
      "[Pretrain] Epoch 133/150  Loss=1.2297  Acc=0.5991\n",
      "[Pretrain] Epoch 134/150  Loss=1.2444  Acc=0.5943\n",
      "[Pretrain] Epoch 135/150  Loss=1.2179  Acc=0.6033\n",
      "[Pretrain] Epoch 136/150  Loss=1.2332  Acc=0.6009\n",
      "[Pretrain] Epoch 137/150  Loss=1.2244  Acc=0.5972\n",
      "[Pretrain] Epoch 138/150  Loss=1.2373  Acc=0.6011\n",
      "[Pretrain] Epoch 139/150  Loss=1.2206  Acc=0.6067\n",
      "[Pretrain] Epoch 140/150  Loss=1.2410  Acc=0.6006\n",
      "[Pretrain] Epoch 141/150  Loss=1.2252  Acc=0.5995\n",
      "[Pretrain] Epoch 142/150  Loss=1.2328  Acc=0.5957\n",
      "[Pretrain] Epoch 143/150  Loss=1.2223  Acc=0.6017\n",
      "[Pretrain] Epoch 144/150  Loss=1.2256  Acc=0.6018\n",
      "[Pretrain] Epoch 145/150  Loss=1.2201  Acc=0.6034\n",
      "[Pretrain] Epoch 146/150  Loss=1.2284  Acc=0.5948\n",
      "[Pretrain] Epoch 147/150  Loss=1.2320  Acc=0.6043\n",
      "[Pretrain] Epoch 148/150  Loss=1.2243  Acc=0.6034\n",
      "[Pretrain] Epoch 149/150  Loss=1.2148  Acc=0.5979\n",
      "[Pretrain] Epoch 150/150  Loss=1.2322  Acc=0.5990\n",
      "[Fine-tune] Epoch 1/150  Loss=3.2965\n",
      "[Fine-tune] Epoch 2/150  Loss=3.1484\n",
      "[Fine-tune] Epoch 3/150  Loss=3.0850\n",
      "[Fine-tune] Epoch 4/150  Loss=3.0623\n",
      "[Fine-tune] Epoch 5/150  Loss=3.0464\n",
      "[Fine-tune] Epoch 6/150  Loss=3.0266\n",
      "[Fine-tune] Epoch 7/150  Loss=2.9386\n",
      "[Fine-tune] Epoch 8/150  Loss=2.7283\n",
      "[Fine-tune] Epoch 9/150  Loss=2.5992\n",
      "[Fine-tune] Epoch 10/150  Loss=2.4989\n",
      "[Fine-tune] Epoch 11/150  Loss=2.4394\n",
      "[Fine-tune] Epoch 12/150  Loss=2.4061\n",
      "[Fine-tune] Epoch 13/150  Loss=2.3617\n",
      "[Fine-tune] Epoch 14/150  Loss=2.3204\n",
      "[Fine-tune] Epoch 15/150  Loss=2.2915\n",
      "[Fine-tune] Epoch 16/150  Loss=2.2445\n",
      "[Fine-tune] Epoch 17/150  Loss=2.1943\n",
      "[Fine-tune] Epoch 18/150  Loss=2.1697\n",
      "[Fine-tune] Epoch 19/150  Loss=2.1549\n",
      "[Fine-tune] Epoch 20/150  Loss=2.1156\n",
      "[Fine-tune] Epoch 21/150  Loss=2.1012\n",
      "[Fine-tune] Epoch 22/150  Loss=2.0656\n",
      "[Fine-tune] Epoch 23/150  Loss=2.0427\n",
      "[Fine-tune] Epoch 24/150  Loss=2.0241\n",
      "[Fine-tune] Epoch 25/150  Loss=2.0272\n",
      "[Fine-tune] Epoch 26/150  Loss=1.9876\n",
      "[Fine-tune] Epoch 27/150  Loss=1.9736\n",
      "[Fine-tune] Epoch 28/150  Loss=1.9643\n",
      "[Fine-tune] Epoch 29/150  Loss=1.9201\n",
      "[Fine-tune] Epoch 30/150  Loss=1.9145\n",
      "[Fine-tune] Epoch 31/150  Loss=1.8852\n",
      "[Fine-tune] Epoch 32/150  Loss=1.8634\n",
      "[Fine-tune] Epoch 33/150  Loss=1.8568\n",
      "[Fine-tune] Epoch 34/150  Loss=1.8413\n",
      "[Fine-tune] Epoch 35/150  Loss=1.8006\n",
      "[Fine-tune] Epoch 36/150  Loss=1.8005\n",
      "[Fine-tune] Epoch 37/150  Loss=1.7909\n",
      "[Fine-tune] Epoch 38/150  Loss=1.7853\n",
      "[Fine-tune] Epoch 39/150  Loss=1.7648\n",
      "[Fine-tune] Epoch 40/150  Loss=1.7415\n",
      "[Fine-tune] Epoch 41/150  Loss=1.7473\n",
      "[Fine-tune] Epoch 42/150  Loss=1.7268\n",
      "[Fine-tune] Epoch 43/150  Loss=1.7017\n",
      "[Fine-tune] Epoch 44/150  Loss=1.6926\n",
      "[Fine-tune] Epoch 45/150  Loss=1.6973\n",
      "[Fine-tune] Epoch 46/150  Loss=1.6735\n",
      "[Fine-tune] Epoch 47/150  Loss=1.6654\n",
      "[Fine-tune] Epoch 48/150  Loss=1.6486\n",
      "[Fine-tune] Epoch 49/150  Loss=1.6553\n",
      "[Fine-tune] Epoch 50/150  Loss=1.6411\n",
      "[Fine-tune] Epoch 51/150  Loss=1.6418\n",
      "[Fine-tune] Epoch 52/150  Loss=1.6086\n",
      "[Fine-tune] Epoch 53/150  Loss=1.6150\n",
      "[Fine-tune] Epoch 54/150  Loss=1.6202\n",
      "[Fine-tune] Epoch 55/150  Loss=1.6112\n",
      "[Fine-tune] Epoch 56/150  Loss=1.6002\n",
      "[Fine-tune] Epoch 57/150  Loss=1.6054\n",
      "[Fine-tune] Epoch 58/150  Loss=1.5965\n",
      "[Fine-tune] Epoch 59/150  Loss=1.5764\n",
      "[Fine-tune] Epoch 60/150  Loss=1.5916\n",
      "[Fine-tune] Epoch 61/150  Loss=1.5734\n",
      "[Fine-tune] Epoch 62/150  Loss=1.5716\n",
      "[Fine-tune] Epoch 63/150  Loss=1.5737\n",
      "[Fine-tune] Epoch 64/150  Loss=1.5651\n",
      "[Fine-tune] Epoch 65/150  Loss=1.5439\n",
      "[Fine-tune] Epoch 66/150  Loss=1.5503\n",
      "[Fine-tune] Epoch 67/150  Loss=1.5506\n",
      "[Fine-tune] Epoch 68/150  Loss=1.5394\n",
      "[Fine-tune] Epoch 69/150  Loss=1.5521\n",
      "[Fine-tune] Epoch 70/150  Loss=1.5506\n",
      "[Fine-tune] Epoch 71/150  Loss=1.5271\n",
      "[Fine-tune] Epoch 72/150  Loss=1.5382\n",
      "[Fine-tune] Epoch 73/150  Loss=1.5307\n",
      "[Fine-tune] Epoch 74/150  Loss=1.5340\n",
      "[Fine-tune] Epoch 75/150  Loss=1.5265\n",
      "[Fine-tune] Epoch 76/150  Loss=1.5233\n",
      "[Fine-tune] Epoch 77/150  Loss=1.5174\n",
      "[Fine-tune] Epoch 78/150  Loss=1.5089\n",
      "[Fine-tune] Epoch 79/150  Loss=1.5235\n",
      "[Fine-tune] Epoch 80/150  Loss=1.5166\n",
      "[Fine-tune] Epoch 81/150  Loss=1.5204\n",
      "[Fine-tune] Epoch 82/150  Loss=1.4950\n",
      "[Fine-tune] Epoch 83/150  Loss=1.5084\n",
      "[Fine-tune] Epoch 84/150  Loss=1.5187\n",
      "[Fine-tune] Epoch 85/150  Loss=1.5360\n",
      "[Fine-tune] Epoch 86/150  Loss=1.5052\n",
      "[Fine-tune] Epoch 87/150  Loss=1.4992\n",
      "[Fine-tune] Epoch 88/150  Loss=1.5025\n",
      "[Fine-tune] Epoch 89/150  Loss=1.4972\n",
      "[Fine-tune] Epoch 90/150  Loss=1.5093\n",
      "[Fine-tune] Epoch 91/150  Loss=1.4971\n",
      "[Fine-tune] Epoch 92/150  Loss=1.5016\n",
      "[Fine-tune] Epoch 93/150  Loss=1.5012\n",
      "[Fine-tune] Epoch 94/150  Loss=1.4999\n",
      "[Fine-tune] Epoch 95/150  Loss=1.4908\n",
      "[Fine-tune] Epoch 96/150  Loss=1.4937\n",
      "[Fine-tune] Epoch 97/150  Loss=1.4955\n",
      "[Fine-tune] Epoch 98/150  Loss=1.4998\n",
      "[Fine-tune] Epoch 99/150  Loss=1.4989\n",
      "[Fine-tune] Epoch 100/150  Loss=1.4950\n",
      "[Fine-tune] Epoch 101/150  Loss=1.4992\n",
      "[Fine-tune] Epoch 102/150  Loss=1.4926\n",
      "[Fine-tune] Epoch 103/150  Loss=1.4992\n",
      "[Fine-tune] Epoch 104/150  Loss=1.4834\n",
      "[Fine-tune] Epoch 105/150  Loss=1.4951\n",
      "[Fine-tune] Epoch 106/150  Loss=1.4927\n",
      "[Fine-tune] Epoch 107/150  Loss=1.4767\n",
      "[Fine-tune] Epoch 108/150  Loss=1.4941\n",
      "[Fine-tune] Epoch 109/150  Loss=1.4830\n",
      "[Fine-tune] Epoch 110/150  Loss=1.4948\n",
      "[Fine-tune] Epoch 111/150  Loss=1.5023\n",
      "[Fine-tune] Epoch 112/150  Loss=1.4974\n",
      "[Fine-tune] Epoch 113/150  Loss=1.4865\n",
      "[Fine-tune] Epoch 114/150  Loss=1.4830\n",
      "[Fine-tune] Epoch 115/150  Loss=1.4808\n",
      "[Fine-tune] Epoch 116/150  Loss=1.4950\n",
      "[Fine-tune] Epoch 117/150  Loss=1.4693\n",
      "[Fine-tune] Epoch 118/150  Loss=1.4849\n",
      "[Fine-tune] Epoch 119/150  Loss=1.4817\n",
      "[Fine-tune] Epoch 120/150  Loss=1.4685\n",
      "[Fine-tune] Epoch 121/150  Loss=1.4786\n",
      "[Fine-tune] Epoch 122/150  Loss=1.4856\n",
      "[Fine-tune] Epoch 123/150  Loss=1.4951\n",
      "[Fine-tune] Epoch 124/150  Loss=1.4918\n",
      "[Fine-tune] Epoch 125/150  Loss=1.4816\n",
      "[Fine-tune] Epoch 126/150  Loss=1.4818\n",
      "[Fine-tune] Epoch 127/150  Loss=1.4858\n",
      "[Fine-tune] Epoch 128/150  Loss=1.4733\n",
      "[Fine-tune] Epoch 129/150  Loss=1.4956\n",
      "[Fine-tune] Epoch 130/150  Loss=1.4839\n",
      "[Fine-tune] Epoch 131/150  Loss=1.4799\n",
      "[Fine-tune] Epoch 132/150  Loss=1.4789\n",
      "[Fine-tune] Epoch 133/150  Loss=1.4921\n",
      "[Fine-tune] Epoch 134/150  Loss=1.4774\n",
      "[Fine-tune] Epoch 135/150  Loss=1.4743\n",
      "[Fine-tune] Epoch 136/150  Loss=1.4850\n",
      "[Fine-tune] Epoch 137/150  Loss=1.4901\n",
      "[Fine-tune] Epoch 138/150  Loss=1.4777\n",
      "[Fine-tune] Epoch 139/150  Loss=1.4799\n",
      "[Fine-tune] Epoch 140/150  Loss=1.4806\n",
      "[Fine-tune] Epoch 141/150  Loss=1.4857\n",
      "[Fine-tune] Epoch 142/150  Loss=1.4665\n",
      "[Fine-tune] Epoch 143/150  Loss=1.4777\n",
      "[Fine-tune] Epoch 144/150  Loss=1.4804\n",
      "[Fine-tune] Epoch 145/150  Loss=1.4787\n",
      "[Fine-tune] Epoch 146/150  Loss=1.4703\n",
      "[Fine-tune] Epoch 147/150  Loss=1.4885\n",
      "[Fine-tune] Epoch 148/150  Loss=1.4915\n",
      "[Fine-tune] Epoch 149/150  Loss=1.5025\n",
      "[Fine-tune] Epoch 150/150  Loss=1.4899\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[93]\u001B[39m\u001B[32m, line 47\u001B[39m\n\u001B[32m     44\u001B[39m embd_unit = embd_train / np.linalg.norm(embd_train, axis=\u001B[32m1\u001B[39m, keepdims=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m     45\u001B[39m writer.add_figure(\u001B[33m\"\u001B[39m\u001B[33mtsne_test\u001B[39m\u001B[33m\"\u001B[39m, fig_test)\n\u001B[32m---> \u001B[39m\u001B[32m47\u001B[39m fig = \u001B[43mplot_distance_distribution_return\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     48\u001B[39m \u001B[43m    \u001B[49m\u001B[43membeddings\u001B[49m\u001B[43m=\u001B[49m\u001B[43membd_unit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     49\u001B[39m \u001B[43m    \u001B[49m\u001B[43mparticipant_ids\u001B[49m\u001B[43m=\u001B[49m\u001B[43mnp\u001B[49m\u001B[43m.\u001B[49m\u001B[43marray\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_train_encoded\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     50\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdistance_type\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43meuclidean\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     51\u001B[39m \u001B[43m    \u001B[49m\u001B[43mbins\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m30\u001B[39;49m\n\u001B[32m     52\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     53\u001B[39m writer.add_figure(\u001B[33m\"\u001B[39m\u001B[33mdistance_distribution_euclidean\u001B[39m\u001B[33m\"\u001B[39m, fig)\n\u001B[32m     55\u001B[39m fig = plot_distance_distribution_return(\n\u001B[32m     56\u001B[39m     embeddings=embd_train,\n\u001B[32m     57\u001B[39m     participant_ids=np.array(y_train_encoded),\n\u001B[32m     58\u001B[39m     distance_type=\u001B[33m\"\u001B[39m\u001B[33mcosine\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     59\u001B[39m     bins=\u001B[32m30\u001B[39m\n\u001B[32m     60\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\Neuron\\NeuroGuard\\artificial-intelligence\\eeg_lib\\utils\\visualisations.py:262\u001B[39m, in \u001B[36mplot_distance_distribution_return\u001B[39m\u001B[34m(embeddings, participant_ids, distance_type, bins, figsize)\u001B[39m\n\u001B[32m    260\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(N):\n\u001B[32m    261\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m j \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(i+\u001B[32m1\u001B[39m, N):\n\u001B[32m--> \u001B[39m\u001B[32m262\u001B[39m         (genuine \u001B[38;5;28;01mif\u001B[39;00m participant_ids[i]==participant_ids[j] \u001B[38;5;28;01melse\u001B[39;00m imposter).append(all_dists[i,j])\n\u001B[32m    264\u001B[39m ax.hist(genuine, bins=bins, alpha=\u001B[32m0.5\u001B[39m, color=\u001B[33m\"\u001B[39m\u001B[33mtab:blue\u001B[39m\u001B[33m\"\u001B[39m, label=\u001B[33m\"\u001B[39m\u001B[33mGenuine\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    265\u001B[39m ax.hist(imposter, bins=bins, alpha=\u001B[32m0.5\u001B[39m, color=\u001B[33m\"\u001B[39m\u001B[33mtab:orange\u001B[39m\u001B[33m\"\u001B[39m, label=\u001B[33m\"\u001B[39m\u001B[33mImposter\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg8AAAFlCAYAAABsogsDAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAGIRJREFUeJzt3X1sV9X9B/APDwKaSdUxQFiVqfNpKigIQyTGhUmiwfnHMqYGGPFhTmcczSYgCuJTnVNDMlEi6vSPOXBGjBFSdUxinCxEkEQ3wShqmZGnOSlDLQr3l3N/aUehKAfbQuH1Sm7g3p7Te77H2vvm3HPu7VAURREAALup4+4WBABIhAcAIIvwAABkER4AgCzCAwCQRXgAALIIDwBAFuEBAMgiPAAAWYQHAKB1w8NLL70Uo0aNij59+kSHDh3i6aef/so6ixYtijPOOCO6du0axx13XDz66KO5pwUA2mt42Lx5c/Tv3z9mzpy5W+XffffduOCCC+Lcc8+N5cuXx69+9au4/PLL47nnntuT9gIAe1mHr/NirDTyMG/evLjooot2WWbixIkxf/78eOONNxqP/fSnP42PP/44ampq9vTUAMBe0rm1T7B48eIYMWJEk2MjR44sRyB2pb6+vtwabNu2LT766KP45je/WQYWAGD3pDGCTZs2ldMNOnbs2D7Cw5o1a6JXr15NjqX9urq6+PTTT+Pggw/eqU51dXVMnz69tZsGAAeM1atXx7e//e32ER72xOTJk6Oqqqpxf+PGjXHUUUeVH7x79+57tW0A0J6kf6xXVlbGoYce2mLfs9XDQ+/evWPt2rVNjqX9FAKaG3VI0qqMtO0o1REeACBfS972b/XnPAwdOjQWLlzY5NgLL7xQHgcA2p/s8PDf//63XHKZtoalmOnvtbW1jbccxo4d21j+qquuilWrVsX1118fK1asiPvvvz+eeOKJmDBhQkt+DgBgXw0Pr776apx++unllqS5CenvU6dOLfc//PDDxiCRfOc73ymXaqbRhvR8iHvuuSceeuihcsUFAHCAPeehLSd7VFRUlBMnzXkAgL17DfVuCwAgi/AAAGQRHgCALMIDAJBFeAAAsggPAEAW4QEAyCI8AABZhAcAIIvwAABkER4AgCzCAwCQRXgAALIIDwBAFuEBAMgiPAAAWYQHACCL8AAAZBEeAIAswgMAkEV4AACyCA8AQBbhAQDIIjwAAFmEBwAgi/AAAGQRHgCALMIDAJBFeAAAsggPAEAW4QEAyCI8AABZhAcAIIvwAABkER4AgCzCAwCQRXgAALIIDwBAFuEBAMgiPAAAWYQHACCL8AAAZBEeAIAswgMAkEV4AACyCA8AQBbhAQDIIjwAAFmEBwAgi/AAAGQRHgCA1g8PM2fOjH79+kW3bt1iyJAhsWTJki8tP2PGjDjhhBPi4IMPjsrKypgwYUJ89tlne3JqAKC9hYe5c+dGVVVVTJs2LZYtWxb9+/ePkSNHxrp165ot//jjj8ekSZPK8m+++WY8/PDD5fe44YYbWqL9AMC+Hh7uvffeuOKKK2L8+PFx8sknx6xZs+KQQw6JRx55pNnyr7zySgwbNiwuueSScrTivPPOi4svvvgrRysAgP0gPGzZsiWWLl0aI0aM+N836Nix3F+8eHGzdc4666yyTkNYWLVqVSxYsCDOP//8XZ6nvr4+6urqmmwAwL6hc07hDRs2xNatW6NXr15Njqf9FStWNFsnjTikemeffXYURRFffPFFXHXVVV9626K6ujqmT5+e0zQAYH9ZbbFo0aK444474v777y/nSDz11FMxf/78uPXWW3dZZ/LkybFx48bGbfXq1a3dTACgNUYeevToEZ06dYq1a9c2OZ72e/fu3Wydm266KcaMGROXX355uX/qqafG5s2b48orr4wpU6aUtz121LVr13IDANr5yEOXLl1i4MCBsXDhwsZj27ZtK/eHDh3abJ1PPvlkp4CQAkiSbmMAAPvxyEOSlmmOGzcuBg0aFIMHDy6f4ZBGEtLqi2Ts2LHRt2/fct5CMmrUqHKFxumnn14+E+Ltt98uRyPS8YYQAQDsx+Fh9OjRsX79+pg6dWqsWbMmBgwYEDU1NY2TKGtra5uMNNx4443RoUOH8s8PPvggvvWtb5XB4fbbb2/ZTwIAtIkORTu4d5CWalZUVJSTJ7t37763mwMA7UZrXEO92wIAyCI8AABZhAcAIIvwAABkER4AgCzCAwCQRXgAALIIDwBAFuEBAMgiPAAAWYQHACCL8AAAZBEeAIAswgMAkEV4AACyCA8AQBbhAQDIIjwAAFmEBwAgi/AAAGQRHgCALMIDAJBFeAAAsggPAEAW4QEAyCI8AABZhAcAIIvwAABkER4AgCzCAwCQRXgAALIIDwBAFuEBAMgiPAAAWYQHACCL8AAAZBEeAIAswgMAkEV4AACyCA8AQBbhAQDIIjwAAFmEBwAgi/AAAGQRHgCALMIDAJBFeAAAsggPAEAW4QEAyCI8AACtHx5mzpwZ/fr1i27dusWQIUNiyZIlX1r+448/jmuuuSaOPPLI6Nq1axx//PGxYMGCPTk1ALCXdc6tMHfu3KiqqopZs2aVwWHGjBkxcuTIWLlyZfTs2XOn8lu2bIkf/vCH5deefPLJ6Nu3b7z//vtx2GGHtdRnAADaUIeiKIqcCikwnHnmmXHfffeV+9u2bYvKysq49tprY9KkSTuVTyHjd7/7XaxYsSIOOuigPWpkXV1dVFRUxMaNG6N79+579D0A4EBU1wrX0KzbFmkUYenSpTFixIj/fYOOHcv9xYsXN1vnmWeeiaFDh5a3LXr16hWnnHJK3HHHHbF169Zdnqe+vr78sNtvAMC+ISs8bNiwobzopxCwvbS/Zs2aZuusWrWqvF2R6qV5DjfddFPcc889cdttt+3yPNXV1WVKatjSyAYAcICstki3NdJ8hwcffDAGDhwYo0ePjilTppS3M3Zl8uTJ5fBKw7Z69erWbiYA0BoTJnv06BGdOnWKtWvXNjme9nv37t1snbTCIs11SPUanHTSSeVIRboN0qVLl53qpBUZaQMA2vnIQ7rQp9GDhQsXNhlZSPtpXkNzhg0bFm+//XZZrsFbb71VhormggMAsJ/dtkjLNGfPnh2PPfZYvPnmm/GLX/wiNm/eHOPHjy+/Pnbs2PK2Q4P09Y8++iiuu+66MjTMnz+/nDCZJlACAAfAcx7SnIX169fH1KlTy1sPAwYMiJqamsZJlLW1teUKjAZpsuNzzz0XEyZMiNNOO618zkMKEhMnTmzZTwIA7JvPedgbPOcBANrpcx4AAIQHACCL8AAAZBEeAIAswgMAkEV4AACyCA8AQBbhAQDIIjwAAFmEBwAgi/AAAGQRHgCALMIDAJBFeAAAsggPAEAW4QEAyCI8AABZhAcAIIvwAABkER4AgCzCAwCQRXgAALIIDwBAFuEBAMgiPAAAWYQHACCL8AAAZBEeAIAswgMAkEV4AACyCA8AQBbhAQDIIjwAAFmEBwAgi/AAAGQRHgCALMIDAJBFeAAAsggPAEAW4QEAyCI8AABZhAcAIIvwAABkER4AgCzCAwCQRXgAALIIDwBAFuEBAMgiPAAAWYQHACCL8AAAtH54mDlzZvTr1y+6desWQ4YMiSVLluxWvTlz5kSHDh3ioosu2pPTAgDtMTzMnTs3qqqqYtq0abFs2bLo379/jBw5MtatW/el9d5777349a9/HcOHD/867QUA2lt4uPfee+OKK66I8ePHx8knnxyzZs2KQw45JB555JFd1tm6dWtceumlMX369DjmmGO+bpsBgPYSHrZs2RJLly6NESNG/O8bdOxY7i9evHiX9W655Zbo2bNnXHbZZbt1nvr6+qirq2uyAQDtMDxs2LChHEXo1atXk+Npf82aNc3Wefnll+Phhx+O2bNn7/Z5qquro6KionGrrKzMaSYA0F5XW2zatCnGjBlTBocePXrsdr3JkyfHxo0bG7fVq1e3ZjMBgAydcwqnANCpU6dYu3Ztk+Npv3fv3juVf+edd8qJkqNGjWo8tm3btv8/cefOsXLlyjj22GN3qte1a9dyAwDa+chDly5dYuDAgbFw4cImYSDtDx06dKfyJ554Yrz++uuxfPnyxu3CCy+Mc889t/y72xEAsJ+PPCRpmea4ceNi0KBBMXjw4JgxY0Zs3ry5XH2RjB07Nvr27VvOW0jPgTjllFOa1D/ssMPKP3c8DgDsp+Fh9OjRsX79+pg6dWo5SXLAgAFRU1PTOImytra2XIEBAOyfOhRFUcQ+Li3VTKsu0uTJ7t277+3mAEC70RrXUEMEAEAW4QEAyCI8AABZhAcAIIvwAABkER4AgCzCAwCQRXgAALIIDwBAFuEBAMgiPAAAWYQHACCL8AAAZBEeAIAswgMAkEV4AACyCA8AQBbhAQDIIjwAAFmEBwAgi/AAAGQRHgCALMIDAJBFeAAAsggPAEAW4QEAyCI8AABZhAcAIIvwAABkER4AgCzCAwCQRXgAALIIDwBAFuEBAMgiPAAAWYQHACCL8AAAZBEeAIAswgMAkEV4AACyCA8AQBbhAQDIIjwAAFmEBwAgi/AAAGQRHgCALMIDAJBFeAAAsggPAEAW4QEAaP3wMHPmzOjXr19069YthgwZEkuWLNll2dmzZ8fw4cPj8MMPL7cRI0Z8aXkAYD8LD3Pnzo2qqqqYNm1aLFu2LPr37x8jR46MdevWNVt+0aJFcfHFF8eLL74YixcvjsrKyjjvvPPigw8+aIn2AwBtrENRFEVOhTTScOaZZ8Z9991X7m/btq0MBNdee21MmjTpK+tv3bq1HIFI9ceOHbtb56yrq4uKiorYuHFjdO/ePae5AHBAq2uFa2jWyMOWLVti6dKl5a2Hxm/QsWO5n0YVdscnn3wSn3/+eRxxxBH5rQUA9rrOOYU3bNhQjhz06tWryfG0v2LFit36HhMnTow+ffo0CSA7qq+vL7ftUxMAcACutrjzzjtjzpw5MW/evHKy5a5UV1eXQywNW7otAgC0w/DQo0eP6NSpU6xdu7bJ8bTfu3fvL6179913l+Hh+eefj9NOO+1Ly06ePLm8N9OwrV69OqeZAMC+Eh66dOkSAwcOjIULFzYeSxMm0/7QoUN3We+uu+6KW2+9NWpqamLQoEFfeZ6uXbuWkzq23wCAdjjnIUnLNMeNG1eGgMGDB8eMGTNi8+bNMX78+PLraQVF3759y1sPyW9/+9uYOnVqPP744+WzIdasWVMe/8Y3vlFuAMB+Hh5Gjx4d69evLwNBCgIDBgwoRxQaJlHW1taWKzAaPPDAA+UqjR//+MdNvk96TsTNN9/cEp8BANiXn/OwN3jOAwC00+c8AAAIDwBAFuEBAMgiPAAAWYQHACCL8AAAZBEeAIAswgMAkEV4AACyCA8AQBbhAQDIIjwAAFmEBwAgi/AAAGQRHgCALMIDAJBFeAAAsggPAEAW4QEAyCI8AABZhAcAIIvwAABkER4AgCzCAwCQRXgAALIIDwBAFuEBAMgiPAAAWYQHACCL8AAAZBEeAIAswgMAkEV4AACyCA8AQBbhAQDIIjwAAFmEBwAgi/AAAGQRHgCALMIDAJBFeAAAsggPAEAW4QEAyCI8AABZhAcAIIvwAABkER4AgCzCAwCQRXgAALIIDwBAFuEBAGj98DBz5szo169fdOvWLYYMGRJLliz50vJ//vOf48QTTyzLn3rqqbFgwYI9OS0A0B7Dw9y5c6OqqiqmTZsWy5Yti/79+8fIkSNj3bp1zZZ/5ZVX4uKLL47LLrssXnvttbjooovK7Y033miJ9gMAbaxDURRFToU00nDmmWfGfffdV+5v27YtKisr49prr41JkybtVH706NGxefPmePbZZxuPff/7348BAwbErFmzduucdXV1UVFRERs3bozu3bvnNBcADmh1rXAN7ZxTeMuWLbF06dKYPHly47GOHTvGiBEjYvHixc3WScfTSMX20kjF008/vcvz1NfXl1uD9IEbOgAA2H0N187MsYKWCw8bNmyIrVu3Rq9evZocT/srVqxots6aNWuaLZ+O70p1dXVMnz59p+NphAMAyPfvf/+7HIFo8/DQVtLIxvajFR9//HEcffTRUVtb22IfnK9OqimsrV692q2iNqLP254+b3v6vO2l0fujjjoqjjjiiBb7nlnhoUePHtGpU6dYu3Ztk+Npv3fv3s3WScdzyiddu3Yttx2l4OCHrW2l/tbnbUuftz193vb0edtL0wxa7HvlFO7SpUsMHDgwFi5c2HgsTZhM+0OHDm22Tjq+ffnkhRde2GV5AGDfln3bIt1OGDduXAwaNCgGDx4cM2bMKFdTjB8/vvz62LFjo2/fvuW8heS6666Lc845J+6555644IILYs6cOfHqq6/Ggw8+2PKfBgDY98JDWnq5fv36mDp1ajnpMS25rKmpaZwUmeYlbD80ctZZZ8Xjjz8eN954Y9xwww3x3e9+t1xpccopp+z2OdMtjPRcieZuZdA69Hnb0+dtT5+3PX2+f/R59nMeAIADm3dbAABZhAcAIIvwAABkER4AgPYZHrzme9/u89mzZ8fw4cPj8MMPL7f0PpOv+m/E1/85b5CWOHfo0KF8Iy2t2+fpibbXXHNNHHnkkeXs9OOPP97vl1bu87Tk/4QTToiDDz64fPrkhAkT4rPPPmuz9rZnL730UowaNSr69OlT/o74svdGNVi0aFGcccYZ5c/3cccdF48++mj+iYt9wJw5c4ouXboUjzzySPGPf/yjuOKKK4rDDjusWLt2bbPl//a3vxWdOnUq7rrrruKf//xnceONNxYHHXRQ8frrr7d529ur3D6/5JJLipkzZxavvfZa8eabbxY/+9nPioqKiuJf//pXm7f9QOnzBu+++27Rt2/fYvjw4cWPfvSjNmvvgdjn9fX1xaBBg4rzzz+/ePnll8u+X7RoUbF8+fI2b/uB0ud//OMfi65du5Z/pv5+7rnniiOPPLKYMGFCm7e9PVqwYEExZcqU4qmnnkorJ4t58+Z9aflVq1YVhxxySFFVVVVeP3//+9+X19Oampqs8+4T4WHw4MHFNddc07i/devWok+fPkV1dXWz5X/yk58UF1xwQZNjQ4YMKX7+85+3elv3F7l9vqMvvviiOPTQQ4vHHnusFVu5f9mTPk/9fNZZZxUPPfRQMW7cOOGhlfv8gQceKI455phiy5YtbdjKA7vPU9kf/OAHTY6lC9uwYcNava37m9iN8HD99dcX3/ve95ocGz16dDFy5Misc+312xYNr/lOw+A5r/nevnzDa753VZ6v3+c7+uSTT+Lzzz9v0Ret7M/2tM9vueWW6NmzZ1x22WVt1NIDu8+feeaZ8tH56bZFevBdepjdHXfcUb5NmNbp8/QgwVSn4dbGqlWryttE559/fpu1+0CyuIWun3v9rZpt9Zpvvl6f72jixInlPbYdfwhpuT5/+eWX4+GHH47ly5e3USv3L3vS5+nC9de//jUuvfTS8gL29ttvx9VXX10G5fSEPlq+zy+55JKy3tlnn51GwuOLL76Iq666qnwiMS1vV9fP9LbTTz/9tJx3sjv2+sgD7c+dd95ZTuCbN29eOSGKlrdp06YYM2ZMOVE1vc2WtpFe9JdGetK7d9JLANPj+KdMmRKzZs3a203bb6XJe2l05/77749ly5bFU089FfPnz49bb711bzeNfXnkoa1e883X6/MGd999dxke/vKXv8Rpp53Wyi09cPv8nXfeiffee6+cRb39hS3p3LlzrFy5Mo499tg2aPmB9XOeVlgcdNBBZb0GJ510UvmvtTQkn94sTMv2+U033VQG5csvv7zcT6vn0ssWr7zyyjK4teRrpIldXj/T69F3d9Qh2ev/Vbzmu330eXLXXXeV/xpIL0JLb1Wl9fo8LUN+/fXXy1sWDduFF14Y5557bvn3tJyNlv85HzZsWHmroiGoJW+99VYZKgSH1unzNH9qx4DQEN68eqnltdj1s9hHlvakpTqPPvpouXTkyiuvLJf2rFmzpvz6mDFjikmTJjVZqtm5c+fi7rvvLpcNTps2zVLNVu7zO++8s1x+9eSTTxYffvhh47Zp06a9+Cn27z7fkdUWrd/ntbW15SqiX/7yl8XKlSuLZ599tujZs2dx22237cVPsX/3efr9nfr8T3/6U7mM8Pnnny+OPfbYclUdXy39Dk5L6NOWLun33ntv+ff333+//Hrq69TnOy7V/M1vflNeP9MS/Ha7VDNJa02POuqo8gKVlvr8/e9/b/zaOeecU/7i3N4TTzxRHH/88WX5tOxk/vz5e6HV7VtOnx999NHlD+aOW/ofn9b7Od+e8NA2ff7KK6+US7/TBTAt27z99tvLJbO0Tp9//vnnxc0331wGhm7duhWVlZXF1VdfXfznP//ZS61vX1588cVmfzc39HH6M/X5jnUGDBhQ/vdJP+N/+MMfss/rldwAQJa9PucBAGhfhAcAIIvwAABkER4AgCzCAwCQRXgAALIIDwBAFuEBAMgiPAAAWYQHACCL8AAAZBEeAIDI8X9FHsEa3YYIFwAAAABJRU5ErkJggg=="
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 93
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
